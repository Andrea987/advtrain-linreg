{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea987/advtrain-linreg/blob/main/notebooks/fig1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Sgo-CifolM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ggDSA-ktpXgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065beb7b-8397-489a-a3d4-42bd0a5c17a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CLARABEL', 'CVXOPT', 'GLPK', 'GLPK_MI', 'HIGHS', 'OSQP', 'SCIPY', 'SCS']\n",
            "coef :  [ 1.99974237 -1.01212669 -0.01133473 -0.00225247]\n",
            "intercpt  -0.003824996916149618\n",
            "coef :  [ 1.99974237 -1.01212669 -0.01133473 -0.00225247]\n",
            "intercpt  -0.003824996916149618\n",
            "coef :  [ 1.9997191  -1.01211809 -0.01133743 -0.00224857]\n",
            "intercpt  -0.0038305705447095485\n",
            "coef :  [ 1.9997191  -1.01211809 -0.01133743 -0.00224857]\n",
            "intercpt  -0.0038305705447095485\n",
            "coef :  [ 1.99739528e+00 -1.01125873e+00 -1.16069312e-02 -1.85868964e-03]\n",
            "intercpt  -0.004387474372122001\n",
            "coef :  [ 1.99739528e+00 -1.01125873e+00 -1.16069312e-02 -1.85868964e-03]\n",
            "intercpt  -0.004387474372122001\n",
            "coef :  [ 1.97663305e+00 -1.00342380e+00 -1.39793933e-02  1.60496220e-03]\n",
            "intercpt  -0.00937956076587029\n",
            "coef :  [ 1.97663305e+00 -1.00342380e+00 -1.39793933e-02  1.60496220e-03]\n",
            "intercpt  -0.00937956076587029\n",
            "end block\n"
          ]
        }
      ],
      "source": [
        "from re import VERBOSE\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from sklearn.linear_model import lasso_path\n",
        "from sklearn import datasets\n",
        "from sklearn import linear_model\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import ridge_regression\n",
        "import tqdm\n",
        "import cvxpy as cp\n",
        "print(cp.installed_solvers())\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "import traceback\n",
        "\n",
        "\n",
        "def compute_q(p):\n",
        "    if p != np.inf and p > 1:\n",
        "        q = p / (p - 1)\n",
        "    elif p == 1:\n",
        "        q = np.inf\n",
        "    else:\n",
        "        q = 1\n",
        "    return q\n",
        "\n",
        "\n",
        "class AdversarialTraining:\n",
        "    def __init__(self, X, y, S_dict, p):  # S is the matrix such that ||S^(-1) @ Dx||\\leq delta. As a consequence, S appears in the unconstrained problem\n",
        "        # S: (d, d) matrix, or S = np.concatenate(tS), with tS = [S1,..,S_m], so S is (d * n, d)\n",
        "        n, d = X.shape\n",
        "        q = compute_q(p)\n",
        "\n",
        "        #print(\"who is X\", X)\n",
        "        #print(\"who is y\", y)\n",
        "        #print(\"who is S\", S)\n",
        "        #print(\"who is q in AdversarialTraining: \", q)\n",
        "        #Formulate problem\n",
        "        param = cp.Variable(d)\n",
        "        #print(\"shape param \", param.shape)\n",
        "        #print(\"dim \", n)\n",
        "        print(\"X \", n,\" \", d)\n",
        "        print(\"y shape\", y.shape)\n",
        "        #print(\"S_dict \", S_dict)\n",
        "        #print(\"S in adv training\", S)\n",
        "        print(\"nm \", d*n)\n",
        "        S_dts = S_dict['S_dts']\n",
        "        S_mis = S_dict['S_mis']\n",
        "        adv_radius_times_scale_dts = cp.Parameter(name='adv_radius_times_dts', nonneg=True)\n",
        "        adv_radius_times_scale_mis = cp.Parameter(name='adv_radius_times_mis', nonneg=True)\n",
        "        #scale_dts = cp.Parameter(name='scale_dts', nonneg=True)\n",
        "        #scale_mis = cp.Parameter(name='scale_mis', nonneg=True)\n",
        "        print(\"S_mis in Adbvt training \", S_mis)\n",
        "        #if np.sum(S_mis * S_mis) == 0:\n",
        "        if np.all(S_dict['S_mis'] == 0):\n",
        "          print(\"no missing part\")\n",
        "          S = S_dts * adv_radius_times_scale_dts\n",
        "        else:  # S_mis.shape == (n, d, d):\n",
        "          S_dts_tiled = np.concatenate([S_dts] * n)\n",
        "          S_mis_conc = np.concatenate(S_mis)\n",
        "          #np.concatenate([yyy] * 2)\n",
        "          S = S_dts_tiled * adv_radius_times_scale_dts + S_mis_conc * adv_radius_times_scale_mis\n",
        "          print(\"S type \", type(S))\n",
        "          #S = np.concatenate(S)\n",
        "          print(\"S is a tensor, concatenated\")\n",
        "          print(\"final S after conc \\n\", S)\n",
        "\n",
        "        if S.shape == (d, d):\n",
        "          print(\"one matrix in input, S.shape = (n, n)\")\n",
        "          partial = S @ param  # should be (m * n,)\n",
        "          param_norm = cp.pnorm(partial, p=q)\n",
        "        elif S.shape == (d * n, d):  # should be a stack of matrices\n",
        "          print(\"multiple matrices in input, S conc\")\n",
        "          partial = S @ param  # should be (m * n,)\n",
        "          partial = cp.reshape(partial, (n, d), order='C')\n",
        "          param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        else:\n",
        "          print(\"--------> ERROR: NO MATRIX S FOUND IN ADVERSARIAL TRAINING\")\n",
        "        #elif S.shape == (m , n):  # stack of diagonal matrices\n",
        "        #  print(\"multiple matrices in input, S_i diag\")\n",
        "          #S_cvx = cp.Constant(S)\n",
        "        #  partial = cp.multiply(cp.Parameter(S), param)\n",
        "        #  param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        abs_error = cp.abs(X @ param - y)\n",
        "        adv_loss = 1 / n * cp.sum((abs_error + param_norm) ** 2)\n",
        "        prob = cp.Problem(cp.Minimize(adv_loss))\n",
        "        self.prob = prob\n",
        "        self.adv_radius_times_scale_dts = adv_radius_times_scale_dts\n",
        "        self.adv_radius_times_scale_mis = adv_radius_times_scale_mis\n",
        "        #self.scale_dts = scale_dts\n",
        "        #self.scale_mis = scale_mis\n",
        "        self.param = param\n",
        "        self.warm_start = False\n",
        "\n",
        "\n",
        "    def __call__(self, dict_hyper_p, **kwargs):\n",
        "        try:\n",
        "            #print(\"dic thyper p \", dict_hyper_p)\n",
        "            self.adv_radius_times_scale_dts.value = dict_hyper_p['adv_radius_times_dts']\n",
        "            self.adv_radius_times_scale_mis.value = dict_hyper_p['adv_radius_times_mis']\n",
        "            #self.scale_dts.value = dict_hyper_p['scale_dts\n",
        "            #self.scale_mis.value = dict_hyper_p['scale_mis']\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "\n",
        "'''\n",
        "    def __call__(self, adv_radius, **kwargs):\n",
        "        try:\n",
        "            self.adv_radius.value = adv_radius\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "'''\n",
        "\n",
        "\n",
        "def get_lasso_path(X, y, eps_lasso=1e-5):\n",
        "    alphas, coefs, _ = lasso_path(X, y, eps=eps_lasso)\n",
        "    coefs= np.concatenate([np.zeros([X.shape[1], 1]), coefs], axis=1)\n",
        "    alphas = np.concatenate([1e2 * np.ones([1]), alphas], axis=0)\n",
        "    return alphas, coefs, []\n",
        "\n",
        "# dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4 'eps_adv_rad_times_delta_dts': 1e-4}}\n",
        "def get_path(X, y, estimator, S_dict): #eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "    _, m = X.shape\n",
        "\n",
        "    if S_dict['algo_superv_learn'] == 'adv':\n",
        "      n_a_dts = S_dict['n_a_dts']\n",
        "      a_d_dts_max = S_dict['adv_rad_times_delta_dts_max']\n",
        "      a_d_dts_min = a_d_dts_max * S_dict['eps_adv_rad_times_delta_dts']\n",
        "      if np.all(S_dict['S_mis'] == 0):\n",
        "        n_a_mis, a_d_mis_max, a_d_mis_min = 1, 0, 0\n",
        "      else:\n",
        "        n_a_mis = S_dict['n_a_mis']\n",
        "        a_d_mis_max = S_dict['adv_rad_times_delta_mis_max']\n",
        "        a_d_mis_min = a_d_mis_max * S_dict['eps_adv_rad_times_delta_mis']\n",
        "\n",
        "\n",
        "      if a_d_dts_max < 0 or a_d_mis_max < 0 or n_a_dts < 1 or n_a_mis <1:\n",
        "        print(\"WARNING: some bad values for the grid of cross validation, the number of grid point should be strictly potive, the radius strictly positive\")\n",
        "      alphas_dts = np.logspace(np.log10(a_d_dts_min), np.log10(a_d_dts_max), n_a_dts) if a_d_dts_max > 0 else np.zeros(1)\n",
        "      alphas_mis = np.logspace(np.log10(a_d_mis_min), np.log10(a_d_mis_max), n_a_mis) if a_d_mis_max > 0 else np.zeros(1)\n",
        "      #alphas_dts = np.logspace(np.log10(a_d_dts_min), np.log10(a_d_dts_max), n_a_dts)\n",
        "      #alphas_mis = np.logspace(np.log10(a_d_mis_min), np.log10(a_d_mis_max), n_a_mis)\n",
        "      print(\"dts deltas \", alphas_dts)\n",
        "      print(\"mis deltas \", alphas_mis)\n",
        "      #hyper_p = {'scale_dts': dts_deltas, 'scale_mis': mis_deltas}\n",
        "      hyper_p_ret_ = []\n",
        "      coefs_ = []\n",
        "      for a_mis_value in tqdm.tqdm(alphas_mis):\n",
        "        for a_dts_value in tqdm.tqdm(alphas_dts):\n",
        "            #tuple_key = (scale_dts_value, scale_mis_value)\n",
        "            #coefs_ = []\n",
        "            #for a in tqdm.tqdm(alphas):\n",
        "              #dict_hyper_p_values = {'adv_radius': a, 'scale_dts': scale_dts_value, 'scale_mis': scale_mis_value}\n",
        "              dict_hyper_p_values = {'adv_radius_times_dts': a_dts_value, 'adv_radius_times_mis': a_mis_value}\n",
        "              #print(\"dict hyper in get path \", dict_hyper_p_values)\n",
        "              coefs = estimator(X, y, dict_hyper_p_values)\n",
        "              #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "              coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "              hyper_p_ret_.append([a_dts_value, a_mis_value])\n",
        "            #res[tuple_key] = np.stack((coefs_)).T\n",
        "    elif S_dict['algo_superv_learn'] == 'ridge':\n",
        "      n_a_rid = S_dict['n_a_rid']\n",
        "      a_rid_max = S_dict['alpha_ridge_reg_max']\n",
        "      a_rid_min = a_rid_max * S_dict['eps_alpha_ridge_reg']\n",
        "      alphas_rid = np.logspace(np.log10(a_rid_min), np.log10(a_rid_max), n_a_rid) if a_rid_max > 0 else np.zeros(1)\n",
        "      print(\"rid alphas \", alphas_rid)\n",
        "      hyper_p_ret_ = []\n",
        "      coefs_ = []\n",
        "      print(\"S_dts_inv in get path, ridge regression \\n\", S_dict['S_dts'])\n",
        "      S_dts_inv = np.linalg.inv(S_dict['S_dts'])  # (d, d)\n",
        "      print(\"S_dts_inv in get path, ridge regression \\n\", S_dts_inv)\n",
        "      for a_rid in tqdm.tqdm(alphas_rid):\n",
        "            #dict_hyper_p_values = {'adv_radius_times_dts': a_dts_value, 'adv_radius_times_mis': a_mis_value}\n",
        "            #print(\"dict hyper in get path \", dict_hyper_p_values)\n",
        "            coefs = estimator(X @ S_dts_inv, y, a_rid)\n",
        "            coefs = S_dts_inv @ coefs\n",
        "            #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "            coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "            hyper_p_ret_.append([a_rid, a_rid])  #([a_dts_value, a_mis_value])\n",
        "\n",
        "\n",
        "    '''\n",
        "    for scale_dts_value in tqdm.tqdm(dts_deltas):\n",
        "        for scale_mis_value in tqdm.tqdm(mis_deltas):\n",
        "          #tuple_key = (scale_dts_value, scale_mis_value)\n",
        "          #coefs_ = []\n",
        "          for a in tqdm.tqdm(alphas):\n",
        "              #dict_hyper_p_values = {'adv_radius': a, 'scale_dts': scale_dts_value, 'scale_mis': scale_mis_value}\n",
        "              dict_hyper_p_values = {'adv_radius_times_scale_dts': a * scale_dts_value, 'adv_radius_times_scale_mis': a * scale_mis_value}\n",
        "              coefs = estimator(X, y, dict_hyper_p_values)\n",
        "              #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "              coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "              hyper_p_ret_.append([a, scale_dts_value, scale_mis_value])\n",
        "          #res[tuple_key] = np.stack((coefs_)).T\n",
        "    '''\n",
        "    return np.stack((hyper_p_ret_)).T, np.stack((coefs_)).T\n",
        "\n",
        "#dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg': 1,\n",
        "#                             'eps_adv_rad_times_delta_dts': 1e-4, 'eps_adv_rad_times_delta_mis': 1e-4, 'eps_alpha_ridge_reg': 1e-4,\n",
        "#                             'n_a_dts': 25, 'n_a_mis':4, 'n_a_rid': 25}}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "def get_path(X, y, estimator, amax, eps=1e-5, n_alphas=200):\n",
        "    _, m = X.shape\n",
        "    amin = eps * amax\n",
        "    alphas = np.logspace(np.log10(amin), np.log10(amax), n_alphas)\n",
        "    coefs_ = []\n",
        "    for a in tqdm.tqdm(alphas):\n",
        "        coefs = estimator(X, y, a)\n",
        "        #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "        coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "    return alphas, np.stack((coefs_)).T\n",
        "'''\n",
        "\n",
        "\n",
        "def plot_coefs(alphas, coefs, ax):\n",
        "    #print(\"you are printing coefs in function of 1/alphas\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).sum(axis=0)\n",
        "    ax.set_xlabel(\"1/alphas\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.semilogx(1/alphas, coef_l, c=c)\n",
        "        #ax.semilogx(1/alphas, l1norm, c=c)\n",
        "        #ax.plot(1/alphas, coef_l, c=c)\n",
        "\n",
        "\n",
        "def plot_coefs_l1norm(coefs, ax):\n",
        "    #print(\"you are printing coeff in function of l1 norm\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).mean(axis=0)\n",
        "    l1norm = np.abs(coefs).sum(axis=0)\n",
        "    #print(\"coef \", coefs)\n",
        "    #print(\"l1norm \", l1norm)\n",
        "    ax.set_xlabel(\"l1norm\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "\n",
        "\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.plot(l1norm, coef_l, c=c)\n",
        "\n",
        "\n",
        "def train_and_plot(X, y, S_dict, list_ax):\n",
        "\n",
        "    if S_dict['algo_superv_learn'] == 'adv':\n",
        "      linfadvtrain = AdversarialTraining(X, y, S_dict, p=np.inf)\n",
        "      estimator = lambda X, y, dic_h:  linfadvtrain(dict_hyper_p=dic_h)\n",
        "      hyper_p, coefs_advtrain_linf  = get_path(X, y, estimator, S_dict)\n",
        "    elif S_dict['algo_superv_learn'] == 'ridge':\n",
        "      estimator = lambda XX, yy, rad: ridge_regression(XX, yy, alpha=rad, return_intercept=False)#, random_state=0)\n",
        "      hyper_p, coefs_advtrain_linf  = get_path(X, y, estimator, S_dict)\n",
        "      #estimator = lambda X, y, a: linear_model.Ridge(alpha=a).fit(X, y).coef_\n",
        "    #print(\"hyper_p used\\n \", hyper_p)\n",
        "    if len(list_ax) > 0:\n",
        "      plot_coefs_l1norm(coefs_advtrain_linf, list_ax[0])\n",
        "      plot_coefs(alphas_adv, coefs_advtrain_linf, list_ax[1])\n",
        "    return hyper_p, coefs_advtrain_linf\n",
        "\n",
        "\n",
        "X = np.random.randn(100, 4) #rng.randn(100, 4)\n",
        "\n",
        "y = 2.0 * X[:, 0] - 1.0 * X[:, 1] + 0.1 * np.random.randn(100)\n",
        "\n",
        "alphas = [0.00001, 0.001, 0.1, 1]\n",
        "estim = lambda XX, yy, rad: ridge_regression(XX, yy, alpha=rad, return_intercept=True, random_state=0)\n",
        "for a in alphas:\n",
        "  coef, intercept = estim(X, y, a)\n",
        "  print(\"coef : \", coef)\n",
        "  print(\"intercpt \", intercept)\n",
        "  coef, intercept = ridge_regression(X, y, alpha=a, return_intercept=True, random_state=0)\n",
        "  print(\"coef : \", coef)\n",
        "  print(\"intercpt \", intercept)\n",
        "\n",
        "\n",
        "'''\n",
        "def add_rectangles_old(x, y, box_width, box_height, ax):\n",
        "  r_c = (np.random.binomial(1, 1, size=x.size) == 1)  # 1 taken, 0 not taken\n",
        "  #print(r_c)\n",
        "\n",
        "  for xi, yi in zip(x[r_c], y[r_c]):\n",
        "      rect = patches.Rectangle(\n",
        "        (xi-box_width/2, yi-box_height/2),\n",
        "        box_width, box_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "      )\n",
        "      ax.add_patch(rect)\n",
        "'''\n",
        "\n",
        "def add_rectangles(x, y, S, ax):\n",
        "  r_c = (np.random.binomial(1, 1, size=x.size) == 1)  # 1 taken, 0 not taken\n",
        "  #print(r_c)\n",
        "  d = S.shape[-1]\n",
        "  #S = S * 100\n",
        "  if S.ndim == 2 or S.shape == (1, d, d):\n",
        "    S = S.squeeze()\n",
        "    print(\"------------------------> who is S in add_rectangles\\n\", S)\n",
        "    box_width = S[0, 0]\n",
        "    box_height = S[1, 1]\n",
        "    for xi, yi in zip(x[r_c], y[r_c]):\n",
        "        rect = patches.Rectangle(\n",
        "          (xi-box_width/2, yi-box_height/2),\n",
        "          box_width, box_height,\n",
        "          linewidth=1, edgecolor='r', facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "  else:  # S is something like (n, d, d)\n",
        "    #print(\"---------------> who is S in add_rectangles (mult imp)\\n\", S)\n",
        "    box_width = S[:, 0, 0]\n",
        "    box_height = S[:, 1, 1]\n",
        "    #print(\"bw\\n \", box_width)\n",
        "    #print(\"bh\\n \", box_height)\n",
        "    #print(\"------------------------------> boxes printed\")\n",
        "    for xi, yi, bw, bh in zip(x[r_c], y[r_c], box_width[r_c], box_height[r_c]):\n",
        "        #print(\"bw, bh \", bw, \",   \", bh)\n",
        "        rect = patches.Rectangle(\n",
        "          (xi-bw/2, yi-bh/2),\n",
        "          bw, bh, linewidth=1, edgecolor='r', facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "\n",
        "\n",
        "print(\"end block\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation's block\n",
        "\n",
        "def clear_dataset(X, y, masks):\n",
        "  # remove observations full NaN\n",
        "  # X is an (n, d) matrix, y is a (n,) vector,\n",
        "  # masks is an (n, d) binary matrix associated to X. 1 missing, 0 seen\n",
        "  M = np.sum(1 - masks, axis=1) > 0\n",
        "  print(\"X shape in clear data \", X.shape)\n",
        "  print(\"y shape in clear data \", y.shape)\n",
        "  print(\"M shape in clear data \", M.shape)\n",
        "  M_col = np.sum(1 - masks, axis=0) > 0  # True if in the column there is at least one seen component\n",
        "  if np.sum(M_col) < masks.shape[1]:\n",
        "    print(\"Careful, there is one column full of nan\")\n",
        "  return X[M, :][:, M_col], y[M], masks[M, :][:, M_col]\n",
        "\n",
        "\n",
        "def single_imputation(X_nan, impute_estimator):\n",
        "    ice = IterativeImputer(estimator=impute_estimator)\n",
        "    return ice.fit_transform(X_nan)\n",
        "\n",
        "\n",
        "def multiple_imputation(nbr_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 100000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res shape\", res.shape)\n",
        "       #if nbr_mi == 1:\n",
        "        #res = res[0, :, :]\n",
        "        #print(\"fin res shape\", res.shape)\n",
        "    return res\n",
        "\n",
        "\n",
        "def imputation_elliptic(mu, sigma, x, masks):\n",
        "  # mu, mean elliptical distribution (,d)\n",
        "  # sigma, cov matrix elliptical distribution (d, d)\n",
        "  # x: dataset (n, d)\n",
        "  # masks: mask data, 0 seen, 1 missing\n",
        "  n, d = x.shape\n",
        "  print(n, d)\n",
        "  x_imp = x.copy()\n",
        "  #print(\"x_imp clean\", x_imp)\n",
        "  for i in range(n):\n",
        "    if not (masks[i, :] == 0).all():  # if we have at least one missing component\n",
        "      #print(\"nbr : \", i)\n",
        "      x_c = x[i, :]\n",
        "      m_bool = (masks[i, :] == 0)  # True seen, False missing\n",
        "      sigma_aa_inv = np.linalg.inv(sigma[m_bool, :][:, m_bool])\n",
        "      sigma_ma = sigma[~m_bool, :][:, m_bool]\n",
        "      mu_cond = mu[~m_bool] + sigma_ma @ sigma_aa_inv @ (x_c[m_bool] - mu[m_bool])\n",
        "      x_imp[i, ~m_bool] = mu_cond\n",
        "  return x_imp\n",
        "\n",
        "\n",
        "def listwise_delection(X, masks):\n",
        "  # masks: 1 missing, 0 seen\n",
        "    M = np.sum(masks, axis=1) == 0  # zeros components are the one with full entries\n",
        "    ret = X[M, :] if X.ndim == 2 else X[M]\n",
        "    return ret\n"
      ],
      "metadata": {
        "id": "qyWskXpdOW9e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ElCvHxBiO_2t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZA7J67yAuQM8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(42)\n",
        "\n",
        "#p_miss_2d = [0.2, 0.4, 0.4]\n",
        "#beta_2d = np.array([0.5, 2])  # ground truth\n",
        "\n",
        "from sklearn.datasets import make_moons, make_circles\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import train_test_split\n",
        "'''\n",
        "def generate_masks_2d(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "'''\n",
        "\n",
        "def generate_masks(dictio_data):#nbr_of_sample, dim, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    dim = len(dictio_data['beta_gt'][0])\n",
        "    nbr_of_sample = dictio_data['n_train'][-1]  # last one should be the biggest one\n",
        "    p_missing = dictio_data['p_miss'][0]\n",
        "    print(\"p_missing in generate mask \", p_missing)\n",
        "    if dim == 2:\n",
        "      if len(p_missing) < 3:\n",
        "        print(\"WARNING: p_missing should be a list with a length of 3 if the dimension is 2\")\n",
        "      masks = np.zeros((nbr_of_sample, 2))\n",
        "      v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "      masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "      masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "      masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    else:\n",
        "      # in this branch, p_missing = [p1,.., pl],\n",
        "      masks = np.array([np.random.binomial(1, 1-pr, (nbr_of_sample, dim)) for pr in p_missing])\n",
        "      masks = np.cumsum(masks, axis=0)  # each round\n",
        "      masks[masks>1] = 1\n",
        "    return masks\n",
        "\n",
        "def best_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  r = hat_y - y  # residual\n",
        "  score = np.mean(r * r, axis=1)\n",
        "  print(\"scores:  \", score)\n",
        "  i_min = np.argmin(score)\n",
        "  return coeff[:, i_min], score[i_min]\n",
        "\n",
        "def best_idx_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  r = hat_y - y  # residual\n",
        "  #score = np.mean(r * r, axis=1)\n",
        "  score = np.mean(r * r, axis=1)\n",
        "  #print(\"score in best idx\", score)\n",
        "  i_min = np.argmin(score)\n",
        "  #### find the minimum value with a threshold, so we get bigger uncertainty set that are visible\n",
        "  min = np.min(score)\n",
        "  max = np.max(score)\n",
        "  score[ score < min + -1 ] = max\n",
        "  ####\n",
        "  #print(\"score after \", score)\n",
        "  i_min = np.argmin(score)\n",
        "  return i_min, score[i_min]\n",
        "\n",
        "\n",
        "\n",
        "def generate_X(data, dim):\n",
        "    if data == 'Gaussian':\n",
        "      def generator(n):\n",
        "        return np.random.randn(n, dim)\n",
        "    elif data == 'Uniform':\n",
        "      def generator(n):\n",
        "        return np.random.rand(n, dim)\n",
        "    elif data == 'moons':\n",
        "      def generator(n):\n",
        "        return make_moons(n, noise=0.1)[0]\n",
        "    elif data == 'circles':\n",
        "      def generator(n):\n",
        "        return make_circles(n, noise=0.1, factor=0.4)[0]\n",
        "    return generator\n"
      ],
      "metadata": {
        "id": "AN61ok0A_Mbv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jB0J9uh-dJBp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwSkM31ztfUZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment 2d with dataset generated externally\n",
        "\n",
        "def imputations(info, dict_obs_for_imp):  # X_nan, y):\n",
        "  # info contains the method and possible extra information\n",
        "  # X_nan is the dataset with nan in place of the missing components\n",
        "  # y is return as it is, unless the method require to change it, like in\n",
        "  # listwise deletion\n",
        "    #print(info)\n",
        "    X_nan = dict_obs_for_imp['X_nan']\n",
        "    y = dict_obs_for_imp['y_train']\n",
        "    mask_from_X_nan = np.isnan(X_nan).astype(int)\n",
        "    if info['imp_method'] == 'BR_si':  # Baeysian_Ridge_single_imputation\n",
        "        X = single_imputation(X_nan, BayesianRidge())\n",
        "    elif info['imp_method'] in  ['mi', 'mi_pure']:\n",
        "        X = multiple_imputation(info['mi_nbr'], X_nan)  # size (info['mi_nbr], n, d)\n",
        "    elif info['imp_method'] == 'l_d':  # listwise_deletion\n",
        "        #mask_from_X_nan = np.isnan(X_nan).astype(int)\n",
        "        X = listwise_delection(X_nan, mask_from_X_nan)\n",
        "        y = listwise_delection(y, mask_from_X_nan)\n",
        "        if len(X) == 0:  # no elements left, add an artificial element\n",
        "            X = np.zeros((1, X_nan.shape[-1]))\n",
        "            y = np.zeros(1)\n",
        "        mask_from_X_nan = np.zeros_like(X)\n",
        "    elif info['imp_method'] == 'oracle':\n",
        "        X = dict_obs_for_imp['X_train_masked'][0]\n",
        "        mask_from_X_nan = np.zeros_like(X)\n",
        "    else:\n",
        "      print(\"-------------------> ERROR: WRONG KEYWORD (in imputations)\")\n",
        "    return X, y, mask_from_X_nan\n",
        "\n",
        "\n",
        "def cov_strategy(info, dict_observations):\n",
        "    X_imputed = dict_observations['X_imputed']\n",
        "    X_nan = dict_observations['X_nan']\n",
        "    masks = dict_observations['masks_after_imputation']\n",
        "    print(np.sum(masks, axis=-1))\n",
        "    if info['cov_strategy'] == 'sd':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      #print(\"sd in cov strategy \", sd)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(sd)\n",
        "    elif info['cov_strategy'] == 'inv_sd':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(1 / sd)\n",
        "    elif info['cov_strategy'] == 'zero':\n",
        "      #sd = np.std(X_imputed, axis=0)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.zeros((X_imputed.shape[-1], X_imputed.shape[-1]))\n",
        "    elif info['cov_strategy'] == 'eye':\n",
        "      S = np.eye(X_imputed.shape[-1])\n",
        "    elif info['cov_strategy'] == 'threshold':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      sd[sd < info['threshold']] = info['threshold']\n",
        "      #S = np.diag(sd) The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(sd)\n",
        "    elif info['cov_strategy'] == 'std_nan':\n",
        "      if info['imp_method'] in ['oracle']:\n",
        "        print(\"DON'T USE std_nan with oracle and ld because you do not have any nan. Use sd\")\n",
        "      else:\n",
        "        std_columnwise = np.nanstd(X_nan, axis=0)\n",
        "        S = np.diag(std_columnwise)\n",
        "    elif info['imp_method'] in ['mi_pure', 'mi']:\n",
        "      if info['cov_strategy'] == 'std_mi':   # std of the imputed dataset, then the mean\n",
        "        std_vectors = np.std(X_imputed, axis=-2)  # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        #s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        S = std_vectors[:, None, :] * np.eye(std_vectors.shape[-1])  # should be (m, d, d), with each diagonal the diagonals of std_vectors\n",
        "        #S = s_within\n",
        "        #S = np.diag(s_within)\n",
        "        print(\"final S.shape in cov strategy std_mi \", S.shape)\n",
        "      elif info['cov_strategy'] == 'RR':\n",
        "        #if info['mi_nbr'] == 1:\n",
        "        #  X_imputed = np.array([X_imputed])\n",
        "        # X shape = (m, n, d)\n",
        "        std_vectors = np.std(X_imputed, axis=-2)  # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        print(\"s_within \", s_within)\n",
        "        print(\"cov computed\")\n",
        "        #print(s_mean)\n",
        "        s_between = np.std(std_vectors, axis=0) # between imputation variance  # shape: d. That's already scaled because we are computing the std\n",
        "        print(\"s_between \", s_between)\n",
        "        S = np.diag(s_within + s_between * (1 + 1 / info['mi_nbr']))\n",
        "        print(\"final S in cov strategy RR \", S)\n",
        "        #mu = np.mean(X_imputed, axis=0)\n",
        "        #sigma = np.cov(X_imputed, rowvar=False)\n",
        "      elif info['cov_strategy'] == 'RR_scaled (to check)':\n",
        "        print(\"Rub Rule right scaled\")\n",
        "        #if info['mi_nbr'] == 1:\n",
        "        #  X_imputed = np.array([X_imputed])\n",
        "        # X shape = (m, n, d)\n",
        "        std_vectors = np.std(X_imputed, axis=-2) # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        print(\"s_within \", s_within)\n",
        "        print(\"cov computed\")\n",
        "        #print(s_mean)\n",
        "        s_between = np.std(std_vectors, axis=0) # between imputation variance  # shape: d\n",
        "        #s_between = np.sqrt(s_between)\n",
        "        print(\"s_between \", s_between)\n",
        "        S = np.diag(s_within + s_between * (1 + 1 / info['mi_nbr']))\n",
        "        #S = np.sqrt(S)\n",
        "        print(\"final S in cov strategy RR \", S)\n",
        "      #elif info['cov_strategy'] == 'cond_var':\n",
        "        # we have imputed [X1,..,X_m]\n",
        "        #s = np.std(X_imputed, axis=0)\n",
        "        #print(\"s\\n \", s)\n",
        "        #eye = np.array([np.eye(X_imputed.shape[-1])] * X_imputed.shape[-2])\n",
        "        #S = eye * s[:, None, :]\n",
        "        #S = np.concatenate(S, axis=0)\n",
        "        #print(\"S in cond variance \", S)\n",
        "    elif info['cov_strategy'] == 'lounici':\n",
        "      mu = np.nanmean(X_nan, axis=0)\n",
        "      print(\"means \", mu)\n",
        "      delta = 1 - np.mean(masks) # parameter missingness\n",
        "      print(\"delta \", delta)\n",
        "      X_0 = np.nan_to_num(X_nan - mu)  # check if this is correct\n",
        "      print(\"nbr obs\", X_0.shape[0])\n",
        "      S =  X_0.T @ X_0 / X_0.shape[0]\n",
        "      S = (1/delta - 1/(delta**2)) * np.diag(np.diag(S)) + 1/(delta**2) * S\n",
        "    else:\n",
        "      raise ValueError(\"-------------> ERROR: NO COVARIANCE METHOD HAS BEEN CHOSEN\")\n",
        "      #print(\"-------------> ERROR: NO COVARIANCE METHOD HAS BEEN CHOSEN\")\n",
        "      #S = np.diag(S)\n",
        "      #mu = np.mean(X_imputed, axis=0)\n",
        "      #sigma = np.cov(X_imputed, rowvar=False)\n",
        "    return S\n",
        "\n",
        "\n",
        "def cov_strategy_missing(info, dict_observations):\n",
        "    # undertainty that come from the imputed part. It is zero\n",
        "    X_imputed = dict_observations['X_imputed']\n",
        "    if info['imp_method'] in ['mi', 'mi_pure'] and 'cov_strategy_between' in info.keys():\n",
        "      m, n, d = X_imputed.shape\n",
        "      if info['cov_strategy_between'] == 'cond_var':\n",
        "        # we have imputed [X1,..,X_m], so shape (m, n, d)\n",
        "        s = np.std(X_imputed, axis=0)\n",
        "        s[s<1e-14] = 0  # set to zero values that are basically zero\n",
        "        #print(\"var \", s)\n",
        "        eye = np.array([np.eye(X_imputed.shape[-1])] * X_imputed.shape[-2])\n",
        "        S_mis = eye * s[:, None, :]\n",
        "        if info['post_imp'] == 'conc':\n",
        "          S_mis = np.tile(S_mis, (m, 1, 1))\n",
        "    else:  # not using a mi method, so uncertainty on missing part should be zero\n",
        "      print(\"shape oject in cov strategy missing \", dict_observations['X_test'].shape[-1])\n",
        "      print(\"shape oject in cov strategy missing \", dict_observations['X_test'].shape)\n",
        "      d = dict_observations['X_test'].shape[-1]\n",
        "      S_mis = np.zeros((d, d))\n",
        "    return S_mis\n",
        "\n",
        "\n",
        "def post_imputation(info_imp, dict_dataset):\n",
        "  # X_imptued should be a matrix (n, d) or tensor (m, d, n) (in multiple imputations methods)\n",
        "    X_imputed = dict_dataset['X_imputed']\n",
        "    y_train = dict_dataset['y_from_X_imputed']\n",
        "    #print(\"info imp in post_imp\", info_imp)\n",
        "    print(\"shape X_imputed in post_imputation \", X_imputed.shape)\n",
        "    mask_train = dict_dataset['masks_after_imputation']\n",
        "    if 'post_imp' not in info_imp.keys():\n",
        "      X_train = X_imputed\n",
        "    elif info_imp['post_imp'] == 'mean':\n",
        "      #print(\"entered in pst_iputation, in mi_mean\")\n",
        "      X_train = np.mean(X_imputed, axis=0)\n",
        "    elif info_imp['post_imp'] == 'conc':\n",
        "      print(\"shape X_imputed \", X_imputed.shape)\n",
        "      X_train = np.concatenate(X_imputed)\n",
        "      y_train = np.tile(y_train, X_imputed.shape[0])\n",
        "    else:\n",
        "      X_train = X_imputed\n",
        "    return X_train, y_train, mask_train\n",
        "\n",
        "\n",
        "def generate_dataset(data, n_tot, dim, beta_gt, perc_test, p_miss, err):\n",
        "    print(data)\n",
        "    if data['data'] == 'Gaussian':\n",
        "      X_complete = np.random.randn(n_tot, dim)\n",
        "    elif data['data'] == 'Normal':\n",
        "      #print(\"you are here\")\n",
        "      if len(beta_gt) != len(data['mean']) or len(beta_gt) != data['cov'].shape[0]:\n",
        "        print(\"ERROR: DIMENSION MISSMATCH\")\n",
        "      X_complete = np.random.multivariate_normal(mean=data['mean'], cov=data['cov'], size=n_tot)\n",
        "    elif data['data'] == 'LogNormal':\n",
        "      if len(beta_gt) != len(data['mean']) or len(beta_gt) != data['cov'].shape[0]:\n",
        "        print(\"ERROR: DIMENSION MISSMATCH\")\n",
        "      X_complete = np.random.lognormal(mean=data['mean'], sigma=data['cov'], size=n_tot)\n",
        "    elif data['data'] == 'Uniform':\n",
        "      X_complete = np.random.rand(n_tot, dim) -0.5\n",
        "    elif data['data'] == 'Logistic':\n",
        "      X_complete = np.random.logistic(loc=0.0, scale=1.0, size=(n_tot, dim))\n",
        "    elif data['data'] == 'moons':\n",
        "      X_complete = make_moons(n_tot, noise=0.1)[0]\n",
        "    elif data['data'] == 'circles':\n",
        "      X_complete = make_circles(n_tot, noise=0.1, factor=0.4)[0]\n",
        "\n",
        "    if err['type'] == 'Gaussian_on_y':\n",
        "      #print(\"---> you have entered in GAUSSIAN ERROR \", \"scaling : \", err['scaling'])\n",
        "      error = np.random.randn(n_tot) * err['scaling']\n",
        "    elif err['type'] == 'Uniform_on_y':\n",
        "      error = (np.random.rand(n_tot)-0.5) * err['scaling']\n",
        "    elif err['type'] == 'Gaussian_on_X':\n",
        "      error = (np.random.randn(n_tot, dim) @ beta_gt) * err['scaling']  # error is of the form DX@beta_gt + error\n",
        "    elif err['type'] == 'Uniform_on_X':\n",
        "      error = ((np.random.rand(n_tot, dim)-0.5) @ beta_gt) * err['scaling']\n",
        "    #elif err['type'] == 'Gaussian':\n",
        "    #  error = np.random.randn(n_tot) * err['scaling']\n",
        "\n",
        "    print(X_complete.shape)\n",
        "\n",
        "    y_complete = X_complete @ beta_gt + error  #np.random.randn(n_tot) * err  # (np.random.rand(n_tot) - 0.5) * err\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_complete, y_complete, test_size=perc_test)\n",
        "    n_train = X_train.shape[0]\n",
        "    # masks_train = generate_masks_2d(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    # masks_train = generate_masks_binomial(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    #X_train, y_train, masks_train = clear_dataset(X_train, y_train, masks_train)\n",
        "    # M = np.sum(masks, axis=1)  # M[i] > 0 iff i has missing component\n",
        "    # dict_obs = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test, 'masks_train': masks_train}\n",
        "    dict_obs = {'X_train_masked': (X_train, []), 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}#, 'masks_train': masks_train}\n",
        "    return dict_obs\n",
        "\n",
        "\n",
        "def experiment_2d_ext_dataset(dict_obs, dict_imp, ax):\n",
        "    # dict_obs contains info on the observations, i.e. train, test, masks\n",
        "    # dict_imp contains info on the imputation an covariance methods used,\n",
        "    # dict_imp = {'imp_method': , 'cov_strategy': , .... }\n",
        "    # ax contains info for the plots\n",
        "\n",
        "    X_test = dict_obs['X_test']\n",
        "    y_test = dict_obs['y_test']\n",
        "    mask = dict_obs['X_train_masked'][1]\n",
        "\n",
        "    M = np.sum(mask, axis=1)  # M[i] > 0 iff i has missing component\n",
        "\n",
        "    X_nan_train = dict_obs['X_train_masked'][0].copy()\n",
        "    oracle_sd = np.std(X_nan_train, axis=0)\n",
        "    print(\"-------> ORACLE SD, std of the original dataset (with no missing)\", oracle_sd)\n",
        "    X_nan_train[mask == 1] = np.nan\n",
        "    #print(\"dict imp -----> \", dict_imp)\n",
        "    dict_obs = dict_obs | {'X_nan': X_nan_train} #, 'y_from_X_imputed': y_from_X_imputed, 'masks_after_imputation': mask_from_X_imputed}\n",
        "    if len(dict_obs['imp_ds'][dict_imp['imp_method']]) == 0:  # no previous imputation has been done\n",
        "      #results = imputations(dict_imp, X_nan_train, dict_obs['y_train'])\n",
        "      print(\"NO PREVIOUS IMPUTATION HAS BEEN DONE\")\n",
        "      results = imputations(dict_imp, dict_obs)\n",
        "      X_imputed, y_from_X_imputed, mask_from_X_imputed = results  # imputations(dict_imp, X_nan_train, dict_obs['y_train'])\n",
        "      dict_obs['imp_ds'][dict_imp['imp_method']].append(results)\n",
        "      print(\"crush test-------------------------------------------------> \", np.sum(X_imputed))\n",
        "    else:\n",
        "      print(\"A PREVIOUS IMPUTATION HAS BEEN DONE\")\n",
        "      X_imputed, y_from_X_imputed, mask_from_X_imputed = dict_obs['imp_ds'][dict_imp['imp_method']][0]\n",
        "      print(\"crush test-------------------------------------------------> \", np.sum(X_imputed))\n",
        "    #print(\"X_imputed \", X_imputed)\n",
        "    n_imputed, n_test = X_imputed.shape[-2], X_test.shape[-2]\n",
        "    #print(\"X_train\\n \", X_train)\n",
        "    M = np.sum(mask_from_X_imputed, axis=1)  # M[i] > 0 iff i has missing component\n",
        "\n",
        "    dict_obs = dict_obs | {'X_imputed': X_imputed, 'y_from_X_imputed': y_from_X_imputed, 'masks_after_imputation': mask_from_X_imputed}\n",
        "    #  print(dict_obs)\n",
        "    S_dataset = cov_strategy(dict_imp, dict_obs) #* dict_imp['multip_dataset']\n",
        "    print(\"S dataset \\n\", S_dataset)\n",
        "    #  dict_obs = dict_obs | {'cov_within': S_within}\n",
        "    S_missing = cov_strategy_missing(dict_imp, dict_obs)  #* dict_imp['multip_missing']\n",
        "    print(\"S missing shape\\n \", S_missing.shape)\n",
        "    print(\"S missing\\n \", S_missing)\n",
        "    if 'post_imp' in dict_obs.keys():\n",
        "      if dict_obs['post_imp'] == 'conc':\n",
        "        print(S_missing)\n",
        "    #  dict_obs = dict_obs | {'cov_between': S_between}\n",
        "    S_dict = {'S_dts': S_dataset, 'S_mis': S_missing} | dict_obs['info_algo'] | {'algo_superv_learn': dict_imp['algo_superv_learn']}  # , 'multipliers_dts': dict_imp['multip_dataset'], 'multipliers_mis': dict_imp['multip_missing']}\n",
        "    # dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4 'eps_adv_rad_times_delta_dts': 1e-4}}\n",
        "\n",
        "    #if True:  # check what to do of this part later\n",
        "      #S = S_dataset * dict_imp['multip_dataset'] + S_missing * dict_imp['multip_missing']\n",
        "      #if S.ndim == 2:\n",
        "      #  print(\"final S \\n\", S)\n",
        "\n",
        "\n",
        "    #print(\"matrices S \\n\", S)\n",
        "    #print(\"---....---....----....--> diag matrix: \", np.diag(S))\n",
        "\n",
        "    #if dict_imp['imp_method'] == 'mi':  # prepare the training set in case of multiple imputation\n",
        "    #  X_train = np.concatenate(X_train)  # X_train, if the method is mi, should be (mi_nbr, n, dim)\n",
        "    #  y_train = np.tile(y_train, reps=dict_imp['mi_nbr'])\n",
        "    #  mask_train = np.tile(mask_train, reps=(dict_imp['mi_nbr'], 1))\n",
        "    #  M = np.sum(mask_train, axis=1)\n",
        "    #print(\"final matrices (exp 2d ext run)\\n \", S)\n",
        "    X_train, y_train, mask_train = post_imputation(dict_imp, dict_obs)\n",
        "    n_train = X_train.shape[-2]\n",
        "    print(\"y_train length \", y_train.shape[0])\n",
        "    print(\"-------> size test: \", n_test, \" , size train: \", n_train, \"nbr_seen (train): \", np.sum(M == 0), \" nbr_miss : \", np.sum(M > 0))\n",
        "\n",
        "#    plt.tight_layout()\n",
        "    #S_between = S.copy()\n",
        "    if dict_imp['imp_method'] == 'mi' and dict_imp['cov_strategy'] == 'std_mi':  # run a standard multiple imputation procedure\n",
        "      best_coeff = np.zeros(X_train.shape[-1])\n",
        "      best_alpha = 0\n",
        "      min_score = 0\n",
        "      temporary_dictionary = copy.deepcopy(S_dict)\n",
        "      for i in range(dict_imp['mi_nbr']):\n",
        "        print(\"i  mi .-------------> \", i)\n",
        "        #dict_obs_i = {'X_imputed': X_train[i, :, :], 'X_nan': X_nan_train, 'masks': mask_train}\n",
        "        #dict_imp_new = {'imp_method': dict_imp['imp_method'], 'cov_strategy': dict_imp['cov_strategy_within']}\n",
        "        #S_within = cov_strategy(dict_imp_new, dict_obs_i)  # within the dataset\n",
        "        #print(\"S_within \", S_within)\n",
        "        #S = S_within[None, :, :] + S_between\n",
        "        #S = np.concatenate(S, axis=0)\n",
        "        #print(S)\n",
        "        #alphas_used, coeff_results = train_and_plot(X_train[i, :, :], y_train, S, [ax[1], ax[2]])\n",
        "        temporary_dictionary['S_dts'] = S_dict['S_dts'][i, :, :]\n",
        "        print(\"temporary dict \", temporary_dictionary)\n",
        "        hyper_p_used, coeff_results = train_and_plot(X_train[i, :, :], y_train, temporary_dictionary, [])\n",
        "        idx_best, min_score_partial = best_idx_predictor(X_test, coeff_results, y_test)\n",
        "        print(\"weee \", idx_best)\n",
        "        print(coeff_results.shape)\n",
        "        print(hyper_p_used.shape)\n",
        "        best_coeff_partial, _ = coeff_results[:, idx_best], hyper_p_used[:, idx_best]\n",
        "        print(\"best coeff partial \", best_coeff_partial)\n",
        "        best_coeff += best_coeff_partial\n",
        "        min_score += min_score_partial\n",
        "        #best_alpha += best_alpha_partial\n",
        "        if len(ax) > 0:\n",
        "          ax[0].scatter(X_train[i, M == 0, 0], X_train[i, M == 0, 1])\n",
        "          ax[0].scatter(X_train[i, M == 1, 0], X_train[i, M == 1, 1])\n",
        "          ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', n_s: ' + str(np.sum(M == 0)) + \" n_m: \" + str(np.sum(M > 0)))  # n_s = nbr seen, n_m = nbr missing\n",
        "          add_rectangles(X_train[i, :, 0], X_train[i, :, 1], S[0, 0] * best_alpha_partial, S[1, 1] * best_alpha_partial, ax[0])\n",
        "      best_coeff /= dict_imp['mi_nbr']\n",
        "      min_score /=  dict_imp['mi_nbr']\n",
        "      best_hyper_p = 0  # not important right now\n",
        "      best_alpha_delta_dts = 1  # not important right now\n",
        "      #best_alpha /= dict_imp['mi_nbr']\n",
        "    else:\n",
        "      #alphas_used, coeff_results = train_and_plot(X_train, y_train, S_dict, [ax[1], ax[2]])\n",
        "      hyper_p_used, coeff_results = train_and_plot(X_train, y_train, S_dict, [])\n",
        "      idx_best, min_score = best_idx_predictor(X_test, coeff_results, y_test)\n",
        "      #best_coeff, best_alpha = coeff_results[:, idx_best], alphas_used[idx_best]\n",
        "      #print(\"-----------------> shape hyper_p used \", hyper_p_used.shape)\n",
        "      best_coeff, best_hyper_p = coeff_results[:, idx_best], hyper_p_used[:, idx_best]\n",
        "      #print(\"hyper_p_used \", hyper_p_used.T)\n",
        "      #input()\n",
        "      #print(X_br_train[M == 0, 0])\n",
        "      best_alpha_delta_dts, best_alpha_delta_mis = best_hyper_p[0], best_hyper_p[1]\n",
        "#     print(\"best alpha ----> \", best_alpha_dts)\n",
        "      if len(ax) > 0:\n",
        "        ax[0].scatter(X_train[M == 0, 0], X_train[M == 0, 1])\n",
        "        ax[0].scatter(X_train[M == 1, 0], X_train[M == 1, 1])\n",
        "        #ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', n_s: ' + str(np.sum(M == 0)) + \" n_m: \" + str(np.sum(M > 0)))  # n_s = nbr seen, n_m = nbr missing\n",
        "        # 'multip_betw': 1, 'multip_with':1\n",
        "        ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', dts:'+str(dict_imp['multip_dataset']) + ', mis:' + str(dict_imp['multip_missing']) )  # n_s = nbr seen, n_m = nbr missing\n",
        "        S_plot = S_dict['S_dts'] * best_alpha_delta_dts + S_dict['S_mis'] * best_alpha_delta_mis\n",
        "        #print(\"S_plot \", S_plot)\n",
        "        add_rectangles(X_train[:, 0], X_train[:, 1], S_plot, ax[0])\n",
        "        ax[0].set_aspect('equal')  # equal proportion of the axis\n",
        "    #print(\"X_train \", X_train)\n",
        "    #print(\"y_train \", y_train)\n",
        "    #print(\"mask_train \", mask_train)\n",
        "    #print(\"M \", M)\n",
        "\n",
        "\n",
        "    print(\"X_test shape, \", X_test.shape, \",   y_test shape \", y_test.shape)\n",
        "    #print(\"X_test shape, \", X_test.shape)\n",
        "    print(\"---------------------------------> best idx \", idx_best, \" best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]: \", best_hyper_p, \", min score \", min_score)\n",
        "    print(\"---------------------------------> best coeff \", best_coeff)\n",
        "    #input()\n",
        "    #print(\"best 1/alpha \", 1 / best_alpha)\n",
        "    #print(\"min score \", min_score)\n",
        "\n",
        "    #\n",
        "    #add_rectangles(X_train[:, 0], X_train[:, 1], S[0, 0] * best_alpha, S[1, 1] * best_alpha, ax[0])\n",
        "\n",
        "\n",
        "    # obsere that one day you shoul add the return of alpha_delta_mis also\n",
        "    return best_coeff, min_score, best_hyper_p  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n",
        "\n"
      ],
      "metadata": {
        "id": "OhNXUBahJgBL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiments(dictio, methods_strategy):  # ---------------------> new\n",
        "  # dictio: dictionary of lists that contains the parameters of generate_dataset.\n",
        "  # Each list should have the same length\n",
        "  # methods_strategy = list of dictionary, each one of the form\n",
        "  # {'imp_method': .., 'cov_strategy':.., extra info}\n",
        "\n",
        "    l = len(dictio['data'])  # how many trials shall we do\n",
        "    m = len(methods_strategy)\n",
        "    nbr_iter = len(methods_strategy)\n",
        "    coeff_fin = np.zeros((nbr_iter, 2, l))\n",
        "    scores_fin = np.zeros((nbr_iter, l))\n",
        "\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(3 * l , 9 *l), num='advtrain_linf_')\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(6 * l , 9 *l), num='advtrain_linf_')\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(6 * l / 2, 9 *l / 2), num='advtrain_linf_')\n",
        "    print(dictio['plots'])\n",
        "    print(dictio['plots'][0])\n",
        "    nbr_ima = len(dictio['plots'][0])\n",
        "    if nbr_ima == 1:\n",
        "      #nbr_ima = 1\n",
        "      fig, ax = plt.subplots(nbr_ima * nbr_iter, l, figsize=(3 * l, 8/3 * m), squeeze=False)#, num='advtrain_linf_')\n",
        "    elif nbr_ima == 3:  # == 3, one day should be more general\n",
        "      #nbr_ima = 3\n",
        "      fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(3 * l, 8 * m), squeeze=False)#, num='advtrain_linf_')\n",
        "\n",
        "    res = {}\n",
        "    for info_imp_cov_dict in methods_strategy:\n",
        "      key_list = []\n",
        "      for value in info_imp_cov_dict.values():\n",
        "        print(value)\n",
        "        key_list.append(value)\n",
        "      key_tuple = tuple(key_list)\n",
        "      res[key_tuple] = {'best_coeff':[], 'l2_dist_best_coeff_gt':[], 'best_score':[], 'best_hyper_p':[], 'best_alpha_dts':[], 'best_alpha_mis':[]}\n",
        "      #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])] = {'best_coeff':[], 'l2_dist_best_coeff_gt':[], 'best_score':[], 'best_alpha':[]}\n",
        "\n",
        "    if dictio['generation'] == 'fixed':  # use this if you want to fix the generated data, and not change at every iteartion\n",
        "      dictio_obser_fixed  = generate_dataset(data=dictio['data'][0],\n",
        "                                    n_tot=dictio['n_tot'][-1],  # last one should be the biggest\n",
        "                                    dim=dictio['dim'][0],\n",
        "                                    beta_gt=dictio['beta_gt'][0],\n",
        "                                    perc_test=dictio['perc_test'][-1],\n",
        "                                    p_miss=dictio['p_miss'][0],\n",
        "                                    err=dictio['err'][0]\n",
        "                                             )  # return {'X_train_masked':(X_train, mask_train) , 'X_test':.., 'y_train':, 'y_test'}\n",
        "      #mask_no_both_seen = generate_masks_2d(dictio['n_train'][0], [0, 0.5, 0.5]) # generate a mask where there are no entries both seen. The idea then will be to consider percentage of this mask seen\n",
        "      full_masks = generate_masks(dictio)\n",
        "    dictio_obser_fixed_copy = copy.deepcopy(dictio_obser_fixed)\n",
        "\n",
        "    for i in range(l):\n",
        "      print(\"---------------------------------------------------------------------------------------------------------------------------> iteration \", i)\n",
        "      #  dict_obs = {'X_train_masked': (X_train, masks_train), 'X_test': ....., 'y_train': ....., 'y_test': ....}\n",
        "      dict_obser_partial = generate_dataset(data=dictio['data'][i],\n",
        "                                    n_tot=dictio['n_tot'][i],\n",
        "                                    dim=dictio['dim'][i],\n",
        "                                    beta_gt=dictio['beta_gt'][i],\n",
        "                                    perc_test=dictio['perc_test'][i],\n",
        "                                    p_miss=dictio['p_miss'][i],\n",
        "                                    err=dictio['err'][i])\n",
        "      if dictio['generation'] == 'fixed':\n",
        "        dict_obser = dictio_obser_fixed\n",
        "        if len(dictio['beta_gt'][0]) == 2:\n",
        "          #mask_partial = dict_obser_partial['X_train_masked'][1]\n",
        "          p_i = dictio['p_miss'][i][0]  # probability of seen both component at round i\n",
        "          n_train = full_masks.shape[0]\n",
        "          mask_partial = full_masks.copy()\n",
        "          mask_partial[0:int(n_train * p_i), :] = 0\n",
        "          tuple_partial = (dictio_obser_fixed['X_train_masked'][0], mask_partial)\n",
        "          dict_obser['X_train_masked'] = tuple_partial\n",
        "        else:\n",
        "          #print(\"size in run experiment\", dictio_obser_fixed_copy['X_train_masked'][0].shape, \"wee \", dictio_obser_fixed['y_train'].shape)\n",
        "          ## we use the next line of code with dictio_obser_fixed_copy because we need to test the mask with the original dataset, otherwise we get size error (the dataset change if an observation get fully hidden)\n",
        "          n_train = dictio['n_train']\n",
        "          print(\"n_tot_fll \", n_train, \",  \", n_train[i])\n",
        "          #print(dictio_obser_fixed_copy['X_train_masked'][0][0:n_train[i], :].shape)\n",
        "          #print(dictio_obser_fixed_copy['X_train_masked'][0].shape)\n",
        "          X_train_cleaned, y_train_cleaned, masks_train_cleaned = clear_dataset(dictio_obser_fixed_copy['X_train_masked'][0][0:n_train[i], :], dictio_obser_fixed_copy['y_train'][0:n_train[i]], full_masks[i][0:n_train[i], :])\n",
        "          print(\"shapes X_train cleaned, mask train cleaned, y train cleaned\")\n",
        "          print(X_train_cleaned.shape)\n",
        "          print(masks_train_cleaned.shape)\n",
        "          print(y_train_cleaned.shape)\n",
        "          #tuple_partial = (dictio_obser_fixed['X_train_masked'][0], full_masks[i])\n",
        "          print(\"full masks in run experiment \", full_masks[i])\n",
        "          dict_obser['X_train_masked'] = (X_train_cleaned, masks_train_cleaned)\n",
        "          dict_obser['y_train'] = y_train_cleaned\n",
        "      else:\n",
        "        dict_obser = dict_obser_partial\n",
        "\n",
        "      #print(\"dict obser \", dict_obser)\n",
        "      print(\"info algo in run experiments \", dictio['info_algo'])\n",
        "      dict_obser = dict_obser | {'imp_ds':{'BR_si':[], 'l_d':[], 'oracle':[], 'mi':[]}} | {'info_algo': dictio['info_algo']}  # add an entry for imputed dataset, and info for algorithm\n",
        "      print(\"ciaoooooo dict obser in run experiments \\n \", dict_obser)\n",
        "      for idx, info_imp_cov_dict in enumerate(methods_strategy):\n",
        "        print(\"----------------------------------------------> new method tested: \", info_imp_cov_dict)\n",
        "        if nbr_ima > 0:\n",
        "          coeff_round, score_round, hyper_p_round = experiment_2d_ext_dataset(dict_obser, info_imp_cov_dict, ax[(idx * nbr_ima):((idx+1) * nbr_ima), i])\n",
        "        else:  # == 0\n",
        "          coeff_round, score_round, hyper_p_round = experiment_2d_ext_dataset(dict_obser, info_imp_cov_dict, [])\n",
        "        r = coeff_round - dictio['beta_gt'][i]\n",
        "        l2_dist = np.linalg.norm(r)\n",
        "        key_list = []\n",
        "        for value in info_imp_cov_dict.values():\n",
        "          print(value)\n",
        "          key_list.append(value)\n",
        "        key_tuple = tuple(key_list)\n",
        "        res[key_tuple]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "        res[key_tuple]['best_coeff'].append(coeff_round)\n",
        "        res[key_tuple]['best_score'].append(score_round)\n",
        "        res[key_tuple]['best_hyper_p'].append(hyper_p_round)  # both hyperparameters\n",
        "        res[key_tuple]['best_alpha_dts'].append(hyper_p_round[0])  # one of the hyperparameter\n",
        "        res[key_tuple]['best_alpha_mis'].append(hyper_p_round[1])  # the other hyperparameter\n",
        "\n",
        "        #res[key_tuple]['best_alpha'].append(alpha_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_coeff'].append(coeff_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_score'].append(score_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_alpha'].append(alpha_round)\n",
        "    plt.tight_layout()\n",
        "    return res\n",
        "\n",
        "\n",
        "def plot_res(x_axis_info, res, extra_info):\n",
        "  x_axis = x_axis_info['vector']\n",
        "  print(\"x_axis for print in plot_res----> \", x_axis)\n",
        "  l = len(x_axis)\n",
        "  lb = extra_info['what_to_plot']\n",
        "  nbr_plot = len(lb)\n",
        "  fig_res, ax_res = plt.subplots(1, nbr_plot,\n",
        "                                 figsize=(35 * (nbr_plot / 3 ), 5))  # , num='advtrain_linf_res')\n",
        "  positions = range(l)\n",
        "\n",
        "  for key, values in res.items():\n",
        "    print(\"key in plot_res\", key, \": values\\n\", values)\n",
        "    #print(\"values \", values)\n",
        "  #print(\"res\\n \", res)\n",
        "\n",
        "  ch = ['o', 'x', '+', '*', '<', '>', 'p', 'D', 'd', 'v']\n",
        "  # lb = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha']\n",
        "  for i in range(nbr_plot):\n",
        "    for idx, (key, dictio) in enumerate(res.items()):\n",
        "      #print(dictio)\n",
        "      print(\"lb[i] in plot_res \", lb[i], \"  \", dictio[lb[i]])\n",
        "      ax_res[i].plot(positions, dictio[lb[i]], marker=ch[idx], label=str(key))  # the marker is linked to the key (= method), different key correspond to different marker\n",
        "      #ax_res[1].plot(positions, dictio[lb[idx]], marker=ch[idx], label=str(key))\n",
        "      #ax_res[2].plot(positions, -np.log(dictio['best_alpha']), marker=ch[idx], label=str(key))\n",
        "      #ax_res[0].xticks(positions, n_tot)  # Set custom labels for the x-axis\n",
        "    ax_res[i].set_xticks(positions)         # Set the tick positions\n",
        "    ax_res[i].set_xticklabels(x_axis)        # Set the labels at those positions\n",
        "    ax_res[i].set_xlabel(x_axis_info['name'])\n",
        "    #ax_res[i].legend(loc='upper center', bbox_to_anchor=(1, 1))\n",
        "    ax_res[i].legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0., fontsize=20,)\n",
        "  ax_res[0].set_ylabel(\"||hat_Beta - Beta^*||_2\")\n",
        "  ax_res[1].set_ylabel(\"||hat_y - y||_2^2 / n_test\")\n",
        "  dict_err = extra_info['err'][0]\n",
        "  #size_train = extra_info['n_tot'][0]\n",
        "  #ax_res[0].set_title(\"\")\n",
        "  n_test = extra_info['n_test'][0]\n",
        "  #ax_res[1].set_title(\"err: \" + dict_err['type'] + \", scale: \" + str(dict_err['scaling'])  + \", n_test: \" + str(n_test))\n",
        "  #ax_res[0].set_title('n_test: ' + str(n_test) + extra_info['title_infer_error'])\n",
        "  #ax_res[1].set_title('n_test: ' + str(n_test) + extra_info['title_test_error'])\n",
        "  ax_res[0].set_title(extra_info['title_infer_error'], fontweight='bold', fontsize = 24)\n",
        "  ax_res[1].set_title(extra_info['title_test_error'], fontweight='bold', fontsize = 24)\n",
        "  ax_res[2].set_ylabel(\"-log10(alpha)\")\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n",
        "def make_dictionary_data(nbr_experiments, n_train, n_test, data, beta_gt, p_miss, err_vector, plots):\n",
        "  # make a dictionary where each element is a list of nbr_experiments element made by the other element of the function\n",
        "  if isinstance(n_train, int):  # in case n_train is just a number\n",
        "    n_train = [n_train] * nbr_experiments\n",
        "  else:  # should be a list of integer\n",
        "    print(\"change nbr_experiments to match the size of n_train\")\n",
        "    nbr_experiments = len(n_train)\n",
        "  if isinstance(n_test, int):  # in case n_test is just a number\n",
        "    n_test = [n_test] * nbr_experiments\n",
        "  n_tot = [x + y for x, y in zip(n_train, n_test)]\n",
        "  perc_test = [x / (x+y) for x, y in zip(n_test, n_train)]\n",
        "  dim = beta_gt.size\n",
        "\n",
        "  list_errors = []\n",
        "  for i in range(nbr_experiments):\n",
        "    err_dic_app = {'type': err_vector[0], 'scaling': err_vector[1][i]}\n",
        "    list_errors.append(err_dic_app)\n",
        "\n",
        "  dictio = {'data':[data] * nbr_experiments,\n",
        "        'n_tot': n_tot,\n",
        "        'n_train': n_train,\n",
        "        'n_test': n_test,\n",
        "        'dim': [dim] * nbr_experiments,\n",
        "        'beta_gt': [beta_gt] * nbr_experiments,\n",
        "        'perc_test': perc_test,\n",
        "        #'p_miss': [p_miss] * nbr_experiments,\n",
        "        'err': list_errors,\n",
        "        'plots': [plots] * nbr_experiments\n",
        "        }\n",
        "  dictio['p_miss'] = p_miss\n",
        "\n",
        "  return dictio\n",
        "\n",
        "def make_probabilities(list_prob):\n",
        "  l = []\n",
        "  for x in list_prob:\n",
        "    l.append([x, 0.5 - x/2, 0.5 - x/2])\n",
        "  return l\n",
        "\n",
        "def make_info_axis(vector, name):\n",
        "  if name == 'train':\n",
        "    dictio = {'name': 'size train set', 'vector': vector}\n",
        "  elif name == 'p_seen':\n",
        "    dictio = {'name': 'probability seen full entries', 'vector': vector}\n",
        "  elif name == 'error':\n",
        "    dictio = {'name': 'error', 'vector': vector}\n",
        "  else:\n",
        "    print(\"wrong info_axis\")\n",
        "  return dictio\n",
        "\n",
        "def make_dictionary_method(list_meth):\n",
        "  # make a dictionary where each element is a list of nbr_experiments element made by the other element of the function\n",
        "  list_dictio=[]\n",
        "  list_key = ['imp_method', 'cov_strategy', 'mi_nbr']\n",
        "  for meth in list_meth:\n",
        "    dictio_imp = {}\n",
        "    for i in range(len(meth)):\n",
        "      dictio_imp[list_key[i]] = meth[i] #= {list_key[i]: meth[i]}\n",
        "      #print(dictio_imp)\n",
        "    list_dictio.append(dictio_imp)\n",
        "  return list_dictio\n",
        "\n",
        "\n",
        "def run_multiple_experiments(nbr_exp, rdm_seed, dictio, info_x_axis):\n",
        "  #rdm_seed = 4654321\n",
        "  np.random.seed(rdm_seed)\n",
        "  res = run_experiments(dicc, list_methods_strategy)\n",
        "  plot_res(info_x_axis, res, dicc)\n",
        "  '''\n",
        "  if nbr_exp > 1:\n",
        "    for k in res:\n",
        "      for h in res[k]:\n",
        "        res[k][h] = [res[k][h]]\n",
        "    for i in range(nbr_exp-1):\n",
        "      print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "      #np.random.seed(rdm_seed * (i+2))\n",
        "      res_partial = run_experiments(dictio, list_methods_strategy)\n",
        "      plot_res(info_x_axis, res_partial, dictio)\n",
        "      print(res)\n",
        "      for k in res:\n",
        "        res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "        res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "        res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "        #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "        #res.append(res['l2_dist_best_coeff_gt'])\n",
        "  '''\n",
        "  for k in res:\n",
        "    for h in res[k]:\n",
        "      res[k][h] = [res[k][h]]\n",
        "  for i in range(nbr_exp-1):\n",
        "      print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "      #np.random.seed(rdm_seed * (i+2))\n",
        "      res_partial = run_experiments(dictio, list_methods_strategy)\n",
        "      print(\"res partial \\n\")\n",
        "      for k, value in res_partial.items():\n",
        "        print(\"key: \", k, \" value: \", value)\n",
        "      plot_res(info_x_axis, res_partial, dictio)\n",
        "      print(\"res in run multipl experiments\\n\")\n",
        "#      for k, value in res.items():\n",
        "#        print(\"key: \", k, \" value: \", value)\n",
        "      for k in res:\n",
        "        res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "        res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "        res[k]['best_hyper_p'].append(res_partial[k]['best_hyper_p'])\n",
        "        res[k]['best_alpha_dts'].append(res_partial[k]['best_alpha_dts'])\n",
        "        res[k]['best_alpha_mis'].append(res_partial[k]['best_alpha_mis'])\n",
        "\n",
        "        #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "        #res.append(res['l2_dist_best_coeff_gt'])\n",
        "\n",
        "  print(\"final step, let's take the mean of the results\")\n",
        "  #print(\"res, after all the experimetns \", res)\n",
        "  for k in res:\n",
        "    print(\"key in res \", k)\n",
        "    print(np.array(res[k]['l2_dist_best_coeff_gt']))\n",
        "    print(\"mean l2_dist              \", np.mean(np.array(res[k]['l2_dist_best_coeff_gt']), axis=0))\n",
        "    print(\"mean_l2_dist diff method: \", np.mean(res[k]['l2_dist_best_coeff_gt'], axis=0))\n",
        "  #mean_res = {k: np.mean(v, axis=0) for k, v in res.items()}\n",
        "  mean_res = {k: {v: np.mean(w, axis=0) for v, w in res[k].items()} for k in res}\n",
        "  print(\"final dictionary, dictionary of the means:\")\n",
        "  for k, v in mean_res.items():\n",
        "    print(\"k:   \", k)\n",
        "    for s, t in v.items():\n",
        "      print(s, \": \", t)\n",
        "  return mean_res\n",
        "  #print(np.mean(res, axis=0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_2LB5UnMpgCC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#info_axis = 'train'\n",
        "#n_train = [400, 800, 1200, 1600, 2000]\n",
        "#p_seen = make_probabilities([0.8, 0.8, 0.8, 0.8, 0.8])\n",
        "#main_vec = n_train if info_axis == 'train' else p_seen\n",
        "#info_x_axis = make_info_axis(main_vec, info_axis)\n",
        "\n",
        "# def get_path(X, y, estimator, amax, dts_max, mis_max, S_dict, eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "gen = 'fixed'\n",
        "info_axis = 'train'  # train or p_seen\n",
        "#p_seen_both = [1, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.40, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.02]\n",
        "#p_seen_both = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
        "#p_seen_both = [1, 0.9, 0.8/0.9, 0.7/0.8, 0.6/0.7, 0.5/0.6]\n",
        "#p_seen_both = [1, 0.9, 0.8/0.9, 0.7/0.8, 0.6/0.7, 0.5/0.6, 0.4/0.5, 0.3/0.4]\n",
        "n_train = [40, 50, 60, 70, 80, 90, 100]  # check how dataset are generated, there should be some problems with 'fixed'\n",
        "lenght_vec = len(n_train)\n",
        "p_seen_both = [0.66, 1, 1, 1, 1, 1, 1]\n",
        "#p_seen_both = [1, 0.9, 0.8]\n",
        "length_vec = len(p_seen_both)\n",
        "#n_train = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
        "error_vec =  [0] * length_vec\n",
        "#p_seen = make_probabilities(p_seen_both)\n",
        "p_seen = [p_seen_both] * length_vec\n",
        "if info_axis == 'train':\n",
        "  main_vec = n_train\n",
        "elif info_axis == 'p_seen':\n",
        "  main_vec = np.cumprod(p_seen_both)  # p_seen_both\n",
        "elif info_axis == 'error':\n",
        "  main_vec = error_vec\n",
        "#main_vec = n_train if info_axis == 'train' else p_seen_both\n",
        "info_x_axis = make_info_axis(main_vec, info_axis)\n",
        "number_test = 20000\n",
        "cov_var = 0.6\n",
        "#beta_gt = np.array([-0.5, 2, 1, 3, -2, -3, 4, 0.5, 7, -9, -1, -2, -3, 4, 5, 6, 7, 8])\n",
        "#beta_gt = np.array([2, 4, -0.5, 2, 1, 3, -2, -3, 4, 0.5, 7, -9, -1, -2, -3, 4])\n",
        "beta_gt = np.random.randn(3)\n",
        "print(beta_gt)\n",
        "dim = len(beta_gt)\n",
        "mean = np.array([0] * dim)\n",
        "matr = np.random.randn(dim, dim) * 1\n",
        "cov = matr.T @ matr + np.eye(dim) * 0.5\n",
        "# np.array([[1, cov_var], [cov_var, 1]])\n",
        "\n",
        "dicc = make_dictionary_data(\n",
        "    nbr_experiments= len(main_vec), n_train = n_train, n_test=number_test,\n",
        "    data = {'data': 'Gaussian', 'mean': mean, 'cov': cov},\n",
        "    beta_gt = beta_gt,\n",
        "    p_miss = p_seen,\n",
        "    err_vector = ['Gaussian_on_X', error_vec],\n",
        "    plots = []#['points', 'l1_vs_coef', '1/alpha_vs_coef']\n",
        ")\n",
        "#dicc = dicc | {'generation':gen}\n",
        "dicc['what_to_plot'] = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts']\n",
        "dicc = dicc | {'generation': gen, 'title_infer_error':' inference_error', 'title_test_error':'  test_error'}\n",
        "dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10,\n",
        "                             'eps_adv_rad_times_delta_dts': 1e-5, 'eps_adv_rad_times_delta_mis': 1e-5, 'eps_alpha_ridge_reg': 1e-5,\n",
        "                             'n_a_dts': 20, 'n_a_mis':20, 'n_a_rid': 20}}\n",
        "\n",
        "for key, value in dicc.items():\n",
        "  print(key, \": \" , value)\n",
        "\n",
        "# (imp method, cov strategy, mi_nbr)\n",
        "#list_imp_cov_methods = [('BR_si', 'sd'), ('l_d', 'sd'), ('mi', 'sd', 1)]\n",
        "\n",
        "#list_methods_strategy = make_dictionary_method(list_imp_cov_methods)\n",
        "mi_nbr = 5\n",
        "# def get_path(X, y, estimator, amax, dts_max, mis_max, S_dict, eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "\n",
        "list_methods_strategy = [{'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'},  #, 'multip_dataset': 3, 'multip_missing':0},\n",
        "                        #{'imp_method': 'l_d', 'cov_strategy': 'std_nan', 'multip_dataset': 3, 'multip_missing':3},\n",
        "                        {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'},  #, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'},#, 'multip_dataset': 3, 'multip_missing':0},\n",
        "                        #{'imp_method': 'l_d', 'cov_strategy': 'std_nan', 'multip_dataset': 3, 'multip_missing':3},\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn':'ridge'},#, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        {'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'algo_superv_learn':'adv'}, #, 'multip_dataset': 3, 'multip_missing': 3},\n",
        "                        {'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'algo_superv_learn':'ridge'}\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'sd', 'multip_dataset': 0, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 1},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 3},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'std_mi', 'mi_nbr': mi_nbr},\n",
        "                        #{'imp_method': 'mi_pure', 'cov_strategy': 'cond_var', 'cov_strategy_within': 'sd', 'mi_nbr': 5},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 1},\n",
        "                        #{'imp_method': 'mi_mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'eye', 'mi_nbr': 5},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'multip_betw': 0, 'multip_with': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.2},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.4},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.6},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 0, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 0, 'multip_missing': 1},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'conc', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr}#, 'multip_dataset': 3, 'multip_missing': 3}\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 5},\n",
        "                        ]\n",
        "print(list_methods_strategy)\n",
        "for el in list_methods_strategy:\n",
        "  for key, value in el.items():\n",
        "    print(key,\": \" , value)\n",
        "\n",
        "print(\"----> Starting experiments\")\n",
        "\n",
        "'''\n",
        "nbr_exp = 2\n",
        "#res[key_tuple]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "#res[key_tuple]['best_coeff'].append(coeff_round)\n",
        "#res[key_tuple]['best_score'].append(score_round)\n",
        "#res[key_tuple]['best_alpha'].append(alpha_round)\n",
        "res_l2 = []\n",
        "\n",
        "rdm_seed = 4654321\n",
        "np.random.seed(rdm_seed)\n",
        "res = run_experiments(dicc, list_methods_strategy)\n",
        "plot_res(info_x_axis, res, dicc)\n",
        "if nbr_exp > 1:\n",
        "  for k in res:\n",
        "    for h in res[k]:\n",
        "      res[k][h] = [res[k][h]]\n",
        "  for i in range(nbr_exp-1):\n",
        "    print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "    #np.random.seed(rdm_seed * (i+2))\n",
        "    res_partial = run_experiments(dicc, list_methods_strategy)\n",
        "    plot_res(info_x_axis, res_partial, dicc)\n",
        "    print(res)\n",
        "    for k in res:\n",
        "      res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "      res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "      res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "      #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "    #res.append(res['l2_dist_best_coeff_gt'])\n",
        "\n",
        "print(\"final \")\n",
        "print(res)\n",
        "for k in res:\n",
        "  print(k)\n",
        "  print(np.array(res[k]['l2_dist_best_coeff_gt']))\n",
        "  print(np.mean(np.array(res[k]['l2_dist_best_coeff_gt']), axis=0))\n",
        "  print(np.mean(res[k]['l2_dist_best_coeff_gt'], axis=0))\n",
        "#mean_res = {k: np.mean(v, axis=0) for k, v in res.items()}\n",
        "mean_res = {k: {v: np.mean(w, axis=0) for v, w in res[k].items()} for k in res}\n",
        "for k, v in mean_res.items():\n",
        "  print(\"k:   \", k)\n",
        "  for s, t in v.items():\n",
        "    print(s, \": \", t)\n",
        "#print(np.mean(res, axis=0))\n",
        "'''\n",
        "\n",
        "nbr_exp = 2\n",
        "seed = 67\n",
        "mean_res = run_multiple_experiments(nbr_exp, seed, dicc, info_x_axis)\n",
        "print(\"PLOT OF THE MEANS\")\n",
        "dicc['title_infer_error'] = 'seed: ' + str(seed) + ', nbr_exp: ' + str(nbr_exp) + ', cov: ' + str(cov_var)\n",
        "dicc['title_test_error'] = 'sigma_err: ' + str(error_vec[0]) + ', n_train: ' + str(n_train[0]) + ', n_test: ' + str(number_test)\n",
        "#dicc = dicc | {'generation':gen, 'title_infer_error':'mean_infer_error, rep: ' + str(nbr_exp), 'title_mean_error':'mean_test_error'}\n",
        "dicc['what_to_plot'] = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts', 'best_alpha_mis']\n",
        "plot_res(info_x_axis, mean_res, dicc)\n",
        "\n",
        "## you can see if you manage to take the index i that maximize alpha\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXcjBX8GqIAF",
        "outputId": "1f01df12-4663-453d-ed09-ebe6ab62f133"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.60584391 -0.9027603  -0.43100982]\n",
            "change nbr_experiments to match the size of n_train\n",
            "data :  [{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}]\n",
            "n_tot :  [20040, 20050, 20060, 20070, 20080, 20090, 20100]\n",
            "n_train :  [40, 50, 60, 70, 80, 90, 100]\n",
            "n_test :  [20000, 20000, 20000, 20000, 20000, 20000, 20000]\n",
            "dim :  [3, 3, 3, 3, 3, 3, 3]\n",
            "beta_gt :  [array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982])]\n",
            "perc_test :  [0.998003992015968, 0.9975062344139651, 0.9970089730807578, 0.9965122072745392, 0.9960159362549801, 0.9955201592832255, 0.9950248756218906]\n",
            "err :  [{'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}]\n",
            "plots :  [[], [], [], [], [], [], []]\n",
            "p_miss :  [[0.66, 1, 1, 1, 1, 1, 1], [0.66, 1, 1, 1, 1, 1, 1], [0.66, 1, 1, 1, 1, 1, 1], [0.66, 1, 1, 1, 1, 1, 1], [0.66, 1, 1, 1, 1, 1, 1], [0.66, 1, 1, 1, 1, 1, 1], [0.66, 1, 1, 1, 1, 1, 1]]\n",
            "what_to_plot :  ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts']\n",
            "generation :  fixed\n",
            "title_infer_error :   inference_error\n",
            "title_test_error :    test_error\n",
            "info_algo :  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "[{'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}, {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}, {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}, {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}, {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}]\n",
            "imp_method :  BR_si\n",
            "cov_strategy :  std_nan\n",
            "algo_superv_learn :  adv\n",
            "imp_method :  oracle\n",
            "cov_strategy :  sd\n",
            "algo_superv_learn :  adv\n",
            "imp_method :  BR_si\n",
            "cov_strategy :  std_nan\n",
            "algo_superv_learn :  ridge\n",
            "imp_method :  mi\n",
            "post_imp :  mean\n",
            "cov_strategy_between :  cond_var\n",
            "cov_strategy :  std_nan\n",
            "mi_nbr :  5\n",
            "algo_superv_learn :  adv\n",
            "imp_method :  mi\n",
            "post_imp :  mean\n",
            "cov_strategy_between :  cond_var\n",
            "cov_strategy :  std_nan\n",
            "mi_nbr :  5\n",
            "algo_superv_learn :  ridge\n",
            "----> Starting experiments\n",
            "[[], [], [], [], [], [], []]\n",
            "[]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20100, 3)\n",
            "p_missing in generate mask  [0.66, 1, 1, 1, 1, 1, 1]\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  0\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20040, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   40\n",
            "X shape in clear data  (40, 3)\n",
            "y shape in clear data  (40,)\n",
            "M shape in clear data  (40,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(39, 3)\n",
            "(39, 3)\n",
            "(39,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.34874672,  0.12880878, -0.39575018],\n",
            "       [ 2.03440496, -0.7364663 ,  0.14765257],\n",
            "       [-1.93805473, -1.32668622,  0.27603886],\n",
            "       [ 0.61042982,  0.00459682,  0.19170315],\n",
            "       [ 0.94365935, -1.43434126,  0.50645103],\n",
            "       [-0.42403535, -0.93576142, -0.63184545],\n",
            "       [-1.08349271, -0.290857  , -0.32209072],\n",
            "       [ 0.02226566,  0.3094647 ,  1.72254516],\n",
            "       [ 0.60875449, -0.78748954, -0.10980159],\n",
            "       [-0.67462106,  0.7586794 , -1.83572918],\n",
            "       [ 0.58004405,  1.16777225, -0.6712442 ],\n",
            "       [-2.29258519,  0.93508287, -0.24557696],\n",
            "       [ 0.93604723,  0.92081444, -1.00230523],\n",
            "       [-1.38463222,  0.10993258, -0.38392901],\n",
            "       [-0.48108551, -0.55581083,  1.15487716],\n",
            "       [-0.2707817 , -1.25445809,  0.53489175],\n",
            "       [ 1.82509762, -0.52616778,  0.5021699 ],\n",
            "       [ 0.3828516 ,  0.14180845, -1.08295106],\n",
            "       [-1.47459168,  0.79466499, -1.37292582],\n",
            "       [-0.67967491,  1.47588969, -1.04401964],\n",
            "       [-0.19533168, -1.69187442, -0.35776372],\n",
            "       [ 0.87891938,  0.14482416,  0.58110269],\n",
            "       [ 0.61965983,  0.1655677 , -0.57654715],\n",
            "       [ 0.44850941, -1.66036407, -0.74194324],\n",
            "       [-0.62911229, -0.49797951,  0.24454919],\n",
            "       [-0.38494715, -0.95734304,  0.84378794],\n",
            "       [-0.83536774,  0.29347368,  1.33444067],\n",
            "       [-0.48873332,  1.6821597 , -0.87065875],\n",
            "       [ 0.49785766, -0.50059035,  1.39092028],\n",
            "       [ 2.05499204,  0.53226236, -1.3236699 ],\n",
            "       [ 1.04632081,  0.5087837 , -0.43143791],\n",
            "       [-0.06415189, -0.04646157,  1.08402583],\n",
            "       [-1.14587692,  0.28366376, -1.42670437],\n",
            "       [-0.71414908, -0.10834585, -1.10571681],\n",
            "       [-0.48081469, -0.57188288,  0.29810572],\n",
            "       [-1.11198913,  1.61718388, -2.0673696 ],\n",
            "       [-0.17335241,  1.29312229,  2.23244701],\n",
            "       [-1.77576666,  0.00519575,  0.64220617],\n",
            "       [-0.05917629,  0.44951301,  0.14550145]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01750938 0.87948838 0.97904916]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -2.3857430767097574\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0]\n",
            "S dataset \n",
            " [[1.02217266 0.         0.        ]\n",
            " [0.         0.86267678 0.        ]\n",
            " [0.         0.         1.00965506]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (39, 3)\n",
            "y_train length  39\n",
            "-------> size test:  20000  , size train:  39 nbr_seen (train):  14  nbr_miss :  25\n",
            "X  39   3\n",
            "y shape (39,)\n",
            "nm  117\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 232.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  9  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.02335721 0.        ] , min score  0.044850361014041634\n",
            "---------------------------------> best coeff  [-1.4562972  -1.02703805 -0.34741063]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01750938 0.87948838 0.97904916]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -9.947436191243472\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.01750938 0.         0.        ]\n",
            " [0.         0.87948838 0.        ]\n",
            " [0.         0.         0.97904916]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (39, 3)\n",
            "y_train length  39\n",
            "-------> size test:  20000  , size train:  39 nbr_seen (train):  39  nbr_miss :  0\n",
            "X  39   3\n",
            "y shape (39,)\n",
            "nm  117\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 158.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  3.361738999781952e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01750938 0.87948838 0.97904916]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -2.3857430767097574\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0]\n",
            "S dataset \n",
            " [[1.02217266 0.         0.        ]\n",
            " [0.         0.86267678 0.        ]\n",
            " [0.         0.         1.00965506]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (39, 3)\n",
            "y_train length  39\n",
            "-------> size test:  20000  , size train:  39 nbr_seen (train):  14  nbr_miss :  25\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.02217266 0.         0.        ]\n",
            " [0.         0.86267678 0.        ]\n",
            " [0.         0.         1.00965506]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.9783083  0.         0.        ]\n",
            " [0.         1.1591827  0.        ]\n",
            " [0.         0.         0.99043727]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1159.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.05062148498769628\n",
            "---------------------------------> best coeff  [-1.46847358 -1.07003848 -0.3709771 ]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01750938 0.87948838 0.97904916]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -12.299692007944815\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0]\n",
            "S dataset \n",
            " [[1.02217266 0.         0.        ]\n",
            " [0.         0.86267678 0.        ]\n",
            " [0.         0.         1.00965506]]\n",
            "S missing shape\n",
            "  (39, 3, 3)\n",
            "S missing\n",
            "  [[[1.48019338 0.         0.        ]\n",
            "  [0.         0.46685887 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.42599146 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.30980651 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.67356075]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75716113 0.         0.        ]\n",
            "  [0.         0.74830164 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97998541 0.        ]\n",
            "  [0.         0.         0.67961503]]\n",
            "\n",
            " [[1.26780155 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54639311]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.33024709 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07392476 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.70125226]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81991715]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.11864943]]\n",
            "\n",
            " [[0.9159199  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.72397027]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15255225 0.        ]\n",
            "  [0.         0.         0.47636973]]\n",
            "\n",
            " [[0.44494589 0.         0.        ]\n",
            "  [0.         1.75362411 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56030805]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.4608642  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.06079903 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.0285286  0.        ]\n",
            "  [0.         0.         0.92537425]]\n",
            "\n",
            " [[0.49529897 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78281321 0.        ]\n",
            "  [0.         0.         0.34882452]]\n",
            "\n",
            " [[1.09828371 0.         0.        ]\n",
            "  [0.         0.76717666 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.66324748 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06463522 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09354842 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.40062191 0.         0.        ]\n",
            "  [0.         0.46884957 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 39, 3)\n",
            "y_train length  39\n",
            "-------> size test:  20000  , size train:  39 nbr_seen (train):  14  nbr_miss :  25\n",
            "X  39   3\n",
            "y shape (39,)\n",
            "nm  117\n",
            "S_mis in Adbvt training  [[[1.48019338 0.         0.        ]\n",
            "  [0.         0.46685887 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.42599146 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.30980651 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.67356075]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75716113 0.         0.        ]\n",
            "  [0.         0.74830164 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97998541 0.        ]\n",
            "  [0.         0.         0.67961503]]\n",
            "\n",
            " [[1.26780155 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54639311]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.33024709 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07392476 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.70125226]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81991715]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.11864943]]\n",
            "\n",
            " [[0.9159199  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.72397027]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15255225 0.        ]\n",
            "  [0.         0.         0.47636973]]\n",
            "\n",
            " [[0.44494589 0.         0.        ]\n",
            "  [0.         1.75362411 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56030805]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.4608642  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.06079903 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.0285286  0.        ]\n",
            "  [0.         0.         0.92537425]]\n",
            "\n",
            " [[0.49529897 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78281321 0.        ]\n",
            "  [0.         0.         0.34882452]]\n",
            "\n",
            " [[1.09828371 0.         0.        ]\n",
            "  [0.         0.76717666 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.66324748 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06463522 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09354842 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.40062191 0.         0.        ]\n",
            "  [0.         0.46884957 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.02 0.00 0.00]\n",
            " [0.00 0.86 0.00]\n",
            " ...\n",
            " [0.00 0.86 0.00]\n",
            " [0.00 0.00 1.01]] @ Promote(adv_radius_times_dts, (117, 3)) + [[1.48 0.00 0.00]\n",
            " [0.00 0.47 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (117, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 127.01it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:03,  6.20it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 131.78it/s]\n",
            " 10%|█         | 2/20 [00:00<00:02,  6.31it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 145.96it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:02,  6.62it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 143.50it/s]\n",
            " 20%|██        | 4/20 [00:00<00:02,  6.73it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 146.38it/s]\n",
            " 25%|██▌       | 5/20 [00:00<00:02,  6.84it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 141.83it/s]\n",
            " 30%|███       | 6/20 [00:00<00:02,  6.84it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 144.91it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:01,  6.87it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 132.31it/s]\n",
            " 40%|████      | 8/20 [00:01<00:01,  6.72it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 159.03it/s]\n",
            " 45%|████▌     | 9/20 [00:01<00:01,  6.99it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 164.58it/s]\n",
            " 50%|█████     | 10/20 [00:01<00:01,  7.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 163.16it/s]\n",
            " 55%|█████▌    | 11/20 [00:01<00:01,  7.34it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 156.93it/s]\n",
            " 60%|██████    | 12/20 [00:01<00:01,  7.41it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 167.94it/s]\n",
            " 65%|██████▌   | 13/20 [00:01<00:00,  7.53it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 163.76it/s]\n",
            " 70%|███████   | 14/20 [00:01<00:00,  7.60it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 164.74it/s]\n",
            " 75%|███████▌  | 15/20 [00:02<00:00,  7.61it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 123.15it/s]\n",
            " 80%|████████  | 16/20 [00:02<00:00,  7.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 141.84it/s]\n",
            " 85%|████████▌ | 17/20 [00:02<00:00,  6.98it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 146.45it/s]\n",
            " 90%|█████████ | 18/20 [00:02<00:00,  6.96it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 145.31it/s]\n",
            " 95%|█████████▌| 19/20 [00:02<00:00,  6.95it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 97.97it/s] \n",
            "100%|██████████| 20/20 [00:02<00:00,  6.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  11  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.078476 0.0001  ] , min score  0.07926840193351885\n",
            "---------------------------------> best coeff  [-1.43357371 -1.07576749 -0.29039822]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01750938 0.87948838 0.97904916]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -12.299692007944815\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0]\n",
            "S dataset \n",
            " [[1.02217266 0.         0.        ]\n",
            " [0.         0.86267678 0.        ]\n",
            " [0.         0.         1.00965506]]\n",
            "S missing shape\n",
            "  (39, 3, 3)\n",
            "S missing\n",
            "  [[[1.48019338 0.         0.        ]\n",
            "  [0.         0.46685887 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.42599146 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.30980651 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.67356075]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75716113 0.         0.        ]\n",
            "  [0.         0.74830164 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97998541 0.        ]\n",
            "  [0.         0.         0.67961503]]\n",
            "\n",
            " [[1.26780155 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54639311]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.33024709 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07392476 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.70125226]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81991715]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.11864943]]\n",
            "\n",
            " [[0.9159199  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.72397027]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15255225 0.        ]\n",
            "  [0.         0.         0.47636973]]\n",
            "\n",
            " [[0.44494589 0.         0.        ]\n",
            "  [0.         1.75362411 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56030805]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.4608642  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.06079903 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.0285286  0.        ]\n",
            "  [0.         0.         0.92537425]]\n",
            "\n",
            " [[0.49529897 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78281321 0.        ]\n",
            "  [0.         0.         0.34882452]]\n",
            "\n",
            " [[1.09828371 0.         0.        ]\n",
            "  [0.         0.76717666 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.66324748 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06463522 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09354842 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.40062191 0.         0.        ]\n",
            "  [0.         0.46884957 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 39, 3)\n",
            "y_train length  39\n",
            "-------> size test:  20000  , size train:  39 nbr_seen (train):  14  nbr_miss :  25\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.02217266 0.         0.        ]\n",
            " [0.         0.86267678 0.        ]\n",
            " [0.         0.         1.00965506]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.9783083  0.         0.        ]\n",
            " [0.         1.1591827  0.        ]\n",
            " [0.         0.         0.99043727]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1030.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  16  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.62377674 1.62377674] , min score  0.10404339456912555\n",
            "---------------------------------> best coeff  [-1.41512181 -1.14037531 -0.32606607]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  1\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20050, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   50\n",
            "X shape in clear data  (50, 3)\n",
            "y shape in clear data  (50,)\n",
            "M shape in clear data  (50,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(48, 3)\n",
            "(48, 3)\n",
            "(48,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.34874672,  0.12880878, -0.39575018],\n",
            "       [ 2.03440496, -0.7364663 ,  0.14765257],\n",
            "       [-1.93805473, -1.32668622,  0.27603886],\n",
            "       [ 0.61042982,  0.00459682,  0.19170315],\n",
            "       [ 0.94365935, -1.43434126,  0.50645103],\n",
            "       [-0.42403535, -0.93576142, -0.63184545],\n",
            "       [-1.08349271, -0.290857  , -0.32209072],\n",
            "       [ 0.02226566,  0.3094647 ,  1.72254516],\n",
            "       [ 0.60875449, -0.78748954, -0.10980159],\n",
            "       [-0.67462106,  0.7586794 , -1.83572918],\n",
            "       [ 0.58004405,  1.16777225, -0.6712442 ],\n",
            "       [-2.29258519,  0.93508287, -0.24557696],\n",
            "       [ 0.93604723,  0.92081444, -1.00230523],\n",
            "       [-1.38463222,  0.10993258, -0.38392901],\n",
            "       [-0.48108551, -0.55581083,  1.15487716],\n",
            "       [-0.2707817 , -1.25445809,  0.53489175],\n",
            "       [ 1.82509762, -0.52616778,  0.5021699 ],\n",
            "       [ 0.3828516 ,  0.14180845, -1.08295106],\n",
            "       [-1.47459168,  0.79466499, -1.37292582],\n",
            "       [-0.67967491,  1.47588969, -1.04401964],\n",
            "       [-0.19533168, -1.69187442, -0.35776372],\n",
            "       [ 0.87891938,  0.14482416,  0.58110269],\n",
            "       [ 0.61965983,  0.1655677 , -0.57654715],\n",
            "       [ 0.44850941, -1.66036407, -0.74194324],\n",
            "       [-0.62911229, -0.49797951,  0.24454919],\n",
            "       [-0.38494715, -0.95734304,  0.84378794],\n",
            "       [-0.83536774,  0.29347368,  1.33444067],\n",
            "       [-0.48873332,  1.6821597 , -0.87065875],\n",
            "       [ 0.49785766, -0.50059035,  1.39092028],\n",
            "       [ 2.05499204,  0.53226236, -1.3236699 ],\n",
            "       [ 1.04632081,  0.5087837 , -0.43143791],\n",
            "       [-0.06415189, -0.04646157,  1.08402583],\n",
            "       [-1.14587692,  0.28366376, -1.42670437],\n",
            "       [-0.71414908, -0.10834585, -1.10571681],\n",
            "       [-0.48081469, -0.57188288,  0.29810572],\n",
            "       [-1.11198913,  1.61718388, -2.0673696 ],\n",
            "       [-0.17335241,  1.29312229,  2.23244701],\n",
            "       [-1.77576666,  0.00519575,  0.64220617],\n",
            "       [-0.05917629,  0.44951301,  0.14550145],\n",
            "       [-0.9021952 ,  0.13372589,  1.51512749],\n",
            "       [ 0.84251877,  0.21802816, -0.87220702],\n",
            "       [-0.04508411,  1.64485712,  1.0467005 ],\n",
            "       [ 0.63878731, -2.30086042, -0.12049271],\n",
            "       [ 1.0776905 , -0.16970561, -0.93971813],\n",
            "       [-0.41692465,  1.11872571,  0.03333225],\n",
            "       [ 1.70469431,  0.82559349,  0.27523557],\n",
            "       [ 0.3436325 ,  0.04118471, -3.89086165],\n",
            "       [-0.24570041, -1.52188303,  0.63525469]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717,  0.67502741,\n",
            "       -1.17385102, -1.86365186,  1.10326626, -1.17237151, -0.35479177,\n",
            "       -3.60141524,  1.08799951,  1.49465107]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.99370973 0.94109038 1.09564384]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  1.6751434854860934\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1]\n",
            "S dataset \n",
            " [[1.01846677 0.         0.        ]\n",
            " [0.         0.95983816 0.        ]\n",
            " [0.         0.         0.96929569]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (48, 3)\n",
            "y_train length  48\n",
            "-------> size test:  20000  , size train:  48 nbr_seen (train):  17  nbr_miss :  31\n",
            "X  48   3\n",
            "y shape (48,)\n",
            "nm  144\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 111.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.05699195314454706\n",
            "---------------------------------> best coeff  [-1.43950509 -1.00622581 -0.2941482 ]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.99370973 0.94109038 1.09564384]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -9.277980131285391\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.99370973 0.         0.        ]\n",
            " [0.         0.94109038 0.        ]\n",
            " [0.         0.         1.09564384]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (48, 3)\n",
            "y_train length  48\n",
            "-------> size test:  20000  , size train:  48 nbr_seen (train):  48  nbr_miss :  0\n",
            "X  48   3\n",
            "y shape (48,)\n",
            "nm  144\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 105.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  2.0557854585767778e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.99370973 0.94109038 1.09564384]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  1.6751434854860934\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1]\n",
            "S dataset \n",
            " [[1.01846677 0.         0.        ]\n",
            " [0.         0.95983816 0.        ]\n",
            " [0.         0.         0.96929569]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (48, 3)\n",
            "y_train length  48\n",
            "-------> size test:  20000  , size train:  48 nbr_seen (train):  17  nbr_miss :  31\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01846677 0.         0.        ]\n",
            " [0.         0.95983816 0.        ]\n",
            " [0.         0.         0.96929569]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98186807 0.         0.        ]\n",
            " [0.         1.0418423  0.        ]\n",
            " [0.         0.         1.03167693]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 508.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.05698784467098297\n",
            "---------------------------------> best coeff  [-1.43955701 -1.00633719 -0.29418459]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.99370973 0.94109038 1.09564384]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  17.922067353324884\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1]\n",
            "S dataset \n",
            " [[1.01846677 0.         0.        ]\n",
            " [0.         0.95983816 0.        ]\n",
            " [0.         0.         0.96929569]]\n",
            "S missing shape\n",
            "  (48, 3, 3)\n",
            "S missing\n",
            "  [[[0.88595566 0.         0.        ]\n",
            "  [0.         0.87133143 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.25826273 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61370346 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.98289134]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94123863 0.         0.        ]\n",
            "  [0.         1.1773196  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72316618 0.        ]\n",
            "  [0.         0.         0.57998378]]\n",
            "\n",
            " [[0.94441208 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.4220555 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93343723 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49514285 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02412125]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.88682171]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79364638]]\n",
            "\n",
            " [[0.63493637 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53738602]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06218801 0.        ]\n",
            "  [0.         0.         0.59646214]]\n",
            "\n",
            " [[1.10815708 0.         0.        ]\n",
            "  [0.         1.23636793 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.38593724]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.37499946 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3119724  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47130153 0.        ]\n",
            "  [0.         0.         1.24249772]]\n",
            "\n",
            " [[0.56076853 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.51631072 0.        ]\n",
            "  [0.         0.         0.16206862]]\n",
            "\n",
            " [[1.2980639  0.         0.        ]\n",
            "  [0.         1.25961813 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75654328 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.61774034 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89047382 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.51893817 0.         0.        ]\n",
            "  [0.         0.62609831 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.45777019 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.27674822 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.4774126  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3513374  0.         0.        ]\n",
            "  [0.         0.40414422 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09097206]]\n",
            "\n",
            " [[0.62434185 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 48, 3)\n",
            "y_train length  48\n",
            "-------> size test:  20000  , size train:  48 nbr_seen (train):  17  nbr_miss :  31\n",
            "X  48   3\n",
            "y shape (48,)\n",
            "nm  144\n",
            "S_mis in Adbvt training  [[[0.88595566 0.         0.        ]\n",
            "  [0.         0.87133143 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.25826273 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61370346 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.98289134]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94123863 0.         0.        ]\n",
            "  [0.         1.1773196  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72316618 0.        ]\n",
            "  [0.         0.         0.57998378]]\n",
            "\n",
            " [[0.94441208 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.4220555 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93343723 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49514285 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02412125]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.88682171]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79364638]]\n",
            "\n",
            " [[0.63493637 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53738602]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06218801 0.        ]\n",
            "  [0.         0.         0.59646214]]\n",
            "\n",
            " [[1.10815708 0.         0.        ]\n",
            "  [0.         1.23636793 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.38593724]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.37499946 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3119724  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47130153 0.        ]\n",
            "  [0.         0.         1.24249772]]\n",
            "\n",
            " [[0.56076853 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.51631072 0.        ]\n",
            "  [0.         0.         0.16206862]]\n",
            "\n",
            " [[1.2980639  0.         0.        ]\n",
            "  [0.         1.25961813 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75654328 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.61774034 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89047382 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.51893817 0.         0.        ]\n",
            "  [0.         0.62609831 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.45777019 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.27674822 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.4774126  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3513374  0.         0.        ]\n",
            "  [0.         0.40414422 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09097206]]\n",
            "\n",
            " [[0.62434185 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.02 0.00 0.00]\n",
            " [0.00 0.96 0.00]\n",
            " ...\n",
            " [0.00 0.96 0.00]\n",
            " [0.00 0.00 0.97]] @ Promote(adv_radius_times_dts, (144, 3)) + [[0.89 0.00 0.00]\n",
            " [0.00 0.87 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (144, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 131.20it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:03,  6.32it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 129.67it/s]\n",
            " 10%|█         | 2/20 [00:00<00:02,  6.24it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 136.82it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:02,  6.33it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 123.20it/s]\n",
            " 20%|██        | 4/20 [00:00<00:02,  6.09it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 121.93it/s]\n",
            " 25%|██▌       | 5/20 [00:00<00:02,  5.94it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 112.05it/s]\n",
            " 30%|███       | 6/20 [00:01<00:02,  5.76it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 121.62it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:02,  5.75it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 123.93it/s]\n",
            " 40%|████      | 8/20 [00:01<00:02,  5.82it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 122.65it/s]\n",
            " 45%|████▌     | 9/20 [00:01<00:01,  5.85it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 140.64it/s]\n",
            " 50%|█████     | 10/20 [00:01<00:01,  6.12it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 141.62it/s]\n",
            " 55%|█████▌    | 11/20 [00:01<00:01,  6.30it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 130.82it/s]\n",
            " 60%|██████    | 12/20 [00:01<00:01,  6.28it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 131.39it/s]\n",
            " 65%|██████▌   | 13/20 [00:02<00:01,  6.31it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 144.28it/s]\n",
            " 70%|███████   | 14/20 [00:02<00:00,  6.46it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 138.83it/s]\n",
            " 75%|███████▌  | 15/20 [00:02<00:00,  6.49it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 130.98it/s]\n",
            " 80%|████████  | 16/20 [00:02<00:00,  6.44it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 122.61it/s]\n",
            " 85%|████████▌ | 17/20 [00:02<00:00,  6.29it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 125.46it/s]\n",
            " 90%|█████████ | 18/20 [00:02<00:00,  6.22it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 115.11it/s]\n",
            " 95%|█████████▌| 19/20 [00:03<00:00,  6.01it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 129.97it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.14314647880757098\n",
            "---------------------------------> best coeff  [-1.26644504 -0.85125315 -0.27002656]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.99370973 0.94109038 1.09564384]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  17.922067353324884\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1]\n",
            "S dataset \n",
            " [[1.01846677 0.         0.        ]\n",
            " [0.         0.95983816 0.        ]\n",
            " [0.         0.         0.96929569]]\n",
            "S missing shape\n",
            "  (48, 3, 3)\n",
            "S missing\n",
            "  [[[0.88595566 0.         0.        ]\n",
            "  [0.         0.87133143 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.25826273 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61370346 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.98289134]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94123863 0.         0.        ]\n",
            "  [0.         1.1773196  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72316618 0.        ]\n",
            "  [0.         0.         0.57998378]]\n",
            "\n",
            " [[0.94441208 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.4220555 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93343723 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49514285 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02412125]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.88682171]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79364638]]\n",
            "\n",
            " [[0.63493637 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53738602]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06218801 0.        ]\n",
            "  [0.         0.         0.59646214]]\n",
            "\n",
            " [[1.10815708 0.         0.        ]\n",
            "  [0.         1.23636793 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.38593724]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.37499946 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3119724  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47130153 0.        ]\n",
            "  [0.         0.         1.24249772]]\n",
            "\n",
            " [[0.56076853 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.51631072 0.        ]\n",
            "  [0.         0.         0.16206862]]\n",
            "\n",
            " [[1.2980639  0.         0.        ]\n",
            "  [0.         1.25961813 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75654328 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.61774034 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89047382 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.51893817 0.         0.        ]\n",
            "  [0.         0.62609831 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.45777019 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.27674822 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.4774126  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3513374  0.         0.        ]\n",
            "  [0.         0.40414422 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09097206]]\n",
            "\n",
            " [[0.62434185 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 48, 3)\n",
            "y_train length  48\n",
            "-------> size test:  20000  , size train:  48 nbr_seen (train):  17  nbr_miss :  31\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01846677 0.         0.        ]\n",
            " [0.         0.95983816 0.        ]\n",
            " [0.         0.         0.96929569]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98186807 0.         0.        ]\n",
            " [0.         1.0418423  0.        ]\n",
            " [0.         0.         1.03167693]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1076.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.1429710880583534\n",
            "---------------------------------> best coeff  [-1.26658299 -0.85149517 -0.27020702]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  2\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20060, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   60\n",
            "X shape in clear data  (60, 3)\n",
            "y shape in clear data  (60,)\n",
            "M shape in clear data  (60,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(58, 3)\n",
            "(58, 3)\n",
            "(58,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.34874672,  0.12880878, -0.39575018],\n",
            "       [ 2.03440496, -0.7364663 ,  0.14765257],\n",
            "       [-1.93805473, -1.32668622,  0.27603886],\n",
            "       [ 0.61042982,  0.00459682,  0.19170315],\n",
            "       [ 0.94365935, -1.43434126,  0.50645103],\n",
            "       [-0.42403535, -0.93576142, -0.63184545],\n",
            "       [-1.08349271, -0.290857  , -0.32209072],\n",
            "       [ 0.02226566,  0.3094647 ,  1.72254516],\n",
            "       [ 0.60875449, -0.78748954, -0.10980159],\n",
            "       [-0.67462106,  0.7586794 , -1.83572918],\n",
            "       [ 0.58004405,  1.16777225, -0.6712442 ],\n",
            "       [-2.29258519,  0.93508287, -0.24557696],\n",
            "       [ 0.93604723,  0.92081444, -1.00230523],\n",
            "       [-1.38463222,  0.10993258, -0.38392901],\n",
            "       [-0.48108551, -0.55581083,  1.15487716],\n",
            "       [-0.2707817 , -1.25445809,  0.53489175],\n",
            "       [ 1.82509762, -0.52616778,  0.5021699 ],\n",
            "       [ 0.3828516 ,  0.14180845, -1.08295106],\n",
            "       [-1.47459168,  0.79466499, -1.37292582],\n",
            "       [-0.67967491,  1.47588969, -1.04401964],\n",
            "       [-0.19533168, -1.69187442, -0.35776372],\n",
            "       [ 0.87891938,  0.14482416,  0.58110269],\n",
            "       [ 0.61965983,  0.1655677 , -0.57654715],\n",
            "       [ 0.44850941, -1.66036407, -0.74194324],\n",
            "       [-0.62911229, -0.49797951,  0.24454919],\n",
            "       [-0.38494715, -0.95734304,  0.84378794],\n",
            "       [-0.83536774,  0.29347368,  1.33444067],\n",
            "       [-0.48873332,  1.6821597 , -0.87065875],\n",
            "       [ 0.49785766, -0.50059035,  1.39092028],\n",
            "       [ 2.05499204,  0.53226236, -1.3236699 ],\n",
            "       [ 1.04632081,  0.5087837 , -0.43143791],\n",
            "       [-0.06415189, -0.04646157,  1.08402583],\n",
            "       [-1.14587692,  0.28366376, -1.42670437],\n",
            "       [-0.71414908, -0.10834585, -1.10571681],\n",
            "       [-0.48081469, -0.57188288,  0.29810572],\n",
            "       [-1.11198913,  1.61718388, -2.0673696 ],\n",
            "       [-0.17335241,  1.29312229,  2.23244701],\n",
            "       [-1.77576666,  0.00519575,  0.64220617],\n",
            "       [-0.05917629,  0.44951301,  0.14550145],\n",
            "       [-0.9021952 ,  0.13372589,  1.51512749],\n",
            "       [ 0.84251877,  0.21802816, -0.87220702],\n",
            "       [-0.04508411,  1.64485712,  1.0467005 ],\n",
            "       [ 0.63878731, -2.30086042, -0.12049271],\n",
            "       [ 1.0776905 , -0.16970561, -0.93971813],\n",
            "       [-0.41692465,  1.11872571,  0.03333225],\n",
            "       [ 1.70469431,  0.82559349,  0.27523557],\n",
            "       [ 0.3436325 ,  0.04118471, -3.89086165],\n",
            "       [-0.24570041, -1.52188303,  0.63525469],\n",
            "       [-0.29604848, -2.69646068,  0.75198107],\n",
            "       [ 0.54570934, -0.97044372, -2.57180436],\n",
            "       [-1.61543695, -0.39002212, -1.13991388],\n",
            "       [-0.35979717,  0.57655519,  0.39205486],\n",
            "       [-0.779612  ,  2.23910082, -1.41590718],\n",
            "       [ 0.19919213,  1.98055456, -1.20305637],\n",
            "       [-2.3567142 , -1.03140696, -0.49500531],\n",
            "       [-1.40918128,  1.58020401, -0.54114835],\n",
            "       [ 0.63700524, -1.24153146, -0.72254212],\n",
            "       [-1.45747496, -0.52369234, -0.0394866 ]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717,  0.67502741,\n",
            "       -1.17385102, -1.86365186,  1.10326626, -1.17237151, -0.35479177,\n",
            "       -3.60141524,  1.08799951,  1.49465107,  2.58555405,  1.10822697,\n",
            "        3.43755015, -0.11169254, -0.15916623, -1.58930837,  4.92898055,\n",
            "        1.06961998,  0.40929708,  2.83026505]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01558565 1.06280774 1.08687623]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -3.9678091060020373\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1]\n",
            "S dataset \n",
            " [[1.04359878 0.         0.        ]\n",
            " [0.         1.1339784  0.        ]\n",
            " [0.         0.         0.94741028]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (58, 3)\n",
            "y_train length  58\n",
            "-------> size test:  20000  , size train:  58 nbr_seen (train):  20  nbr_miss :  38\n",
            "X  58   3\n",
            "y shape (58,)\n",
            "nm  174\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 152.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.018772629180271474\n",
            "---------------------------------> best coeff  [-1.56085873 -0.87593397 -0.30435686]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01558565 1.06280774 1.08687623]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -23.632309390050203\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.01558565 0.         0.        ]\n",
            " [0.         1.06280774 0.        ]\n",
            " [0.         0.         1.08687623]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (58, 3)\n",
            "y_train length  58\n",
            "-------> size test:  20000  , size train:  58 nbr_seen (train):  58  nbr_miss :  0\n",
            "X  58   3\n",
            "y shape (58,)\n",
            "nm  174\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 146.56it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  8.860410440719698e-22\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01558565 1.06280774 1.08687623]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -3.9678091060020373\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1]\n",
            "S dataset \n",
            " [[1.04359878 0.         0.        ]\n",
            " [0.         1.1339784  0.        ]\n",
            " [0.         0.         0.94741028]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (58, 3)\n",
            "y_train length  58\n",
            "-------> size test:  20000  , size train:  58 nbr_seen (train):  20  nbr_miss :  38\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.04359878 0.         0.        ]\n",
            " [0.         1.1339784  0.        ]\n",
            " [0.         0.         0.94741028]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.95822266 0.         0.        ]\n",
            " [0.         0.88185101 0.        ]\n",
            " [0.         0.         1.05550891]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1002.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.018767539488994768\n",
            "---------------------------------> best coeff  [-1.56093688 -0.87600319 -0.30433412]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01558565 1.06280774 1.08687623]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -4.785322158968148\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1]\n",
            "S dataset \n",
            " [[1.04359878 0.         0.        ]\n",
            " [0.         1.1339784  0.        ]\n",
            " [0.         0.         0.94741028]]\n",
            "S missing shape\n",
            "  (58, 3, 3)\n",
            "S missing\n",
            "  [[[1.63515252 0.         0.        ]\n",
            "  [0.         0.66927806 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96339764 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63151735 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.85653161]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.73574872 0.         0.        ]\n",
            "  [0.         1.17338614 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94762561 0.        ]\n",
            "  [0.         0.         1.01735335]]\n",
            "\n",
            " [[1.03388156 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87012102]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68061194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.59044625 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8499413 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99636488]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.01364628]]\n",
            "\n",
            " [[1.3695934  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.38902518]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98324889 0.        ]\n",
            "  [0.         0.         1.12700711]]\n",
            "\n",
            " [[0.63118411 0.         0.        ]\n",
            "  [0.         0.78626805 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53422442]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.64623386 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.85920852 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.35650877 0.        ]\n",
            "  [0.         0.         0.51725375]]\n",
            "\n",
            " [[1.4376108  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72050408 0.        ]\n",
            "  [0.         0.         0.38320813]]\n",
            "\n",
            " [[0.33214254 0.         0.        ]\n",
            "  [0.         0.69198256 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77755682 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.05502966 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.65180795 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89439535 0.         0.        ]\n",
            "  [0.         1.12444005 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74042962 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8620278  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77330547 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.82152989 0.         0.        ]\n",
            "  [0.         0.83070753 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.51876779]]\n",
            "\n",
            " [[0.76639993 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96961326]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.45404261]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91501656]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.28190908 0.        ]\n",
            "  [0.         0.         0.62041578]]\n",
            "\n",
            " [[1.17206143 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6775275 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.75907878]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93853908 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 58, 3)\n",
            "y_train length  58\n",
            "-------> size test:  20000  , size train:  58 nbr_seen (train):  20  nbr_miss :  38\n",
            "X  58   3\n",
            "y shape (58,)\n",
            "nm  174\n",
            "S_mis in Adbvt training  [[[1.63515252 0.         0.        ]\n",
            "  [0.         0.66927806 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96339764 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63151735 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.85653161]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.73574872 0.         0.        ]\n",
            "  [0.         1.17338614 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94762561 0.        ]\n",
            "  [0.         0.         1.01735335]]\n",
            "\n",
            " [[1.03388156 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87012102]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68061194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.59044625 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8499413 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99636488]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.01364628]]\n",
            "\n",
            " [[1.3695934  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.38902518]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98324889 0.        ]\n",
            "  [0.         0.         1.12700711]]\n",
            "\n",
            " [[0.63118411 0.         0.        ]\n",
            "  [0.         0.78626805 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53422442]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.64623386 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.85920852 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.35650877 0.        ]\n",
            "  [0.         0.         0.51725375]]\n",
            "\n",
            " [[1.4376108  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72050408 0.        ]\n",
            "  [0.         0.         0.38320813]]\n",
            "\n",
            " [[0.33214254 0.         0.        ]\n",
            "  [0.         0.69198256 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77755682 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.05502966 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.65180795 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89439535 0.         0.        ]\n",
            "  [0.         1.12444005 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74042962 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8620278  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77330547 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.82152989 0.         0.        ]\n",
            "  [0.         0.83070753 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.51876779]]\n",
            "\n",
            " [[0.76639993 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96961326]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.45404261]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91501656]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.28190908 0.        ]\n",
            "  [0.         0.         0.62041578]]\n",
            "\n",
            " [[1.17206143 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6775275 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.75907878]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93853908 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.04 0.00 0.00]\n",
            " [0.00 1.13 0.00]\n",
            " ...\n",
            " [0.00 1.13 0.00]\n",
            " [0.00 0.00 0.95]] @ Promote(adv_radius_times_dts, (174, 3)) + [[1.64 0.00 0.00]\n",
            " [0.00 0.67 0.00]\n",
            " ...\n",
            " [0.00 0.94 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (174, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 98.48it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:03,  4.81it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 105.15it/s]\n",
            " 10%|█         | 2/20 [00:00<00:03,  4.99it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 111.78it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:03,  5.19it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 106.24it/s]\n",
            " 20%|██        | 4/20 [00:00<00:03,  5.16it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 97.86it/s] \n",
            " 25%|██▌       | 5/20 [00:00<00:02,  5.00it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 108.04it/s]\n",
            " 30%|███       | 6/20 [00:01<00:02,  5.09it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 100.95it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:02,  5.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 106.41it/s]\n",
            " 40%|████      | 8/20 [00:01<00:02,  5.07it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 105.21it/s]\n",
            " 45%|████▌     | 9/20 [00:01<00:02,  5.09it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 91.06it/s] \n",
            " 50%|█████     | 10/20 [00:02<00:02,  4.86it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 67.71it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 70.71it/s]\n",
            " 55%|█████▌    | 11/20 [00:02<00:02,  4.33it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 59.59it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.26it/s]\n",
            " 60%|██████    | 12/20 [00:02<00:02,  3.94it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 74.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 78.73it/s]\n",
            " 65%|██████▌   | 13/20 [00:02<00:01,  3.92it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 82.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 82.90it/s]\n",
            " 70%|███████   | 14/20 [00:03<00:01,  3.96it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.59it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 78.08it/s]\n",
            " 75%|███████▌  | 15/20 [00:03<00:01,  3.91it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.90it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 75.77it/s]\n",
            " 80%|████████  | 16/20 [00:03<00:01,  3.84it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 80.95it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 75.98it/s]\n",
            " 85%|████████▌ | 17/20 [00:03<00:00,  3.81it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.01it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 81.50it/s]\n",
            " 90%|█████████ | 18/20 [00:04<00:00,  3.87it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 74.23it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.63it/s]\n",
            " 95%|█████████▌| 19/20 [00:04<00:00,  3.79it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 67.09it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.50it/s]\n",
            "100%|██████████| 20/20 [00:04<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.04034378888854511\n",
            "---------------------------------> best coeff  [-1.47380579 -0.76181253 -0.37329275]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.01558565 1.06280774 1.08687623]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -4.785322158968148\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1]\n",
            "S dataset \n",
            " [[1.04359878 0.         0.        ]\n",
            " [0.         1.1339784  0.        ]\n",
            " [0.         0.         0.94741028]]\n",
            "S missing shape\n",
            "  (58, 3, 3)\n",
            "S missing\n",
            "  [[[1.63515252 0.         0.        ]\n",
            "  [0.         0.66927806 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96339764 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63151735 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.85653161]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.73574872 0.         0.        ]\n",
            "  [0.         1.17338614 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94762561 0.        ]\n",
            "  [0.         0.         1.01735335]]\n",
            "\n",
            " [[1.03388156 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87012102]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68061194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.59044625 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8499413 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99636488]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.01364628]]\n",
            "\n",
            " [[1.3695934  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.38902518]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98324889 0.        ]\n",
            "  [0.         0.         1.12700711]]\n",
            "\n",
            " [[0.63118411 0.         0.        ]\n",
            "  [0.         0.78626805 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53422442]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.64623386 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.85920852 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.35650877 0.        ]\n",
            "  [0.         0.         0.51725375]]\n",
            "\n",
            " [[1.4376108  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72050408 0.        ]\n",
            "  [0.         0.         0.38320813]]\n",
            "\n",
            " [[0.33214254 0.         0.        ]\n",
            "  [0.         0.69198256 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77755682 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.05502966 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.65180795 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89439535 0.         0.        ]\n",
            "  [0.         1.12444005 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74042962 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8620278  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77330547 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.82152989 0.         0.        ]\n",
            "  [0.         0.83070753 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.51876779]]\n",
            "\n",
            " [[0.76639993 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96961326]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.45404261]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91501656]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.28190908 0.        ]\n",
            "  [0.         0.         0.62041578]]\n",
            "\n",
            " [[1.17206143 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6775275 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.75907878]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93853908 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 58, 3)\n",
            "y_train length  58\n",
            "-------> size test:  20000  , size train:  58 nbr_seen (train):  20  nbr_miss :  38\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.04359878 0.         0.        ]\n",
            " [0.         1.1339784  0.        ]\n",
            " [0.         0.         0.94741028]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.95822266 0.         0.        ]\n",
            " [0.         0.88185101 0.        ]\n",
            " [0.         0.         1.05550891]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 887.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.04028077176201654\n",
            "---------------------------------> best coeff  [-1.47392779 -0.76187421 -0.37341093]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  3\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20070, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   70\n",
            "X shape in clear data  (70, 3)\n",
            "y shape in clear data  (70,)\n",
            "M shape in clear data  (70,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(67, 3)\n",
            "(67, 3)\n",
            "(67,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-3.48746721e-01,  1.28808784e-01, -3.95750178e-01],\n",
            "       [ 2.03440496e+00, -7.36466295e-01,  1.47652574e-01],\n",
            "       [-1.93805473e+00, -1.32668622e+00,  2.76038864e-01],\n",
            "       [ 6.10429821e-01,  4.59681822e-03,  1.91703154e-01],\n",
            "       [ 9.43659349e-01, -1.43434126e+00,  5.06451033e-01],\n",
            "       [-4.24035350e-01, -9.35761416e-01, -6.31845451e-01],\n",
            "       [-1.08349271e+00, -2.90856996e-01, -3.22090720e-01],\n",
            "       [ 2.22656584e-02,  3.09464699e-01,  1.72254516e+00],\n",
            "       [ 6.08754495e-01, -7.87489544e-01, -1.09801587e-01],\n",
            "       [-6.74621063e-01,  7.58679401e-01, -1.83572918e+00],\n",
            "       [ 5.80044053e-01,  1.16777225e+00, -6.71244196e-01],\n",
            "       [-2.29258519e+00,  9.35082875e-01, -2.45576960e-01],\n",
            "       [ 9.36047232e-01,  9.20814445e-01, -1.00230523e+00],\n",
            "       [-1.38463222e+00,  1.09932584e-01, -3.83929008e-01],\n",
            "       [-4.81085507e-01, -5.55810832e-01,  1.15487716e+00],\n",
            "       [-2.70781700e-01, -1.25445809e+00,  5.34891746e-01],\n",
            "       [ 1.82509762e+00, -5.26167778e-01,  5.02169903e-01],\n",
            "       [ 3.82851599e-01,  1.41808445e-01, -1.08295106e+00],\n",
            "       [-1.47459168e+00,  7.94664991e-01, -1.37292582e+00],\n",
            "       [-6.79674908e-01,  1.47588969e+00, -1.04401964e+00],\n",
            "       [-1.95331684e-01, -1.69187442e+00, -3.57763716e-01],\n",
            "       [ 8.78919379e-01,  1.44824160e-01,  5.81102688e-01],\n",
            "       [ 6.19659835e-01,  1.65567702e-01, -5.76547152e-01],\n",
            "       [ 4.48509413e-01, -1.66036407e+00, -7.41943240e-01],\n",
            "       [-6.29112294e-01, -4.97979506e-01,  2.44549191e-01],\n",
            "       [-3.84947154e-01, -9.57343038e-01,  8.43787942e-01],\n",
            "       [-8.35367742e-01,  2.93473681e-01,  1.33444067e+00],\n",
            "       [-4.88733325e-01,  1.68215970e+00, -8.70658747e-01],\n",
            "       [ 4.97857663e-01, -5.00590347e-01,  1.39092028e+00],\n",
            "       [ 2.05499204e+00,  5.32262359e-01, -1.32366990e+00],\n",
            "       [ 1.04632081e+00,  5.08783702e-01, -4.31437912e-01],\n",
            "       [-6.41518926e-02, -4.64615690e-02,  1.08402583e+00],\n",
            "       [-1.14587692e+00,  2.83663759e-01, -1.42670437e+00],\n",
            "       [-7.14149078e-01, -1.08345853e-01, -1.10571681e+00],\n",
            "       [-4.80814685e-01, -5.71882880e-01,  2.98105722e-01],\n",
            "       [-1.11198913e+00,  1.61718388e+00, -2.06736960e+00],\n",
            "       [-1.73352405e-01,  1.29312229e+00,  2.23244701e+00],\n",
            "       [-1.77576666e+00,  5.19574843e-03,  6.42206169e-01],\n",
            "       [-5.91762866e-02,  4.49513012e-01,  1.45501445e-01],\n",
            "       [-9.02195198e-01,  1.33725890e-01,  1.51512749e+00],\n",
            "       [ 8.42518775e-01,  2.18028158e-01, -8.72207018e-01],\n",
            "       [-4.50841079e-02,  1.64485712e+00,  1.04670050e+00],\n",
            "       [ 6.38787307e-01, -2.30086042e+00, -1.20492708e-01],\n",
            "       [ 1.07769050e+00, -1.69705608e-01, -9.39718127e-01],\n",
            "       [-4.16924652e-01,  1.11872571e+00,  3.33322533e-02],\n",
            "       [ 1.70469431e+00,  8.25593492e-01,  2.75235573e-01],\n",
            "       [ 3.43632502e-01,  4.11847054e-02, -3.89086165e+00],\n",
            "       [-2.45700412e-01, -1.52188303e+00,  6.35254694e-01],\n",
            "       [-2.96048476e-01, -2.69646068e+00,  7.51981074e-01],\n",
            "       [ 5.45709338e-01, -9.70443716e-01, -2.57180436e+00],\n",
            "       [-1.61543695e+00, -3.90022124e-01, -1.13991388e+00],\n",
            "       [-3.59797168e-01,  5.76555194e-01,  3.92054859e-01],\n",
            "       [-7.79611999e-01,  2.23910082e+00, -1.41590718e+00],\n",
            "       [ 1.99192128e-01,  1.98055456e+00, -1.20305637e+00],\n",
            "       [-2.35671420e+00, -1.03140696e+00, -4.95005310e-01],\n",
            "       [-1.40918128e+00,  1.58020401e+00, -5.41148354e-01],\n",
            "       [ 6.37005237e-01, -1.24153146e+00, -7.22542121e-01],\n",
            "       [-1.45747496e+00, -5.23692341e-01, -3.94865956e-02],\n",
            "       [-1.42002673e+00, -6.72689764e-01,  2.94568125e-03],\n",
            "       [-7.04493429e-01,  3.60823485e-01, -1.22701075e+00],\n",
            "       [-4.41663638e-01,  2.92399455e-01, -9.74306359e-02],\n",
            "       [-4.79408753e-01,  6.12078472e-01, -2.52772755e+00],\n",
            "       [ 7.23655143e-01,  4.91772765e-01,  3.45253083e-01],\n",
            "       [-1.04797989e+00, -7.24880029e-01, -7.68947790e-01],\n",
            "       [ 6.51624311e-01, -1.91806039e+00,  1.25976458e+00],\n",
            "       [-1.65118789e-01, -7.74970608e-01,  8.44948048e-01],\n",
            "       [ 3.67386128e-01,  1.09695228e+00,  9.13658362e-01]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717,  0.67502741,\n",
            "       -1.17385102, -1.86365186,  1.10326626, -1.17237151, -0.35479177,\n",
            "       -3.60141524,  1.08799951,  1.49465107,  2.58555405,  1.10822697,\n",
            "        3.43755015, -0.11169254, -0.15916623, -1.58930837,  4.92898055,\n",
            "        1.06961998,  0.40929708,  2.83026505,  2.88634927,  1.33442305,\n",
            "        0.48726981,  1.30677088, -1.7548376 ,  2.66870908,  0.14217093,\n",
            "        0.60058679, -1.97404546]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9801693  1.04211132 1.09379743]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -4.069736670952668\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0]\n",
            "S dataset \n",
            " [[0.99993376 0.         0.        ]\n",
            " [0.         1.1014859  0.        ]\n",
            " [0.         0.         0.92574732]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (67, 3)\n",
            "y_train length  67\n",
            "-------> size test:  20000  , size train:  67 nbr_seen (train):  25  nbr_miss :  42\n",
            "X  67   3\n",
            "y shape (67,)\n",
            "nm  201\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 101.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  7  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00695193 0.        ] , min score  0.010843420618185466\n",
            "---------------------------------> best coeff  [-1.60097172 -0.86520544 -0.33421176]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9801693  1.04211132 1.09379743]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -28.63945633688823\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.9801693  0.         0.        ]\n",
            " [0.         1.04211132 0.        ]\n",
            " [0.         0.         1.09379743]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (67, 3)\n",
            "y_train length  67\n",
            "-------> size test:  20000  , size train:  67 nbr_seen (train):  67  nbr_miss :  0\n",
            "X  67   3\n",
            "y shape (67,)\n",
            "nm  201\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 48.09it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.0366490448101213e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9801693  1.04211132 1.09379743]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -4.069736670952668\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0]\n",
            "S dataset \n",
            " [[0.99993376 0.         0.        ]\n",
            " [0.         1.1014859  0.        ]\n",
            " [0.         0.         0.92574732]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (67, 3)\n",
            "y_train length  67\n",
            "-------> size test:  20000  , size train:  67 nbr_seen (train):  25  nbr_miss :  42\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.99993376 0.         0.        ]\n",
            " [0.         1.1014859  0.        ]\n",
            " [0.         0.         0.92574732]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.00006625 0.         0.        ]\n",
            " [0.         0.90786455 0.        ]\n",
            " [0.         0.         1.08020836]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 603.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.010950628809399983\n",
            "---------------------------------> best coeff  [-1.6048729  -0.8676055  -0.33263177]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9801693  1.04211132 1.09379743]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.965087041361572\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0]\n",
            "S dataset \n",
            " [[0.99993376 0.         0.        ]\n",
            " [0.         1.1014859  0.        ]\n",
            " [0.         0.         0.92574732]]\n",
            "S missing shape\n",
            "  (67, 3, 3)\n",
            "S missing\n",
            "  [[[0.89531175 0.         0.        ]\n",
            "  [0.         0.79303595 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.34154847 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84080355 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.32253679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.6367622  0.         0.        ]\n",
            "  [0.         1.10816807 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.50612657 0.        ]\n",
            "  [0.         0.         0.54779166]]\n",
            "\n",
            " [[1.04071565 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.08963498]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.74143325 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61053232 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.64566861]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.24207936]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62633791]]\n",
            "\n",
            " [[1.09834705 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7038948 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.44024769 0.        ]\n",
            "  [0.         0.         0.90632731]]\n",
            "\n",
            " [[0.22201392 0.         0.        ]\n",
            "  [0.         1.28678148 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.23516359]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72068324 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84489233 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.82738428 0.        ]\n",
            "  [0.         0.         1.17469161]]\n",
            "\n",
            " [[0.80290248 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.157395   0.        ]\n",
            "  [0.         0.         0.73232707]]\n",
            "\n",
            " [[1.13965389 0.         0.        ]\n",
            "  [0.         0.92600863 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.11903977 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11639437 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.58650214 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.55263106 0.         0.        ]\n",
            "  [0.         0.78160263 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06710388 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8929119  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.84897226 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63411628 0.         0.        ]\n",
            "  [0.         0.3352325  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.638264  ]]\n",
            "\n",
            " [[0.94345852 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.71310667]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81914027]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99589715]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.99627277 0.        ]\n",
            "  [0.         0.         0.90071361]]\n",
            "\n",
            " [[0.68789431 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.36081622]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00481732]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54564185 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.65266561 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.64650715 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.36255305]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.30888211]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 67, 3)\n",
            "y_train length  67\n",
            "-------> size test:  20000  , size train:  67 nbr_seen (train):  25  nbr_miss :  42\n",
            "X  67   3\n",
            "y shape (67,)\n",
            "nm  201\n",
            "S_mis in Adbvt training  [[[0.89531175 0.         0.        ]\n",
            "  [0.         0.79303595 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.34154847 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84080355 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.32253679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.6367622  0.         0.        ]\n",
            "  [0.         1.10816807 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.50612657 0.        ]\n",
            "  [0.         0.         0.54779166]]\n",
            "\n",
            " [[1.04071565 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.08963498]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.74143325 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61053232 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.64566861]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.24207936]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62633791]]\n",
            "\n",
            " [[1.09834705 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7038948 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.44024769 0.        ]\n",
            "  [0.         0.         0.90632731]]\n",
            "\n",
            " [[0.22201392 0.         0.        ]\n",
            "  [0.         1.28678148 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.23516359]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72068324 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84489233 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.82738428 0.        ]\n",
            "  [0.         0.         1.17469161]]\n",
            "\n",
            " [[0.80290248 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.157395   0.        ]\n",
            "  [0.         0.         0.73232707]]\n",
            "\n",
            " [[1.13965389 0.         0.        ]\n",
            "  [0.         0.92600863 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.11903977 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11639437 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.58650214 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.55263106 0.         0.        ]\n",
            "  [0.         0.78160263 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06710388 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8929119  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.84897226 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63411628 0.         0.        ]\n",
            "  [0.         0.3352325  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.638264  ]]\n",
            "\n",
            " [[0.94345852 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.71310667]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81914027]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99589715]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.99627277 0.        ]\n",
            "  [0.         0.         0.90071361]]\n",
            "\n",
            " [[0.68789431 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.36081622]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00481732]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54564185 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.65266561 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.64650715 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.36255305]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.30888211]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.00 0.00 0.00]\n",
            " [0.00 1.10 0.00]\n",
            " ...\n",
            " [0.00 1.10 0.00]\n",
            " [0.00 0.00 0.93]] @ Promote(adv_radius_times_dts, (201, 3)) + [[0.90 0.00 0.00]\n",
            " [0.00 0.79 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (201, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.29it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 86.02it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:04,  4.22it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 87.01it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 88.88it/s]\n",
            " 10%|█         | 2/20 [00:00<00:04,  4.28it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 94.01it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 92.70it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:03,  4.39it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 92.04it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 85.87it/s]\n",
            " 20%|██        | 4/20 [00:00<00:03,  4.32it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 85.44it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 94.63it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:03,  4.40it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 87.77it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 95.03it/s]\n",
            " 30%|███       | 6/20 [00:01<00:03,  4.47it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.87it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 95.56it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:02,  4.53it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 96.12it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 94.97it/s]\n",
            " 40%|████      | 8/20 [00:01<00:02,  4.56it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 84.32it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 87.14it/s]\n",
            " 45%|████▌     | 9/20 [00:02<00:02,  4.46it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.60it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 86.30it/s]\n",
            " 50%|█████     | 10/20 [00:02<00:02,  4.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.67it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 86.66it/s]\n",
            " 55%|█████▌    | 11/20 [00:02<00:02,  4.33it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 85.35it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 83.22it/s]\n",
            " 60%|██████    | 12/20 [00:02<00:01,  4.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 87.50it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 79.26it/s]\n",
            " 65%|██████▌   | 13/20 [00:03<00:01,  4.12it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.63it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.67it/s]\n",
            " 70%|███████   | 14/20 [00:03<00:01,  4.21it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 89.15it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 87.37it/s]\n",
            " 75%|███████▌  | 15/20 [00:03<00:01,  4.23it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 96.82it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 96.18it/s]\n",
            " 80%|████████  | 16/20 [00:03<00:00,  4.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 86.56it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.22it/s]\n",
            " 85%|████████▌ | 17/20 [00:03<00:00,  4.35it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 85.29it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 86.91it/s]\n",
            " 90%|█████████ | 18/20 [00:04<00:00,  4.32it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 95.33it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 94.91it/s]\n",
            " 95%|█████████▌| 19/20 [00:04<00:00,  4.41it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 86.42it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.52it/s]\n",
            "100%|██████████| 20/20 [00:04<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.04866470214825213\n",
            "---------------------------------> best coeff  [-1.48000339 -0.84744845 -0.25830443]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9801693  1.04211132 1.09379743]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.965087041361572\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0]\n",
            "S dataset \n",
            " [[0.99993376 0.         0.        ]\n",
            " [0.         1.1014859  0.        ]\n",
            " [0.         0.         0.92574732]]\n",
            "S missing shape\n",
            "  (67, 3, 3)\n",
            "S missing\n",
            "  [[[0.89531175 0.         0.        ]\n",
            "  [0.         0.79303595 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.34154847 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84080355 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.32253679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.6367622  0.         0.        ]\n",
            "  [0.         1.10816807 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.50612657 0.        ]\n",
            "  [0.         0.         0.54779166]]\n",
            "\n",
            " [[1.04071565 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.08963498]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.74143325 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61053232 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.64566861]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.24207936]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62633791]]\n",
            "\n",
            " [[1.09834705 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7038948 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.44024769 0.        ]\n",
            "  [0.         0.         0.90632731]]\n",
            "\n",
            " [[0.22201392 0.         0.        ]\n",
            "  [0.         1.28678148 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.23516359]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72068324 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84489233 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.82738428 0.        ]\n",
            "  [0.         0.         1.17469161]]\n",
            "\n",
            " [[0.80290248 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.157395   0.        ]\n",
            "  [0.         0.         0.73232707]]\n",
            "\n",
            " [[1.13965389 0.         0.        ]\n",
            "  [0.         0.92600863 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.11903977 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11639437 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.58650214 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.55263106 0.         0.        ]\n",
            "  [0.         0.78160263 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06710388 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8929119  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.84897226 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63411628 0.         0.        ]\n",
            "  [0.         0.3352325  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.638264  ]]\n",
            "\n",
            " [[0.94345852 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.71310667]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81914027]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99589715]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.99627277 0.        ]\n",
            "  [0.         0.         0.90071361]]\n",
            "\n",
            " [[0.68789431 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.36081622]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00481732]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54564185 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.65266561 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.64650715 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.36255305]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.30888211]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 67, 3)\n",
            "y_train length  67\n",
            "-------> size test:  20000  , size train:  67 nbr_seen (train):  25  nbr_miss :  42\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.99993376 0.         0.        ]\n",
            " [0.         1.1014859  0.        ]\n",
            " [0.         0.         0.92574732]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.00006625 0.         0.        ]\n",
            " [0.         0.90786455 0.        ]\n",
            " [0.         0.         1.08020836]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1163.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.04861995504511866\n",
            "---------------------------------> best coeff  [-1.48005393 -0.84754852 -0.25836496]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  4\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20080, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   80\n",
            "X shape in clear data  (80, 3)\n",
            "y shape in clear data  (80,)\n",
            "M shape in clear data  (80,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(77, 3)\n",
            "(77, 3)\n",
            "(77,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-3.48746721e-01,  1.28808784e-01, -3.95750178e-01],\n",
            "       [ 2.03440496e+00, -7.36466295e-01,  1.47652574e-01],\n",
            "       [-1.93805473e+00, -1.32668622e+00,  2.76038864e-01],\n",
            "       [ 6.10429821e-01,  4.59681822e-03,  1.91703154e-01],\n",
            "       [ 9.43659349e-01, -1.43434126e+00,  5.06451033e-01],\n",
            "       [-4.24035350e-01, -9.35761416e-01, -6.31845451e-01],\n",
            "       [-1.08349271e+00, -2.90856996e-01, -3.22090720e-01],\n",
            "       [ 2.22656584e-02,  3.09464699e-01,  1.72254516e+00],\n",
            "       [ 6.08754495e-01, -7.87489544e-01, -1.09801587e-01],\n",
            "       [-6.74621063e-01,  7.58679401e-01, -1.83572918e+00],\n",
            "       [ 5.80044053e-01,  1.16777225e+00, -6.71244196e-01],\n",
            "       [-2.29258519e+00,  9.35082875e-01, -2.45576960e-01],\n",
            "       [ 9.36047232e-01,  9.20814445e-01, -1.00230523e+00],\n",
            "       [-1.38463222e+00,  1.09932584e-01, -3.83929008e-01],\n",
            "       [-4.81085507e-01, -5.55810832e-01,  1.15487716e+00],\n",
            "       [-2.70781700e-01, -1.25445809e+00,  5.34891746e-01],\n",
            "       [ 1.82509762e+00, -5.26167778e-01,  5.02169903e-01],\n",
            "       [ 3.82851599e-01,  1.41808445e-01, -1.08295106e+00],\n",
            "       [-1.47459168e+00,  7.94664991e-01, -1.37292582e+00],\n",
            "       [-6.79674908e-01,  1.47588969e+00, -1.04401964e+00],\n",
            "       [-1.95331684e-01, -1.69187442e+00, -3.57763716e-01],\n",
            "       [ 8.78919379e-01,  1.44824160e-01,  5.81102688e-01],\n",
            "       [ 6.19659835e-01,  1.65567702e-01, -5.76547152e-01],\n",
            "       [ 4.48509413e-01, -1.66036407e+00, -7.41943240e-01],\n",
            "       [-6.29112294e-01, -4.97979506e-01,  2.44549191e-01],\n",
            "       [-3.84947154e-01, -9.57343038e-01,  8.43787942e-01],\n",
            "       [-8.35367742e-01,  2.93473681e-01,  1.33444067e+00],\n",
            "       [-4.88733325e-01,  1.68215970e+00, -8.70658747e-01],\n",
            "       [ 4.97857663e-01, -5.00590347e-01,  1.39092028e+00],\n",
            "       [ 2.05499204e+00,  5.32262359e-01, -1.32366990e+00],\n",
            "       [ 1.04632081e+00,  5.08783702e-01, -4.31437912e-01],\n",
            "       [-6.41518926e-02, -4.64615690e-02,  1.08402583e+00],\n",
            "       [-1.14587692e+00,  2.83663759e-01, -1.42670437e+00],\n",
            "       [-7.14149078e-01, -1.08345853e-01, -1.10571681e+00],\n",
            "       [-4.80814685e-01, -5.71882880e-01,  2.98105722e-01],\n",
            "       [-1.11198913e+00,  1.61718388e+00, -2.06736960e+00],\n",
            "       [-1.73352405e-01,  1.29312229e+00,  2.23244701e+00],\n",
            "       [-1.77576666e+00,  5.19574843e-03,  6.42206169e-01],\n",
            "       [-5.91762866e-02,  4.49513012e-01,  1.45501445e-01],\n",
            "       [-9.02195198e-01,  1.33725890e-01,  1.51512749e+00],\n",
            "       [ 8.42518775e-01,  2.18028158e-01, -8.72207018e-01],\n",
            "       [-4.50841079e-02,  1.64485712e+00,  1.04670050e+00],\n",
            "       [ 6.38787307e-01, -2.30086042e+00, -1.20492708e-01],\n",
            "       [ 1.07769050e+00, -1.69705608e-01, -9.39718127e-01],\n",
            "       [-4.16924652e-01,  1.11872571e+00,  3.33322533e-02],\n",
            "       [ 1.70469431e+00,  8.25593492e-01,  2.75235573e-01],\n",
            "       [ 3.43632502e-01,  4.11847054e-02, -3.89086165e+00],\n",
            "       [-2.45700412e-01, -1.52188303e+00,  6.35254694e-01],\n",
            "       [-2.96048476e-01, -2.69646068e+00,  7.51981074e-01],\n",
            "       [ 5.45709338e-01, -9.70443716e-01, -2.57180436e+00],\n",
            "       [-1.61543695e+00, -3.90022124e-01, -1.13991388e+00],\n",
            "       [-3.59797168e-01,  5.76555194e-01,  3.92054859e-01],\n",
            "       [-7.79611999e-01,  2.23910082e+00, -1.41590718e+00],\n",
            "       [ 1.99192128e-01,  1.98055456e+00, -1.20305637e+00],\n",
            "       [-2.35671420e+00, -1.03140696e+00, -4.95005310e-01],\n",
            "       [-1.40918128e+00,  1.58020401e+00, -5.41148354e-01],\n",
            "       [ 6.37005237e-01, -1.24153146e+00, -7.22542121e-01],\n",
            "       [-1.45747496e+00, -5.23692341e-01, -3.94865956e-02],\n",
            "       [-1.42002673e+00, -6.72689764e-01,  2.94568125e-03],\n",
            "       [-7.04493429e-01,  3.60823485e-01, -1.22701075e+00],\n",
            "       [-4.41663638e-01,  2.92399455e-01, -9.74306359e-02],\n",
            "       [-4.79408753e-01,  6.12078472e-01, -2.52772755e+00],\n",
            "       [ 7.23655143e-01,  4.91772765e-01,  3.45253083e-01],\n",
            "       [-1.04797989e+00, -7.24880029e-01, -7.68947790e-01],\n",
            "       [ 6.51624311e-01, -1.91806039e+00,  1.25976458e+00],\n",
            "       [-1.65118789e-01, -7.74970608e-01,  8.44948048e-01],\n",
            "       [ 3.67386128e-01,  1.09695228e+00,  9.13658362e-01],\n",
            "       [-9.00484389e-02,  1.32622239e+00,  1.62079155e+00],\n",
            "       [ 4.89370112e-01,  1.66001818e+00, -1.08011411e+00],\n",
            "       [-6.34814654e-01, -3.73299892e-01, -2.51153507e+00],\n",
            "       [-1.15805819e+00, -6.47767715e-01, -1.71003728e+00],\n",
            "       [-1.97682929e-02,  5.44442063e-01,  3.72891542e-01],\n",
            "       [ 8.03633802e-01,  3.80742570e-01,  1.65852848e-01],\n",
            "       [ 5.21702786e-01, -6.08498627e-02,  4.97373451e-02],\n",
            "       [ 8.65184954e-01,  8.02307063e-01, -6.66455769e-01],\n",
            "       [ 1.43236249e-01, -1.95112945e-01, -6.23772791e-01],\n",
            "       [-1.29882434e+00, -7.99661257e-01,  1.05149617e+00]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717,  0.67502741,\n",
            "       -1.17385102, -1.86365186,  1.10326626, -1.17237151, -0.35479177,\n",
            "       -3.60141524,  1.08799951,  1.49465107,  2.58555405,  1.10822697,\n",
            "        3.43755015, -0.11169254, -0.15916623, -1.58930837,  4.92898055,\n",
            "        1.06961998,  0.40929708,  2.83026505,  2.88634927,  1.33442305,\n",
            "        0.48726981,  1.30677088, -1.7548376 ,  2.66870908,  0.14217093,\n",
            "        0.60058679, -1.97404546, -1.75123426, -1.81891073,  2.43890985,\n",
            "        3.18148252, -0.6204758 , -1.70571393, -0.80427769, -1.82639397,\n",
            "        0.21497736,  2.35440641]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.95275147 1.01704378 1.10661563]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -6.820845279466315\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0]\n",
            "S dataset \n",
            " [[0.9816231  0.         0.        ]\n",
            " [0.         1.08181588 0.        ]\n",
            " [0.         0.         0.99388567]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (77, 3)\n",
            "y_train length  77\n",
            "-------> size test:  20000  , size train:  77 nbr_seen (train):  27  nbr_miss :  50\n",
            "X  77   3\n",
            "y shape (77,)\n",
            "nm  231\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 115.53it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  9  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.02335721 0.        ] , min score  0.00021610004776895892\n",
            "---------------------------------> best coeff  [-1.60845561 -0.89861364 -0.41716899]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.95275147 1.01704378 1.10661563]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -29.711947311922334\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.95275147 0.         0.        ]\n",
            " [0.         1.01704378 0.        ]\n",
            " [0.         0.         1.10661563]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (77, 3)\n",
            "y_train length  77\n",
            "-------> size test:  20000  , size train:  77 nbr_seen (train):  77  nbr_miss :  0\n",
            "X  77   3\n",
            "y shape (77,)\n",
            "nm  231\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 102.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.0908231145037802e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.95275147 1.01704378 1.10661563]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -6.820845279466315\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0]\n",
            "S dataset \n",
            " [[0.9816231  0.         0.        ]\n",
            " [0.         1.08181588 0.        ]\n",
            " [0.         0.         0.99388567]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (77, 3)\n",
            "y_train length  77\n",
            "-------> size test:  20000  , size train:  77 nbr_seen (train):  27  nbr_miss :  50\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.9816231  0.         0.        ]\n",
            " [0.         1.08181588 0.        ]\n",
            " [0.         0.         0.99388567]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01872093 0.         0.        ]\n",
            " [0.         0.92437171 0.        ]\n",
            " [0.         0.         1.00615195]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 877.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  13  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.26366509 0.26366509] , min score  0.0006812379235736418\n",
            "---------------------------------> best coeff  [-1.61679885 -0.90343892 -0.40722509]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.95275147 1.01704378 1.10661563]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -27.13316752894653\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0]\n",
            "S dataset \n",
            " [[0.9816231  0.         0.        ]\n",
            " [0.         1.08181588 0.        ]\n",
            " [0.         0.         0.99388567]]\n",
            "S missing shape\n",
            "  (77, 3, 3)\n",
            "S missing\n",
            "  [[[0.49541283 0.         0.        ]\n",
            "  [0.         0.993947   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64301023 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.96110545 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.14397899]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.47157121 0.         0.        ]\n",
            "  [0.         0.72178332 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24335663 0.        ]\n",
            "  [0.         0.         0.92026873]]\n",
            "\n",
            " [[1.37567425 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65721249]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.27334195 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.44852493 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.98969855]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76145098]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97024921]]\n",
            "\n",
            " [[0.75222953 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69153797]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.12060609 0.        ]\n",
            "  [0.         0.         0.89495659]]\n",
            "\n",
            " [[0.80531973 0.         0.        ]\n",
            "  [0.         0.89548528 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97889666]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.25512256 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.87627276 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.55277128 0.        ]\n",
            "  [0.         0.         1.38052024]]\n",
            "\n",
            " [[0.78789509 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96561835 0.        ]\n",
            "  [0.         0.         0.8641906 ]]\n",
            "\n",
            " [[0.89061499 0.         0.        ]\n",
            "  [0.         1.10862046 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07394518 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94766513 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64165132 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.38099623 0.         0.        ]\n",
            "  [0.         0.63622101 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.84490202 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49976275 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.88090031 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.64876972 0.         0.        ]\n",
            "  [0.         0.88879003 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.34242121]]\n",
            "\n",
            " [[0.40208467 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62899411]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.49890786]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.3442903 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77556205 0.        ]\n",
            "  [0.         0.         0.63827564]]\n",
            "\n",
            " [[1.25508646 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02815351]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53637427]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52353869 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.71341397 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8860595  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69162334]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57731026]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.39333582 0.         0.        ]\n",
            "  [0.         0.80457087 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75915864 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8546778 ]]\n",
            "\n",
            " [[0.836023   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.47210841]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75879305 0.        ]\n",
            "  [0.         0.         0.66576137]]\n",
            "\n",
            " [[0.21300591 0.         0.        ]\n",
            "  [0.         1.16358602 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.60347636 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56114961]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 77, 3)\n",
            "y_train length  77\n",
            "-------> size test:  20000  , size train:  77 nbr_seen (train):  27  nbr_miss :  50\n",
            "X  77   3\n",
            "y shape (77,)\n",
            "nm  231\n",
            "S_mis in Adbvt training  [[[0.49541283 0.         0.        ]\n",
            "  [0.         0.993947   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64301023 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.96110545 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.14397899]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.47157121 0.         0.        ]\n",
            "  [0.         0.72178332 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24335663 0.        ]\n",
            "  [0.         0.         0.92026873]]\n",
            "\n",
            " [[1.37567425 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65721249]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.27334195 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.44852493 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.98969855]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76145098]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97024921]]\n",
            "\n",
            " [[0.75222953 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69153797]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.12060609 0.        ]\n",
            "  [0.         0.         0.89495659]]\n",
            "\n",
            " [[0.80531973 0.         0.        ]\n",
            "  [0.         0.89548528 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97889666]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.25512256 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.87627276 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.55277128 0.        ]\n",
            "  [0.         0.         1.38052024]]\n",
            "\n",
            " [[0.78789509 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96561835 0.        ]\n",
            "  [0.         0.         0.8641906 ]]\n",
            "\n",
            " [[0.89061499 0.         0.        ]\n",
            "  [0.         1.10862046 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07394518 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94766513 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64165132 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.38099623 0.         0.        ]\n",
            "  [0.         0.63622101 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.84490202 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49976275 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.88090031 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.64876972 0.         0.        ]\n",
            "  [0.         0.88879003 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.34242121]]\n",
            "\n",
            " [[0.40208467 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62899411]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.49890786]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.3442903 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77556205 0.        ]\n",
            "  [0.         0.         0.63827564]]\n",
            "\n",
            " [[1.25508646 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02815351]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53637427]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52353869 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.71341397 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8860595  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69162334]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57731026]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.39333582 0.         0.        ]\n",
            "  [0.         0.80457087 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75915864 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8546778 ]]\n",
            "\n",
            " [[0.836023   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.47210841]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75879305 0.        ]\n",
            "  [0.         0.         0.66576137]]\n",
            "\n",
            " [[0.21300591 0.         0.        ]\n",
            "  [0.         1.16358602 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.60347636 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56114961]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[0.98 0.00 0.00]\n",
            " [0.00 1.08 0.00]\n",
            " ...\n",
            " [0.00 1.08 0.00]\n",
            " [0.00 0.00 0.99]] @ Promote(adv_radius_times_dts, (231, 3)) + [[0.50 0.00 0.00]\n",
            " [0.00 0.99 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (231, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 4/20 [00:00<00:00, 39.23it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 49.79it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 50.06it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:07,  2.47it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 42.10it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 46.38it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 51.46it/s]\n",
            " 10%|█         | 2/20 [00:00<00:07,  2.51it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 60.75it/s]\u001b[A\n",
            " 70%|███████   | 14/20 [00:00<00:00, 56.85it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 57.03it/s]\n",
            " 15%|█▌        | 3/20 [00:01<00:06,  2.64it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 44.53it/s]\u001b[A\n",
            " 55%|█████▌    | 11/20 [00:00<00:00, 52.45it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 49.35it/s]\n",
            " 20%|██        | 4/20 [00:01<00:06,  2.56it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 48.06it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 56.25it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 57.74it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:05,  2.65it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.93it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 57.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 53.89it/s]\n",
            " 30%|███       | 6/20 [00:02<00:05,  2.65it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 48.45it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 57.46it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 55.39it/s]\n",
            " 35%|███▌      | 7/20 [00:02<00:04,  2.68it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 53.19it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 54.22it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 53.30it/s]\n",
            " 40%|████      | 8/20 [00:03<00:04,  2.66it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.40it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 54.54it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 57.45it/s]\n",
            " 45%|████▌     | 9/20 [00:03<00:04,  2.71it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 83.50it/s]\n",
            " 50%|█████     | 10/20 [00:03<00:03,  3.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 79.07it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 81.38it/s]\n",
            " 55%|█████▌    | 11/20 [00:03<00:02,  3.27it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 85.81it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 85.42it/s]\n",
            " 60%|██████    | 12/20 [00:04<00:02,  3.50it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.24it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 88.88it/s]\n",
            " 65%|██████▌   | 13/20 [00:04<00:01,  3.71it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.96it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 84.15it/s]\n",
            " 70%|███████   | 14/20 [00:04<00:01,  3.83it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 83.78it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 80.08it/s]\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.85it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 84.60it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 87.47it/s]\n",
            " 80%|████████  | 16/20 [00:05<00:01,  3.96it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.09it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 83.62it/s]\n",
            " 85%|████████▌ | 17/20 [00:05<00:00,  4.00it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.52it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.38it/s]\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  4.12it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 92.55it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 93.94it/s]\n",
            " 95%|█████████▌| 19/20 [00:05<00:00,  4.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.46it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 79.95it/s]\n",
            "100%|██████████| 20/20 [00:06<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.04227818318127093\n",
            "---------------------------------> best coeff  [-1.52958233 -0.88072671 -0.24110246]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.95275147 1.01704378 1.10661563]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -27.13316752894653\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0]\n",
            "S dataset \n",
            " [[0.9816231  0.         0.        ]\n",
            " [0.         1.08181588 0.        ]\n",
            " [0.         0.         0.99388567]]\n",
            "S missing shape\n",
            "  (77, 3, 3)\n",
            "S missing\n",
            "  [[[0.49541283 0.         0.        ]\n",
            "  [0.         0.993947   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64301023 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.96110545 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.14397899]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.47157121 0.         0.        ]\n",
            "  [0.         0.72178332 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24335663 0.        ]\n",
            "  [0.         0.         0.92026873]]\n",
            "\n",
            " [[1.37567425 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65721249]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.27334195 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.44852493 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.98969855]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76145098]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97024921]]\n",
            "\n",
            " [[0.75222953 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69153797]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.12060609 0.        ]\n",
            "  [0.         0.         0.89495659]]\n",
            "\n",
            " [[0.80531973 0.         0.        ]\n",
            "  [0.         0.89548528 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97889666]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.25512256 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.87627276 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.55277128 0.        ]\n",
            "  [0.         0.         1.38052024]]\n",
            "\n",
            " [[0.78789509 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96561835 0.        ]\n",
            "  [0.         0.         0.8641906 ]]\n",
            "\n",
            " [[0.89061499 0.         0.        ]\n",
            "  [0.         1.10862046 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07394518 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94766513 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64165132 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.38099623 0.         0.        ]\n",
            "  [0.         0.63622101 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.84490202 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49976275 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.88090031 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.64876972 0.         0.        ]\n",
            "  [0.         0.88879003 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.34242121]]\n",
            "\n",
            " [[0.40208467 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62899411]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.49890786]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.3442903 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77556205 0.        ]\n",
            "  [0.         0.         0.63827564]]\n",
            "\n",
            " [[1.25508646 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02815351]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.53637427]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52353869 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.71341397 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8860595  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69162334]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57731026]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.39333582 0.         0.        ]\n",
            "  [0.         0.80457087 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75915864 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8546778 ]]\n",
            "\n",
            " [[0.836023   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.47210841]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75879305 0.        ]\n",
            "  [0.         0.         0.66576137]]\n",
            "\n",
            " [[0.21300591 0.         0.        ]\n",
            "  [0.         1.16358602 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.60347636 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56114961]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 77, 3)\n",
            "y_train length  77\n",
            "-------> size test:  20000  , size train:  77 nbr_seen (train):  27  nbr_miss :  50\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.9816231  0.         0.        ]\n",
            " [0.         1.08181588 0.        ]\n",
            " [0.         0.         0.99388567]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01872093 0.         0.        ]\n",
            " [0.         0.92437171 0.        ]\n",
            " [0.         0.         1.00615195]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 606.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.04225103373749461\n",
            "---------------------------------> best coeff  [-1.52970131 -0.88087    -0.24110864]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  5\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20090, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   90\n",
            "X shape in clear data  (90, 3)\n",
            "y shape in clear data  (90,)\n",
            "M shape in clear data  (90,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(86, 3)\n",
            "(86, 3)\n",
            "(86,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-3.48746721e-01,  1.28808784e-01, -3.95750178e-01],\n",
            "       [ 2.03440496e+00, -7.36466295e-01,  1.47652574e-01],\n",
            "       [-1.93805473e+00, -1.32668622e+00,  2.76038864e-01],\n",
            "       [ 6.10429821e-01,  4.59681822e-03,  1.91703154e-01],\n",
            "       [ 9.43659349e-01, -1.43434126e+00,  5.06451033e-01],\n",
            "       [-4.24035350e-01, -9.35761416e-01, -6.31845451e-01],\n",
            "       [-1.08349271e+00, -2.90856996e-01, -3.22090720e-01],\n",
            "       [ 2.22656584e-02,  3.09464699e-01,  1.72254516e+00],\n",
            "       [ 6.08754495e-01, -7.87489544e-01, -1.09801587e-01],\n",
            "       [-6.74621063e-01,  7.58679401e-01, -1.83572918e+00],\n",
            "       [ 5.80044053e-01,  1.16777225e+00, -6.71244196e-01],\n",
            "       [-2.29258519e+00,  9.35082875e-01, -2.45576960e-01],\n",
            "       [ 9.36047232e-01,  9.20814445e-01, -1.00230523e+00],\n",
            "       [-1.38463222e+00,  1.09932584e-01, -3.83929008e-01],\n",
            "       [-4.81085507e-01, -5.55810832e-01,  1.15487716e+00],\n",
            "       [-2.70781700e-01, -1.25445809e+00,  5.34891746e-01],\n",
            "       [ 1.82509762e+00, -5.26167778e-01,  5.02169903e-01],\n",
            "       [ 3.82851599e-01,  1.41808445e-01, -1.08295106e+00],\n",
            "       [-1.47459168e+00,  7.94664991e-01, -1.37292582e+00],\n",
            "       [-6.79674908e-01,  1.47588969e+00, -1.04401964e+00],\n",
            "       [-1.95331684e-01, -1.69187442e+00, -3.57763716e-01],\n",
            "       [ 8.78919379e-01,  1.44824160e-01,  5.81102688e-01],\n",
            "       [ 6.19659835e-01,  1.65567702e-01, -5.76547152e-01],\n",
            "       [ 4.48509413e-01, -1.66036407e+00, -7.41943240e-01],\n",
            "       [-6.29112294e-01, -4.97979506e-01,  2.44549191e-01],\n",
            "       [-3.84947154e-01, -9.57343038e-01,  8.43787942e-01],\n",
            "       [-8.35367742e-01,  2.93473681e-01,  1.33444067e+00],\n",
            "       [-4.88733325e-01,  1.68215970e+00, -8.70658747e-01],\n",
            "       [ 4.97857663e-01, -5.00590347e-01,  1.39092028e+00],\n",
            "       [ 2.05499204e+00,  5.32262359e-01, -1.32366990e+00],\n",
            "       [ 1.04632081e+00,  5.08783702e-01, -4.31437912e-01],\n",
            "       [-6.41518926e-02, -4.64615690e-02,  1.08402583e+00],\n",
            "       [-1.14587692e+00,  2.83663759e-01, -1.42670437e+00],\n",
            "       [-7.14149078e-01, -1.08345853e-01, -1.10571681e+00],\n",
            "       [-4.80814685e-01, -5.71882880e-01,  2.98105722e-01],\n",
            "       [-1.11198913e+00,  1.61718388e+00, -2.06736960e+00],\n",
            "       [-1.73352405e-01,  1.29312229e+00,  2.23244701e+00],\n",
            "       [-1.77576666e+00,  5.19574843e-03,  6.42206169e-01],\n",
            "       [-5.91762866e-02,  4.49513012e-01,  1.45501445e-01],\n",
            "       [-9.02195198e-01,  1.33725890e-01,  1.51512749e+00],\n",
            "       [ 8.42518775e-01,  2.18028158e-01, -8.72207018e-01],\n",
            "       [-4.50841079e-02,  1.64485712e+00,  1.04670050e+00],\n",
            "       [ 6.38787307e-01, -2.30086042e+00, -1.20492708e-01],\n",
            "       [ 1.07769050e+00, -1.69705608e-01, -9.39718127e-01],\n",
            "       [-4.16924652e-01,  1.11872571e+00,  3.33322533e-02],\n",
            "       [ 1.70469431e+00,  8.25593492e-01,  2.75235573e-01],\n",
            "       [ 3.43632502e-01,  4.11847054e-02, -3.89086165e+00],\n",
            "       [-2.45700412e-01, -1.52188303e+00,  6.35254694e-01],\n",
            "       [-2.96048476e-01, -2.69646068e+00,  7.51981074e-01],\n",
            "       [ 5.45709338e-01, -9.70443716e-01, -2.57180436e+00],\n",
            "       [-1.61543695e+00, -3.90022124e-01, -1.13991388e+00],\n",
            "       [-3.59797168e-01,  5.76555194e-01,  3.92054859e-01],\n",
            "       [-7.79611999e-01,  2.23910082e+00, -1.41590718e+00],\n",
            "       [ 1.99192128e-01,  1.98055456e+00, -1.20305637e+00],\n",
            "       [-2.35671420e+00, -1.03140696e+00, -4.95005310e-01],\n",
            "       [-1.40918128e+00,  1.58020401e+00, -5.41148354e-01],\n",
            "       [ 6.37005237e-01, -1.24153146e+00, -7.22542121e-01],\n",
            "       [-1.45747496e+00, -5.23692341e-01, -3.94865956e-02],\n",
            "       [-1.42002673e+00, -6.72689764e-01,  2.94568125e-03],\n",
            "       [-7.04493429e-01,  3.60823485e-01, -1.22701075e+00],\n",
            "       [-4.41663638e-01,  2.92399455e-01, -9.74306359e-02],\n",
            "       [-4.79408753e-01,  6.12078472e-01, -2.52772755e+00],\n",
            "       [ 7.23655143e-01,  4.91772765e-01,  3.45253083e-01],\n",
            "       [-1.04797989e+00, -7.24880029e-01, -7.68947790e-01],\n",
            "       [ 6.51624311e-01, -1.91806039e+00,  1.25976458e+00],\n",
            "       [-1.65118789e-01, -7.74970608e-01,  8.44948048e-01],\n",
            "       [ 3.67386128e-01,  1.09695228e+00,  9.13658362e-01],\n",
            "       [-9.00484389e-02,  1.32622239e+00,  1.62079155e+00],\n",
            "       [ 4.89370112e-01,  1.66001818e+00, -1.08011411e+00],\n",
            "       [-6.34814654e-01, -3.73299892e-01, -2.51153507e+00],\n",
            "       [-1.15805819e+00, -6.47767715e-01, -1.71003728e+00],\n",
            "       [-1.97682929e-02,  5.44442063e-01,  3.72891542e-01],\n",
            "       [ 8.03633802e-01,  3.80742570e-01,  1.65852848e-01],\n",
            "       [ 5.21702786e-01, -6.08498627e-02,  4.97373451e-02],\n",
            "       [ 8.65184954e-01,  8.02307063e-01, -6.66455769e-01],\n",
            "       [ 1.43236249e-01, -1.95112945e-01, -6.23772791e-01],\n",
            "       [-1.29882434e+00, -7.99661257e-01,  1.05149617e+00],\n",
            "       [-8.55278813e-01,  1.53558442e-01,  7.40844207e-01],\n",
            "       [-1.37359731e+00, -1.92397297e-01,  1.42125591e-01],\n",
            "       [ 1.17231912e+00, -5.09292527e-01,  2.59601783e-01],\n",
            "       [ 5.11652921e-01, -5.52885980e-01,  3.62198253e-01],\n",
            "       [-3.67798797e-01, -1.08126841e-01,  6.25490570e-01],\n",
            "       [-8.08499076e-01, -1.56140694e+00,  1.12999049e+00],\n",
            "       [-1.37694900e+00,  1.01431955e+00,  5.76387753e-01],\n",
            "       [ 1.13159764e+00, -4.47363059e-01, -2.05671987e+00],\n",
            "       [-5.30580929e-01,  8.50280366e-02,  1.35943678e+00]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717,  0.67502741,\n",
            "       -1.17385102, -1.86365186,  1.10326626, -1.17237151, -0.35479177,\n",
            "       -3.60141524,  1.08799951,  1.49465107,  2.58555405,  1.10822697,\n",
            "        3.43755015, -0.11169254, -0.15916623, -1.58930837,  4.92898055,\n",
            "        1.06961998,  0.40929708,  2.83026505,  2.88634927,  1.33442305,\n",
            "        0.48726981,  1.30677088, -1.7548376 ,  2.66870908,  0.14217093,\n",
            "        0.60058679, -1.97404546, -1.75123426, -1.81891073,  2.43890985,\n",
            "        3.18148252, -0.6204758 , -1.70571393, -0.80427769, -1.82639397,\n",
            "        0.21497736,  2.35440641,  0.91550668,  2.31821398, -1.53468336,\n",
            "       -0.47862222,  0.4186475 ,  2.22086251,  1.04704897, -0.5268411 ,\n",
            "        0.18933962]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9512115  0.98797631 1.10383459]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -5.610762778395392\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1]\n",
            "S dataset \n",
            " [[0.97379911 0.         0.        ]\n",
            " [0.         1.04798376 0.        ]\n",
            " [0.         0.         0.96184898]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (86, 3)\n",
            "y_train length  86\n",
            "-------> size test:  20000  , size train:  86 nbr_seen (train):  30  nbr_miss :  56\n",
            "X  86   3\n",
            "y shape (86,)\n",
            "nm  258\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 119.18it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  8  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.01274275 0.        ] , min score  0.002059958735089633\n",
            "---------------------------------> best coeff  [-1.61287576 -0.89001502 -0.38807604]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9512115  0.98797631 1.10383459]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -31.188292624502903\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.9512115  0.         0.        ]\n",
            " [0.         0.98797631 0.        ]\n",
            " [0.         0.         1.10383459]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (86, 3)\n",
            "y_train length  86\n",
            "-------> size test:  20000  , size train:  86 nbr_seen (train):  86  nbr_miss :  0\n",
            "X  86   3\n",
            "y shape (86,)\n",
            "nm  258\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 104.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.388734279396532e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9512115  0.98797631 1.10383459]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -5.610762778395392\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1]\n",
            "S dataset \n",
            " [[0.97379911 0.         0.        ]\n",
            " [0.         1.04798376 0.        ]\n",
            " [0.         0.         0.96184898]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (86, 3)\n",
            "y_train length  86\n",
            "-------> size test:  20000  , size train:  86 nbr_seen (train):  30  nbr_miss :  56\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.97379911 0.         0.        ]\n",
            " [0.         1.04798376 0.        ]\n",
            " [0.         0.         0.96184898]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.02690585 0.         0.        ]\n",
            " [0.         0.95421326 0.        ]\n",
            " [0.         0.         1.03966425]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 718.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.002487756060899781\n",
            "---------------------------------> best coeff  [-1.62353044 -0.89731559 -0.38461695]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9512115  0.98797631 1.10383459]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -17.311391701693204\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1]\n",
            "S dataset \n",
            " [[0.97379911 0.         0.        ]\n",
            " [0.         1.04798376 0.        ]\n",
            " [0.         0.         0.96184898]]\n",
            "S missing shape\n",
            "  (86, 3, 3)\n",
            "S missing\n",
            "  [[[0.52913069 0.         0.        ]\n",
            "  [0.         0.92173304 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77426608 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.5757798  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46591025]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.39940594 0.         0.        ]\n",
            "  [0.         0.7974833  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74995435 0.        ]\n",
            "  [0.         0.         0.71365865]]\n",
            "\n",
            " [[0.57498902 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.32599199]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.81937603 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.10846336 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97619568]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94690264]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.80575065]]\n",
            "\n",
            " [[0.25111201 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96955311]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.14506429 0.        ]\n",
            "  [0.         0.         1.31622705]]\n",
            "\n",
            " [[0.62718178 0.         0.        ]\n",
            "  [0.         1.25920796 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6085538 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7464922  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.5523815  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47615004 0.        ]\n",
            "  [0.         0.         0.63592134]]\n",
            "\n",
            " [[1.05184375 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.63595739 0.        ]\n",
            "  [0.         0.         0.82838172]]\n",
            "\n",
            " [[0.45825167 0.         0.        ]\n",
            "  [0.         0.54923118 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.96123555 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48549222 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52503391 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.78329303 0.         0.        ]\n",
            "  [0.         1.46968748 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94001016 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79386611 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.97239022 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.26431989 0.         0.        ]\n",
            "  [0.         1.34637277 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65520251]]\n",
            "\n",
            " [[0.57808917 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.63531936]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84141244]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.50964794]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77401459 0.        ]\n",
            "  [0.         0.         0.60406016]]\n",
            "\n",
            " [[1.31513139 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00645139]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84844055]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.24100778 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.19282594 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.28421186 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.88523551]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56415978]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93239142 0.         0.        ]\n",
            "  [0.         1.03570731 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98956669 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76680347]]\n",
            "\n",
            " [[0.8775856  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54665495]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.31596193 0.        ]\n",
            "  [0.         0.         0.67499772]]\n",
            "\n",
            " [[0.56980888 0.         0.        ]\n",
            "  [0.         0.7416854  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61180415 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00032012]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.86443843 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.18733897 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7069114  0.        ]\n",
            "  [0.         0.         0.90719084]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.83292711 0.        ]\n",
            "  [0.         0.         0.66060955]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.73412913 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.58028214]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.19576169 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 86, 3)\n",
            "y_train length  86\n",
            "-------> size test:  20000  , size train:  86 nbr_seen (train):  30  nbr_miss :  56\n",
            "X  86   3\n",
            "y shape (86,)\n",
            "nm  258\n",
            "S_mis in Adbvt training  [[[0.52913069 0.         0.        ]\n",
            "  [0.         0.92173304 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77426608 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.5757798  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46591025]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.39940594 0.         0.        ]\n",
            "  [0.         0.7974833  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74995435 0.        ]\n",
            "  [0.         0.         0.71365865]]\n",
            "\n",
            " [[0.57498902 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.32599199]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.81937603 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.10846336 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97619568]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94690264]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.80575065]]\n",
            "\n",
            " [[0.25111201 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96955311]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.14506429 0.        ]\n",
            "  [0.         0.         1.31622705]]\n",
            "\n",
            " [[0.62718178 0.         0.        ]\n",
            "  [0.         1.25920796 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6085538 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7464922  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.5523815  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47615004 0.        ]\n",
            "  [0.         0.         0.63592134]]\n",
            "\n",
            " [[1.05184375 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.63595739 0.        ]\n",
            "  [0.         0.         0.82838172]]\n",
            "\n",
            " [[0.45825167 0.         0.        ]\n",
            "  [0.         0.54923118 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.96123555 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48549222 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52503391 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.78329303 0.         0.        ]\n",
            "  [0.         1.46968748 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94001016 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79386611 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.97239022 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.26431989 0.         0.        ]\n",
            "  [0.         1.34637277 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65520251]]\n",
            "\n",
            " [[0.57808917 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.63531936]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84141244]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.50964794]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77401459 0.        ]\n",
            "  [0.         0.         0.60406016]]\n",
            "\n",
            " [[1.31513139 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00645139]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84844055]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.24100778 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.19282594 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.28421186 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.88523551]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56415978]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93239142 0.         0.        ]\n",
            "  [0.         1.03570731 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98956669 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76680347]]\n",
            "\n",
            " [[0.8775856  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54665495]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.31596193 0.        ]\n",
            "  [0.         0.         0.67499772]]\n",
            "\n",
            " [[0.56980888 0.         0.        ]\n",
            "  [0.         0.7416854  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61180415 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00032012]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.86443843 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.18733897 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7069114  0.        ]\n",
            "  [0.         0.         0.90719084]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.83292711 0.        ]\n",
            "  [0.         0.         0.66060955]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.73412913 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.58028214]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.19576169 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[0.97 0.00 0.00]\n",
            " [0.00 1.05 0.00]\n",
            " ...\n",
            " [0.00 1.05 0.00]\n",
            " [0.00 0.00 0.96]] @ Promote(adv_radius_times_dts, (258, 3)) + [[0.53 0.00 0.00]\n",
            " [0.00 0.92 0.00]\n",
            " ...\n",
            " [0.00 1.20 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (258, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 65.12it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.93it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:05,  3.40it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.93it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.32it/s]\n",
            " 10%|█         | 2/20 [00:00<00:05,  3.48it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 58.40it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.77it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:05,  3.38it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.63it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.99it/s]\n",
            " 20%|██        | 4/20 [00:01<00:04,  3.47it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 83.77it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 81.26it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:04,  3.61it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 77.46it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 79.89it/s]\n",
            " 30%|███       | 6/20 [00:01<00:03,  3.69it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 64.84it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 74.90it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:03,  3.68it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.35it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 78.47it/s]\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.72it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 81.53it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 79.26it/s]\n",
            " 45%|████▌     | 9/20 [00:02<00:02,  3.75it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.90it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 78.94it/s]\n",
            " 50%|█████     | 10/20 [00:02<00:02,  3.79it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 63.90it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 75.85it/s]\n",
            " 55%|█████▌    | 11/20 [00:02<00:02,  3.77it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.46it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 80.36it/s]\n",
            " 60%|██████    | 12/20 [00:03<00:02,  3.81it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.40it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 80.24it/s]\n",
            " 65%|██████▌   | 13/20 [00:03<00:01,  3.84it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.29it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 80.52it/s]\n",
            " 70%|███████   | 14/20 [00:03<00:01,  3.86it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 56.24it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.49it/s]\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.77it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.06it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 56.10it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 55.10it/s]\n",
            " 80%|████████  | 16/20 [00:04<00:01,  3.37it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.18it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 55.36it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 53.46it/s]\n",
            " 85%|████████▌ | 17/20 [00:04<00:00,  3.10it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 51.19it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 51.59it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 53.36it/s]\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  2.94it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 54.72it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 55.16it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 54.13it/s]\n",
            " 95%|█████████▌| 19/20 [00:05<00:00,  2.85it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.60it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 58.53it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 57.25it/s]\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.020880103065808384\n",
            "---------------------------------> best coeff  [-1.62121637 -0.76927173 -0.37963377]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9512115  0.98797631 1.10383459]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -17.311391701693204\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1]\n",
            "S dataset \n",
            " [[0.97379911 0.         0.        ]\n",
            " [0.         1.04798376 0.        ]\n",
            " [0.         0.         0.96184898]]\n",
            "S missing shape\n",
            "  (86, 3, 3)\n",
            "S missing\n",
            "  [[[0.52913069 0.         0.        ]\n",
            "  [0.         0.92173304 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77426608 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.5757798  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46591025]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.39940594 0.         0.        ]\n",
            "  [0.         0.7974833  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74995435 0.        ]\n",
            "  [0.         0.         0.71365865]]\n",
            "\n",
            " [[0.57498902 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.32599199]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.81937603 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.10846336 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.97619568]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94690264]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.80575065]]\n",
            "\n",
            " [[0.25111201 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96955311]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.14506429 0.        ]\n",
            "  [0.         0.         1.31622705]]\n",
            "\n",
            " [[0.62718178 0.         0.        ]\n",
            "  [0.         1.25920796 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6085538 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7464922  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.5523815  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47615004 0.        ]\n",
            "  [0.         0.         0.63592134]]\n",
            "\n",
            " [[1.05184375 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.63595739 0.        ]\n",
            "  [0.         0.         0.82838172]]\n",
            "\n",
            " [[0.45825167 0.         0.        ]\n",
            "  [0.         0.54923118 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.96123555 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48549222 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52503391 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.78329303 0.         0.        ]\n",
            "  [0.         1.46968748 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94001016 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79386611 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.97239022 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.26431989 0.         0.        ]\n",
            "  [0.         1.34637277 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65520251]]\n",
            "\n",
            " [[0.57808917 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.63531936]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84141244]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.50964794]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77401459 0.        ]\n",
            "  [0.         0.         0.60406016]]\n",
            "\n",
            " [[1.31513139 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00645139]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84844055]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.24100778 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.19282594 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.28421186 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.88523551]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56415978]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93239142 0.         0.        ]\n",
            "  [0.         1.03570731 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98956669 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76680347]]\n",
            "\n",
            " [[0.8775856  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54665495]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.31596193 0.        ]\n",
            "  [0.         0.         0.67499772]]\n",
            "\n",
            " [[0.56980888 0.         0.        ]\n",
            "  [0.         0.7416854  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.61180415 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00032012]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.86443843 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.18733897 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7069114  0.        ]\n",
            "  [0.         0.         0.90719084]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.83292711 0.        ]\n",
            "  [0.         0.         0.66060955]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.73412913 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.58028214]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.19576169 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 86, 3)\n",
            "y_train length  86\n",
            "-------> size test:  20000  , size train:  86 nbr_seen (train):  30  nbr_miss :  56\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.97379911 0.         0.        ]\n",
            " [0.         1.04798376 0.        ]\n",
            " [0.         0.         0.96184898]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.02690585 0.         0.        ]\n",
            " [0.         0.95421326 0.        ]\n",
            " [0.         0.         1.03966425]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1079.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.020863147907294325\n",
            "---------------------------------> best coeff  [-1.62134337 -0.76932678 -0.37969482]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  6\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20100, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   100\n",
            "X shape in clear data  (100, 3)\n",
            "y shape in clear data  (100,)\n",
            "M shape in clear data  (100,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(95, 3)\n",
            "(95, 3)\n",
            "(95,)\n",
            "full masks in run experiment  [[1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 1 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-3.48746721e-01,  1.28808784e-01, -3.95750178e-01],\n",
            "       [ 2.03440496e+00, -7.36466295e-01,  1.47652574e-01],\n",
            "       [-1.93805473e+00, -1.32668622e+00,  2.76038864e-01],\n",
            "       [ 6.10429821e-01,  4.59681822e-03,  1.91703154e-01],\n",
            "       [ 9.43659349e-01, -1.43434126e+00,  5.06451033e-01],\n",
            "       [-4.24035350e-01, -9.35761416e-01, -6.31845451e-01],\n",
            "       [-1.08349271e+00, -2.90856996e-01, -3.22090720e-01],\n",
            "       [ 2.22656584e-02,  3.09464699e-01,  1.72254516e+00],\n",
            "       [ 6.08754495e-01, -7.87489544e-01, -1.09801587e-01],\n",
            "       [-6.74621063e-01,  7.58679401e-01, -1.83572918e+00],\n",
            "       [ 5.80044053e-01,  1.16777225e+00, -6.71244196e-01],\n",
            "       [-2.29258519e+00,  9.35082875e-01, -2.45576960e-01],\n",
            "       [ 9.36047232e-01,  9.20814445e-01, -1.00230523e+00],\n",
            "       [-1.38463222e+00,  1.09932584e-01, -3.83929008e-01],\n",
            "       [-4.81085507e-01, -5.55810832e-01,  1.15487716e+00],\n",
            "       [-2.70781700e-01, -1.25445809e+00,  5.34891746e-01],\n",
            "       [ 1.82509762e+00, -5.26167778e-01,  5.02169903e-01],\n",
            "       [ 3.82851599e-01,  1.41808445e-01, -1.08295106e+00],\n",
            "       [-1.47459168e+00,  7.94664991e-01, -1.37292582e+00],\n",
            "       [-6.79674908e-01,  1.47588969e+00, -1.04401964e+00],\n",
            "       [-1.95331684e-01, -1.69187442e+00, -3.57763716e-01],\n",
            "       [ 8.78919379e-01,  1.44824160e-01,  5.81102688e-01],\n",
            "       [ 6.19659835e-01,  1.65567702e-01, -5.76547152e-01],\n",
            "       [ 4.48509413e-01, -1.66036407e+00, -7.41943240e-01],\n",
            "       [-6.29112294e-01, -4.97979506e-01,  2.44549191e-01],\n",
            "       [-3.84947154e-01, -9.57343038e-01,  8.43787942e-01],\n",
            "       [-8.35367742e-01,  2.93473681e-01,  1.33444067e+00],\n",
            "       [-4.88733325e-01,  1.68215970e+00, -8.70658747e-01],\n",
            "       [ 4.97857663e-01, -5.00590347e-01,  1.39092028e+00],\n",
            "       [ 2.05499204e+00,  5.32262359e-01, -1.32366990e+00],\n",
            "       [ 1.04632081e+00,  5.08783702e-01, -4.31437912e-01],\n",
            "       [-6.41518926e-02, -4.64615690e-02,  1.08402583e+00],\n",
            "       [-1.14587692e+00,  2.83663759e-01, -1.42670437e+00],\n",
            "       [-7.14149078e-01, -1.08345853e-01, -1.10571681e+00],\n",
            "       [-4.80814685e-01, -5.71882880e-01,  2.98105722e-01],\n",
            "       [-1.11198913e+00,  1.61718388e+00, -2.06736960e+00],\n",
            "       [-1.73352405e-01,  1.29312229e+00,  2.23244701e+00],\n",
            "       [-1.77576666e+00,  5.19574843e-03,  6.42206169e-01],\n",
            "       [-5.91762866e-02,  4.49513012e-01,  1.45501445e-01],\n",
            "       [-9.02195198e-01,  1.33725890e-01,  1.51512749e+00],\n",
            "       [ 8.42518775e-01,  2.18028158e-01, -8.72207018e-01],\n",
            "       [-4.50841079e-02,  1.64485712e+00,  1.04670050e+00],\n",
            "       [ 6.38787307e-01, -2.30086042e+00, -1.20492708e-01],\n",
            "       [ 1.07769050e+00, -1.69705608e-01, -9.39718127e-01],\n",
            "       [-4.16924652e-01,  1.11872571e+00,  3.33322533e-02],\n",
            "       [ 1.70469431e+00,  8.25593492e-01,  2.75235573e-01],\n",
            "       [ 3.43632502e-01,  4.11847054e-02, -3.89086165e+00],\n",
            "       [-2.45700412e-01, -1.52188303e+00,  6.35254694e-01],\n",
            "       [-2.96048476e-01, -2.69646068e+00,  7.51981074e-01],\n",
            "       [ 5.45709338e-01, -9.70443716e-01, -2.57180436e+00],\n",
            "       [-1.61543695e+00, -3.90022124e-01, -1.13991388e+00],\n",
            "       [-3.59797168e-01,  5.76555194e-01,  3.92054859e-01],\n",
            "       [-7.79611999e-01,  2.23910082e+00, -1.41590718e+00],\n",
            "       [ 1.99192128e-01,  1.98055456e+00, -1.20305637e+00],\n",
            "       [-2.35671420e+00, -1.03140696e+00, -4.95005310e-01],\n",
            "       [-1.40918128e+00,  1.58020401e+00, -5.41148354e-01],\n",
            "       [ 6.37005237e-01, -1.24153146e+00, -7.22542121e-01],\n",
            "       [-1.45747496e+00, -5.23692341e-01, -3.94865956e-02],\n",
            "       [-1.42002673e+00, -6.72689764e-01,  2.94568125e-03],\n",
            "       [-7.04493429e-01,  3.60823485e-01, -1.22701075e+00],\n",
            "       [-4.41663638e-01,  2.92399455e-01, -9.74306359e-02],\n",
            "       [-4.79408753e-01,  6.12078472e-01, -2.52772755e+00],\n",
            "       [ 7.23655143e-01,  4.91772765e-01,  3.45253083e-01],\n",
            "       [-1.04797989e+00, -7.24880029e-01, -7.68947790e-01],\n",
            "       [ 6.51624311e-01, -1.91806039e+00,  1.25976458e+00],\n",
            "       [-1.65118789e-01, -7.74970608e-01,  8.44948048e-01],\n",
            "       [ 3.67386128e-01,  1.09695228e+00,  9.13658362e-01],\n",
            "       [-9.00484389e-02,  1.32622239e+00,  1.62079155e+00],\n",
            "       [ 4.89370112e-01,  1.66001818e+00, -1.08011411e+00],\n",
            "       [-6.34814654e-01, -3.73299892e-01, -2.51153507e+00],\n",
            "       [-1.15805819e+00, -6.47767715e-01, -1.71003728e+00],\n",
            "       [-1.97682929e-02,  5.44442063e-01,  3.72891542e-01],\n",
            "       [ 8.03633802e-01,  3.80742570e-01,  1.65852848e-01],\n",
            "       [ 5.21702786e-01, -6.08498627e-02,  4.97373451e-02],\n",
            "       [ 8.65184954e-01,  8.02307063e-01, -6.66455769e-01],\n",
            "       [ 1.43236249e-01, -1.95112945e-01, -6.23772791e-01],\n",
            "       [-1.29882434e+00, -7.99661257e-01,  1.05149617e+00],\n",
            "       [-8.55278813e-01,  1.53558442e-01,  7.40844207e-01],\n",
            "       [-1.37359731e+00, -1.92397297e-01,  1.42125591e-01],\n",
            "       [ 1.17231912e+00, -5.09292527e-01,  2.59601783e-01],\n",
            "       [ 5.11652921e-01, -5.52885980e-01,  3.62198253e-01],\n",
            "       [-3.67798797e-01, -1.08126841e-01,  6.25490570e-01],\n",
            "       [-8.08499076e-01, -1.56140694e+00,  1.12999049e+00],\n",
            "       [-1.37694900e+00,  1.01431955e+00,  5.76387753e-01],\n",
            "       [ 1.13159764e+00, -4.47363059e-01, -2.05671987e+00],\n",
            "       [-5.30580929e-01,  8.50280366e-02,  1.35943678e+00],\n",
            "       [-5.17911957e-01, -7.70285941e-01,  2.92473636e+00],\n",
            "       [-8.95084707e-01,  1.93752269e-01, -2.19532226e-01],\n",
            "       [-1.09871623e+00,  1.24808747e+00,  5.25737131e-01],\n",
            "       [-8.59443418e-01,  5.32822600e-01,  4.57954779e-01],\n",
            "       [ 3.67983619e-01,  6.30652652e-01,  1.28334427e+00],\n",
            "       [ 8.78531135e-01,  7.09453183e-01,  2.42863761e-01],\n",
            "       [-1.82424576e-01, -6.11107517e-01,  1.23690421e+00],\n",
            "       [-6.67217463e-02,  9.76109290e-01,  2.03379324e-01],\n",
            "       [-1.28796648e-01, -4.36490105e-02, -6.57951202e-01]]), array([[1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0]])), 'X_test': array([[ 1.08788468, -1.41940549, -0.13699568],\n",
            "       [ 1.33663957,  0.87024634,  0.62990795],\n",
            "       [ 0.51208924,  0.88363372,  0.62390017],\n",
            "       ...,\n",
            "       [ 0.26999224, -0.08584243,  0.38305568],\n",
            "       [-0.32185724, -0.87323065,  0.23330342],\n",
            "       [-1.81079398, -0.52674558, -0.64311048]]), 'y_train': array([ 0.61432156, -2.66572399,  4.19091758, -1.06703078, -0.43878865,\n",
            "        1.79803443,  2.14131859, -1.05756149, -0.21932484,  1.18964779,\n",
            "       -1.69636579,  2.94322435, -1.90241707,  2.28973763,  0.77654879,\n",
            "        1.33676451, -2.67225869, -0.2760564 ,  2.24231658,  0.20905991,\n",
            "        1.99522892, -1.7926098 , -0.89604744,  1.09845948,  1.35440917,\n",
            "        1.11873544,  0.50137678, -0.35849508, -0.94706891, -3.20998706,\n",
            "       -1.95358365, -0.32226419,  2.19894268,  1.72119709,  1.1599    ,\n",
            "        1.21680818, -1.85120914,  2.57011639, -0.37348717,  0.67502741,\n",
            "       -1.17385102, -1.86365186,  1.10326626, -1.17237151, -0.35479177,\n",
            "       -3.60141524,  1.08799951,  1.49465107,  2.58555405,  1.10822697,\n",
            "        3.43755015, -0.11169254, -0.15916623, -1.58930837,  4.92898055,\n",
            "        1.06961998,  0.40929708,  2.83026505,  2.88634927,  1.33442305,\n",
            "        0.48726981,  1.30677088, -1.7548376 ,  2.66870908,  0.14217093,\n",
            "        0.60058679, -1.97404546, -1.75123426, -1.81891073,  2.43890985,\n",
            "        3.18148252, -0.6204758 , -1.70571393, -0.80427769, -1.82639397,\n",
            "        0.21497736,  2.35440641,  0.91550668,  2.31821398, -1.53468336,\n",
            "       -0.47862222,  0.4186475 ,  2.22086251,  1.04704897, -0.5268411 ,\n",
            "        0.18933962,  0.26647923,  1.35707502,  0.41104508,  0.70173788,\n",
            "       -1.71338641, -2.15592671,  0.31151114, -0.86170649,  0.52981534]), 'y_test': array([-0.40654359, -3.20355488, -1.88895193, ..., -0.52117102,\n",
            "        1.20461439,  3.66056442]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.92442487 0.96596841 1.12078451]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  2.0877137479309553\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1 1 2 1 2 1 2 2 1 0]\n",
            "S dataset \n",
            " [[0.94640292 0.         0.        ]\n",
            " [0.         1.03363056 0.        ]\n",
            " [0.         0.         1.00976067]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (95, 3)\n",
            "y_train length  95\n",
            "-------> size test:  20000  , size train:  95 nbr_seen (train):  31  nbr_miss :  64\n",
            "X  95   3\n",
            "y shape (95,)\n",
            "nm  285\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 94.12it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 95.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  7  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00695193 0.        ] , min score  0.006106099601442178\n",
            "---------------------------------> best coeff  [-1.62593036 -0.87920445 -0.35939302]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.92442487 0.96596841 1.12078451]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -24.827605754534222\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.92442487 0.         0.        ]\n",
            " [0.         0.96596841 0.        ]\n",
            " [0.         0.         1.12078451]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (95, 3)\n",
            "y_train length  95\n",
            "-------> size test:  20000  , size train:  95 nbr_seen (train):  95  nbr_miss :  0\n",
            "X  95   3\n",
            "y shape (95,)\n",
            "nm  285\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 4/20 [00:00<00:00, 37.54it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 49.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 61.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.7651762116345125e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.92442487 0.96596841 1.12078451]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  2.0877137479309553\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1 1 2 1 2 1 2 2 1 0]\n",
            "S dataset \n",
            " [[0.94640292 0.         0.        ]\n",
            " [0.         1.03363056 0.        ]\n",
            " [0.         0.         1.00976067]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (95, 3)\n",
            "y_train length  95\n",
            "-------> size test:  20000  , size train:  95 nbr_seen (train):  31  nbr_miss :  64\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.94640292 0.         0.        ]\n",
            " [0.         1.03363056 0.        ]\n",
            " [0.         0.         1.00976067]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.05663241 0.         0.        ]\n",
            " [0.         0.96746365 0.        ]\n",
            " [0.         0.         0.99033368]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 379.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.006249582355372349\n",
            "---------------------------------> best coeff  [-1.63297736 -0.88236222 -0.35969715]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.92442487 0.96596841 1.12078451]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -1.9524248450512474\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1 1 2 1 2 1 2 2 1 0]\n",
            "S dataset \n",
            " [[0.94640292 0.         0.        ]\n",
            " [0.         1.03363056 0.        ]\n",
            " [0.         0.         1.00976067]]\n",
            "S missing shape\n",
            "  (95, 3, 3)\n",
            "S missing\n",
            "  [[[0.5076951  0.         0.        ]\n",
            "  [0.         0.931599   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11078645 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.81489424 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.08390074]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89785627 0.         0.        ]\n",
            "  [0.         1.02310342 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.43329125 0.        ]\n",
            "  [0.         0.         0.84222211]]\n",
            "\n",
            " [[0.71095261 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94762984]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.12202352 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75161877 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00118587]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.20979379]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.20693413]]\n",
            "\n",
            " [[0.7183907  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.44682012]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86883172 0.        ]\n",
            "  [0.         0.         0.65154052]]\n",
            "\n",
            " [[0.49886114 0.         0.        ]\n",
            "  [0.         0.37091841 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68043773]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.36662437 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.43964485 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.41373589 0.        ]\n",
            "  [0.         0.         0.63821744]]\n",
            "\n",
            " [[0.2747041  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.04011971 0.        ]\n",
            "  [0.         0.         0.76310995]]\n",
            "\n",
            " [[0.42456167 0.         0.        ]\n",
            "  [0.         0.71952221 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.74206572 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.2953579  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53891851 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.1156713  0.         0.        ]\n",
            "  [0.         1.36682821 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48353251 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50518059 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79662727 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.23012193 0.         0.        ]\n",
            "  [0.         0.53776695 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91474013]]\n",
            "\n",
            " [[0.88840571 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46473388]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87403793]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76342562]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7899393  0.        ]\n",
            "  [0.         0.         0.80194784]]\n",
            "\n",
            " [[1.07462583 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8732545 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57124902]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.867008   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.83866605 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.43929313 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.77065515]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81579779]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.46018316 0.         0.        ]\n",
            "  [0.         1.27908135 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16643154 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7959343 ]]\n",
            "\n",
            " [[1.3621154  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.16484023]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.4341513  0.        ]\n",
            "  [0.         0.         0.75086834]]\n",
            "\n",
            " [[0.53872188 0.         0.        ]\n",
            "  [0.         1.00278258 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.95587538 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.07061603]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69233638 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.32905559 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78013775 0.        ]\n",
            "  [0.         0.         0.55283678]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53736064 0.        ]\n",
            "  [0.         0.         0.70658477]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.40863981 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91313362]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.79538556 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8124559  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72322109 0.        ]\n",
            "  [0.         0.         0.96809113]]\n",
            "\n",
            " [[1.51675663 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.32098563 0.        ]\n",
            "  [0.         0.         0.46194005]]\n",
            "\n",
            " [[1.15444467 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7162303  0.        ]\n",
            "  [0.         0.         1.5298155 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15311475 0.        ]\n",
            "  [0.         0.         0.46005042]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.10730829]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 95, 3)\n",
            "y_train length  95\n",
            "-------> size test:  20000  , size train:  95 nbr_seen (train):  31  nbr_miss :  64\n",
            "X  95   3\n",
            "y shape (95,)\n",
            "nm  285\n",
            "S_mis in Adbvt training  [[[0.5076951  0.         0.        ]\n",
            "  [0.         0.931599   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11078645 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.81489424 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.08390074]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89785627 0.         0.        ]\n",
            "  [0.         1.02310342 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.43329125 0.        ]\n",
            "  [0.         0.         0.84222211]]\n",
            "\n",
            " [[0.71095261 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94762984]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.12202352 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75161877 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00118587]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.20979379]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.20693413]]\n",
            "\n",
            " [[0.7183907  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.44682012]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86883172 0.        ]\n",
            "  [0.         0.         0.65154052]]\n",
            "\n",
            " [[0.49886114 0.         0.        ]\n",
            "  [0.         0.37091841 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68043773]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.36662437 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.43964485 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.41373589 0.        ]\n",
            "  [0.         0.         0.63821744]]\n",
            "\n",
            " [[0.2747041  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.04011971 0.        ]\n",
            "  [0.         0.         0.76310995]]\n",
            "\n",
            " [[0.42456167 0.         0.        ]\n",
            "  [0.         0.71952221 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.74206572 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.2953579  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53891851 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.1156713  0.         0.        ]\n",
            "  [0.         1.36682821 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48353251 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50518059 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79662727 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.23012193 0.         0.        ]\n",
            "  [0.         0.53776695 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91474013]]\n",
            "\n",
            " [[0.88840571 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46473388]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87403793]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76342562]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7899393  0.        ]\n",
            "  [0.         0.         0.80194784]]\n",
            "\n",
            " [[1.07462583 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8732545 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57124902]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.867008   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.83866605 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.43929313 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.77065515]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81579779]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.46018316 0.         0.        ]\n",
            "  [0.         1.27908135 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16643154 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7959343 ]]\n",
            "\n",
            " [[1.3621154  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.16484023]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.4341513  0.        ]\n",
            "  [0.         0.         0.75086834]]\n",
            "\n",
            " [[0.53872188 0.         0.        ]\n",
            "  [0.         1.00278258 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.95587538 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.07061603]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69233638 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.32905559 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78013775 0.        ]\n",
            "  [0.         0.         0.55283678]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53736064 0.        ]\n",
            "  [0.         0.         0.70658477]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.40863981 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91313362]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.79538556 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8124559  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72322109 0.        ]\n",
            "  [0.         0.         0.96809113]]\n",
            "\n",
            " [[1.51675663 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.32098563 0.        ]\n",
            "  [0.         0.         0.46194005]]\n",
            "\n",
            " [[1.15444467 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7162303  0.        ]\n",
            "  [0.         0.         1.5298155 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15311475 0.        ]\n",
            "  [0.         0.         0.46005042]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.10730829]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[0.95 0.00 0.00]\n",
            " [0.00 1.03 0.00]\n",
            " ...\n",
            " [0.00 1.03 0.00]\n",
            " [0.00 0.00 1.01]] @ Promote(adv_radius_times_dts, (285, 3)) + [[0.51 0.00 0.00]\n",
            " [0.00 0.93 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (285, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 54.56it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 61.71it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 60.80it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:06,  3.00it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.60it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 65.54it/s]\n",
            " 10%|█         | 2/20 [00:00<00:05,  3.12it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 64.12it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.50it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:05,  3.21it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 65.13it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.02it/s]\n",
            " 20%|██        | 4/20 [00:01<00:04,  3.24it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 49.54it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.91it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:04,  3.26it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.81it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.45it/s]\n",
            " 30%|███       | 6/20 [00:01<00:04,  3.37it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 72.83it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.81it/s]\n",
            " 35%|███▌      | 7/20 [00:02<00:03,  3.42it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 67.18it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.52it/s]\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.40it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.31it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.56it/s]\n",
            " 45%|████▌     | 9/20 [00:02<00:03,  3.45it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.68it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.21it/s]\n",
            " 50%|█████     | 10/20 [00:02<00:02,  3.49it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.55it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.08it/s]\n",
            " 55%|█████▌    | 11/20 [00:03<00:02,  3.51it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.10it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 70.08it/s]\n",
            " 60%|██████    | 12/20 [00:03<00:02,  3.49it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.81it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 71.40it/s]\n",
            " 65%|██████▌   | 13/20 [00:03<00:02,  3.49it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.36it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.59it/s]\n",
            " 70%|███████   | 14/20 [00:04<00:01,  3.52it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 67.57it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 70.95it/s]\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.50it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 56.22it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.65it/s]\n",
            " 80%|████████  | 16/20 [00:04<00:01,  3.46it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 72.97it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.20it/s]\n",
            " 85%|████████▌ | 17/20 [00:04<00:00,  3.50it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.38it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 71.93it/s]\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  3.51it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.83it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.52it/s]\n",
            " 95%|█████████▌| 19/20 [00:05<00:00,  3.52it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 75.50it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 74.95it/s]\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.0371775172216542\n",
            "---------------------------------> best coeff  [-1.50749628 -0.82989443 -0.28205357]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.92442487 0.96596841 1.12078451]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -1.9524248450512474\n",
            "[2 1 2 0 0 0 0 2 0 2 2 1 1 1 0 1 0 1 2 0 2 2 0 1 1 1 0 2 1 0 2 2 1 0 1 1 0\n",
            " 2 0 1 0 1 0 1 2 0 1 1 0 1 0 0 1 1 2 2 1 1 1 1 0 1 0 1 0 0 0 2 0 1 1 2 2 2\n",
            " 1 1 0 1 0 1 0 2 2 0 2 1 1 2 1 2 1 2 2 1 0]\n",
            "S dataset \n",
            " [[0.94640292 0.         0.        ]\n",
            " [0.         1.03363056 0.        ]\n",
            " [0.         0.         1.00976067]]\n",
            "S missing shape\n",
            "  (95, 3, 3)\n",
            "S missing\n",
            "  [[[0.5076951  0.         0.        ]\n",
            "  [0.         0.931599   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11078645 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.81489424 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.08390074]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89785627 0.         0.        ]\n",
            "  [0.         1.02310342 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.43329125 0.        ]\n",
            "  [0.         0.         0.84222211]]\n",
            "\n",
            " [[0.71095261 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94762984]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.12202352 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75161877 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.00118587]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.20979379]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.20693413]]\n",
            "\n",
            " [[0.7183907  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.44682012]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86883172 0.        ]\n",
            "  [0.         0.         0.65154052]]\n",
            "\n",
            " [[0.49886114 0.         0.        ]\n",
            "  [0.         0.37091841 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68043773]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.36662437 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.43964485 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.41373589 0.        ]\n",
            "  [0.         0.         0.63821744]]\n",
            "\n",
            " [[0.2747041  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.04011971 0.        ]\n",
            "  [0.         0.         0.76310995]]\n",
            "\n",
            " [[0.42456167 0.         0.        ]\n",
            "  [0.         0.71952221 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.74206572 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.2953579  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53891851 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.1156713  0.         0.        ]\n",
            "  [0.         1.36682821 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48353251 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50518059 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79662727 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.23012193 0.         0.        ]\n",
            "  [0.         0.53776695 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91474013]]\n",
            "\n",
            " [[0.88840571 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46473388]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87403793]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76342562]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7899393  0.        ]\n",
            "  [0.         0.         0.80194784]]\n",
            "\n",
            " [[1.07462583 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8732545 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57124902]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.867008   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.83866605 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.43929313 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.77065515]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.81579779]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.46018316 0.         0.        ]\n",
            "  [0.         1.27908135 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16643154 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7959343 ]]\n",
            "\n",
            " [[1.3621154  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.16484023]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.4341513  0.        ]\n",
            "  [0.         0.         0.75086834]]\n",
            "\n",
            " [[0.53872188 0.         0.        ]\n",
            "  [0.         1.00278258 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.95587538 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.07061603]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69233638 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.32905559 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78013775 0.        ]\n",
            "  [0.         0.         0.55283678]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53736064 0.        ]\n",
            "  [0.         0.         0.70658477]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.40863981 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.91313362]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.79538556 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8124559  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.72322109 0.        ]\n",
            "  [0.         0.         0.96809113]]\n",
            "\n",
            " [[1.51675663 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.32098563 0.        ]\n",
            "  [0.         0.         0.46194005]]\n",
            "\n",
            " [[1.15444467 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.7162303  0.        ]\n",
            "  [0.         0.         1.5298155 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15311475 0.        ]\n",
            "  [0.         0.         0.46005042]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.10730829]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 95, 3)\n",
            "y_train length  95\n",
            "-------> size test:  20000  , size train:  95 nbr_seen (train):  31  nbr_miss :  64\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.94640292 0.         0.        ]\n",
            " [0.         1.03363056 0.        ]\n",
            " [0.         0.         1.00976067]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.05663241 0.         0.        ]\n",
            " [0.         0.96746365 0.        ]\n",
            " [0.         0.         0.99033368]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1261.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.03709941145266385\n",
            "---------------------------------> best coeff  [-1.50761567 -0.83003054 -0.28217033]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "x_axis for print in plot_res---->  [40, 50, 60, 70, 80, 90, 100]\n",
            "key in plot_res ('BR_si', 'std_nan', 'adv') : values\n",
            " {'best_coeff': [array([-1.4562972 , -1.02703805, -0.34741063]), array([-1.43950509, -1.00622581, -0.2941482 ]), array([-1.56085873, -0.87593397, -0.30435686]), array([-1.60097172, -0.86520544, -0.33421176]), array([-1.60845561, -0.89861364, -0.41716899]), array([-1.61287576, -0.89001502, -0.38807604]), array([-1.62593036, -0.87920445, -0.35939302])], 'l2_dist_best_coeff_gt': [np.float64(0.21165538466519604), np.float64(0.23896615195718146), np.float64(0.13705579514933083), np.float64(0.1039421469405221), np.float64(0.014682790110277243), np.float64(0.04533429554752139), np.float64(0.07802121237742637)], 'best_score': [np.float64(0.044850361014041634), np.float64(0.05699195314454706), np.float64(0.018772629180271474), np.float64(0.010843420618185466), np.float64(0.00021610004776895892), np.float64(0.002059958735089633), np.float64(0.006106099601442178)], 'best_hyper_p': [array([0.02335721, 0.        ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.00695193, 0.        ]), array([0.02335721, 0.        ]), array([0.01274275, 0.        ]), array([0.00695193, 0.        ])], 'best_alpha_dts': [np.float64(0.023357214690901212), np.float64(0.0001), np.float64(0.0001), np.float64(0.0069519279617756054), np.float64(0.023357214690901212), np.float64(0.012742749857031334), np.float64(0.0069519279617756054)], 'best_alpha_mis': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]}\n",
            "key in plot_res ('oracle', 'sd', 'adv') : values\n",
            " {'best_coeff': [array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982])], 'l2_dist_best_coeff_gt': [np.float64(5.790549085899884e-11), np.float64(4.533761924990149e-11), np.float64(2.975964229552401e-11), np.float64(3.217760740374142e-11), np.float64(3.30082777413363e-11), np.float64(3.725115310447492e-11), np.float64(4.200272238196339e-11)], 'best_score': [np.float64(3.361738999781952e-21), np.float64(2.0557854585767778e-21), np.float64(8.860410440719698e-22), np.float64(1.0366490448101213e-21), np.float64(1.0908231145037802e-21), np.float64(1.388734279396532e-21), np.float64(1.7651762116345125e-21)], 'best_hyper_p': [array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ])], 'best_alpha_dts': [np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225)], 'best_alpha_mis': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]}\n",
            "key in plot_res ('BR_si', 'std_nan', 'ridge') : values\n",
            " {'best_coeff': [array([-1.46847358, -1.07003848, -0.3709771 ]), array([-1.43955701, -1.00633719, -0.29418459]), array([-1.56093688, -0.87600319, -0.30433412]), array([-1.6048729 , -0.8676055 , -0.33263177]), array([-1.61679885, -0.90343892, -0.40722509]), array([-1.62353044, -0.89731559, -0.38461695]), array([-1.63297736, -0.88236222, -0.35969715])], 'l2_dist_best_coeff_gt': [np.float64(0.22462530047985005), np.float64(0.23895742211350485), np.float64(0.1370376541903519), np.float64(0.10447508702890121), np.float64(0.026195123764839085), np.float64(0.049947536707293065), np.float64(0.07897975763319948)], 'best_score': [np.float64(0.05062148498769628), np.float64(0.05698784467098297), np.float64(0.018767539488994768), np.float64(0.010950628809399983), np.float64(0.0006812379235736418), np.float64(0.002487756060899781), np.float64(0.006249582355372349)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.26366509, 0.26366509]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.26366508987303583), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.26366508987303583), np.float64(0.0001), np.float64(0.0001)]}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 'adv') : values\n",
            " {'best_coeff': [array([-1.43357371, -1.07576749, -0.29039822]), array([-1.26644504, -0.85125315, -0.27002656]), array([-1.47380579, -0.76181253, -0.37329275]), array([-1.48000339, -0.84744845, -0.25830443]), array([-1.52958233, -0.88072671, -0.24110246]), array([-1.62121637, -0.76927173, -0.37963377]), array([-1.50749628, -0.82989443, -0.28205357])], 'l2_dist_best_coeff_gt': [np.float64(0.28174480002595026), np.float64(0.379157215360503), np.float64(0.20157280583330506), np.float64(0.22073148238947232), np.float64(0.20583030303509217), np.float64(0.1438575958750949), np.float64(0.19279433912166116)], 'best_score': [np.float64(0.07926840193351885), np.float64(0.14314647880757098), np.float64(0.04034378888854511), np.float64(0.04866470214825213), np.float64(0.04227818318127093), np.float64(0.020880103065808384), np.float64(0.0371775172216542)], 'best_hyper_p': [array([0.078476, 0.0001  ]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.07847599703514607), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 'ridge') : values\n",
            " {'best_coeff': [array([-1.41512181, -1.14037531, -0.32606607]), array([-1.26658299, -0.85149517, -0.27020702]), array([-1.47392779, -0.76187421, -0.37341093]), array([-1.48005393, -0.84754852, -0.25836496]), array([-1.52970131, -0.88087   , -0.24110864]), array([-1.62134337, -0.76932678, -0.37969482]), array([-1.50761567, -0.83003054, -0.28217033])], 'l2_dist_best_coeff_gt': [np.float64(0.3222561215305936), np.float64(0.37892429868240657), np.float64(0.2014159492587136), np.float64(0.22063024593468378), np.float64(0.20576524761438544), np.float64(0.14379835214297831), np.float64(0.19259178577174124)], 'best_score': [np.float64(0.10404339456912555), np.float64(0.1429710880583534), np.float64(0.04028077176201654), np.float64(0.04861995504511866), np.float64(0.04225103373749461), np.float64(0.020863147907294325), np.float64(0.03709941145266385)], 'best_hyper_p': [array([1.62377674, 1.62377674]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(1.623776739188721), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(1.623776739188721), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.21165538466519604), np.float64(0.23896615195718146), np.float64(0.13705579514933083), np.float64(0.1039421469405221), np.float64(0.014682790110277243), np.float64(0.04533429554752139), np.float64(0.07802121237742637)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(5.790549085899884e-11), np.float64(4.533761924990149e-11), np.float64(2.975964229552401e-11), np.float64(3.217760740374142e-11), np.float64(3.30082777413363e-11), np.float64(3.725115310447492e-11), np.float64(4.200272238196339e-11)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.22462530047985005), np.float64(0.23895742211350485), np.float64(0.1370376541903519), np.float64(0.10447508702890121), np.float64(0.026195123764839085), np.float64(0.049947536707293065), np.float64(0.07897975763319948)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.28174480002595026), np.float64(0.379157215360503), np.float64(0.20157280583330506), np.float64(0.22073148238947232), np.float64(0.20583030303509217), np.float64(0.1438575958750949), np.float64(0.19279433912166116)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.3222561215305936), np.float64(0.37892429868240657), np.float64(0.2014159492587136), np.float64(0.22063024593468378), np.float64(0.20576524761438544), np.float64(0.14379835214297831), np.float64(0.19259178577174124)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.044850361014041634), np.float64(0.05699195314454706), np.float64(0.018772629180271474), np.float64(0.010843420618185466), np.float64(0.00021610004776895892), np.float64(0.002059958735089633), np.float64(0.006106099601442178)]\n",
            "lb[i] in plot_res  best_score    [np.float64(3.361738999781952e-21), np.float64(2.0557854585767778e-21), np.float64(8.860410440719698e-22), np.float64(1.0366490448101213e-21), np.float64(1.0908231145037802e-21), np.float64(1.388734279396532e-21), np.float64(1.7651762116345125e-21)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.05062148498769628), np.float64(0.05698784467098297), np.float64(0.018767539488994768), np.float64(0.010950628809399983), np.float64(0.0006812379235736418), np.float64(0.002487756060899781), np.float64(0.006249582355372349)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.07926840193351885), np.float64(0.14314647880757098), np.float64(0.04034378888854511), np.float64(0.04866470214825213), np.float64(0.04227818318127093), np.float64(0.020880103065808384), np.float64(0.0371775172216542)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.10404339456912555), np.float64(0.1429710880583534), np.float64(0.04028077176201654), np.float64(0.04861995504511866), np.float64(0.04225103373749461), np.float64(0.020863147907294325), np.float64(0.03709941145266385)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.023357214690901212), np.float64(0.0001), np.float64(0.0001), np.float64(0.0069519279617756054), np.float64(0.023357214690901212), np.float64(0.012742749857031334), np.float64(0.0069519279617756054)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.26366508987303583), np.float64(0.0001), np.float64(0.0001)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.07847599703514607), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(1.623776739188721), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]\n",
            "--------------------------------------------------------------------------------------nbr_experiment external --------------->  2 - 2   2 - 2   2\n",
            "[[], [], [], [], [], [], []]\n",
            "[]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20100, 3)\n",
            "p_missing in generate mask  [0.66, 1, 1, 1, 1, 1, 1]\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  0\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20040, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   40\n",
            "X shape in clear data  (40, 3)\n",
            "y shape in clear data  (40,)\n",
            "M shape in clear data  (40,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(40, 3)\n",
            "(40, 3)\n",
            "(40,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.04357056 1.05237352 0.9219381 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  4.067191550001843\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0]\n",
            "S dataset \n",
            " [[1.07367106 0.         0.        ]\n",
            " [0.         1.1492501  0.        ]\n",
            " [0.         0.         0.95676402]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (40, 3)\n",
            "y_train length  40\n",
            "-------> size test:  20000  , size train:  40 nbr_seen (train):  9  nbr_miss :  31\n",
            "X  40   3\n",
            "y shape (40,)\n",
            "nm  120\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 204.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.1557149707130631\n",
            "---------------------------------> best coeff  [-1.46456953 -0.60304177 -0.21837017]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.04357056 1.05237352 0.9219381 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  7.914307008503925\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.04357056 0.         0.        ]\n",
            " [0.         1.05237352 0.        ]\n",
            " [0.         0.         0.9219381 ]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (40, 3)\n",
            "y_train length  40\n",
            "-------> size test:  20000  , size train:  40 nbr_seen (train):  40  nbr_miss :  0\n",
            "X  40   3\n",
            "y shape (40,)\n",
            "nm  120\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 135.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.2376927153823157e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.04357056 1.05237352 0.9219381 ]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  4.067191550001843\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0]\n",
            "S dataset \n",
            " [[1.07367106 0.         0.        ]\n",
            " [0.         1.1492501  0.        ]\n",
            " [0.         0.         0.95676402]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (40, 3)\n",
            "y_train length  40\n",
            "-------> size test:  20000  , size train:  40 nbr_seen (train):  9  nbr_miss :  31\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.07367106 0.         0.        ]\n",
            " [0.         1.1492501  0.        ]\n",
            " [0.         0.         0.95676402]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.93138396 0.         0.        ]\n",
            " [0.         0.87013262 0.        ]\n",
            " [0.         0.         1.04518981]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 560.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.15564760588356144\n",
            "---------------------------------> best coeff  [-1.46460654 -0.60309785 -0.2184241 ]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.04357056 1.05237352 0.9219381 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  8.518224356504547\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0]\n",
            "S dataset \n",
            " [[1.07367106 0.         0.        ]\n",
            " [0.         1.1492501  0.        ]\n",
            " [0.         0.         0.95676402]]\n",
            "S missing shape\n",
            "  (40, 3, 3)\n",
            "S missing\n",
            "  [[[0.86297354 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.23494159 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66418834]]\n",
            "\n",
            " [[1.23014485 0.         0.        ]\n",
            "  [0.         0.47763584 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.92140708 0.        ]\n",
            "  [0.         0.         0.82593375]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.24968178]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8570284  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.39315468 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.70484008 0.        ]\n",
            "  [0.         0.         0.77493598]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.86722797 0.         0.        ]\n",
            "  [0.         0.59929386 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93538246]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.55868471]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.95108971 0.        ]\n",
            "  [0.         0.         0.8754846 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.49264968 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.6675118  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66648728]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09924883 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.414487   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98702427 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61831075]]\n",
            "\n",
            " [[1.16414059 0.         0.        ]\n",
            "  [0.         1.27754307 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.7091616  0.         0.        ]\n",
            "  [0.         0.84097579 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.73588613 0.        ]\n",
            "  [0.         0.         0.71927524]]\n",
            "\n",
            " [[0.71514751 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16923458 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.01933344 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.86527298]]\n",
            "\n",
            " [[1.38384811 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.38858384]]\n",
            "\n",
            " [[1.09496162 0.         0.        ]\n",
            "  [0.         0.93397506 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78934118 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.99580642 0.         0.        ]\n",
            "  [0.         1.35295894 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.88773332 0.        ]\n",
            "  [0.         0.         0.57410057]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 40, 3)\n",
            "y_train length  40\n",
            "-------> size test:  20000  , size train:  40 nbr_seen (train):  9  nbr_miss :  31\n",
            "X  40   3\n",
            "y shape (40,)\n",
            "nm  120\n",
            "S_mis in Adbvt training  [[[0.86297354 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.23494159 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66418834]]\n",
            "\n",
            " [[1.23014485 0.         0.        ]\n",
            "  [0.         0.47763584 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.92140708 0.        ]\n",
            "  [0.         0.         0.82593375]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.24968178]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8570284  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.39315468 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.70484008 0.        ]\n",
            "  [0.         0.         0.77493598]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.86722797 0.         0.        ]\n",
            "  [0.         0.59929386 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93538246]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.55868471]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.95108971 0.        ]\n",
            "  [0.         0.         0.8754846 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.49264968 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.6675118  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66648728]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09924883 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.414487   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98702427 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61831075]]\n",
            "\n",
            " [[1.16414059 0.         0.        ]\n",
            "  [0.         1.27754307 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.7091616  0.         0.        ]\n",
            "  [0.         0.84097579 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.73588613 0.        ]\n",
            "  [0.         0.         0.71927524]]\n",
            "\n",
            " [[0.71514751 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16923458 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.01933344 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.86527298]]\n",
            "\n",
            " [[1.38384811 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.38858384]]\n",
            "\n",
            " [[1.09496162 0.         0.        ]\n",
            "  [0.         0.93397506 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78934118 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.99580642 0.         0.        ]\n",
            "  [0.         1.35295894 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.88773332 0.        ]\n",
            "  [0.         0.         0.57410057]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.07 0.00 0.00]\n",
            " [0.00 1.15 0.00]\n",
            " ...\n",
            " [0.00 1.15 0.00]\n",
            " [0.00 0.00 0.96]] @ Promote(adv_radius_times_dts, (120, 3)) + [[0.86 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (120, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.30it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.25it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:05,  3.59it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 85.80it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 88.26it/s]\n",
            " 10%|█         | 2/20 [00:00<00:04,  3.97it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 84.23it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:04,  4.04it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 103.75it/s]\n",
            " 20%|██        | 4/20 [00:00<00:03,  4.39it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 102.16it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:03,  4.59it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 112.82it/s]\n",
            " 30%|███       | 6/20 [00:01<00:02,  4.86it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 127.30it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:02,  5.23it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 125.79it/s]\n",
            " 40%|████      | 8/20 [00:01<00:02,  5.47it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 127.63it/s]\n",
            " 45%|████▌     | 9/20 [00:01<00:01,  5.66it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 124.78it/s]\n",
            " 50%|█████     | 10/20 [00:01<00:01,  5.78it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 127.17it/s]\n",
            " 55%|█████▌    | 11/20 [00:02<00:01,  5.89it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 114.43it/s]\n",
            " 60%|██████    | 12/20 [00:02<00:01,  5.79it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 131.10it/s]\n",
            " 65%|██████▌   | 13/20 [00:02<00:01,  5.95it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 125.66it/s]\n",
            " 70%|███████   | 14/20 [00:02<00:01,  5.99it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 128.90it/s]\n",
            " 75%|███████▌  | 15/20 [00:02<00:00,  6.06it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 133.97it/s]\n",
            " 80%|████████  | 16/20 [00:02<00:00,  6.17it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 129.16it/s]\n",
            " 85%|████████▌ | 17/20 [00:03<00:00,  6.21it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 129.13it/s]\n",
            " 90%|█████████ | 18/20 [00:03<00:00,  6.19it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 116.45it/s]\n",
            " 95%|█████████▌| 19/20 [00:03<00:00,  6.00it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 126.77it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.2975405324656542\n",
            "---------------------------------> best coeff  [-1.44550302 -0.48578006 -0.12034573]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.04357056 1.05237352 0.9219381 ]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  8.518224356504547\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0]\n",
            "S dataset \n",
            " [[1.07367106 0.         0.        ]\n",
            " [0.         1.1492501  0.        ]\n",
            " [0.         0.         0.95676402]]\n",
            "S missing shape\n",
            "  (40, 3, 3)\n",
            "S missing\n",
            "  [[[0.86297354 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.23494159 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66418834]]\n",
            "\n",
            " [[1.23014485 0.         0.        ]\n",
            "  [0.         0.47763584 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.92140708 0.        ]\n",
            "  [0.         0.         0.82593375]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.24968178]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8570284  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.39315468 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.70484008 0.        ]\n",
            "  [0.         0.         0.77493598]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.86722797 0.         0.        ]\n",
            "  [0.         0.59929386 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93538246]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.55868471]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.95108971 0.        ]\n",
            "  [0.         0.         0.8754846 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.49264968 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.6675118  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66648728]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09924883 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.414487   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98702427 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61831075]]\n",
            "\n",
            " [[1.16414059 0.         0.        ]\n",
            "  [0.         1.27754307 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.7091616  0.         0.        ]\n",
            "  [0.         0.84097579 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.73588613 0.        ]\n",
            "  [0.         0.         0.71927524]]\n",
            "\n",
            " [[0.71514751 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16923458 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.01933344 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.86527298]]\n",
            "\n",
            " [[1.38384811 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.38858384]]\n",
            "\n",
            " [[1.09496162 0.         0.        ]\n",
            "  [0.         0.93397506 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78934118 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.99580642 0.         0.        ]\n",
            "  [0.         1.35295894 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.88773332 0.        ]\n",
            "  [0.         0.         0.57410057]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 40, 3)\n",
            "y_train length  40\n",
            "-------> size test:  20000  , size train:  40 nbr_seen (train):  9  nbr_miss :  31\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.07367106 0.         0.        ]\n",
            " [0.         1.1492501  0.        ]\n",
            " [0.         0.         0.95676402]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.93138396 0.         0.        ]\n",
            " [0.         0.87013262 0.        ]\n",
            " [0.         0.         1.04518981]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 636.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.2973490607466435\n",
            "---------------------------------> best coeff  [-1.4456124  -0.48593057 -0.12039457]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  1\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20050, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   50\n",
            "X shape in clear data  (50, 3)\n",
            "y shape in clear data  (50,)\n",
            "M shape in clear data  (50,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(50, 3)\n",
            "(50, 3)\n",
            "(50,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468],\n",
            "       [-0.72900408,  0.89520914, -0.56632818],\n",
            "       [-0.95056766, -0.90711733, -1.71907826],\n",
            "       [-1.27576047, -2.94005899, -0.73959924],\n",
            "       [ 1.37544471, -1.90704468,  0.38290844],\n",
            "       [-0.38420033, -0.83535649, -0.82359467],\n",
            "       [-0.36790112,  0.10549094,  1.47770934],\n",
            "       [ 0.07416557, -1.41049811,  0.79117911],\n",
            "       [-0.33200417, -0.69935181,  0.61001841],\n",
            "       [-1.24522791,  0.26689302,  0.5333737 ],\n",
            "       [-1.84372823,  2.53984314, -0.43497275]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01,\n",
            "        6.06600497e-01,  3.08631241e+00,  5.02161525e+00, -6.52182597e-01,\n",
            "        1.72606982e+00, -1.41348503e-01,  8.13237393e-01,  9.01569995e-01,\n",
            "        1.52881194e+00,  8.55347733e-01]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03138728 1.16200991 0.92455829]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.417213005801179\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0]\n",
            "S dataset \n",
            " [[1.10965356 0.         0.        ]\n",
            " [0.         1.28634903 0.        ]\n",
            " [0.         0.         0.96165096]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (50, 3)\n",
            "y_train length  50\n",
            "-------> size test:  20000  , size train:  50 nbr_seen (train):  12  nbr_miss :  38\n",
            "X  50   3\n",
            "y shape (50,)\n",
            "nm  150\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 127.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.06361217916860534\n",
            "---------------------------------> best coeff  [-1.44394845 -0.72880694 -0.34795195]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03138728 1.16200991 0.92455829]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -3.1448519254856304\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "S dataset \n",
            " [[1.03138728 0.         0.        ]\n",
            " [0.         1.16200991 0.        ]\n",
            " [0.         0.         0.92455829]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (50, 3)\n",
            "y_train length  50\n",
            "-------> size test:  20000  , size train:  50 nbr_seen (train):  50  nbr_miss :  0\n",
            "X  50   3\n",
            "y shape (50,)\n",
            "nm  150\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 120.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  4  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00112884 0.        ] , min score  5.366579767446593e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03138728 1.16200991 0.92455829]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.417213005801179\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0]\n",
            "S dataset \n",
            " [[1.10965356 0.         0.        ]\n",
            " [0.         1.28634903 0.        ]\n",
            " [0.         0.         0.96165096]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (50, 3)\n",
            "y_train length  50\n",
            "-------> size test:  20000  , size train:  50 nbr_seen (train):  12  nbr_miss :  38\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.10965356 0.         0.        ]\n",
            " [0.         1.28634903 0.        ]\n",
            " [0.         0.         0.96165096]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.90118217 0.         0.        ]\n",
            " [0.         0.77739399 0.        ]\n",
            " [0.         0.         1.03987833]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 541.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.06357290879553121\n",
            "---------------------------------> best coeff  [-1.44399214 -0.72882733 -0.34805817]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03138728 1.16200991 0.92455829]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -45.07546238262471\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0]\n",
            "S dataset \n",
            " [[1.10965356 0.         0.        ]\n",
            " [0.         1.28634903 0.        ]\n",
            " [0.         0.         0.96165096]]\n",
            "S missing shape\n",
            "  (50, 3, 3)\n",
            "S missing\n",
            "  [[[0.35403611 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56489598 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.82860253]]\n",
            "\n",
            " [[0.85282407 0.         0.        ]\n",
            "  [0.         0.75119817 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.1713225  0.        ]\n",
            "  [0.         0.         0.36609879]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93794378]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.13084583 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74493873 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93329436 0.        ]\n",
            "  [0.         0.         0.82991543]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62740565 0.         0.        ]\n",
            "  [0.         1.37779311 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6385135 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02229867]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53245889 0.        ]\n",
            "  [0.         0.         0.90242283]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.79359135 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93529455 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.27933146]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77112713 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.71584401 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93858368 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.23609919]]\n",
            "\n",
            " [[0.89364685 0.         0.        ]\n",
            "  [0.         1.09872738 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.11618223 0.         0.        ]\n",
            "  [0.         0.62251334 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78810376 0.        ]\n",
            "  [0.         0.         1.10221487]]\n",
            "\n",
            " [[0.39797727 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06483981 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86186389 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99558069]]\n",
            "\n",
            " [[0.74669935 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.86006792]]\n",
            "\n",
            " [[1.03292532 0.         0.        ]\n",
            "  [0.         1.1250967  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16914683 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69701939 0.         0.        ]\n",
            "  [0.         0.71875155 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24830736 0.        ]\n",
            "  [0.         0.         0.74841148]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.7114594  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.65782333 0.         0.        ]\n",
            "  [0.         0.85464675 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68638356 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3012122  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.59427705]]\n",
            "\n",
            " [[1.35861546 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.1837709  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.37182956 0.        ]\n",
            "  [0.         0.         0.67852018]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 50, 3)\n",
            "y_train length  50\n",
            "-------> size test:  20000  , size train:  50 nbr_seen (train):  12  nbr_miss :  38\n",
            "X  50   3\n",
            "y shape (50,)\n",
            "nm  150\n",
            "S_mis in Adbvt training  [[[0.35403611 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56489598 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.82860253]]\n",
            "\n",
            " [[0.85282407 0.         0.        ]\n",
            "  [0.         0.75119817 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.1713225  0.        ]\n",
            "  [0.         0.         0.36609879]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93794378]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.13084583 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74493873 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93329436 0.        ]\n",
            "  [0.         0.         0.82991543]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62740565 0.         0.        ]\n",
            "  [0.         1.37779311 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6385135 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02229867]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53245889 0.        ]\n",
            "  [0.         0.         0.90242283]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.79359135 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93529455 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.27933146]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77112713 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.71584401 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93858368 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.23609919]]\n",
            "\n",
            " [[0.89364685 0.         0.        ]\n",
            "  [0.         1.09872738 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.11618223 0.         0.        ]\n",
            "  [0.         0.62251334 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78810376 0.        ]\n",
            "  [0.         0.         1.10221487]]\n",
            "\n",
            " [[0.39797727 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06483981 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86186389 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99558069]]\n",
            "\n",
            " [[0.74669935 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.86006792]]\n",
            "\n",
            " [[1.03292532 0.         0.        ]\n",
            "  [0.         1.1250967  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16914683 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69701939 0.         0.        ]\n",
            "  [0.         0.71875155 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24830736 0.        ]\n",
            "  [0.         0.         0.74841148]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.7114594  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.65782333 0.         0.        ]\n",
            "  [0.         0.85464675 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68638356 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3012122  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.59427705]]\n",
            "\n",
            " [[1.35861546 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.1837709  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.37182956 0.        ]\n",
            "  [0.         0.         0.67852018]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.11 0.00 0.00]\n",
            " [0.00 1.29 0.00]\n",
            " ...\n",
            " [0.00 1.29 0.00]\n",
            " [0.00 0.00 0.96]] @ Promote(adv_radius_times_dts, (150, 3)) + [[0.35 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (150, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.78it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 89.58it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:04,  4.39it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.90it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.31it/s]\n",
            " 10%|█         | 2/20 [00:00<00:04,  4.40it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 101.56it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:03,  4.64it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 101.00it/s]\n",
            " 20%|██        | 4/20 [00:00<00:03,  4.68it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 112.22it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:03,  4.91it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 108.24it/s]\n",
            " 30%|███       | 6/20 [00:01<00:02,  5.01it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 111.45it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:02,  5.14it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 107.79it/s]\n",
            " 40%|████      | 8/20 [00:01<00:02,  5.19it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 108.54it/s]\n",
            " 45%|████▌     | 9/20 [00:01<00:02,  5.22it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.33it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 96.95it/s] \n",
            " 50%|█████     | 10/20 [00:02<00:01,  5.06it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 105.35it/s]\n",
            " 55%|█████▌    | 11/20 [00:02<00:01,  5.07it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 111.29it/s]\n",
            " 60%|██████    | 12/20 [00:02<00:01,  5.18it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 113.66it/s]\n",
            " 65%|██████▌   | 13/20 [00:02<00:01,  5.27it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 108.43it/s]\n",
            " 70%|███████   | 14/20 [00:02<00:01,  5.28it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 103.11it/s]\n",
            " 75%|███████▌  | 15/20 [00:02<00:00,  5.21it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 110.67it/s]\n",
            " 80%|████████  | 16/20 [00:03<00:00,  5.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 111.09it/s]\n",
            " 85%|████████▌ | 17/20 [00:03<00:00,  5.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 106.47it/s]\n",
            " 90%|█████████ | 18/20 [00:03<00:00,  5.16it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 109.32it/s]\n",
            " 95%|█████████▌| 19/20 [00:03<00:00,  5.20it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 107.27it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.1655573502062121\n",
            "---------------------------------> best coeff  [-1.25796944 -0.70369121 -0.36839222]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03138728 1.16200991 0.92455829]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -45.07546238262471\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0]\n",
            "S dataset \n",
            " [[1.10965356 0.         0.        ]\n",
            " [0.         1.28634903 0.        ]\n",
            " [0.         0.         0.96165096]]\n",
            "S missing shape\n",
            "  (50, 3, 3)\n",
            "S missing\n",
            "  [[[0.35403611 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56489598 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.82860253]]\n",
            "\n",
            " [[0.85282407 0.         0.        ]\n",
            "  [0.         0.75119817 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.1713225  0.        ]\n",
            "  [0.         0.         0.36609879]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93794378]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.13084583 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74493873 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93329436 0.        ]\n",
            "  [0.         0.         0.82991543]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62740565 0.         0.        ]\n",
            "  [0.         1.37779311 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6385135 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.02229867]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53245889 0.        ]\n",
            "  [0.         0.         0.90242283]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.79359135 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93529455 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.27933146]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77112713 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.71584401 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.93858368 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.23609919]]\n",
            "\n",
            " [[0.89364685 0.         0.        ]\n",
            "  [0.         1.09872738 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.11618223 0.         0.        ]\n",
            "  [0.         0.62251334 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78810376 0.        ]\n",
            "  [0.         0.         1.10221487]]\n",
            "\n",
            " [[0.39797727 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.06483981 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86186389 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.99558069]]\n",
            "\n",
            " [[0.74669935 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.86006792]]\n",
            "\n",
            " [[1.03292532 0.         0.        ]\n",
            "  [0.         1.1250967  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16914683 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69701939 0.         0.        ]\n",
            "  [0.         0.71875155 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24830736 0.        ]\n",
            "  [0.         0.         0.74841148]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.7114594  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.65782333 0.         0.        ]\n",
            "  [0.         0.85464675 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68638356 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.3012122  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.59427705]]\n",
            "\n",
            " [[1.35861546 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.1837709  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.37182956 0.        ]\n",
            "  [0.         0.         0.67852018]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 50, 3)\n",
            "y_train length  50\n",
            "-------> size test:  20000  , size train:  50 nbr_seen (train):  12  nbr_miss :  38\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.10965356 0.         0.        ]\n",
            " [0.         1.28634903 0.        ]\n",
            " [0.         0.         0.96165096]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.90118217 0.         0.        ]\n",
            " [0.         0.77739399 0.        ]\n",
            " [0.         0.         1.03987833]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 885.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.16538035384417787\n",
            "---------------------------------> best coeff  [-1.2581018  -0.70381434 -0.36866896]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  2\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20060, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   60\n",
            "X shape in clear data  (60, 3)\n",
            "y shape in clear data  (60,)\n",
            "M shape in clear data  (60,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(59, 3)\n",
            "(59, 3)\n",
            "(59,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468],\n",
            "       [-0.72900408,  0.89520914, -0.56632818],\n",
            "       [-0.95056766, -0.90711733, -1.71907826],\n",
            "       [-1.27576047, -2.94005899, -0.73959924],\n",
            "       [ 1.37544471, -1.90704468,  0.38290844],\n",
            "       [-0.38420033, -0.83535649, -0.82359467],\n",
            "       [-0.36790112,  0.10549094,  1.47770934],\n",
            "       [ 0.07416557, -1.41049811,  0.79117911],\n",
            "       [-0.33200417, -0.69935181,  0.61001841],\n",
            "       [-1.24522791,  0.26689302,  0.5333737 ],\n",
            "       [-1.84372823,  2.53984314, -0.43497275],\n",
            "       [-0.33671289, -0.90425078, -0.50244006],\n",
            "       [ 1.20993516,  0.0216535 , -1.83209291],\n",
            "       [ 1.34308443,  0.062579  ,  0.11619287],\n",
            "       [ 0.30523464,  0.76742839,  0.75818238],\n",
            "       [-0.10720166,  0.19385501, -1.63230642],\n",
            "       [ 0.32735891,  0.24514196,  1.13688418],\n",
            "       [ 0.20453336,  0.72006844, -1.40582025],\n",
            "       [ 1.31934245, -0.16201123,  0.12822749],\n",
            "       [-0.53862874,  2.98109984,  0.51936044]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01,\n",
            "        6.06600497e-01,  3.08631241e+00,  5.02161525e+00, -6.52182597e-01,\n",
            "        1.72606982e+00, -1.41348503e-01,  8.13237393e-01,  9.01569995e-01,\n",
            "        1.52881194e+00,  8.55347733e-01,  1.57358665e+00, -1.17286490e+00,\n",
            "       -2.26335807e+00, -1.50974713e+00,  7.00684620e-01, -1.23699999e+00,\n",
            "       -3.72575517e-01, -2.02766804e+00, -2.05011434e+00]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.00386206 1.1560665  0.95535168]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -6.971006297226295\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1]\n",
            "S dataset \n",
            " [[1.05387771 0.         0.        ]\n",
            " [0.         1.201877   0.        ]\n",
            " [0.         0.         1.01131384]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (59, 3)\n",
            "y_train length  59\n",
            "-------> size test:  20000  , size train:  59 nbr_seen (train):  16  nbr_miss :  43\n",
            "X  59   3\n",
            "y shape (59,)\n",
            "nm  177\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 119.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.057897990847169546\n",
            "---------------------------------> best coeff  [-1.43190308 -0.74469649 -0.381491  ]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.00386206 1.1560665  0.95535168]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  1.7938455991987206\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.00386206 0.         0.        ]\n",
            " [0.         1.1560665  0.        ]\n",
            " [0.         0.         0.95535168]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (59, 3)\n",
            "y_train length  59\n",
            "-------> size test:  20000  , size train:  59 nbr_seen (train):  59  nbr_miss :  0\n",
            "X  59   3\n",
            "y shape (59,)\n",
            "nm  177\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 110.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  4  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00112884 0.        ] , min score  5.323337041922529e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.00386206 1.1560665  0.95535168]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -6.971006297226295\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1]\n",
            "S dataset \n",
            " [[1.05387771 0.         0.        ]\n",
            " [0.         1.201877   0.        ]\n",
            " [0.         0.         1.01131384]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (59, 3)\n",
            "y_train length  59\n",
            "-------> size test:  20000  , size train:  59 nbr_seen (train):  16  nbr_miss :  43\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.05387771 0.         0.        ]\n",
            " [0.         1.201877   0.        ]\n",
            " [0.         0.         1.01131384]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.94887669 0.         0.        ]\n",
            " [0.         0.8320319  0.        ]\n",
            " [0.         0.         0.98881273]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 722.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.057870674868799606\n",
            "---------------------------------> best coeff  [-1.43193547 -0.74470991 -0.38160674]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.00386206 1.1560665  0.95535168]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -20.4626131159487\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1]\n",
            "S dataset \n",
            " [[1.05387771 0.         0.        ]\n",
            " [0.         1.201877   0.        ]\n",
            " [0.         0.         1.01131384]]\n",
            "S missing shape\n",
            "  (59, 3, 3)\n",
            "S missing\n",
            "  [[[0.76306501 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.68847377 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.78953873]]\n",
            "\n",
            " [[0.91787918 0.         0.        ]\n",
            "  [0.         0.61873819 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.02129427 0.        ]\n",
            "  [0.         0.         0.79391915]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.43188237]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.84521971 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09217139 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.68727765 0.        ]\n",
            "  [0.         0.         1.12816369]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.21370511 0.         0.        ]\n",
            "  [0.         1.0714383  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.45448055]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.03939511]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.85324373 0.        ]\n",
            "  [0.         0.         0.84684003]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77362727 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77379951 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.30681718]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.90215586 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.92010607 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.82993979 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68710695]]\n",
            "\n",
            " [[0.5860583  0.         0.        ]\n",
            "  [0.         0.64232659 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.54100584 0.         0.        ]\n",
            "  [0.         1.54208262 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.9266897  0.        ]\n",
            "  [0.         0.         0.27590727]]\n",
            "\n",
            " [[0.84292345 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.32502441 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24313748 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94251874]]\n",
            "\n",
            " [[0.9877645  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.44592523]]\n",
            "\n",
            " [[1.60068915 0.         0.        ]\n",
            "  [0.         1.03353061 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6440613  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84085996 0.         0.        ]\n",
            "  [0.         0.71304934 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.41512749 0.        ]\n",
            "  [0.         0.         0.39316009]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.33010037 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.31255198 0.         0.        ]\n",
            "  [0.         1.23467263 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.88471173 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79349452 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.92227422]]\n",
            "\n",
            " [[1.34857631 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.24925875 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47869921 0.        ]\n",
            "  [0.         0.         0.58720661]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7371395 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57221356 0.        ]\n",
            "  [0.         0.         0.4502247 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56666561 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.34863818]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.78956481 0.         0.        ]\n",
            "  [0.         0.34947334 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.05439013 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 59, 3)\n",
            "y_train length  59\n",
            "-------> size test:  20000  , size train:  59 nbr_seen (train):  16  nbr_miss :  43\n",
            "X  59   3\n",
            "y shape (59,)\n",
            "nm  177\n",
            "S_mis in Adbvt training  [[[0.76306501 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.68847377 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.78953873]]\n",
            "\n",
            " [[0.91787918 0.         0.        ]\n",
            "  [0.         0.61873819 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.02129427 0.        ]\n",
            "  [0.         0.         0.79391915]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.43188237]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.84521971 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09217139 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.68727765 0.        ]\n",
            "  [0.         0.         1.12816369]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.21370511 0.         0.        ]\n",
            "  [0.         1.0714383  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.45448055]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.03939511]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.85324373 0.        ]\n",
            "  [0.         0.         0.84684003]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77362727 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77379951 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.30681718]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.90215586 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.92010607 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.82993979 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68710695]]\n",
            "\n",
            " [[0.5860583  0.         0.        ]\n",
            "  [0.         0.64232659 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.54100584 0.         0.        ]\n",
            "  [0.         1.54208262 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.9266897  0.        ]\n",
            "  [0.         0.         0.27590727]]\n",
            "\n",
            " [[0.84292345 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.32502441 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24313748 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94251874]]\n",
            "\n",
            " [[0.9877645  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.44592523]]\n",
            "\n",
            " [[1.60068915 0.         0.        ]\n",
            "  [0.         1.03353061 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6440613  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84085996 0.         0.        ]\n",
            "  [0.         0.71304934 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.41512749 0.        ]\n",
            "  [0.         0.         0.39316009]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.33010037 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.31255198 0.         0.        ]\n",
            "  [0.         1.23467263 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.88471173 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79349452 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.92227422]]\n",
            "\n",
            " [[1.34857631 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.24925875 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47869921 0.        ]\n",
            "  [0.         0.         0.58720661]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7371395 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57221356 0.        ]\n",
            "  [0.         0.         0.4502247 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56666561 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.34863818]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.78956481 0.         0.        ]\n",
            "  [0.         0.34947334 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.05439013 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.05 0.00 0.00]\n",
            " [0.00 1.20 0.00]\n",
            " ...\n",
            " [0.00 1.20 0.00]\n",
            " [0.00 0.00 1.01]] @ Promote(adv_radius_times_dts, (177, 3)) + [[0.76 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 1.05 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (177, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 79.20it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 83.43it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:04,  4.09it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 63.17it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 75.22it/s]\n",
            " 10%|█         | 2/20 [00:00<00:04,  3.84it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 86.12it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 92.42it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:04,  4.11it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 76.63it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 82.32it/s]\n",
            " 20%|██        | 4/20 [00:00<00:03,  4.04it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 87.17it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 82.22it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:03,  4.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 89.22it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 80.49it/s]\n",
            " 30%|███       | 6/20 [00:01<00:03,  3.97it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 89.98it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.63it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:03,  4.10it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 75.66it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 79.61it/s]\n",
            " 40%|████      | 8/20 [00:01<00:02,  4.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 99.86it/s] \n",
            " 45%|████▌     | 9/20 [00:02<00:02,  4.26it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 98.97it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 95.06it/s]\n",
            " 50%|█████     | 10/20 [00:02<00:02,  4.35it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.81it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 77.91it/s]\n",
            " 55%|█████▌    | 11/20 [00:02<00:02,  4.17it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 99.48it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 96.88it/s]\n",
            " 60%|██████    | 12/20 [00:02<00:01,  4.29it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 71.97it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 78.91it/s]\n",
            " 65%|██████▌   | 13/20 [00:03<00:01,  4.14it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 84.16it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 88.09it/s]\n",
            " 70%|███████   | 14/20 [00:03<00:01,  4.19it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 77.72it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 75.44it/s]\n",
            " 75%|███████▌  | 15/20 [00:03<00:01,  4.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 94.05it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 95.16it/s]\n",
            " 80%|████████  | 16/20 [00:03<00:00,  4.20it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 84.74it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 91.13it/s]\n",
            " 85%|████████▌ | 17/20 [00:04<00:00,  4.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 87.69it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 90.75it/s]\n",
            " 90%|█████████ | 18/20 [00:04<00:00,  4.29it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 78.97it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 85.32it/s]\n",
            " 95%|█████████▌| 19/20 [00:04<00:00,  4.24it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 75.08it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 84.88it/s]\n",
            "100%|██████████| 20/20 [00:04<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.16257082841916373\n",
            "---------------------------------> best coeff  [-1.2952683  -0.64689054 -0.41690297]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.00386206 1.1560665  0.95535168]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -20.4626131159487\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1]\n",
            "S dataset \n",
            " [[1.05387771 0.         0.        ]\n",
            " [0.         1.201877   0.        ]\n",
            " [0.         0.         1.01131384]]\n",
            "S missing shape\n",
            "  (59, 3, 3)\n",
            "S missing\n",
            "  [[[0.76306501 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.68847377 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.78953873]]\n",
            "\n",
            " [[0.91787918 0.         0.        ]\n",
            "  [0.         0.61873819 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.02129427 0.        ]\n",
            "  [0.         0.         0.79391915]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.43188237]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.84521971 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09217139 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.68727765 0.        ]\n",
            "  [0.         0.         1.12816369]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.21370511 0.         0.        ]\n",
            "  [0.         1.0714383  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.45448055]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.03939511]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.85324373 0.        ]\n",
            "  [0.         0.         0.84684003]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.77362727 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.77379951 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.30681718]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.90215586 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.92010607 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.82993979 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68710695]]\n",
            "\n",
            " [[0.5860583  0.         0.        ]\n",
            "  [0.         0.64232659 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.54100584 0.         0.        ]\n",
            "  [0.         1.54208262 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.9266897  0.        ]\n",
            "  [0.         0.         0.27590727]]\n",
            "\n",
            " [[0.84292345 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.32502441 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.24313748 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94251874]]\n",
            "\n",
            " [[0.9877645  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.44592523]]\n",
            "\n",
            " [[1.60068915 0.         0.        ]\n",
            "  [0.         1.03353061 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6440613  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84085996 0.         0.        ]\n",
            "  [0.         0.71304934 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.41512749 0.        ]\n",
            "  [0.         0.         0.39316009]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.33010037 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.31255198 0.         0.        ]\n",
            "  [0.         1.23467263 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.88471173 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.79349452 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.92227422]]\n",
            "\n",
            " [[1.34857631 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.24925875 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.47869921 0.        ]\n",
            "  [0.         0.         0.58720661]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.7371395 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57221356 0.        ]\n",
            "  [0.         0.         0.4502247 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56666561 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.34863818]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.78956481 0.         0.        ]\n",
            "  [0.         0.34947334 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.05439013 0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 59, 3)\n",
            "y_train length  59\n",
            "-------> size test:  20000  , size train:  59 nbr_seen (train):  16  nbr_miss :  43\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.05387771 0.         0.        ]\n",
            " [0.         1.201877   0.        ]\n",
            " [0.         0.         1.01131384]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.94887669 0.         0.        ]\n",
            " [0.         0.8320319  0.        ]\n",
            " [0.         0.         0.98881273]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1105.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.16241667460630693\n",
            "---------------------------------> best coeff  [-1.2954015  -0.64701918 -0.41707169]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  3\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20070, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   70\n",
            "X shape in clear data  (70, 3)\n",
            "y shape in clear data  (70,)\n",
            "M shape in clear data  (70,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(69, 3)\n",
            "(69, 3)\n",
            "(69,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468],\n",
            "       [-0.72900408,  0.89520914, -0.56632818],\n",
            "       [-0.95056766, -0.90711733, -1.71907826],\n",
            "       [-1.27576047, -2.94005899, -0.73959924],\n",
            "       [ 1.37544471, -1.90704468,  0.38290844],\n",
            "       [-0.38420033, -0.83535649, -0.82359467],\n",
            "       [-0.36790112,  0.10549094,  1.47770934],\n",
            "       [ 0.07416557, -1.41049811,  0.79117911],\n",
            "       [-0.33200417, -0.69935181,  0.61001841],\n",
            "       [-1.24522791,  0.26689302,  0.5333737 ],\n",
            "       [-1.84372823,  2.53984314, -0.43497275],\n",
            "       [-0.33671289, -0.90425078, -0.50244006],\n",
            "       [ 1.20993516,  0.0216535 , -1.83209291],\n",
            "       [ 1.34308443,  0.062579  ,  0.11619287],\n",
            "       [ 0.30523464,  0.76742839,  0.75818238],\n",
            "       [-0.10720166,  0.19385501, -1.63230642],\n",
            "       [ 0.32735891,  0.24514196,  1.13688418],\n",
            "       [ 0.20453336,  0.72006844, -1.40582025],\n",
            "       [ 1.31934245, -0.16201123,  0.12822749],\n",
            "       [-0.53862874,  2.98109984,  0.51936044],\n",
            "       [-0.35721007,  0.74111547,  0.42549164],\n",
            "       [ 1.14627226, -0.77155583,  0.12255875],\n",
            "       [-0.81732683,  2.25718182, -0.03608141],\n",
            "       [-0.56191629,  0.29927655,  0.26328756],\n",
            "       [ 0.91699987, -0.52011764, -0.27695292],\n",
            "       [ 0.38475242, -0.67043378, -0.18488143],\n",
            "       [-0.75478721, -0.10240347,  2.68343304],\n",
            "       [-0.47903804,  0.05205617,  1.15464275],\n",
            "       [ 1.30244489, -1.83544794, -0.37921224],\n",
            "       [ 0.67390468, -0.04890545, -0.53064843]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01,\n",
            "        6.06600497e-01,  3.08631241e+00,  5.02161525e+00, -6.52182597e-01,\n",
            "        1.72606982e+00, -1.41348503e-01,  8.13237393e-01,  9.01569995e-01,\n",
            "        1.52881194e+00,  8.55347733e-01,  1.57358665e+00, -1.17286490e+00,\n",
            "       -2.26335807e+00, -1.50974713e+00,  7.00684620e-01, -1.23699999e+00,\n",
            "       -3.72575517e-01, -2.02766804e+00, -2.05011434e+00, -2.78817082e-01,\n",
            "       -1.19702839e+00, -7.09643376e-01,  5.18695345e-01, -8.83647675e-01,\n",
            "        6.70743800e-02,  1.47930247e-01,  2.24603715e-01, -2.71109476e-01,\n",
            "       -8.09321142e-01]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97719501 1.13745198 0.9529793 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.183140743538786\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0]\n",
            "S dataset \n",
            " [[1.00942052 0.         0.        ]\n",
            " [0.         1.13973872 0.        ]\n",
            " [0.         0.         0.96399982]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (69, 3)\n",
            "y_train length  69\n",
            "-------> size test:  20000  , size train:  69 nbr_seen (train):  20  nbr_miss :  49\n",
            "X  69   3\n",
            "y shape (69,)\n",
            "nm  207\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 124.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.11356371365400778\n",
            "---------------------------------> best coeff  [-1.37138081 -0.67367923 -0.35526322]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97719501 1.13745198 0.9529793 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  5.890344480485409\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.97719501 0.         0.        ]\n",
            " [0.         1.13745198 0.        ]\n",
            " [0.         0.         0.9529793 ]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (69, 3)\n",
            "y_train length  69\n",
            "-------> size test:  20000  , size train:  69 nbr_seen (train):  69  nbr_miss :  0\n",
            "X  69   3\n",
            "y shape (69,)\n",
            "nm  207\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 121.19it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.257082087635852e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97719501 1.13745198 0.9529793 ]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.183140743538786\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0]\n",
            "S dataset \n",
            " [[1.00942052 0.         0.        ]\n",
            " [0.         1.13973872 0.        ]\n",
            " [0.         0.         0.96399982]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (69, 3)\n",
            "y_train length  69\n",
            "-------> size test:  20000  , size train:  69 nbr_seen (train):  20  nbr_miss :  49\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.00942052 0.         0.        ]\n",
            " [0.         1.13973872 0.        ]\n",
            " [0.         0.         0.96399982]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.9906674  0.         0.        ]\n",
            " [0.         0.87739407 0.        ]\n",
            " [0.         0.         1.03734459]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 885.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.11349500237215905\n",
            "---------------------------------> best coeff  [-1.3714386  -0.67372481 -0.35539615]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97719501 1.13745198 0.9529793 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -35.79833177485423\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0]\n",
            "S dataset \n",
            " [[1.00942052 0.         0.        ]\n",
            " [0.         1.13973872 0.        ]\n",
            " [0.         0.         0.96399982]]\n",
            "S missing shape\n",
            "  (69, 3, 3)\n",
            "S missing\n",
            "  [[[0.73434591 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8761957  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.5881404 ]]\n",
            "\n",
            " [[0.75645783 0.         0.        ]\n",
            "  [0.         1.85647509 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54128411 0.        ]\n",
            "  [0.         0.         1.23461757]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56689815]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54357464 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8656398  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.81987462 0.        ]\n",
            "  [0.         0.         1.14898281]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[2.28664652 0.         0.        ]\n",
            "  [0.         0.77490689 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09199675]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56505314]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.26249909 0.        ]\n",
            "  [0.         0.         0.95795192]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.25022046 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.10368764 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.1817771 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52081822 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71019564 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74730205 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.24948426]]\n",
            "\n",
            " [[1.06583607 0.         0.        ]\n",
            "  [0.         0.90785194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.0708749  0.         0.        ]\n",
            "  [0.         0.64456113 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6936495  0.        ]\n",
            "  [0.         0.         1.22746469]]\n",
            "\n",
            " [[1.4646515  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.95697952 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.3806875  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.70096347]]\n",
            "\n",
            " [[0.63529813 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94146323]]\n",
            "\n",
            " [[1.00478375 0.         0.        ]\n",
            "  [0.         0.99111843 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.56361235 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.17021678 0.         0.        ]\n",
            "  [0.         0.80606627 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.41443175 0.        ]\n",
            "  [0.         0.         0.92643284]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57542337 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.72373064 0.         0.        ]\n",
            "  [0.         0.35299093 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78461901 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.60048979 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.04830259]]\n",
            "\n",
            " [[0.70277056 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.33734738 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89746984 0.        ]\n",
            "  [0.         0.         0.83720478]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.26844903]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97429144 0.        ]\n",
            "  [0.         0.         1.11399656]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.90857829 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61973679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89792606 0.         0.        ]\n",
            "  [0.         1.44193007 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.66262774 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.23339634 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84608419]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52773371 0.        ]\n",
            "  [0.         0.         0.8132801 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.60380237 0.        ]\n",
            "  [0.         0.         0.98556709]]\n",
            "\n",
            " [[0.90885849 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.85765857 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61426833]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 69, 3)\n",
            "y_train length  69\n",
            "-------> size test:  20000  , size train:  69 nbr_seen (train):  20  nbr_miss :  49\n",
            "X  69   3\n",
            "y shape (69,)\n",
            "nm  207\n",
            "S_mis in Adbvt training  [[[0.73434591 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8761957  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.5881404 ]]\n",
            "\n",
            " [[0.75645783 0.         0.        ]\n",
            "  [0.         1.85647509 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54128411 0.        ]\n",
            "  [0.         0.         1.23461757]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56689815]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54357464 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8656398  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.81987462 0.        ]\n",
            "  [0.         0.         1.14898281]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[2.28664652 0.         0.        ]\n",
            "  [0.         0.77490689 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09199675]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56505314]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.26249909 0.        ]\n",
            "  [0.         0.         0.95795192]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.25022046 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.10368764 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.1817771 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52081822 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71019564 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74730205 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.24948426]]\n",
            "\n",
            " [[1.06583607 0.         0.        ]\n",
            "  [0.         0.90785194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.0708749  0.         0.        ]\n",
            "  [0.         0.64456113 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6936495  0.        ]\n",
            "  [0.         0.         1.22746469]]\n",
            "\n",
            " [[1.4646515  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.95697952 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.3806875  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.70096347]]\n",
            "\n",
            " [[0.63529813 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94146323]]\n",
            "\n",
            " [[1.00478375 0.         0.        ]\n",
            "  [0.         0.99111843 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.56361235 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.17021678 0.         0.        ]\n",
            "  [0.         0.80606627 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.41443175 0.        ]\n",
            "  [0.         0.         0.92643284]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57542337 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.72373064 0.         0.        ]\n",
            "  [0.         0.35299093 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78461901 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.60048979 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.04830259]]\n",
            "\n",
            " [[0.70277056 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.33734738 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89746984 0.        ]\n",
            "  [0.         0.         0.83720478]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.26844903]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97429144 0.        ]\n",
            "  [0.         0.         1.11399656]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.90857829 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61973679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89792606 0.         0.        ]\n",
            "  [0.         1.44193007 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.66262774 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.23339634 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84608419]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52773371 0.        ]\n",
            "  [0.         0.         0.8132801 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.60380237 0.        ]\n",
            "  [0.         0.         0.98556709]]\n",
            "\n",
            " [[0.90885849 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.85765857 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61426833]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.01 0.00 0.00]\n",
            " [0.00 1.14 0.00]\n",
            " ...\n",
            " [0.00 1.14 0.00]\n",
            " [0.00 0.00 0.96]] @ Promote(adv_radius_times_dts, (207, 3)) + [[0.73 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (207, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 77.02it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 79.48it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:04,  3.86it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 86.25it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 87.73it/s]\n",
            " 10%|█         | 2/20 [00:00<00:04,  4.10it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 76.89it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 80.29it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:04,  4.02it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 84.88it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 85.64it/s]\n",
            " 20%|██        | 4/20 [00:00<00:03,  4.09it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 59.25it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 77.37it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:03,  3.95it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 88.67it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 84.54it/s]\n",
            " 30%|███       | 6/20 [00:01<00:03,  4.00it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 63.33it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 61.61it/s]\n",
            " 35%|███▌      | 7/20 [00:01<00:03,  3.62it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 61.97it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 58.70it/s]\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.38it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.82it/s]\n",
            " 45%|████▌     | 9/20 [00:02<00:03,  3.34it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 70.57it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.70it/s]\n",
            " 50%|█████     | 10/20 [00:02<00:02,  3.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 72.47it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.15it/s]\n",
            " 55%|█████▌    | 11/20 [00:03<00:02,  3.41it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.05it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 65.53it/s]\n",
            " 60%|██████    | 12/20 [00:03<00:02,  3.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 66.15it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.49it/s]\n",
            " 65%|██████▌   | 13/20 [00:03<00:02,  3.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.88it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.12it/s]\n",
            " 70%|███████   | 14/20 [00:03<00:01,  3.43it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 63.16it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 69.71it/s]\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.43it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 63.32it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.58it/s]\n",
            " 80%|████████  | 16/20 [00:04<00:01,  3.40it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 64.06it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 58.91it/s]\n",
            " 85%|████████▌ | 17/20 [00:04<00:00,  3.23it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 56.52it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 56.07it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 57.99it/s]\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  3.10it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 53.85it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 53.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 56.04it/s]\n",
            " 95%|█████████▌| 19/20 [00:05<00:00,  2.99it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 60.22it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 60.10it/s]\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.18167698416922398\n",
            "---------------------------------> best coeff  [-1.27616502 -0.63414875 -0.41329959]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97719501 1.13745198 0.9529793 ]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -35.79833177485423\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0]\n",
            "S dataset \n",
            " [[1.00942052 0.         0.        ]\n",
            " [0.         1.13973872 0.        ]\n",
            " [0.         0.         0.96399982]]\n",
            "S missing shape\n",
            "  (69, 3, 3)\n",
            "S missing\n",
            "  [[[0.73434591 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.8761957  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.5881404 ]]\n",
            "\n",
            " [[0.75645783 0.         0.        ]\n",
            "  [0.         1.85647509 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54128411 0.        ]\n",
            "  [0.         0.         1.23461757]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56689815]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.54357464 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8656398  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.81987462 0.        ]\n",
            "  [0.         0.         1.14898281]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[2.28664652 0.         0.        ]\n",
            "  [0.         0.77490689 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09199675]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.56505314]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.26249909 0.        ]\n",
            "  [0.         0.         0.95795192]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.25022046 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.10368764 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.1817771 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52081822 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71019564 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74730205 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.24948426]]\n",
            "\n",
            " [[1.06583607 0.         0.        ]\n",
            "  [0.         0.90785194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.0708749  0.         0.        ]\n",
            "  [0.         0.64456113 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6936495  0.        ]\n",
            "  [0.         0.         1.22746469]]\n",
            "\n",
            " [[1.4646515  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.95697952 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.3806875  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.70096347]]\n",
            "\n",
            " [[0.63529813 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94146323]]\n",
            "\n",
            " [[1.00478375 0.         0.        ]\n",
            "  [0.         0.99111843 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.56361235 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.17021678 0.         0.        ]\n",
            "  [0.         0.80606627 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.41443175 0.        ]\n",
            "  [0.         0.         0.92643284]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57542337 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.72373064 0.         0.        ]\n",
            "  [0.         0.35299093 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.78461901 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.60048979 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.04830259]]\n",
            "\n",
            " [[0.70277056 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.33734738 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89746984 0.        ]\n",
            "  [0.         0.         0.83720478]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.26844903]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97429144 0.        ]\n",
            "  [0.         0.         1.11399656]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.90857829 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61973679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.89792606 0.         0.        ]\n",
            "  [0.         1.44193007 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.66262774 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.23339634 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84608419]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.52773371 0.        ]\n",
            "  [0.         0.         0.8132801 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.60380237 0.        ]\n",
            "  [0.         0.         0.98556709]]\n",
            "\n",
            " [[0.90885849 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.85765857 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.61426833]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 69, 3)\n",
            "y_train length  69\n",
            "-------> size test:  20000  , size train:  69 nbr_seen (train):  20  nbr_miss :  49\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.00942052 0.         0.        ]\n",
            " [0.         1.13973872 0.        ]\n",
            " [0.         0.         0.96399982]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.9906674  0.         0.        ]\n",
            " [0.         0.87739407 0.        ]\n",
            " [0.         0.         1.03734459]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1032.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.18155688974579073\n",
            "---------------------------------> best coeff  [-1.27625781 -0.63424683 -0.41345473]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  4\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20080, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   80\n",
            "X shape in clear data  (80, 3)\n",
            "y shape in clear data  (80,)\n",
            "M shape in clear data  (80,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(79, 3)\n",
            "(79, 3)\n",
            "(79,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468],\n",
            "       [-0.72900408,  0.89520914, -0.56632818],\n",
            "       [-0.95056766, -0.90711733, -1.71907826],\n",
            "       [-1.27576047, -2.94005899, -0.73959924],\n",
            "       [ 1.37544471, -1.90704468,  0.38290844],\n",
            "       [-0.38420033, -0.83535649, -0.82359467],\n",
            "       [-0.36790112,  0.10549094,  1.47770934],\n",
            "       [ 0.07416557, -1.41049811,  0.79117911],\n",
            "       [-0.33200417, -0.69935181,  0.61001841],\n",
            "       [-1.24522791,  0.26689302,  0.5333737 ],\n",
            "       [-1.84372823,  2.53984314, -0.43497275],\n",
            "       [-0.33671289, -0.90425078, -0.50244006],\n",
            "       [ 1.20993516,  0.0216535 , -1.83209291],\n",
            "       [ 1.34308443,  0.062579  ,  0.11619287],\n",
            "       [ 0.30523464,  0.76742839,  0.75818238],\n",
            "       [-0.10720166,  0.19385501, -1.63230642],\n",
            "       [ 0.32735891,  0.24514196,  1.13688418],\n",
            "       [ 0.20453336,  0.72006844, -1.40582025],\n",
            "       [ 1.31934245, -0.16201123,  0.12822749],\n",
            "       [-0.53862874,  2.98109984,  0.51936044],\n",
            "       [-0.35721007,  0.74111547,  0.42549164],\n",
            "       [ 1.14627226, -0.77155583,  0.12255875],\n",
            "       [-0.81732683,  2.25718182, -0.03608141],\n",
            "       [-0.56191629,  0.29927655,  0.26328756],\n",
            "       [ 0.91699987, -0.52011764, -0.27695292],\n",
            "       [ 0.38475242, -0.67043378, -0.18488143],\n",
            "       [-0.75478721, -0.10240347,  2.68343304],\n",
            "       [-0.47903804,  0.05205617,  1.15464275],\n",
            "       [ 1.30244489, -1.83544794, -0.37921224],\n",
            "       [ 0.67390468, -0.04890545, -0.53064843],\n",
            "       [ 1.19902632, -1.89751674,  2.66093439],\n",
            "       [-0.33359846, -0.09735403,  0.76204875],\n",
            "       [-0.01468106, -0.30146907, -1.80505347],\n",
            "       [-0.69773062, -0.38168218, -0.13632972],\n",
            "       [ 1.90058059, -0.20261242, -0.8688119 ],\n",
            "       [-0.47107857, -2.11821376, -1.08427031],\n",
            "       [ 0.39812321,  0.4824861 , -0.52115625],\n",
            "       [-0.13751117,  1.26447728,  0.85153198],\n",
            "       [-0.12905058, -0.66658317, -0.73647413],\n",
            "       [ 1.31135299, -0.27576257, -1.10574631]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01,\n",
            "        6.06600497e-01,  3.08631241e+00,  5.02161525e+00, -6.52182597e-01,\n",
            "        1.72606982e+00, -1.41348503e-01,  8.13237393e-01,  9.01569995e-01,\n",
            "        1.52881194e+00,  8.55347733e-01,  1.57358665e+00, -1.17286490e+00,\n",
            "       -2.26335807e+00, -1.50974713e+00,  7.00684620e-01, -1.23699999e+00,\n",
            "       -3.72575517e-01, -2.02766804e+00, -2.05011434e+00, -2.78817082e-01,\n",
            "       -1.19702839e+00, -7.09643376e-01,  5.18695345e-01, -8.83647675e-01,\n",
            "        6.70743800e-02,  1.47930247e-01,  2.24603715e-01, -2.71109476e-01,\n",
            "       -8.09321142e-01, -1.35933520e+00,  2.95143909e-01,  1.07372556e+00,\n",
            "        1.52377343e+00, -2.49465885e+00,  3.13604908e+00, -8.50269568e-01,\n",
            "       -1.28771705e+00,  1.12642748e+00, -1.38029319e+00]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96525949 1.12313947 0.99835092]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -8.150212204406536\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0]\n",
            "S dataset \n",
            " [[1.0156019  0.         0.        ]\n",
            " [0.         1.11728154 0.        ]\n",
            " [0.         0.         1.02086508]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (79, 3)\n",
            "y_train length  79\n",
            "-------> size test:  20000  , size train:  79 nbr_seen (train):  23  nbr_miss :  56\n",
            "X  79   3\n",
            "y shape (79,)\n",
            "nm  237\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 47.44it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 82.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.0821088194806128\n",
            "---------------------------------> best coeff  [-1.3848682  -0.72822008 -0.38129356]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96525949 1.12313947 0.99835092]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  2.738219619183354\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.96525949 0.         0.        ]\n",
            " [0.         1.12313947 0.        ]\n",
            " [0.         0.         0.99835092]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (79, 3)\n",
            "y_train length  79\n",
            "-------> size test:  20000  , size train:  79 nbr_seen (train):  79  nbr_miss :  0\n",
            "X  79   3\n",
            "y shape (79,)\n",
            "nm  237\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 49.08it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 88.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.1448225567002981e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96525949 1.12313947 0.99835092]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -8.150212204406536\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0]\n",
            "S dataset \n",
            " [[1.0156019  0.         0.        ]\n",
            " [0.         1.11728154 0.        ]\n",
            " [0.         0.         1.02086508]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (79, 3)\n",
            "y_train length  79\n",
            "-------> size test:  20000  , size train:  79 nbr_seen (train):  23  nbr_miss :  56\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.0156019  0.         0.        ]\n",
            " [0.         1.11728154 0.        ]\n",
            " [0.         0.         1.02086508]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98463778 0.         0.        ]\n",
            " [0.         0.89502955 0.        ]\n",
            " [0.         0.         0.97956137]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 606.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.08206612879720536\n",
            "---------------------------------> best coeff  [-1.38489972 -0.72826405 -0.38142476]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96525949 1.12313947 0.99835092]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -52.25945787871842\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0]\n",
            "S dataset \n",
            " [[1.0156019  0.         0.        ]\n",
            " [0.         1.11728154 0.        ]\n",
            " [0.         0.         1.02086508]]\n",
            "S missing shape\n",
            "  (79, 3, 3)\n",
            "S missing\n",
            "  [[[0.35100418 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50902245 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.27863862]]\n",
            "\n",
            " [[0.78053525 0.         0.        ]\n",
            "  [0.         1.25102654 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75365689 0.        ]\n",
            "  [0.         0.         1.11098498]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46255221]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.67563562 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94360327 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.41366821 0.        ]\n",
            "  [0.         0.         0.48048494]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.15689913 0.         0.        ]\n",
            "  [0.         1.25750304 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.327175  ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.80829838]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.80624985 0.        ]\n",
            "  [0.         0.         0.59995153]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.56651944 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.20318849 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09957278]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.87279194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.65614254 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11597017 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.13225431]]\n",
            "\n",
            " [[0.42365814 0.         0.        ]\n",
            "  [0.         1.4901614  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.00911414 0.         0.        ]\n",
            "  [0.         1.56074567 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96911961 0.        ]\n",
            "  [0.         0.         1.14736442]]\n",
            "\n",
            " [[0.83839788 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48476247 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.56546144 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.1662681 ]]\n",
            "\n",
            " [[0.96032398 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79150033]]\n",
            "\n",
            " [[0.9359103  0.         0.        ]\n",
            "  [0.         1.21443525 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.2662889  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.49622005 0.         0.        ]\n",
            "  [0.         1.20013204 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09296887 0.        ]\n",
            "  [0.         0.         1.06095208]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.39518827 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.6117122  0.         0.        ]\n",
            "  [0.         0.64614446 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.73522837 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.33160005 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60863709]]\n",
            "\n",
            " [[0.78802664 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49254704 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.64465317 0.        ]\n",
            "  [0.         0.         0.4412669 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68226103]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64954895 0.        ]\n",
            "  [0.         0.         1.11028459]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63324774 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66137795]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.9210069  0.         0.        ]\n",
            "  [0.         0.60244709 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.07539408 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68801763 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57293494]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.28751683 0.        ]\n",
            "  [0.         0.         1.38215847]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.37672377 0.        ]\n",
            "  [0.         0.         1.05571059]]\n",
            "\n",
            " [[0.92541407 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62448971 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94459821]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.95565147 0.        ]\n",
            "  [0.         0.         1.00318542]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.83643214]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.19152325]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.46115011 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.4235574  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8841359 ]]\n",
            "\n",
            " [[0.66075991 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.72248881 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 79, 3)\n",
            "y_train length  79\n",
            "-------> size test:  20000  , size train:  79 nbr_seen (train):  23  nbr_miss :  56\n",
            "X  79   3\n",
            "y shape (79,)\n",
            "nm  237\n",
            "S_mis in Adbvt training  [[[0.35100418 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50902245 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.27863862]]\n",
            "\n",
            " [[0.78053525 0.         0.        ]\n",
            "  [0.         1.25102654 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75365689 0.        ]\n",
            "  [0.         0.         1.11098498]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46255221]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.67563562 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94360327 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.41366821 0.        ]\n",
            "  [0.         0.         0.48048494]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.15689913 0.         0.        ]\n",
            "  [0.         1.25750304 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.327175  ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.80829838]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.80624985 0.        ]\n",
            "  [0.         0.         0.59995153]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.56651944 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.20318849 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09957278]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.87279194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.65614254 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11597017 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.13225431]]\n",
            "\n",
            " [[0.42365814 0.         0.        ]\n",
            "  [0.         1.4901614  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.00911414 0.         0.        ]\n",
            "  [0.         1.56074567 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96911961 0.        ]\n",
            "  [0.         0.         1.14736442]]\n",
            "\n",
            " [[0.83839788 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48476247 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.56546144 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.1662681 ]]\n",
            "\n",
            " [[0.96032398 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79150033]]\n",
            "\n",
            " [[0.9359103  0.         0.        ]\n",
            "  [0.         1.21443525 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.2662889  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.49622005 0.         0.        ]\n",
            "  [0.         1.20013204 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09296887 0.        ]\n",
            "  [0.         0.         1.06095208]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.39518827 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.6117122  0.         0.        ]\n",
            "  [0.         0.64614446 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.73522837 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.33160005 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60863709]]\n",
            "\n",
            " [[0.78802664 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49254704 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.64465317 0.        ]\n",
            "  [0.         0.         0.4412669 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68226103]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64954895 0.        ]\n",
            "  [0.         0.         1.11028459]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63324774 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66137795]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.9210069  0.         0.        ]\n",
            "  [0.         0.60244709 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.07539408 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68801763 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57293494]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.28751683 0.        ]\n",
            "  [0.         0.         1.38215847]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.37672377 0.        ]\n",
            "  [0.         0.         1.05571059]]\n",
            "\n",
            " [[0.92541407 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62448971 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94459821]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.95565147 0.        ]\n",
            "  [0.         0.         1.00318542]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.83643214]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.19152325]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.46115011 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.4235574  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8841359 ]]\n",
            "\n",
            " [[0.66075991 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.72248881 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.02 0.00 0.00]\n",
            " [0.00 1.12 0.00]\n",
            " ...\n",
            " [0.00 1.12 0.00]\n",
            " [0.00 0.00 1.02]] @ Promote(adv_radius_times_dts, (237, 3)) + [[0.35 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (237, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 58.99it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 65.09it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:05,  3.21it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 58.88it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 70.65it/s]\n",
            " 10%|█         | 2/20 [00:00<00:05,  3.34it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 66.88it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.47it/s]\n",
            " 15%|█▌        | 3/20 [00:00<00:05,  3.34it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.59it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 73.86it/s]\n",
            " 20%|██        | 4/20 [00:01<00:04,  3.43it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 75.26it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.53it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:04,  3.38it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 74.74it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 75.20it/s]\n",
            " 30%|███       | 6/20 [00:01<00:04,  3.48it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.04it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 74.72it/s]\n",
            " 35%|███▌      | 7/20 [00:02<00:03,  3.55it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.41it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 74.96it/s]\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.58it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 54.86it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.50it/s]\n",
            " 45%|████▌     | 9/20 [00:02<00:03,  3.48it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 72.90it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.24it/s]\n",
            " 50%|█████     | 10/20 [00:02<00:02,  3.49it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 74.24it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 71.59it/s]\n",
            " 55%|█████▌    | 11/20 [00:03<00:02,  3.49it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.03it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.16it/s]\n",
            " 60%|██████    | 12/20 [00:03<00:02,  3.39it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 64.63it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.22it/s]\n",
            " 65%|██████▌   | 13/20 [00:03<00:02,  3.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 66.95it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 69.73it/s]\n",
            " 70%|███████   | 14/20 [00:04<00:01,  3.37it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.63it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 70.87it/s]\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.39it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 61.95it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 64.19it/s]\n",
            " 80%|████████  | 16/20 [00:04<00:01,  3.32it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.58it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 69.98it/s]\n",
            " 85%|████████▌ | 17/20 [00:04<00:00,  3.35it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 74.32it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.77it/s]\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  3.41it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 8/20 [00:00<00:00, 73.51it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 71.65it/s]\n",
            " 95%|█████████▌| 19/20 [00:05<00:00,  3.44it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.37it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 67.57it/s]\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.20644556541658796\n",
            "---------------------------------> best coeff  [-1.29674379 -0.57616683 -0.36901606]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96525949 1.12313947 0.99835092]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -52.25945787871842\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0]\n",
            "S dataset \n",
            " [[1.0156019  0.         0.        ]\n",
            " [0.         1.11728154 0.        ]\n",
            " [0.         0.         1.02086508]]\n",
            "S missing shape\n",
            "  (79, 3, 3)\n",
            "S missing\n",
            "  [[[0.35100418 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50902245 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.27863862]]\n",
            "\n",
            " [[0.78053525 0.         0.        ]\n",
            "  [0.         1.25102654 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75365689 0.        ]\n",
            "  [0.         0.         1.11098498]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.46255221]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.67563562 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.94360327 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.41366821 0.        ]\n",
            "  [0.         0.         0.48048494]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.15689913 0.         0.        ]\n",
            "  [0.         1.25750304 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.327175  ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.80829838]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.80624985 0.        ]\n",
            "  [0.         0.         0.59995153]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.56651944 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.20318849 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.09957278]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.87279194 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.65614254 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11597017 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.13225431]]\n",
            "\n",
            " [[0.42365814 0.         0.        ]\n",
            "  [0.         1.4901614  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.00911414 0.         0.        ]\n",
            "  [0.         1.56074567 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96911961 0.        ]\n",
            "  [0.         0.         1.14736442]]\n",
            "\n",
            " [[0.83839788 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48476247 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.56546144 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.1662681 ]]\n",
            "\n",
            " [[0.96032398 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79150033]]\n",
            "\n",
            " [[0.9359103  0.         0.        ]\n",
            "  [0.         1.21443525 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.2662889  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.49622005 0.         0.        ]\n",
            "  [0.         1.20013204 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.09296887 0.        ]\n",
            "  [0.         0.         1.06095208]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.39518827 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.6117122  0.         0.        ]\n",
            "  [0.         0.64614446 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.73522837 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.33160005 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60863709]]\n",
            "\n",
            " [[0.78802664 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.49254704 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.64465317 0.        ]\n",
            "  [0.         0.         0.4412669 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68226103]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.64954895 0.        ]\n",
            "  [0.         0.         1.11028459]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63324774 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.66137795]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.9210069  0.         0.        ]\n",
            "  [0.         0.60244709 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.07539408 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.68801763 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57293494]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.28751683 0.        ]\n",
            "  [0.         0.         1.38215847]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.37672377 0.        ]\n",
            "  [0.         0.         1.05571059]]\n",
            "\n",
            " [[0.92541407 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62448971 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.94459821]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.95565147 0.        ]\n",
            "  [0.         0.         1.00318542]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.83643214]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.19152325]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.46115011 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.4235574  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.8841359 ]]\n",
            "\n",
            " [[0.66075991 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.72248881 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 79, 3)\n",
            "y_train length  79\n",
            "-------> size test:  20000  , size train:  79 nbr_seen (train):  23  nbr_miss :  56\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.0156019  0.         0.        ]\n",
            " [0.         1.11728154 0.        ]\n",
            " [0.         0.         1.02086508]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98463778 0.         0.        ]\n",
            " [0.         0.89502955 0.        ]\n",
            " [0.         0.         0.97956137]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 896.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.20627188359120727\n",
            "---------------------------------> best coeff  [-1.29685897 -0.57628293 -0.3692217 ]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  5\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20090, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   90\n",
            "X shape in clear data  (90, 3)\n",
            "y shape in clear data  (90,)\n",
            "M shape in clear data  (90,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(88, 3)\n",
            "(88, 3)\n",
            "(88,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468],\n",
            "       [-0.72900408,  0.89520914, -0.56632818],\n",
            "       [-0.95056766, -0.90711733, -1.71907826],\n",
            "       [-1.27576047, -2.94005899, -0.73959924],\n",
            "       [ 1.37544471, -1.90704468,  0.38290844],\n",
            "       [-0.38420033, -0.83535649, -0.82359467],\n",
            "       [-0.36790112,  0.10549094,  1.47770934],\n",
            "       [ 0.07416557, -1.41049811,  0.79117911],\n",
            "       [-0.33200417, -0.69935181,  0.61001841],\n",
            "       [-1.24522791,  0.26689302,  0.5333737 ],\n",
            "       [-1.84372823,  2.53984314, -0.43497275],\n",
            "       [-0.33671289, -0.90425078, -0.50244006],\n",
            "       [ 1.20993516,  0.0216535 , -1.83209291],\n",
            "       [ 1.34308443,  0.062579  ,  0.11619287],\n",
            "       [ 0.30523464,  0.76742839,  0.75818238],\n",
            "       [-0.10720166,  0.19385501, -1.63230642],\n",
            "       [ 0.32735891,  0.24514196,  1.13688418],\n",
            "       [ 0.20453336,  0.72006844, -1.40582025],\n",
            "       [ 1.31934245, -0.16201123,  0.12822749],\n",
            "       [-0.53862874,  2.98109984,  0.51936044],\n",
            "       [-0.35721007,  0.74111547,  0.42549164],\n",
            "       [ 1.14627226, -0.77155583,  0.12255875],\n",
            "       [-0.81732683,  2.25718182, -0.03608141],\n",
            "       [-0.56191629,  0.29927655,  0.26328756],\n",
            "       [ 0.91699987, -0.52011764, -0.27695292],\n",
            "       [ 0.38475242, -0.67043378, -0.18488143],\n",
            "       [-0.75478721, -0.10240347,  2.68343304],\n",
            "       [-0.47903804,  0.05205617,  1.15464275],\n",
            "       [ 1.30244489, -1.83544794, -0.37921224],\n",
            "       [ 0.67390468, -0.04890545, -0.53064843],\n",
            "       [ 1.19902632, -1.89751674,  2.66093439],\n",
            "       [-0.33359846, -0.09735403,  0.76204875],\n",
            "       [-0.01468106, -0.30146907, -1.80505347],\n",
            "       [-0.69773062, -0.38168218, -0.13632972],\n",
            "       [ 1.90058059, -0.20261242, -0.8688119 ],\n",
            "       [-0.47107857, -2.11821376, -1.08427031],\n",
            "       [ 0.39812321,  0.4824861 , -0.52115625],\n",
            "       [-0.13751117,  1.26447728,  0.85153198],\n",
            "       [-0.12905058, -0.66658317, -0.73647413],\n",
            "       [ 1.31135299, -0.27576257, -1.10574631],\n",
            "       [ 0.52871914, -0.65501092, -0.55382258],\n",
            "       [-0.55474765,  1.22591143,  0.43209377],\n",
            "       [-0.63909823, -0.20700689,  0.7325195 ],\n",
            "       [ 1.01472844, -0.66470013,  0.13512545],\n",
            "       [-1.14130479,  0.02316778, -0.06568743],\n",
            "       [-1.5118712 ,  0.4706899 , -1.25528867],\n",
            "       [ 1.81333954,  0.11964838,  0.46304512],\n",
            "       [-0.52034232, -1.02592943,  0.10630371],\n",
            "       [ 0.9497058 ,  0.39628616, -1.5767185 ]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01,\n",
            "        6.06600497e-01,  3.08631241e+00,  5.02161525e+00, -6.52182597e-01,\n",
            "        1.72606982e+00, -1.41348503e-01,  8.13237393e-01,  9.01569995e-01,\n",
            "        1.52881194e+00,  8.55347733e-01,  1.57358665e+00, -1.17286490e+00,\n",
            "       -2.26335807e+00, -1.50974713e+00,  7.00684620e-01, -1.23699999e+00,\n",
            "       -3.72575517e-01, -2.02766804e+00, -2.05011434e+00, -2.78817082e-01,\n",
            "       -1.19702839e+00, -7.09643376e-01,  5.18695345e-01, -8.83647675e-01,\n",
            "        6.70743800e-02,  1.47930247e-01,  2.24603715e-01, -2.71109476e-01,\n",
            "       -8.09321142e-01, -1.35933520e+00,  2.95143909e-01,  1.07372556e+00,\n",
            "        1.52377343e+00, -2.49465885e+00,  3.13604908e+00, -8.50269568e-01,\n",
            "       -1.28771705e+00,  1.12642748e+00, -1.38029319e+00, -1.90195924e-02,\n",
            "       -4.02102689e-01,  8.97446494e-01, -1.08767099e+00,  1.84015432e+00,\n",
            "        2.54395074e+00, -3.21953107e+00,  1.71593895e+00, -1.20324954e+00]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97521341 1.08457143 0.97874688]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.474757281806136\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0]\n",
            "S dataset \n",
            " [[1.01352729 0.         0.        ]\n",
            " [0.         1.0674375  0.        ]\n",
            " [0.         0.         1.01139098]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (88, 3)\n",
            "y_train length  88\n",
            "-------> size test:  20000  , size train:  88 nbr_seen (train):  27  nbr_miss :  61\n",
            "X  88   3\n",
            "y shape (88,)\n",
            "nm  264\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 107.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.06324698144441689\n",
            "---------------------------------> best coeff  [-1.40143241 -0.75928911 -0.40648389]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97521341 1.08457143 0.97874688]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  0.777975032063869\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.97521341 0.         0.        ]\n",
            " [0.         1.08457143 0.        ]\n",
            " [0.         0.         0.97874688]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (88, 3)\n",
            "y_train length  88\n",
            "-------> size test:  20000  , size train:  88 nbr_seen (train):  88  nbr_miss :  0\n",
            "X  88   3\n",
            "y shape (88,)\n",
            "nm  264\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 59.92it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 78.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.2466420782037162e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97521341 1.08457143 0.97874688]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -7.474757281806136\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0]\n",
            "S dataset \n",
            " [[1.01352729 0.         0.        ]\n",
            " [0.         1.0674375  0.        ]\n",
            " [0.         0.         1.01139098]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (88, 3)\n",
            "y_train length  88\n",
            "-------> size test:  20000  , size train:  88 nbr_seen (train):  27  nbr_miss :  61\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01352729 0.         0.        ]\n",
            " [0.         1.0674375  0.        ]\n",
            " [0.         0.         1.01139098]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98665325 0.         0.        ]\n",
            " [0.         0.936823   0.        ]\n",
            " [0.         0.         0.98873731]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1027.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.06322559854931505\n",
            "---------------------------------> best coeff  [-1.40143693 -0.75933539 -0.40660813]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97521341 1.08457143 0.97874688]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -24.71031678525256\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0]\n",
            "S dataset \n",
            " [[1.01352729 0.         0.        ]\n",
            " [0.         1.0674375  0.        ]\n",
            " [0.         0.         1.01139098]]\n",
            "S missing shape\n",
            "  (88, 3, 3)\n",
            "S missing\n",
            "  [[[0.71711074 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.17854301 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.17679411]]\n",
            "\n",
            " [[0.94388065 0.         0.        ]\n",
            "  [0.         1.03386335 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.5610432  0.        ]\n",
            "  [0.         0.         0.76399657]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93397545]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75329648 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8952777  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6702884  0.        ]\n",
            "  [0.         0.         1.17905451]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.33853696 0.         0.        ]\n",
            "  [0.         0.73444909 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87193524]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.15070148]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98105582 0.        ]\n",
            "  [0.         0.         0.85035156]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8251878  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56954931 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57263752]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.42369867 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.27431803 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.2104963  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.74429001]]\n",
            "\n",
            " [[0.95164263 0.         0.        ]\n",
            "  [0.         0.84445504 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63207405 0.         0.        ]\n",
            "  [0.         1.36602767 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.47437007 0.        ]\n",
            "  [0.         0.         0.98337944]]\n",
            "\n",
            " [[0.56193372 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.62843193 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.01008836 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.92784099]]\n",
            "\n",
            " [[0.67128362 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.2904311 ]]\n",
            "\n",
            " [[0.66426656 0.         0.        ]\n",
            "  [0.         0.92652137 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.4167274  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71786159 0.         0.        ]\n",
            "  [0.         0.476452   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.30769139 0.        ]\n",
            "  [0.         0.         1.81749426]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75878338 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62188834 0.         0.        ]\n",
            "  [0.         0.68158072 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.92263549 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.88075586 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.75354771]]\n",
            "\n",
            " [[0.9134782  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.26624634 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11968757 0.        ]\n",
            "  [0.         0.         1.35098092]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.77488623]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.38040531 0.        ]\n",
            "  [0.         0.         0.49694975]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.914601   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60630125]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.83755513 0.         0.        ]\n",
            "  [0.         0.89760509 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86582208 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.51994445 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.55977284]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.03664134 0.        ]\n",
            "  [0.         0.         0.41082598]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.37330982 0.        ]\n",
            "  [0.         0.         0.64367003]]\n",
            "\n",
            " [[1.13533958 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.53205262 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65572218]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74500994 0.        ]\n",
            "  [0.         0.         0.82336624]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.0203922 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84972516]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.25314007 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.23533067 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.28416652]]\n",
            "\n",
            " [[1.21947221 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.91894161 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60162038]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.57510868 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79637487]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69969326 0.         0.        ]\n",
            "  [0.         0.93120133 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.19342707]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 88, 3)\n",
            "y_train length  88\n",
            "-------> size test:  20000  , size train:  88 nbr_seen (train):  27  nbr_miss :  61\n",
            "X  88   3\n",
            "y shape (88,)\n",
            "nm  264\n",
            "S_mis in Adbvt training  [[[0.71711074 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.17854301 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.17679411]]\n",
            "\n",
            " [[0.94388065 0.         0.        ]\n",
            "  [0.         1.03386335 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.5610432  0.        ]\n",
            "  [0.         0.         0.76399657]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93397545]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75329648 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8952777  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6702884  0.        ]\n",
            "  [0.         0.         1.17905451]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.33853696 0.         0.        ]\n",
            "  [0.         0.73444909 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87193524]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.15070148]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98105582 0.        ]\n",
            "  [0.         0.         0.85035156]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8251878  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56954931 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57263752]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.42369867 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.27431803 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.2104963  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.74429001]]\n",
            "\n",
            " [[0.95164263 0.         0.        ]\n",
            "  [0.         0.84445504 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63207405 0.         0.        ]\n",
            "  [0.         1.36602767 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.47437007 0.        ]\n",
            "  [0.         0.         0.98337944]]\n",
            "\n",
            " [[0.56193372 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.62843193 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.01008836 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.92784099]]\n",
            "\n",
            " [[0.67128362 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.2904311 ]]\n",
            "\n",
            " [[0.66426656 0.         0.        ]\n",
            "  [0.         0.92652137 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.4167274  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71786159 0.         0.        ]\n",
            "  [0.         0.476452   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.30769139 0.        ]\n",
            "  [0.         0.         1.81749426]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75878338 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62188834 0.         0.        ]\n",
            "  [0.         0.68158072 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.92263549 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.88075586 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.75354771]]\n",
            "\n",
            " [[0.9134782  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.26624634 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11968757 0.        ]\n",
            "  [0.         0.         1.35098092]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.77488623]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.38040531 0.        ]\n",
            "  [0.         0.         0.49694975]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.914601   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60630125]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.83755513 0.         0.        ]\n",
            "  [0.         0.89760509 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86582208 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.51994445 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.55977284]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.03664134 0.        ]\n",
            "  [0.         0.         0.41082598]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.37330982 0.        ]\n",
            "  [0.         0.         0.64367003]]\n",
            "\n",
            " [[1.13533958 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.53205262 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65572218]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74500994 0.        ]\n",
            "  [0.         0.         0.82336624]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.0203922 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84972516]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.25314007 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.23533067 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.28416652]]\n",
            "\n",
            " [[1.21947221 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.91894161 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60162038]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.57510868 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79637487]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69969326 0.         0.        ]\n",
            "  [0.         0.93120133 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.19342707]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.01 0.00 0.00]\n",
            " [0.00 1.07 0.00]\n",
            " ...\n",
            " [0.00 1.07 0.00]\n",
            " [0.00 0.00 1.01]] @ Promote(adv_radius_times_dts, (264, 3)) + [[0.72 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (264, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.61it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 63.04it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 62.35it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:06,  3.08it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 52.93it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 59.17it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 60.89it/s]\n",
            " 10%|█         | 2/20 [00:00<00:05,  3.03it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 58.23it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 57.27it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 56.31it/s]\n",
            " 15%|█▌        | 3/20 [00:01<00:05,  2.91it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 63.63it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 68.72it/s]\n",
            " 20%|██        | 4/20 [00:01<00:05,  3.08it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 68.37it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 69.81it/s]\n",
            " 25%|██▌       | 5/20 [00:01<00:04,  3.20it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 69.38it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 72.00it/s]\n",
            " 30%|███       | 6/20 [00:01<00:04,  3.30it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.00it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 65.67it/s]\n",
            " 35%|███▌      | 7/20 [00:02<00:03,  3.27it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.74it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 64.12it/s]\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.23it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.02it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 63.51it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 64.12it/s]\n",
            " 45%|████▌     | 9/20 [00:02<00:03,  3.21it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 54.80it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 53.30it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 57.29it/s]\n",
            " 50%|█████     | 10/20 [00:03<00:03,  3.08it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 59.40it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.92it/s]\n",
            " 55%|█████▌    | 11/20 [00:03<00:02,  3.14it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.89it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.72it/s]\n",
            " 60%|██████    | 12/20 [00:03<00:02,  3.19it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 66.89it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 66.48it/s]\n",
            " 65%|██████▌   | 13/20 [00:04<00:02,  3.20it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 66.76it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 69.20it/s]\n",
            " 70%|███████   | 14/20 [00:04<00:01,  3.26it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 64.93it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 62.08it/s]\n",
            " 75%|███████▌  | 15/20 [00:04<00:01,  3.19it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 67.98it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 69.06it/s]\n",
            " 80%|████████  | 16/20 [00:05<00:01,  3.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 56.68it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 63.96it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 64.25it/s]\n",
            " 85%|████████▌ | 17/20 [00:05<00:00,  3.22it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 55.93it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 59.43it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 61.76it/s]\n",
            " 90%|█████████ | 18/20 [00:05<00:00,  3.17it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 57.00it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 64.25it/s]\n",
            " 95%|█████████▌| 19/20 [00:05<00:00,  3.16it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 65.27it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 64.44it/s]\n",
            "100%|██████████| 20/20 [00:06<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.25003596862682603\n",
            "---------------------------------> best coeff  [-1.22146894 -0.6149611  -0.29622197]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97521341 1.08457143 0.97874688]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -24.71031678525256\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0]\n",
            "S dataset \n",
            " [[1.01352729 0.         0.        ]\n",
            " [0.         1.0674375  0.        ]\n",
            " [0.         0.         1.01139098]]\n",
            "S missing shape\n",
            "  (88, 3, 3)\n",
            "S missing\n",
            "  [[[0.71711074 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.17854301 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.17679411]]\n",
            "\n",
            " [[0.94388065 0.         0.        ]\n",
            "  [0.         1.03386335 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.5610432  0.        ]\n",
            "  [0.         0.         0.76399657]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93397545]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75329648 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8952777  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.6702884  0.        ]\n",
            "  [0.         0.         1.17905451]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.33853696 0.         0.        ]\n",
            "  [0.         0.73444909 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.87193524]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.15070148]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.98105582 0.        ]\n",
            "  [0.         0.         0.85035156]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.8251878  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.56954931 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.57263752]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.42369867 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.27431803 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.2104963  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.74429001]]\n",
            "\n",
            " [[0.95164263 0.         0.        ]\n",
            "  [0.         0.84445504 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.63207405 0.         0.        ]\n",
            "  [0.         1.36602767 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.47437007 0.        ]\n",
            "  [0.         0.         0.98337944]]\n",
            "\n",
            " [[0.56193372 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.62843193 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.01008836 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.92784099]]\n",
            "\n",
            " [[0.67128362 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.2904311 ]]\n",
            "\n",
            " [[0.66426656 0.         0.        ]\n",
            "  [0.         0.92652137 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.4167274  0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71786159 0.         0.        ]\n",
            "  [0.         0.476452   0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.30769139 0.        ]\n",
            "  [0.         0.         1.81749426]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.75878338 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.62188834 0.         0.        ]\n",
            "  [0.         0.68158072 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.92263549 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.88075586 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.75354771]]\n",
            "\n",
            " [[0.9134782  0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.26624634 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.11968757 0.        ]\n",
            "  [0.         0.         1.35098092]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.77488623]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.38040531 0.        ]\n",
            "  [0.         0.         0.49694975]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.914601   0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60630125]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.83755513 0.         0.        ]\n",
            "  [0.         0.89760509 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.86582208 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.51994445 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.55977284]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.03664134 0.        ]\n",
            "  [0.         0.         0.41082598]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.37330982 0.        ]\n",
            "  [0.         0.         0.64367003]]\n",
            "\n",
            " [[1.13533958 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.53205262 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.65572218]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74500994 0.        ]\n",
            "  [0.         0.         0.82336624]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.0203922 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.84972516]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.25314007 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.23533067 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.28416652]]\n",
            "\n",
            " [[1.21947221 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.91894161 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60162038]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.57510868 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.79637487]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.69969326 0.         0.        ]\n",
            "  [0.         0.93120133 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.19342707]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 88, 3)\n",
            "y_train length  88\n",
            "-------> size test:  20000  , size train:  88 nbr_seen (train):  27  nbr_miss :  61\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01352729 0.         0.        ]\n",
            " [0.         1.0674375  0.        ]\n",
            " [0.         0.         1.01139098]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98665325 0.         0.        ]\n",
            " [0.         0.936823   0.        ]\n",
            " [0.         0.         0.98873731]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 590.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.24986721377098656\n",
            "---------------------------------> best coeff  [-1.22156124 -0.61506652 -0.29635606]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  6\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0]), 'cov': array([[ 1.68374077,  0.4690162 , -1.93836024],\n",
            "       [ 0.4690162 ,  1.21637773, -0.7259601 ],\n",
            "       [-1.93836024, -0.7259601 ,  3.89710735]])}\n",
            "(20100, 3)\n",
            "n_tot_fll  [40, 50, 60, 70, 80, 90, 100] ,   100\n",
            "X shape in clear data  (100, 3)\n",
            "y shape in clear data  (100,)\n",
            "M shape in clear data  (100,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(98, 3)\n",
            "(98, 3)\n",
            "(98,)\n",
            "full masks in run experiment  [[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 1 1]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.17253127, -0.07358589,  0.44463197],\n",
            "       [-1.78349587, -0.55806574,  0.04335959],\n",
            "       [-1.52366541,  0.41331474, -1.12709106],\n",
            "       [ 0.16288019, -0.11164071,  1.87878409],\n",
            "       [-0.80875159, -1.01526244,  0.54343791],\n",
            "       [ 0.7271548 , -0.27787846,  0.30767271],\n",
            "       [ 1.73654714,  0.54973455, -0.836114  ],\n",
            "       [-0.72993787, -1.01897278, -0.67913655],\n",
            "       [-0.83997488,  0.36053911, -0.06894909],\n",
            "       [ 0.06687962,  1.53057913, -1.09514495],\n",
            "       [-0.60086947,  0.08794306,  1.88106357],\n",
            "       [ 1.15979016, -0.16054131, -0.08150495],\n",
            "       [-2.10045581,  1.47937389,  0.53285169],\n",
            "       [ 0.47210439, -2.07451069, -0.90015579],\n",
            "       [-0.6359963 ,  1.10012244, -1.50213996],\n",
            "       [ 2.06778581, -0.00886426,  0.11889549],\n",
            "       [ 1.87020254,  0.2589815 ,  0.4397537 ],\n",
            "       [-0.09802243, -0.01298632,  0.47623893],\n",
            "       [ 0.76880003, -0.05962835,  1.32506409],\n",
            "       [-1.51676138,  0.42941802, -0.1943456 ],\n",
            "       [ 0.01807419,  0.99059167,  1.55203233],\n",
            "       [-0.67519246, -0.19320844,  2.01689306],\n",
            "       [-2.18309018,  1.8577495 ,  0.70075167],\n",
            "       [ 0.61743473,  1.61075784, -0.72958208],\n",
            "       [-0.04563809,  1.0905637 ,  0.59369806],\n",
            "       [ 0.56050043,  0.16323296,  0.12364586],\n",
            "       [ 0.28165435, -0.04790182,  1.13177259],\n",
            "       [-0.27590284, -0.42167555,  1.91730397],\n",
            "       [-0.79424711,  0.27285214, -0.92719042],\n",
            "       [ 0.74529402, -2.38106238, -0.27526994],\n",
            "       [ 0.43873621,  1.32961238,  0.03519907],\n",
            "       [ 1.80965549, -0.47591711, -0.51763672],\n",
            "       [ 0.58721367, -0.69334843, -1.33531736],\n",
            "       [-0.25007431, -0.61075861, -0.14353968],\n",
            "       [-0.91871913,  1.86974848, -0.53590573],\n",
            "       [-0.75015692, -0.27946073, -0.18749797],\n",
            "       [ 0.8202818 , -1.08939348,  0.48992045],\n",
            "       [ 0.28288171,  0.27877351,  0.81233788],\n",
            "       [ 1.35876049, -2.88173626,  1.21981251],\n",
            "       [ 0.01096983, -0.83399414,  0.21209468],\n",
            "       [-0.72900408,  0.89520914, -0.56632818],\n",
            "       [-0.95056766, -0.90711733, -1.71907826],\n",
            "       [-1.27576047, -2.94005899, -0.73959924],\n",
            "       [ 1.37544471, -1.90704468,  0.38290844],\n",
            "       [-0.38420033, -0.83535649, -0.82359467],\n",
            "       [-0.36790112,  0.10549094,  1.47770934],\n",
            "       [ 0.07416557, -1.41049811,  0.79117911],\n",
            "       [-0.33200417, -0.69935181,  0.61001841],\n",
            "       [-1.24522791,  0.26689302,  0.5333737 ],\n",
            "       [-1.84372823,  2.53984314, -0.43497275],\n",
            "       [-0.33671289, -0.90425078, -0.50244006],\n",
            "       [ 1.20993516,  0.0216535 , -1.83209291],\n",
            "       [ 1.34308443,  0.062579  ,  0.11619287],\n",
            "       [ 0.30523464,  0.76742839,  0.75818238],\n",
            "       [-0.10720166,  0.19385501, -1.63230642],\n",
            "       [ 0.32735891,  0.24514196,  1.13688418],\n",
            "       [ 0.20453336,  0.72006844, -1.40582025],\n",
            "       [ 1.31934245, -0.16201123,  0.12822749],\n",
            "       [-0.53862874,  2.98109984,  0.51936044],\n",
            "       [-0.35721007,  0.74111547,  0.42549164],\n",
            "       [ 1.14627226, -0.77155583,  0.12255875],\n",
            "       [-0.81732683,  2.25718182, -0.03608141],\n",
            "       [-0.56191629,  0.29927655,  0.26328756],\n",
            "       [ 0.91699987, -0.52011764, -0.27695292],\n",
            "       [ 0.38475242, -0.67043378, -0.18488143],\n",
            "       [-0.75478721, -0.10240347,  2.68343304],\n",
            "       [-0.47903804,  0.05205617,  1.15464275],\n",
            "       [ 1.30244489, -1.83544794, -0.37921224],\n",
            "       [ 0.67390468, -0.04890545, -0.53064843],\n",
            "       [ 1.19902632, -1.89751674,  2.66093439],\n",
            "       [-0.33359846, -0.09735403,  0.76204875],\n",
            "       [-0.01468106, -0.30146907, -1.80505347],\n",
            "       [-0.69773062, -0.38168218, -0.13632972],\n",
            "       [ 1.90058059, -0.20261242, -0.8688119 ],\n",
            "       [-0.47107857, -2.11821376, -1.08427031],\n",
            "       [ 0.39812321,  0.4824861 , -0.52115625],\n",
            "       [-0.13751117,  1.26447728,  0.85153198],\n",
            "       [-0.12905058, -0.66658317, -0.73647413],\n",
            "       [ 1.31135299, -0.27576257, -1.10574631],\n",
            "       [ 0.52871914, -0.65501092, -0.55382258],\n",
            "       [-0.55474765,  1.22591143,  0.43209377],\n",
            "       [-0.63909823, -0.20700689,  0.7325195 ],\n",
            "       [ 1.01472844, -0.66470013,  0.13512545],\n",
            "       [-1.14130479,  0.02316778, -0.06568743],\n",
            "       [-1.5118712 ,  0.4706899 , -1.25528867],\n",
            "       [ 1.81333954,  0.11964838,  0.46304512],\n",
            "       [-0.52034232, -1.02592943,  0.10630371],\n",
            "       [ 0.9497058 ,  0.39628616, -1.5767185 ],\n",
            "       [ 0.69424862,  0.3952741 ,  0.67726832],\n",
            "       [-0.93960138,  0.13840924, -0.85290154],\n",
            "       [ 0.10865089,  0.03520462, -0.20763208],\n",
            "       [ 0.53851437, -0.53892551,  0.77315154],\n",
            "       [-0.5376075 ,  1.0278569 , -0.5662204 ],\n",
            "       [ 0.31257094,  2.26948141, -1.57380313],\n",
            "       [-0.27941134, -1.60261337, -1.53707482],\n",
            "       [-0.9672332 , -0.36478585, -0.2326296 ],\n",
            "       [ 0.68354718, -3.12169937,  1.36175548],\n",
            "       [-0.64347263, -0.06612327, -1.80055185]]), array([[1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 1],\n",
            "       [1, 0, 1],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 1, 1],\n",
            "       [0, 1, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 1, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 1],\n",
            "       [0, 0, 0],\n",
            "       [1, 1, 0],\n",
            "       [1, 1, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0]])), 'X_test': array([[-0.36282349,  0.24335076, -0.53661542],\n",
            "       [ 0.47026998, -0.60484034,  0.15417294],\n",
            "       [-0.82437064, -0.22442317,  0.15055122],\n",
            "       ...,\n",
            "       [ 0.50712336, -0.77477728, -1.04741126],\n",
            "       [-1.40794747,  1.21615961,  0.2627019 ],\n",
            "       [ 0.70368833,  1.03412746, -1.28540238]]), 'y_train': array([ 1.51847955e-01,  3.34912717e+00,  2.55943200e+00, -9.70549755e-01,\n",
            "        1.98104035e+00, -1.04944942e+00, -2.92452883e+00,  2.38476897e+00,\n",
            "        1.05310588e+00, -1.01712606e+00,  7.47542120e-02, -1.68238222e+00,\n",
            "        1.80781986e+00,  1.50263591e+00,  6.75601001e-01, -3.36378407e+00,\n",
            "       -3.42658974e+00, -3.61314013e-02, -1.75185838e+00,  2.13178535e+00,\n",
            "       -1.59223233e+00,  3.89373903e-01,  1.52656874e+00, -2.13117499e+00,\n",
            "       -1.16711965e+00, -1.10072902e+00, -8.96854160e-01, -2.64800230e-03,\n",
            "        1.42874499e+00,  1.07134676e+00, -1.92003428e+00, -2.25327868e+00,\n",
            "        2.58488840e-01,  1.01481594e+00,  1.83654598e-02,  1.53773445e+00,\n",
            "       -5.44943886e-01, -1.05605514e+00, -1.06191352e-01,  6.43866068e-01,\n",
            "        6.06600497e-01,  3.08631241e+00,  5.02161525e+00, -6.52182597e-01,\n",
            "        1.72606982e+00, -1.41348503e-01,  8.13237393e-01,  9.01569995e-01,\n",
            "        1.52881194e+00,  8.55347733e-01,  1.57358665e+00, -1.17286490e+00,\n",
            "       -2.26335807e+00, -1.50974713e+00,  7.00684620e-01, -1.23699999e+00,\n",
            "       -3.72575517e-01, -2.02766804e+00, -2.05011434e+00, -2.78817082e-01,\n",
            "       -1.19702839e+00, -7.09643376e-01,  5.18695345e-01, -8.83647675e-01,\n",
            "        6.70743800e-02,  1.47930247e-01,  2.24603715e-01, -2.71109476e-01,\n",
            "       -8.09321142e-01, -1.35933520e+00,  2.95143909e-01,  1.07372556e+00,\n",
            "        1.52377343e+00, -2.49465885e+00,  3.13604908e+00, -8.50269568e-01,\n",
            "       -1.28771705e+00,  1.12642748e+00, -1.38029319e+00, -1.90195924e-02,\n",
            "       -4.02102689e-01,  8.97446494e-01, -1.08767099e+00,  1.84015432e+00,\n",
            "        2.54395074e+00, -3.21953107e+00,  1.71593895e+00, -1.20324954e+00,\n",
            "       -1.76360198e+00,  1.75151172e+00, -1.16766243e-01, -7.11485381e-01,\n",
            "        1.79451892e-01, -1.87241325e+00,  2.55796107e+00,  1.98280536e+00,\n",
            "        1.13354618e+00,  1.86906561e+00]), 'y_test': array([ 0.594237  , -0.27560439,  1.46152185, ...,  0.33652175,\n",
            "        1.04981616, -1.50956179]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 10, 'alpha_ridge_reg_max': 10, 'eps_adv_rad_times_delta_dts': 1e-05, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-05, 'n_a_dts': 20, 'n_a_mis': 20, 'n_a_rid': 20}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9459055  1.11771566 0.99298907]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -12.632814122419711\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0 0 2 0 2 2 1 0 1 0 1]\n",
            "S dataset \n",
            " [[0.98829519 0.         0.        ]\n",
            " [0.         1.12362516 0.        ]\n",
            " [0.         0.         1.02737607]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (98, 3)\n",
            "y_train length  98\n",
            "-------> size test:  20000  , size train:  98 nbr_seen (train):  31  nbr_miss :  67\n",
            "X  98   3\n",
            "y shape (98,)\n",
            "nm  294\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 107.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.    ] , min score  0.05468590933148299\n",
            "---------------------------------> best coeff  [-1.39884565 -0.79590356 -0.44177372]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9459055  1.11771566 0.99298907]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -6.038378185458282\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "S dataset \n",
            " [[0.9459055  0.         0.        ]\n",
            " [0.         1.11771566 0.        ]\n",
            " [0.         0.         0.99298907]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (98, 3)\n",
            "y_train length  98\n",
            "-------> size test:  20000  , size train:  98 nbr_seen (train):  98  nbr_miss :  0\n",
            "X  98   3\n",
            "y shape (98,)\n",
            "nm  294\n",
            "S_mis in Adbvt training  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 58.39it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 87.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00379269 0.        ] , min score  1.1645389051877343e-21\n",
            "---------------------------------> best coeff  [-1.60584391 -0.9027603  -0.43100982]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9459055  1.11771566 0.99298907]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -12.632814122419711\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0 0 2 0 2 2 1 0 1 0 1]\n",
            "S dataset \n",
            " [[0.98829519 0.         0.        ]\n",
            " [0.         1.12362516 0.        ]\n",
            " [0.         0.         1.02737607]]\n",
            "shape oject in cov strategy missing  3\n",
            "shape oject in cov strategy missing  (20000, 3)\n",
            "S missing shape\n",
            "  (3, 3)\n",
            "S missing\n",
            "  [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (98, 3)\n",
            "y_train length  98\n",
            "-------> size test:  20000  , size train:  98 nbr_seen (train):  31  nbr_miss :  67\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98829519 0.         0.        ]\n",
            " [0.         1.12362516 0.        ]\n",
            " [0.         0.         1.02737607]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01184344 0.         0.        ]\n",
            " [0.         0.88997651 0.        ]\n",
            " [0.         0.         0.97335341]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1159.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.05468204050615319\n",
            "---------------------------------> best coeff  [-1.39884381 -0.79593767 -0.44189976]\n",
            "BR_si\n",
            "std_nan\n",
            "ridge\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'adv'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9459055  1.11771566 0.99298907]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -51.44004169487696\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0 0 2 0 2 2 1 0 1 0 1]\n",
            "S dataset \n",
            " [[0.98829519 0.         0.        ]\n",
            " [0.         1.12362516 0.        ]\n",
            " [0.         0.         1.02737607]]\n",
            "S missing shape\n",
            "  (98, 3, 3)\n",
            "S missing\n",
            "  [[[1.00212975 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.52014759 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.11893206]]\n",
            "\n",
            " [[1.05256316 0.         0.        ]\n",
            "  [0.         0.76088249 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15298719 0.        ]\n",
            "  [0.         0.         0.75748205]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.26773718]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89379326 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.89174549 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.44307734 0.        ]\n",
            "  [0.         0.         1.05999773]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93964388 0.         0.        ]\n",
            "  [0.         1.00743775 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.39379703]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.01593113]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53311653 0.        ]\n",
            "  [0.         0.         0.38213152]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57664812 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.13678893 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69273351]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.73262044 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.59910462 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48363645 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.26805939]]\n",
            "\n",
            " [[1.51647079 0.         0.        ]\n",
            "  [0.         0.84958506 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.37213573 0.         0.        ]\n",
            "  [0.         0.95434558 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.40285337 0.        ]\n",
            "  [0.         0.         0.47849713]]\n",
            "\n",
            " [[0.56643844 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.81436143 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.26553921 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.89275199]]\n",
            "\n",
            " [[0.54952313 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96501714]]\n",
            "\n",
            " [[1.09025418 0.         0.        ]\n",
            "  [0.         1.02228439 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74589284 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.34457387 0.         0.        ]\n",
            "  [0.         0.56142611 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.13120476 0.        ]\n",
            "  [0.         0.         0.8333964 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57810877 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07555621 0.         0.        ]\n",
            "  [0.         0.35333837 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15616378 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.99343802 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68407816]]\n",
            "\n",
            " [[1.07788735 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50604197 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.70427004 0.        ]\n",
            "  [0.         0.         0.87183231]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.3782341 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.00156228 0.        ]\n",
            "  [0.         0.         0.66195923]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.97939075 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54732427]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93298433 0.         0.        ]\n",
            "  [0.         0.89647449 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.58765602 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97807945 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6800644 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.07183068 0.        ]\n",
            "  [0.         0.         1.37101651]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16081639 0.        ]\n",
            "  [0.         0.         0.8540751 ]]\n",
            "\n",
            " [[0.98349197 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71637785 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.42022568]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96614018 0.        ]\n",
            "  [0.         0.         0.40655047]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62598033]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60709679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.49373972 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.66131084 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.1314962 ]]\n",
            "\n",
            " [[0.77499561 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.73796429 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76213134]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94945104 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69525949]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75746772 0.         0.        ]\n",
            "  [0.         1.37770129 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93937696]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94872046 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.16226819]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.83842084 0.         0.        ]\n",
            "  [0.         0.81152769 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.02435658 0.         0.        ]\n",
            "  [0.         1.09893893 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.04545016 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.38154625 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84212583 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 98, 3)\n",
            "y_train length  98\n",
            "-------> size test:  20000  , size train:  98 nbr_seen (train):  31  nbr_miss :  67\n",
            "X  98   3\n",
            "y shape (98,)\n",
            "nm  294\n",
            "S_mis in Adbvt training  [[[1.00212975 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.52014759 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.11893206]]\n",
            "\n",
            " [[1.05256316 0.         0.        ]\n",
            "  [0.         0.76088249 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15298719 0.        ]\n",
            "  [0.         0.         0.75748205]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.26773718]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89379326 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.89174549 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.44307734 0.        ]\n",
            "  [0.         0.         1.05999773]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93964388 0.         0.        ]\n",
            "  [0.         1.00743775 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.39379703]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.01593113]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53311653 0.        ]\n",
            "  [0.         0.         0.38213152]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57664812 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.13678893 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69273351]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.73262044 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.59910462 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48363645 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.26805939]]\n",
            "\n",
            " [[1.51647079 0.         0.        ]\n",
            "  [0.         0.84958506 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.37213573 0.         0.        ]\n",
            "  [0.         0.95434558 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.40285337 0.        ]\n",
            "  [0.         0.         0.47849713]]\n",
            "\n",
            " [[0.56643844 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.81436143 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.26553921 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.89275199]]\n",
            "\n",
            " [[0.54952313 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96501714]]\n",
            "\n",
            " [[1.09025418 0.         0.        ]\n",
            "  [0.         1.02228439 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74589284 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.34457387 0.         0.        ]\n",
            "  [0.         0.56142611 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.13120476 0.        ]\n",
            "  [0.         0.         0.8333964 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57810877 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07555621 0.         0.        ]\n",
            "  [0.         0.35333837 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15616378 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.99343802 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68407816]]\n",
            "\n",
            " [[1.07788735 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50604197 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.70427004 0.        ]\n",
            "  [0.         0.         0.87183231]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.3782341 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.00156228 0.        ]\n",
            "  [0.         0.         0.66195923]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.97939075 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54732427]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93298433 0.         0.        ]\n",
            "  [0.         0.89647449 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.58765602 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97807945 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6800644 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.07183068 0.        ]\n",
            "  [0.         0.         1.37101651]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16081639 0.        ]\n",
            "  [0.         0.         0.8540751 ]]\n",
            "\n",
            " [[0.98349197 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71637785 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.42022568]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96614018 0.        ]\n",
            "  [0.         0.         0.40655047]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62598033]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60709679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.49373972 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.66131084 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.1314962 ]]\n",
            "\n",
            " [[0.77499561 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.73796429 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76213134]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94945104 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69525949]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75746772 0.         0.        ]\n",
            "  [0.         1.37770129 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93937696]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94872046 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.16226819]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.83842084 0.         0.        ]\n",
            "  [0.         0.81152769 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.02435658 0.         0.        ]\n",
            "  [0.         1.09893893 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.04545016 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.38154625 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84212583 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[0.99 0.00 0.00]\n",
            " [0.00 1.12 0.00]\n",
            " ...\n",
            " [0.00 1.12 0.00]\n",
            " [0.00 0.00 1.03]] @ Promote(adv_radius_times_dts, (294, 3)) + [[1.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00]] @ Promote(adv_radius_times_mis, (294, 3))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "mis deltas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 15%|█▌        | 3/20 [00:00<00:00, 28.70it/s]\u001b[A\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 34.92it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 38.94it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.44it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:10,  1.90it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 47.42it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 46.66it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 48.23it/s]\n",
            " 10%|█         | 2/20 [00:00<00:08,  2.15it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 52.39it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 53.39it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 51.62it/s]\n",
            " 15%|█▌        | 3/20 [00:01<00:07,  2.32it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 50.79it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 48.11it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 48.93it/s]\n",
            " 20%|██        | 4/20 [00:01<00:06,  2.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 52.10it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 54.55it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 53.26it/s]\n",
            " 25%|██▌       | 5/20 [00:02<00:06,  2.45it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 49.30it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 49.41it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 50.66it/s]\n",
            " 30%|███       | 6/20 [00:02<00:05,  2.47it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 44.46it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 45.44it/s]\u001b[A\n",
            " 75%|███████▌  | 15/20 [00:00<00:00, 46.54it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 44.57it/s]\n",
            " 35%|███▌      | 7/20 [00:02<00:05,  2.37it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 49.86it/s]\u001b[A\n",
            " 55%|█████▌    | 11/20 [00:00<00:00, 52.22it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 47.22it/s]\n",
            " 40%|████      | 8/20 [00:03<00:05,  2.36it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 4/20 [00:00<00:00, 38.38it/s]\u001b[A\n",
            " 45%|████▌     | 9/20 [00:00<00:00, 40.31it/s]\u001b[A\n",
            " 70%|███████   | 14/20 [00:00<00:00, 40.44it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 40.74it/s]\n",
            " 45%|████▌     | 9/20 [00:03<00:04,  2.24it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 42.99it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 43.46it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 45.45it/s]\n",
            " 50%|█████     | 10/20 [00:04<00:04,  2.24it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 41.57it/s]\u001b[A\n",
            " 50%|█████     | 10/20 [00:00<00:00, 43.03it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 45.59it/s]\n",
            " 55%|█████▌    | 11/20 [00:04<00:04,  2.25it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 43.82it/s]\u001b[A\n",
            " 55%|█████▌    | 11/20 [00:00<00:00, 48.69it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 49.18it/s]\n",
            " 60%|██████    | 12/20 [00:05<00:03,  2.30it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 51.25it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 49.59it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 46.74it/s]\n",
            " 65%|██████▌   | 13/20 [00:05<00:03,  2.30it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 45.12it/s]\u001b[A\n",
            " 55%|█████▌    | 11/20 [00:00<00:00, 51.45it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 49.79it/s]\n",
            " 70%|███████   | 14/20 [00:06<00:02,  2.35it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 52.02it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 58.01it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 55.16it/s]\n",
            " 75%|███████▌  | 15/20 [00:06<00:02,  2.45it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 54.91it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 62.80it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 62.64it/s]\n",
            " 80%|████████  | 16/20 [00:06<00:01,  2.61it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 51.54it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 53.55it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 55.52it/s]\n",
            " 85%|████████▌ | 17/20 [00:07<00:01,  2.65it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 53.33it/s]\u001b[A\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 60.07it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 59.59it/s]\n",
            " 90%|█████████ | 18/20 [00:07<00:00,  2.73it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 5/20 [00:00<00:00, 46.77it/s]\u001b[A\n",
            " 55%|█████▌    | 11/20 [00:00<00:00, 53.46it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 56.61it/s]\n",
            " 95%|█████████▌| 19/20 [00:07<00:00,  2.75it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|███       | 6/20 [00:00<00:00, 51.61it/s]\u001b[A\n",
            " 60%|██████    | 12/20 [00:00<00:00, 53.79it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 54.25it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.14620704383988514\n",
            "---------------------------------> best coeff  [-1.26384566 -0.73473235 -0.42097383]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "adv\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'algo_superv_learn': 'ridge'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.9459055  1.11771566 0.99298907]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -51.44004169487696\n",
            "[1 1 1 2 2 1 0 0 0 1 0 1 2 0 2 1 1 0 2 1 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 2\n",
            " 2 0 0 1 2 0 1 2 1 0 1 2 0 1 0 2 0 0 2 0 2 1 0 0 1 0 1 2 2 1 2 0 0 2 1 1 0\n",
            " 1 2 1 1 0 1 0 1 1 0 2 0 1 0 0 2 0 2 2 1 0 1 0 1]\n",
            "S dataset \n",
            " [[0.98829519 0.         0.        ]\n",
            " [0.         1.12362516 0.        ]\n",
            " [0.         0.         1.02737607]]\n",
            "S missing shape\n",
            "  (98, 3, 3)\n",
            "S missing\n",
            "  [[[1.00212975 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.52014759 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.11893206]]\n",
            "\n",
            " [[1.05256316 0.         0.        ]\n",
            "  [0.         0.76088249 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15298719 0.        ]\n",
            "  [0.         0.         0.75748205]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.26773718]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.89379326 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.89174549 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.44307734 0.        ]\n",
            "  [0.         0.         1.05999773]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93964388 0.         0.        ]\n",
            "  [0.         1.00743775 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.39379703]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.01593113]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.53311653 0.        ]\n",
            "  [0.         0.         0.38213152]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57664812 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.13678893 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69273351]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.73262044 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.59910462 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.48363645 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.26805939]]\n",
            "\n",
            " [[1.51647079 0.         0.        ]\n",
            "  [0.         0.84958506 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.37213573 0.         0.        ]\n",
            "  [0.         0.95434558 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.40285337 0.        ]\n",
            "  [0.         0.         0.47849713]]\n",
            "\n",
            " [[0.56643844 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.81436143 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.26553921 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.89275199]]\n",
            "\n",
            " [[0.54952313 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.96501714]]\n",
            "\n",
            " [[1.09025418 0.         0.        ]\n",
            "  [0.         1.02228439 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.74589284 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.34457387 0.         0.        ]\n",
            "  [0.         0.56142611 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.13120476 0.        ]\n",
            "  [0.         0.         0.8333964 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.57810877 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.07555621 0.         0.        ]\n",
            "  [0.         0.35333837 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.15616378 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.99343802 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.68407816]]\n",
            "\n",
            " [[1.07788735 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.50604197 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.70427004 0.        ]\n",
            "  [0.         0.         0.87183231]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.3782341 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.00156228 0.        ]\n",
            "  [0.         0.         0.66195923]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.97939075 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.54732427]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.93298433 0.         0.        ]\n",
            "  [0.         0.89647449 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.58765602 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.97807945 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.6800644 ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.07183068 0.        ]\n",
            "  [0.         0.         1.37101651]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         1.16081639 0.        ]\n",
            "  [0.         0.         0.8540751 ]]\n",
            "\n",
            " [[0.98349197 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.71637785 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.42022568]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.96614018 0.        ]\n",
            "  [0.         0.         0.40655047]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.62598033]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.60709679]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.49373972 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.66131084 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.1314962 ]]\n",
            "\n",
            " [[0.77499561 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.73796429 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.76213134]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94945104 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.69525949]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.75746772 0.         0.        ]\n",
            "  [0.         1.37770129 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.93937696]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.94872046 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         1.16226819]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.83842084 0.         0.        ]\n",
            "  [0.         0.81152769 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.02435658 0.         0.        ]\n",
            "  [0.         1.09893893 0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.04545016 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[1.38154625 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]\n",
            "\n",
            " [[0.84212583 0.         0.        ]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 98, 3)\n",
            "y_train length  98\n",
            "-------> size test:  20000  , size train:  98 nbr_seen (train):  31  nbr_miss :  67\n",
            "rid alphas  [1.00000000e-04 1.83298071e-04 3.35981829e-04 6.15848211e-04\n",
            " 1.12883789e-03 2.06913808e-03 3.79269019e-03 6.95192796e-03\n",
            " 1.27427499e-02 2.33572147e-02 4.28133240e-02 7.84759970e-02\n",
            " 1.43844989e-01 2.63665090e-01 4.83293024e-01 8.85866790e-01\n",
            " 1.62377674e+00 2.97635144e+00 5.45559478e+00 1.00000000e+01]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[0.98829519 0.         0.        ]\n",
            " [0.         1.12362516 0.        ]\n",
            " [0.         0.         1.02737607]]\n",
            "S_dts_inv in get path, ridge regression \n",
            " [[1.01184344 0.         0.        ]\n",
            " [0.         0.88997651 0.        ]\n",
            " [0.         0.         0.97335341]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1096.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 3) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.0001 0.0001] , min score  0.14609164718076117\n",
            "---------------------------------> best coeff  [-1.26395406 -0.73484643 -0.42108993]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "ridge\n",
            "res partial \n",
            "\n",
            "key:  ('BR_si', 'std_nan', 'adv')  value:  {'best_coeff': [array([-1.46456953, -0.60304177, -0.21837017]), array([-1.44394845, -0.72880694, -0.34795195]), array([-1.43190308, -0.74469649, -0.381491  ]), array([-1.37138081, -0.67367923, -0.35526322]), array([-1.3848682 , -0.72822008, -0.38129356]), array([-1.40143241, -0.75928911, -0.40648389]), array([-1.39884565, -0.79590356, -0.44177372])], 'l2_dist_best_coeff_gt': [np.float64(0.39370708501687035), np.float64(0.25173104937945234), np.float64(0.24019094939086533), np.float64(0.33643517505288906), np.float64(0.28594799797164233), np.float64(0.2509373728551032), np.float64(0.2332005631650674)], 'best_score': [np.float64(0.1557149707130631), np.float64(0.06361217916860534), np.float64(0.057897990847169546), np.float64(0.11356371365400778), np.float64(0.0821088194806128), np.float64(0.06324698144441689), np.float64(0.05468590933148299)], 'best_hyper_p': [array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]}\n",
            "key:  ('oracle', 'sd', 'adv')  value:  {'best_coeff': [array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982])], 'l2_dist_best_coeff_gt': [np.float64(3.508307875011187e-11), np.float64(7.305238997060815e-11), np.float64(7.275742566052098e-11), np.float64(3.535477033472198e-11), np.float64(3.373731111789775e-11), np.float64(3.5207112812517124e-11), np.float64(3.402773947196598e-11)], 'best_score': [np.float64(1.2376927153823157e-21), np.float64(5.366579767446593e-21), np.float64(5.323337041922529e-21), np.float64(1.257082087635852e-21), np.float64(1.1448225567002981e-21), np.float64(1.2466420782037162e-21), np.float64(1.1645389051877343e-21)], 'best_hyper_p': [array([0.00379269, 0.        ]), array([0.00112884, 0.        ]), array([0.00112884, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ])], 'best_alpha_dts': [np.float64(0.00379269019073225), np.float64(0.0011288378916846883), np.float64(0.0011288378916846883), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225)], 'best_alpha_mis': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]}\n",
            "key:  ('BR_si', 'std_nan', 'ridge')  value:  {'best_coeff': [array([-1.46460654, -0.60309785, -0.2184241 ]), array([-1.44399214, -0.72882733, -0.34805817]), array([-1.43193547, -0.74470991, -0.38160674]), array([-1.3714386 , -0.67372481, -0.35539615]), array([-1.38489972, -0.72826405, -0.38142476]), array([-1.40143693, -0.75933539, -0.40660813]), array([-1.39884381, -0.79593767, -0.44189976])], 'l2_dist_best_coeff_gt': [np.float64(0.3936219801079168), np.float64(0.2516538322950736), np.float64(0.24013482687413235), np.float64(0.3363339589338655), np.float64(0.285874014272744), np.float64(0.2508951193400182), np.float64(0.23319242006088192)], 'best_score': [np.float64(0.15564760588356144), np.float64(0.06357290879553121), np.float64(0.057870674868799606), np.float64(0.11349500237215905), np.float64(0.08206612879720536), np.float64(0.06322559854931505), np.float64(0.05468204050615319)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 'adv')  value:  {'best_coeff': [array([-1.44550302, -0.48578006, -0.12034573]), array([-1.25796944, -0.70369121, -0.36839222]), array([-1.2952683 , -0.64689054, -0.41690297]), array([-1.27616502, -0.63414875, -0.41329959]), array([-1.29674379, -0.57616683, -0.36901606]), array([-1.22146894, -0.6149611 , -0.29622197]), array([-1.26384566, -0.73473235, -0.42097383])], 'l2_dist_best_coeff_gt': [np.float64(0.5441451019216828), np.float64(0.4056674873814171), np.float64(0.4026481647124714), np.float64(0.4256218870622818), np.float64(0.4539266490584252), np.float64(0.498738672472295), np.float64(0.3811783225421434)], 'best_score': [np.float64(0.2975405324656542), np.float64(0.1655573502062121), np.float64(0.16257082841916373), np.float64(0.18167698416922398), np.float64(0.20644556541658796), np.float64(0.25003596862682603), np.float64(0.14620704383988514)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 'ridge')  value:  {'best_coeff': [array([-1.4456124 , -0.48593057, -0.12039457]), array([-1.2581018 , -0.70381434, -0.36866896]), array([-1.2954015 , -0.64701918, -0.41707169]), array([-1.27625781, -0.63424683, -0.41345473]), array([-1.29685897, -0.57628293, -0.3692217 ]), array([-1.22156124, -0.61506652, -0.29635606]), array([-1.26395406, -0.73484643, -0.42108993])], 'l2_dist_best_coeff_gt': [np.float64(0.5439696634478808), np.float64(0.4054509230474323), np.float64(0.402457796471956), np.float64(0.42548168415530074), np.float64(0.4537366375370722), np.float64(0.49857046694061463), np.float64(0.38102774033547104)], 'best_score': [np.float64(0.2973490607466435), np.float64(0.16538035384417787), np.float64(0.16241667460630693), np.float64(0.18155688974579073), np.float64(0.20627188359120727), np.float64(0.24986721377098656), np.float64(0.14609164718076117)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "x_axis for print in plot_res---->  [40, 50, 60, 70, 80, 90, 100]\n",
            "key in plot_res ('BR_si', 'std_nan', 'adv') : values\n",
            " {'best_coeff': [array([-1.46456953, -0.60304177, -0.21837017]), array([-1.44394845, -0.72880694, -0.34795195]), array([-1.43190308, -0.74469649, -0.381491  ]), array([-1.37138081, -0.67367923, -0.35526322]), array([-1.3848682 , -0.72822008, -0.38129356]), array([-1.40143241, -0.75928911, -0.40648389]), array([-1.39884565, -0.79590356, -0.44177372])], 'l2_dist_best_coeff_gt': [np.float64(0.39370708501687035), np.float64(0.25173104937945234), np.float64(0.24019094939086533), np.float64(0.33643517505288906), np.float64(0.28594799797164233), np.float64(0.2509373728551032), np.float64(0.2332005631650674)], 'best_score': [np.float64(0.1557149707130631), np.float64(0.06361217916860534), np.float64(0.057897990847169546), np.float64(0.11356371365400778), np.float64(0.0821088194806128), np.float64(0.06324698144441689), np.float64(0.05468590933148299)], 'best_hyper_p': [array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ]), array([0.0001, 0.    ])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]}\n",
            "key in plot_res ('oracle', 'sd', 'adv') : values\n",
            " {'best_coeff': [array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982]), array([-1.60584391, -0.9027603 , -0.43100982])], 'l2_dist_best_coeff_gt': [np.float64(3.508307875011187e-11), np.float64(7.305238997060815e-11), np.float64(7.275742566052098e-11), np.float64(3.535477033472198e-11), np.float64(3.373731111789775e-11), np.float64(3.5207112812517124e-11), np.float64(3.402773947196598e-11)], 'best_score': [np.float64(1.2376927153823157e-21), np.float64(5.366579767446593e-21), np.float64(5.323337041922529e-21), np.float64(1.257082087635852e-21), np.float64(1.1448225567002981e-21), np.float64(1.2466420782037162e-21), np.float64(1.1645389051877343e-21)], 'best_hyper_p': [array([0.00379269, 0.        ]), array([0.00112884, 0.        ]), array([0.00112884, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ]), array([0.00379269, 0.        ])], 'best_alpha_dts': [np.float64(0.00379269019073225), np.float64(0.0011288378916846883), np.float64(0.0011288378916846883), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225)], 'best_alpha_mis': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]}\n",
            "key in plot_res ('BR_si', 'std_nan', 'ridge') : values\n",
            " {'best_coeff': [array([-1.46460654, -0.60309785, -0.2184241 ]), array([-1.44399214, -0.72882733, -0.34805817]), array([-1.43193547, -0.74470991, -0.38160674]), array([-1.3714386 , -0.67372481, -0.35539615]), array([-1.38489972, -0.72826405, -0.38142476]), array([-1.40143693, -0.75933539, -0.40660813]), array([-1.39884381, -0.79593767, -0.44189976])], 'l2_dist_best_coeff_gt': [np.float64(0.3936219801079168), np.float64(0.2516538322950736), np.float64(0.24013482687413235), np.float64(0.3363339589338655), np.float64(0.285874014272744), np.float64(0.2508951193400182), np.float64(0.23319242006088192)], 'best_score': [np.float64(0.15564760588356144), np.float64(0.06357290879553121), np.float64(0.057870674868799606), np.float64(0.11349500237215905), np.float64(0.08206612879720536), np.float64(0.06322559854931505), np.float64(0.05468204050615319)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 'adv') : values\n",
            " {'best_coeff': [array([-1.44550302, -0.48578006, -0.12034573]), array([-1.25796944, -0.70369121, -0.36839222]), array([-1.2952683 , -0.64689054, -0.41690297]), array([-1.27616502, -0.63414875, -0.41329959]), array([-1.29674379, -0.57616683, -0.36901606]), array([-1.22146894, -0.6149611 , -0.29622197]), array([-1.26384566, -0.73473235, -0.42097383])], 'l2_dist_best_coeff_gt': [np.float64(0.5441451019216828), np.float64(0.4056674873814171), np.float64(0.4026481647124714), np.float64(0.4256218870622818), np.float64(0.4539266490584252), np.float64(0.498738672472295), np.float64(0.3811783225421434)], 'best_score': [np.float64(0.2975405324656542), np.float64(0.1655573502062121), np.float64(0.16257082841916373), np.float64(0.18167698416922398), np.float64(0.20644556541658796), np.float64(0.25003596862682603), np.float64(0.14620704383988514)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 'ridge') : values\n",
            " {'best_coeff': [array([-1.4456124 , -0.48593057, -0.12039457]), array([-1.2581018 , -0.70381434, -0.36866896]), array([-1.2954015 , -0.64701918, -0.41707169]), array([-1.27625781, -0.63424683, -0.41345473]), array([-1.29685897, -0.57628293, -0.3692217 ]), array([-1.22156124, -0.61506652, -0.29635606]), array([-1.26395406, -0.73484643, -0.42108993])], 'l2_dist_best_coeff_gt': [np.float64(0.5439696634478808), np.float64(0.4054509230474323), np.float64(0.402457796471956), np.float64(0.42548168415530074), np.float64(0.4537366375370722), np.float64(0.49857046694061463), np.float64(0.38102774033547104)], 'best_score': [np.float64(0.2973490607466435), np.float64(0.16538035384417787), np.float64(0.16241667460630693), np.float64(0.18155688974579073), np.float64(0.20627188359120727), np.float64(0.24986721377098656), np.float64(0.14609164718076117)], 'best_hyper_p': [array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001]), array([0.0001, 0.0001])], 'best_alpha_dts': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)], 'best_alpha_mis': [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]}\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.39370708501687035), np.float64(0.25173104937945234), np.float64(0.24019094939086533), np.float64(0.33643517505288906), np.float64(0.28594799797164233), np.float64(0.2509373728551032), np.float64(0.2332005631650674)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(3.508307875011187e-11), np.float64(7.305238997060815e-11), np.float64(7.275742566052098e-11), np.float64(3.535477033472198e-11), np.float64(3.373731111789775e-11), np.float64(3.5207112812517124e-11), np.float64(3.402773947196598e-11)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.3936219801079168), np.float64(0.2516538322950736), np.float64(0.24013482687413235), np.float64(0.3363339589338655), np.float64(0.285874014272744), np.float64(0.2508951193400182), np.float64(0.23319242006088192)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.5441451019216828), np.float64(0.4056674873814171), np.float64(0.4026481647124714), np.float64(0.4256218870622818), np.float64(0.4539266490584252), np.float64(0.498738672472295), np.float64(0.3811783225421434)]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(0.5439696634478808), np.float64(0.4054509230474323), np.float64(0.402457796471956), np.float64(0.42548168415530074), np.float64(0.4537366375370722), np.float64(0.49857046694061463), np.float64(0.38102774033547104)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.1557149707130631), np.float64(0.06361217916860534), np.float64(0.057897990847169546), np.float64(0.11356371365400778), np.float64(0.0821088194806128), np.float64(0.06324698144441689), np.float64(0.05468590933148299)]\n",
            "lb[i] in plot_res  best_score    [np.float64(1.2376927153823157e-21), np.float64(5.366579767446593e-21), np.float64(5.323337041922529e-21), np.float64(1.257082087635852e-21), np.float64(1.1448225567002981e-21), np.float64(1.2466420782037162e-21), np.float64(1.1645389051877343e-21)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.15564760588356144), np.float64(0.06357290879553121), np.float64(0.057870674868799606), np.float64(0.11349500237215905), np.float64(0.08206612879720536), np.float64(0.06322559854931505), np.float64(0.05468204050615319)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.2975405324656542), np.float64(0.1655573502062121), np.float64(0.16257082841916373), np.float64(0.18167698416922398), np.float64(0.20644556541658796), np.float64(0.25003596862682603), np.float64(0.14620704383988514)]\n",
            "lb[i] in plot_res  best_score    [np.float64(0.2973490607466435), np.float64(0.16538035384417787), np.float64(0.16241667460630693), np.float64(0.18155688974579073), np.float64(0.20627188359120727), np.float64(0.24986721377098656), np.float64(0.14609164718076117)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.00379269019073225), np.float64(0.0011288378916846883), np.float64(0.0011288378916846883), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225), np.float64(0.00379269019073225)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001), np.float64(0.0001)]\n",
            "res in run multipl experiments\n",
            "\n",
            "final step, let's take the mean of the results\n",
            "key in res  ('BR_si', 'std_nan', 'adv')\n",
            "[[0.21165538 0.23896615 0.1370558  0.10394215 0.01468279 0.0453343\n",
            "  0.07802121]\n",
            " [0.39370709 0.25173105 0.24019095 0.33643518 0.285948   0.25093737\n",
            "  0.23320056]]\n",
            "mean l2_dist               [0.30268123 0.2453486  0.18862337 0.22018866 0.15031539 0.14813583\n",
            " 0.15561089]\n",
            "mean_l2_dist diff method:  [0.30268123 0.2453486  0.18862337 0.22018866 0.15031539 0.14813583\n",
            " 0.15561089]\n",
            "key in res  ('oracle', 'sd', 'adv')\n",
            "[[5.79054909e-11 4.53376192e-11 2.97596423e-11 3.21776074e-11\n",
            "  3.30082777e-11 3.72511531e-11 4.20027224e-11]\n",
            " [3.50830788e-11 7.30523900e-11 7.27574257e-11 3.53547703e-11\n",
            "  3.37373111e-11 3.52071128e-11 3.40277395e-11]]\n",
            "mean l2_dist               [4.64942848e-11 5.91950046e-11 5.12585340e-11 3.37661889e-11\n",
            " 3.33727944e-11 3.62291330e-11 3.80152309e-11]\n",
            "mean_l2_dist diff method:  [4.64942848e-11 5.91950046e-11 5.12585340e-11 3.37661889e-11\n",
            " 3.33727944e-11 3.62291330e-11 3.80152309e-11]\n",
            "key in res  ('BR_si', 'std_nan', 'ridge')\n",
            "[[0.2246253  0.23895742 0.13703765 0.10447509 0.02619512 0.04994754\n",
            "  0.07897976]\n",
            " [0.39362198 0.25165383 0.24013483 0.33633396 0.28587401 0.25089512\n",
            "  0.23319242]]\n",
            "mean l2_dist               [0.30912364 0.24530563 0.18858624 0.22040452 0.15603457 0.15042133\n",
            " 0.15608609]\n",
            "mean_l2_dist diff method:  [0.30912364 0.24530563 0.18858624 0.22040452 0.15603457 0.15042133\n",
            " 0.15608609]\n",
            "key in res  ('mi', 'mean', 'cond_var', 'std_nan', 5, 'adv')\n",
            "[[0.2817448  0.37915722 0.20157281 0.22073148 0.2058303  0.1438576\n",
            "  0.19279434]\n",
            " [0.5441451  0.40566749 0.40264816 0.42562189 0.45392665 0.49873867\n",
            "  0.38117832]]\n",
            "mean l2_dist               [0.41294495 0.39241235 0.30211049 0.32317668 0.32987848 0.32129813\n",
            " 0.28698633]\n",
            "mean_l2_dist diff method:  [0.41294495 0.39241235 0.30211049 0.32317668 0.32987848 0.32129813\n",
            " 0.28698633]\n",
            "key in res  ('mi', 'mean', 'cond_var', 'std_nan', 5, 'ridge')\n",
            "[[0.32225612 0.3789243  0.20141595 0.22063025 0.20576525 0.14379835\n",
            "  0.19259179]\n",
            " [0.54396966 0.40545092 0.4024578  0.42548168 0.45373664 0.49857047\n",
            "  0.38102774]]\n",
            "mean l2_dist               [0.43311289 0.39218761 0.30193687 0.32305597 0.32975094 0.32118441\n",
            " 0.28680976]\n",
            "mean_l2_dist diff method:  [0.43311289 0.39218761 0.30193687 0.32305597 0.32975094 0.32118441\n",
            " 0.28680976]\n",
            "final dictionary, dictionary of the means:\n",
            "k:    ('BR_si', 'std_nan', 'adv')\n",
            "best_coeff :  [[-1.4562972  -1.02703805 -0.34741063]\n",
            " [-1.43950509 -1.00622581 -0.2941482 ]\n",
            " [-1.56085873 -0.87593397 -0.30435686]\n",
            " [-1.60097172 -0.86520544 -0.33421176]\n",
            " [-1.60845561 -0.89861364 -0.41716899]\n",
            " [-1.61287576 -0.89001502 -0.38807604]\n",
            " [-1.62593036 -0.87920445 -0.35939302]]\n",
            "l2_dist_best_coeff_gt :  [0.30268123 0.2453486  0.18862337 0.22018866 0.15031539 0.14813583\n",
            " 0.15561089]\n",
            "best_score :  [0.10028267 0.06030207 0.03833531 0.06220357 0.04116246 0.03265347\n",
            " 0.030396  ]\n",
            "best_hyper_p :  [[0.01172861 0.        ]\n",
            " [0.0001     0.        ]\n",
            " [0.0001     0.        ]\n",
            " [0.00352596 0.        ]\n",
            " [0.01172861 0.        ]\n",
            " [0.00642137 0.        ]\n",
            " [0.00352596 0.        ]]\n",
            "best_alpha_dts :  [0.01172861 0.0001     0.0001     0.00352596 0.01172861 0.00642137\n",
            " 0.00352596]\n",
            "best_alpha_mis :  [0. 0. 0. 0. 0. 0. 0.]\n",
            "k:    ('oracle', 'sd', 'adv')\n",
            "best_coeff :  [[-1.60584391 -0.9027603  -0.43100982]\n",
            " [-1.60584391 -0.9027603  -0.43100982]\n",
            " [-1.60584391 -0.9027603  -0.43100982]\n",
            " [-1.60584391 -0.9027603  -0.43100982]\n",
            " [-1.60584391 -0.9027603  -0.43100982]\n",
            " [-1.60584391 -0.9027603  -0.43100982]\n",
            " [-1.60584391 -0.9027603  -0.43100982]]\n",
            "l2_dist_best_coeff_gt :  [4.64942848e-11 5.91950046e-11 5.12585340e-11 3.37661889e-11\n",
            " 3.33727944e-11 3.62291330e-11 3.80152309e-11]\n",
            "best_score :  [2.29971586e-21 3.71118261e-21 3.10468904e-21 1.14686557e-21\n",
            " 1.11782284e-21 1.31768818e-21 1.46485756e-21]\n",
            "best_hyper_p :  [[0.00379269 0.        ]\n",
            " [0.00246076 0.        ]\n",
            " [0.00246076 0.        ]\n",
            " [0.00379269 0.        ]\n",
            " [0.00379269 0.        ]\n",
            " [0.00379269 0.        ]\n",
            " [0.00379269 0.        ]]\n",
            "best_alpha_dts :  [0.00379269 0.00246076 0.00246076 0.00379269 0.00379269 0.00379269\n",
            " 0.00379269]\n",
            "best_alpha_mis :  [0. 0. 0. 0. 0. 0. 0.]\n",
            "k:    ('BR_si', 'std_nan', 'ridge')\n",
            "best_coeff :  [[-1.46847358 -1.07003848 -0.3709771 ]\n",
            " [-1.43955701 -1.00633719 -0.29418459]\n",
            " [-1.56093688 -0.87600319 -0.30433412]\n",
            " [-1.6048729  -0.8676055  -0.33263177]\n",
            " [-1.61679885 -0.90343892 -0.40722509]\n",
            " [-1.62353044 -0.89731559 -0.38461695]\n",
            " [-1.63297736 -0.88236222 -0.35969715]]\n",
            "l2_dist_best_coeff_gt :  [0.30912364 0.24530563 0.18858624 0.22040452 0.15603457 0.15042133\n",
            " 0.15608609]\n",
            "best_score :  [0.10313455 0.06028038 0.03831911 0.06222282 0.04137368 0.03285668\n",
            " 0.03046581]\n",
            "best_hyper_p :  [[1.00000000e-04 1.00000000e-04]\n",
            " [1.00000000e-04 1.00000000e-04]\n",
            " [1.00000000e-04 1.00000000e-04]\n",
            " [1.00000000e-04 1.00000000e-04]\n",
            " [1.31882545e-01 1.31882545e-01]\n",
            " [1.00000000e-04 1.00000000e-04]\n",
            " [1.00000000e-04 1.00000000e-04]]\n",
            "best_alpha_dts :  [1.00000000e-04 1.00000000e-04 1.00000000e-04 1.00000000e-04\n",
            " 1.31882545e-01 1.00000000e-04 1.00000000e-04]\n",
            "best_alpha_mis :  [1.00000000e-04 1.00000000e-04 1.00000000e-04 1.00000000e-04\n",
            " 1.31882545e-01 1.00000000e-04 1.00000000e-04]\n",
            "k:    ('mi', 'mean', 'cond_var', 'std_nan', 5, 'adv')\n",
            "best_coeff :  [[-1.43357371 -1.07576749 -0.29039822]\n",
            " [-1.26644504 -0.85125315 -0.27002656]\n",
            " [-1.47380579 -0.76181253 -0.37329275]\n",
            " [-1.48000339 -0.84744845 -0.25830443]\n",
            " [-1.52958233 -0.88072671 -0.24110246]\n",
            " [-1.62121637 -0.76927173 -0.37963377]\n",
            " [-1.50749628 -0.82989443 -0.28205357]]\n",
            "l2_dist_best_coeff_gt :  [0.41294495 0.39241235 0.30211049 0.32317668 0.32987848 0.32129813\n",
            " 0.28698633]\n",
            "best_score :  [0.18840447 0.15435191 0.10145731 0.11517084 0.12436187 0.13545804\n",
            " 0.09169228]\n",
            "best_hyper_p :  [[0.039288 0.0001  ]\n",
            " [0.0001   0.0001  ]\n",
            " [0.0001   0.0001  ]\n",
            " [0.0001   0.0001  ]\n",
            " [0.0001   0.0001  ]\n",
            " [0.0001   0.0001  ]\n",
            " [0.0001   0.0001  ]]\n",
            "best_alpha_dts :  [0.039288 0.0001   0.0001   0.0001   0.0001   0.0001   0.0001  ]\n",
            "best_alpha_mis :  [0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001]\n",
            "k:    ('mi', 'mean', 'cond_var', 'std_nan', 5, 'ridge')\n",
            "best_coeff :  [[-1.41512181 -1.14037531 -0.32606607]\n",
            " [-1.26658299 -0.85149517 -0.27020702]\n",
            " [-1.47392779 -0.76187421 -0.37341093]\n",
            " [-1.48005393 -0.84754852 -0.25836496]\n",
            " [-1.52970131 -0.88087    -0.24110864]\n",
            " [-1.62134337 -0.76932678 -0.37969482]\n",
            " [-1.50761567 -0.83003054 -0.28217033]]\n",
            "l2_dist_best_coeff_gt :  [0.43311289 0.39218761 0.30193687 0.32305597 0.32975094 0.32118441\n",
            " 0.28680976]\n",
            "best_score :  [0.20069623 0.15417572 0.10134872 0.11508842 0.12426146 0.13536518\n",
            " 0.09159553]\n",
            "best_hyper_p :  [[8.1193837e-01 8.1193837e-01]\n",
            " [1.0000000e-04 1.0000000e-04]\n",
            " [1.0000000e-04 1.0000000e-04]\n",
            " [1.0000000e-04 1.0000000e-04]\n",
            " [1.0000000e-04 1.0000000e-04]\n",
            " [1.0000000e-04 1.0000000e-04]\n",
            " [1.0000000e-04 1.0000000e-04]]\n",
            "best_alpha_dts :  [8.1193837e-01 1.0000000e-04 1.0000000e-04 1.0000000e-04 1.0000000e-04\n",
            " 1.0000000e-04 1.0000000e-04]\n",
            "best_alpha_mis :  [8.1193837e-01 1.0000000e-04 1.0000000e-04 1.0000000e-04 1.0000000e-04\n",
            " 1.0000000e-04 1.0000000e-04]\n",
            "PLOT OF THE MEANS\n",
            "x_axis for print in plot_res---->  [40, 50, 60, 70, 80, 90, 100]\n",
            "key in plot_res ('BR_si', 'std_nan', 'adv') : values\n",
            " {'best_coeff': array([[-1.4562972 , -1.02703805, -0.34741063],\n",
            "       [-1.43950509, -1.00622581, -0.2941482 ],\n",
            "       [-1.56085873, -0.87593397, -0.30435686],\n",
            "       [-1.60097172, -0.86520544, -0.33421176],\n",
            "       [-1.60845561, -0.89861364, -0.41716899],\n",
            "       [-1.61287576, -0.89001502, -0.38807604],\n",
            "       [-1.62593036, -0.87920445, -0.35939302]]), 'l2_dist_best_coeff_gt': array([0.30268123, 0.2453486 , 0.18862337, 0.22018866, 0.15031539,\n",
            "       0.14813583, 0.15561089]), 'best_score': array([0.10028267, 0.06030207, 0.03833531, 0.06220357, 0.04116246,\n",
            "       0.03265347, 0.030396  ]), 'best_hyper_p': array([[0.01172861, 0.        ],\n",
            "       [0.0001    , 0.        ],\n",
            "       [0.0001    , 0.        ],\n",
            "       [0.00352596, 0.        ],\n",
            "       [0.01172861, 0.        ],\n",
            "       [0.00642137, 0.        ],\n",
            "       [0.00352596, 0.        ]]), 'best_alpha_dts': array([0.01172861, 0.0001    , 0.0001    , 0.00352596, 0.01172861,\n",
            "       0.00642137, 0.00352596]), 'best_alpha_mis': array([0., 0., 0., 0., 0., 0., 0.])}\n",
            "key in plot_res ('oracle', 'sd', 'adv') : values\n",
            " {'best_coeff': array([[-1.60584391, -0.9027603 , -0.43100982],\n",
            "       [-1.60584391, -0.9027603 , -0.43100982],\n",
            "       [-1.60584391, -0.9027603 , -0.43100982],\n",
            "       [-1.60584391, -0.9027603 , -0.43100982],\n",
            "       [-1.60584391, -0.9027603 , -0.43100982],\n",
            "       [-1.60584391, -0.9027603 , -0.43100982],\n",
            "       [-1.60584391, -0.9027603 , -0.43100982]]), 'l2_dist_best_coeff_gt': array([4.64942848e-11, 5.91950046e-11, 5.12585340e-11, 3.37661889e-11,\n",
            "       3.33727944e-11, 3.62291330e-11, 3.80152309e-11]), 'best_score': array([2.29971586e-21, 3.71118261e-21, 3.10468904e-21, 1.14686557e-21,\n",
            "       1.11782284e-21, 1.31768818e-21, 1.46485756e-21]), 'best_hyper_p': array([[0.00379269, 0.        ],\n",
            "       [0.00246076, 0.        ],\n",
            "       [0.00246076, 0.        ],\n",
            "       [0.00379269, 0.        ],\n",
            "       [0.00379269, 0.        ],\n",
            "       [0.00379269, 0.        ],\n",
            "       [0.00379269, 0.        ]]), 'best_alpha_dts': array([0.00379269, 0.00246076, 0.00246076, 0.00379269, 0.00379269,\n",
            "       0.00379269, 0.00379269]), 'best_alpha_mis': array([0., 0., 0., 0., 0., 0., 0.])}\n",
            "key in plot_res ('BR_si', 'std_nan', 'ridge') : values\n",
            " {'best_coeff': array([[-1.46847358, -1.07003848, -0.3709771 ],\n",
            "       [-1.43955701, -1.00633719, -0.29418459],\n",
            "       [-1.56093688, -0.87600319, -0.30433412],\n",
            "       [-1.6048729 , -0.8676055 , -0.33263177],\n",
            "       [-1.61679885, -0.90343892, -0.40722509],\n",
            "       [-1.62353044, -0.89731559, -0.38461695],\n",
            "       [-1.63297736, -0.88236222, -0.35969715]]), 'l2_dist_best_coeff_gt': array([0.30912364, 0.24530563, 0.18858624, 0.22040452, 0.15603457,\n",
            "       0.15042133, 0.15608609]), 'best_score': array([0.10313455, 0.06028038, 0.03831911, 0.06222282, 0.04137368,\n",
            "       0.03285668, 0.03046581]), 'best_hyper_p': array([[1.00000000e-04, 1.00000000e-04],\n",
            "       [1.00000000e-04, 1.00000000e-04],\n",
            "       [1.00000000e-04, 1.00000000e-04],\n",
            "       [1.00000000e-04, 1.00000000e-04],\n",
            "       [1.31882545e-01, 1.31882545e-01],\n",
            "       [1.00000000e-04, 1.00000000e-04],\n",
            "       [1.00000000e-04, 1.00000000e-04]]), 'best_alpha_dts': array([1.00000000e-04, 1.00000000e-04, 1.00000000e-04, 1.00000000e-04,\n",
            "       1.31882545e-01, 1.00000000e-04, 1.00000000e-04]), 'best_alpha_mis': array([1.00000000e-04, 1.00000000e-04, 1.00000000e-04, 1.00000000e-04,\n",
            "       1.31882545e-01, 1.00000000e-04, 1.00000000e-04])}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 'adv') : values\n",
            " {'best_coeff': array([[-1.43357371, -1.07576749, -0.29039822],\n",
            "       [-1.26644504, -0.85125315, -0.27002656],\n",
            "       [-1.47380579, -0.76181253, -0.37329275],\n",
            "       [-1.48000339, -0.84744845, -0.25830443],\n",
            "       [-1.52958233, -0.88072671, -0.24110246],\n",
            "       [-1.62121637, -0.76927173, -0.37963377],\n",
            "       [-1.50749628, -0.82989443, -0.28205357]]), 'l2_dist_best_coeff_gt': array([0.41294495, 0.39241235, 0.30211049, 0.32317668, 0.32987848,\n",
            "       0.32129813, 0.28698633]), 'best_score': array([0.18840447, 0.15435191, 0.10145731, 0.11517084, 0.12436187,\n",
            "       0.13545804, 0.09169228]), 'best_hyper_p': array([[0.039288, 0.0001  ],\n",
            "       [0.0001  , 0.0001  ],\n",
            "       [0.0001  , 0.0001  ],\n",
            "       [0.0001  , 0.0001  ],\n",
            "       [0.0001  , 0.0001  ],\n",
            "       [0.0001  , 0.0001  ],\n",
            "       [0.0001  , 0.0001  ]]), 'best_alpha_dts': array([0.039288, 0.0001  , 0.0001  , 0.0001  , 0.0001  , 0.0001  ,\n",
            "       0.0001  ]), 'best_alpha_mis': array([0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001])}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 'ridge') : values\n",
            " {'best_coeff': array([[-1.41512181, -1.14037531, -0.32606607],\n",
            "       [-1.26658299, -0.85149517, -0.27020702],\n",
            "       [-1.47392779, -0.76187421, -0.37341093],\n",
            "       [-1.48005393, -0.84754852, -0.25836496],\n",
            "       [-1.52970131, -0.88087   , -0.24110864],\n",
            "       [-1.62134337, -0.76932678, -0.37969482],\n",
            "       [-1.50761567, -0.83003054, -0.28217033]]), 'l2_dist_best_coeff_gt': array([0.43311289, 0.39218761, 0.30193687, 0.32305597, 0.32975094,\n",
            "       0.32118441, 0.28680976]), 'best_score': array([0.20069623, 0.15417572, 0.10134872, 0.11508842, 0.12426146,\n",
            "       0.13536518, 0.09159553]), 'best_hyper_p': array([[8.1193837e-01, 8.1193837e-01],\n",
            "       [1.0000000e-04, 1.0000000e-04],\n",
            "       [1.0000000e-04, 1.0000000e-04],\n",
            "       [1.0000000e-04, 1.0000000e-04],\n",
            "       [1.0000000e-04, 1.0000000e-04],\n",
            "       [1.0000000e-04, 1.0000000e-04],\n",
            "       [1.0000000e-04, 1.0000000e-04]]), 'best_alpha_dts': array([8.1193837e-01, 1.0000000e-04, 1.0000000e-04, 1.0000000e-04,\n",
            "       1.0000000e-04, 1.0000000e-04, 1.0000000e-04]), 'best_alpha_mis': array([8.1193837e-01, 1.0000000e-04, 1.0000000e-04, 1.0000000e-04,\n",
            "       1.0000000e-04, 1.0000000e-04, 1.0000000e-04])}\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [0.30268123 0.2453486  0.18862337 0.22018866 0.15031539 0.14813583\n",
            " 0.15561089]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [4.64942848e-11 5.91950046e-11 5.12585340e-11 3.37661889e-11\n",
            " 3.33727944e-11 3.62291330e-11 3.80152309e-11]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [0.30912364 0.24530563 0.18858624 0.22040452 0.15603457 0.15042133\n",
            " 0.15608609]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [0.41294495 0.39241235 0.30211049 0.32317668 0.32987848 0.32129813\n",
            " 0.28698633]\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [0.43311289 0.39218761 0.30193687 0.32305597 0.32975094 0.32118441\n",
            " 0.28680976]\n",
            "lb[i] in plot_res  best_score    [0.10028267 0.06030207 0.03833531 0.06220357 0.04116246 0.03265347\n",
            " 0.030396  ]\n",
            "lb[i] in plot_res  best_score    [2.29971586e-21 3.71118261e-21 3.10468904e-21 1.14686557e-21\n",
            " 1.11782284e-21 1.31768818e-21 1.46485756e-21]\n",
            "lb[i] in plot_res  best_score    [0.10313455 0.06028038 0.03831911 0.06222282 0.04137368 0.03285668\n",
            " 0.03046581]\n",
            "lb[i] in plot_res  best_score    [0.18840447 0.15435191 0.10145731 0.11517084 0.12436187 0.13545804\n",
            " 0.09169228]\n",
            "lb[i] in plot_res  best_score    [0.20069623 0.15417572 0.10134872 0.11508842 0.12426146 0.13536518\n",
            " 0.09159553]\n",
            "lb[i] in plot_res  best_alpha_dts    [0.01172861 0.0001     0.0001     0.00352596 0.01172861 0.00642137\n",
            " 0.00352596]\n",
            "lb[i] in plot_res  best_alpha_dts    [0.00379269 0.00246076 0.00246076 0.00379269 0.00379269 0.00379269\n",
            " 0.00379269]\n",
            "lb[i] in plot_res  best_alpha_dts    [1.00000000e-04 1.00000000e-04 1.00000000e-04 1.00000000e-04\n",
            " 1.31882545e-01 1.00000000e-04 1.00000000e-04]\n",
            "lb[i] in plot_res  best_alpha_dts    [0.039288 0.0001   0.0001   0.0001   0.0001   0.0001   0.0001  ]\n",
            "lb[i] in plot_res  best_alpha_dts    [8.1193837e-01 1.0000000e-04 1.0000000e-04 1.0000000e-04 1.0000000e-04\n",
            " 1.0000000e-04 1.0000000e-04]\n",
            "lb[i] in plot_res  best_alpha_mis    [0. 0. 0. 0. 0. 0. 0.]\n",
            "lb[i] in plot_res  best_alpha_mis    [0. 0. 0. 0. 0. 0. 0.]\n",
            "lb[i] in plot_res  best_alpha_mis    [1.00000000e-04 1.00000000e-04 1.00000000e-04 1.00000000e-04\n",
            " 1.31882545e-01 1.00000000e-04 1.00000000e-04]\n",
            "lb[i] in plot_res  best_alpha_mis    [0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001]\n",
            "lb[i] in plot_res  best_alpha_mis    [8.1193837e-01 1.0000000e-04 1.0000000e-04 1.0000000e-04 1.0000000e-04\n",
            " 1.0000000e-04 1.0000000e-04]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 4666.67x500 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAEloAAAHqCAYAAAByjyTJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd4U+X/xvE73YMuZpkFBGQP2creMmQLiIyqgKK4FQUBFRVwKyooCogyRBxsZAjI3hsRgbKl7BZKWzrO7w9+7ZeSpE3apGnL+3VdvaTPec5zPklzmuS25xOTYRiGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8iA3VxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgLDRaAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeRaNlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQJ5FoyUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJBn0WgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADkWTRaAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeRaNlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQJ5FoyUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJBn0WgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADkWTRayiYDBw6UyWQy+1qzZo2rS0M2a9asmcXHwvHjx11dGgAAAADABtOnT7f4vu7NN990dWkAkOOULl3a4u9MAAAAAAAAAAAAAAAAAAAAAAAAIDt5uLoA5CxRUVFavHixlixZot27d+v8+fO6cuWKvLy8lD9/fpUuXVo1a9ZUo0aN1K5dOwUFBZmt8eabb+qtt97Kci1hYWE0HwLskJCQoK1bt2rz5s3asWOHjh49qpMnTyo6Olrx8fEKCAhQoUKFVLNmTTVr1kyPPPKIgoODXV02XOTkyZOaO3eulixZooiICEVGRsrT01NFihRRlSpV1LlzZ3Xr1k2BgYHZVlNsbKyWLVumJUuWaNu2bYqMjNSlS5fk4eGhoKAghYWFqXr16rr//vvVvn17FS5cONtqAwAAAJBWdHS0fv31Vy1YsEAHDhxQZGSk4uPjVaRIEZUpU0YdOnTQww8/rFKlSrm6VCBHCQ8P1/Tp0y1uGzBggNVtlsTHx2v+/PmaP3++du7cqcjISN24cUOFChVSqVKl1LZtW/Xs2VOVKlVyTPFANrt48aLWrVunLVu2aP/+/Tp27JgiIyN1/fp1mUwmBQUFqVSpUqpTp466du2qVq1ayc3N/s8XcWZO5szny+TkZC1ZskTz58/Xpk2bFBkZqejoaBUsWFDFihVTy5Yt1aNHD9WpU8futSVp+/bt+uWXX7Rq1SqdOXNGFy9eVGBgoIoUKaKGDRuqc+fOat++fabucwAAAAAAAAAAAAAAAAAAAABwBZNhGIari7gbDBw4UN9//73Z+OrVq9WsWbPsL+gON2/e1BdffKF33nlHV65csWmfUqVK6cSJE2bjNFpKX7NmzbR27Vqz8YiICJUuXTr7C0Ke8Pzzz2v69OmKioqyeR9fX1+NGjVKr7zyijw86Lt3t4iLi9PYsWP10UcfKT4+Pt25oaGh+uCDD/Too486tabk5GTNmDFDb7zxhs6cOWPTPm5ubrp586bc3d2dWhsAAIAl06dPV3h4uNn4mDFj9Oabb2Z/QUA2mzFjhl599VVFRkamO8/b21svv/yyRo0aJW9v72yqLnc6fvy4ypQpYzbetGlTrVmzJvsLcqDSpUtbzBDvxlh6xYoVatOmjdXt9jRaWrp0qYYNG6ajR4+mO8/NzU2DBw/WuHHjaLhtA5PJZDaWF3Nqaxn+tGnTNHDgwOwv6A6nTp3Sww8/rK1btyo5Odnm/SpWrKgpU6aoUaNGNs13dk7mzOfLzZs3a+jQodq1a1eGc3v27KlPP/1UxYoVs2ntM2fO6Pnnn9e8efMynHvffffpq6++Uv369W1aGwAAAAAAAAAAAAAAAAAAAABciY+Zha5evarWrVvrpZdesrnJkiQlJSU5sSoA9lizZo1dTZYkKTY2ViNGjFDPnj2VmJjopMqQk8TGxqpTp0567733Mrx4TJLOnTunfv36acyYMU6rKT4+Xr1791Z4eLjNTZakW82Z7saLcgEAAABXGzlypAYMGJBh0wjp1uv9d999Vw899JDi4uKyoTog57px44aGDBnikLW+/vprdejQIcMmS9Kt98+TJ09WixYtdPnyZYccH3C2S5cuafPmzXY1WZKkQ4cOqVmzZvrpp58ynOvsnMyZz5eLFi1Ss2bNbGqyJEk///yz7r//fkVERGQ49+jRo2rYsKFNTZYkaefOnWratKmWLl1q03wAAAAAAAAAAAAAAAAAAAAAcCUPVxcA14qJiVHTpk21d+9eV5dipnTp0q4uAbgr/P7773rrrbc0duxYV5cCJ3v00Ue1cuVKu/d7++23FRoaqqeeesqh9SQlJalTp05asWKFQ9cFAABwtvbt22vdunVm46VKlXJBNUD2mThxot577z2791u+fLkGDBhgU+ML5D3z5s2j0ZakN954w6YmJxlZsGCBnnrqKbubD+/atUsdO3bU+vXr5ebG5y8g70pKSlK/fv1Uo0YNVaxY0eo8Z+Zkzny+3LFjh7p3766bN2/atfaJEyfUqlUr7d27V/7+/hbnXLt2TS1bttSpU6fsWjs+Pl5du3bV5s2bVbNmTbv2BQAAAAAAAAAAAAAAAAAAAIDsRKOlu9yzzz5rscmSyWRSmzZt1L59e5UrV05+fn6KiorSkSNHtGXLFq1evdrqmo899phatWpl0/ENw1CXLl0sfpr6M888Y/sNAZDK09NTzZo1U7t27VSuXDn5+/vr8OHDmjJlitVPOf/ggw/0/PPPq0CBAtlcLbLLL7/8ol9//dVs3MPDQ88995xatmypuLg4/fjjjxbnDR8+XJ06dVKJEiUcVtN7771ntcnSAw88oM6dO6tSpUrKly+frl+/rqNHj2rnzp1atWqVzpw547A6AAAA7FW4cGEVLlzY1WUA2erkyZN6/fXXLW7r0qWL+vXrJz8/P/3555/65JNPlJiYmGbO3Llz1bdvXz300EPZUS5ykDp16ri6BJfbunWrPvvssyyvEx0draFDh1psstS0aVM9+eSTyp8/v7Zu3aoJEybo+vXraeZs2rRJX3zxhZ599tks1wJkp8KFC6tDhw5q0qSJihcvrvj4eG3YsEGTJ0/W1atXzeYnJCRo1KhR+vnnny2u58yczJnPl0lJSRo0aJDFJks1atTQ888/rxIlSmjfvn2aMGGCIiMj08w5duyYRo0apY8//thifSNGjNCJEyfMxgsXLqxXX31VNWrU0JkzZ/TZZ5+Z5czx8fEaNGiQNm/eLHd3d4vrAwAAAAAAAAAAAAAAAAAAAICr0WjpLrZmzRpNnTrVbLxw4cL65Zdf1KhRI6v7JiUlaevWrRa3lSpVSqVKlbKphkWLFllsshQWFqauXbvatAaAW/z9/TVs2DA988wzKl68eJptLVu21ODBg/XYY49pxowZZvvGx8dryZIl6tevX3aVi2w2atQoi+NTp05N83Pv2rWrHn/8cbPnh2vXrmn8+PH64osvHFLPv//+q7ffftts3M/PTzNnzlSXLl2s7msYhjZu3MhFWwAAAEA2GjdunGJiYszGH3vsMX333Xep37dr107VqlVT//79zeaOHDmSRku46yQkJOiJJ55QcnJy6lhYWJjFZiYZmTRpksXGw61bt9bSpUtT3ye3adNGjRs3VvPmzc2aMr311lsaMmSIvL297T4+kN2qVKmi4cOHq3fv3vL09EyzrWPHjhoyZIgaNWpk8bxYsmSJ4uLi5OPjY7bNmTmZM58v582bZ7GRftWqVbVx40b5+flJklq1aqX27durVq1aio2NTTN34sSJevXVVxUaGppm/OzZs5o0aZLZ2r6+vvrrr7907733po717NlT9evX1/79+9PM3b59u3777Tf16NHDbB0AAAAAAAAAAAAAAAAAAAAAyAncMrvj+fPn9fnnn6tz58669957FRwcLE9PT/n4+KhQoUKqWbOmevToobFjx2rFihUW/7Dc2rqffvqpunXrpnLlyikkJEReXl4KDQ1VnTp19NJLL2nz5s2ZqnnTpk167bXX1KhRI5UoUUJ+fn7y9/dXWFiY2rVrp48++kgXLlywa82EhAR9/fXXatGihYoUKSIfHx+VLl1aPXv21JIlSzJVp3SrCZLJZDL7GjhwYKbXvJOlTy12c3PTggUL0m2yJEnu7u5q2LBhlmuw9knuzzzzjMsaaLz55psW7/vp06dLutWQ5uuvv1arVq1UrFgxeXl5qUiRImrfvr3mzJlj8RPl7XHu3DmNHTtWtWvXVoECBeTn56cKFSpo6NCh2rdvX4b7ly5d2mL9KbZt26annnpKFStWVGBgoEwmU7oNTRzBEede586dLd6u8ePHW93noYcesmmfgQMHWpy3Zs0aSdKlS5c0YcIE1a9fX4UKFZKPj4/KlCmjgQMHasOGDTbdB82aNbN4jOPHj9u0f0Z69uypf/75R+PGjTNrspTC3d1dX331lUJCQixuP3DggENqyapr167pu+++08CBA1W1alUVKVJEXl5e8vX1VcmSJdWyZUu9/vrrWrt2rZKSkjJcb9u2bRo5cqSaNGmikiVLyt/fX76+vipevLgaNGigl19+WWvXrk13jZo1a5r97Pz8/HTt2rV097P2u3zYsGFmcy3NK126dIa3zxabN2/W33//bTZeqVIli8213nnnHbm5mb9EmDVrluLj4x1S08SJE5WYmGg2Pn369Ax/J5lMJj3wwANpfrcBAADYwlFZxvTp0y2+fnvzzTczrOHnn39Wp06dVLx4cXl7e6t48eJq27atpk2blvr6KKP3pbc7fvy4xbnNmjWTdKtR8vTp09WyZUsVKVJEfn5+qlSpkp599llFRESYrXfy5EkNHz5cVatWVb58+RQcHKz77rtPY8aM0dWrVzO8fceOHdMPP/ygl19+We3bt1e1atVUsGBB+fr6ysPDQ8HBwSpdurTatm2rESNGaO/evRmu6QxxcXH64YcfFB4eripVqqhQoULy8vJS/vz5ValSJT322GP69ddf0zRGsSajn9fly5c1YcIENWzYUKGhoXJ3d5fJZEq9PzP6GUrSr7/+qu7du6tMmTLy9fWVyWTSp59+mqYOZ77vjIuL05w5c8zG3dzc9M4775iN9+vXT5UqVTIb379/v7Zt25bleuxlS862aNEi9e7dW6VLl5aPj4/y58+vhg0b6v3339eNGzecVltKLWXKlLG4fe3atRk+PqSMf/6HDh3Syy+/rKpVqyokJEQmk0k1a9ZMs4azzt+MsqrbZUcu5+yM5k7jx49Pk+mFhISkm2elx9LzgHTrffydWWrTpk3Vtm1bs7mXL1/WggULMnX8rLDld926dev02GOPqVy5cvLz81NQUJBq1aqlUaNGWWzW7yi3P0YtOXHiRKZym3379unNN99Uy5YtFRYWpnz58snHx0clS5ZU8+bN9c4779j1uIuPj9esWbP06KOPqmbNmipQoIC8vb3l6emp4OBgVapUSQ8++KCGDx+un3/+WefPn0+z/+2vX9566y2LxwgPD7fpNYgtP8+s8Pf31+eff649e/aoX79+Zk2WUpQuXVrvv/++xW03btyweP86Mydz9vPltGnTzMakW42jUpospbj33ns1YMAAs7mJiYn64YcfzMZnzJhhMWsdOHBgmiZL0q1G6W+88YbFWqzVCAAAAAAAAAAAAAAAAAAAAAA5gpEJEydONPz9/Q1JNn95enoacXFxVteMiYkxhg0bZvj4+Ni0Xtu2bY2TJ0/aVO+ePXuM+++/36Z1/f39jbfeestISkrKcN1//vnHqFq1arrrdenSxbh8+bIxYMAAi9tXr15tce3Vq1dbnD9gwACbbnNGTp06Zbi5uZmt36NHD4esb4v9+/db/RlcuXIl2+q405gxYyzWNW3aNGPjxo1GuXLl0v2Zd+rUyYiNjbW6ftOmTS3uFxERYcybN8/Inz+/1bU9PDyMt956K936w8LCLO6blJRkvPjiixZ/7p07d3bwvXiLI8+9CxcuGKGhoWb7eXt7GwcPHjSbP336dIvHadasmdkx0js/Fy5caBQuXDjd2p988kkjMTEx3fsivZ97duvUqZPFWgYNGpTttdzu5s2bxqhRo4zAwECbn1umT59udb1Dhw4ZzZs3t3mtunXrGjt27LC41qeffmpxnx9++CHd2zR48GCL+1k6jqV5YWFhdt2H1gwfPtzi+i+//LLVfWrXrm1xn2XLlmW5nri4OCMgIMBs7Tp16mR5bQAAAGscmWVMmzbN4vwxY8ZYPf7FixczfH1aq1Yt459//kn3femdIiIiLM5t2rSpcfr0aaNBgwZWj+fn52f8/vvvqWvNnj073fsoNDTU2LNnj9XbeOjQIbvu35Svdu3aGadOnbLr55kVX375ZYbv81K+KlWqZKxZsybd9dL7eS1fvtzie1lJqdlHej/DixcvGm3atLG4/ZNPPklThzPfdy5dutTi2um9hn/ppZcs7vPaa69luR57pZeznT171mjVqlW6j4Ny5co57f17Zs6ZlMfH7dL7+X/wwQeGl5eX2bYaNWqk7u/M89daVmWJs3O5jO4rRzt48KDh7e2d5jhTp07NVPb7999/W9ynYMGCVveZOHGixX169+7t8NuakfR+10VHRxu9e/dO92dbuHBhY+fOnU6pzdpjNKMva7nN8ePHjfbt29u0hqenp/HMM89k+Lhdu3atUbJkSbtrXLVqVeoa1l6/2PJ152uQ9H6e2e3SpUtW696wYYPZfGfmZM58vrx27Zrh7u5uNs9kMhnR0dEW1164cKHFtRs0aGA2t379+hbnLlq0yOLaUVFRhslkMpvv7u5uXL9+3ertBQAAAAAAAAAAAAAAAAAAAABXMv8Y3gxMmzZNw4YNU0xMjF37JSQkWP1E8dOnT6t+/fqaOHGi4uLibFrvjz/+UJ06dbRjx450582ZM0f169fXxo0bbVo3JiZGY8aMUadOncw+jfh2ERERat68ufbv35/uer///rs6duyoGzdu2HT87PLXX38pOTnZbLxbt246dOiQnn/+eVWvXl2BgYHy8fFR8eLF1a5dO33++ee6fv26Q2r4/PPPLY4PHDhQwcHBDjmGI61YsUKtWrXSkSNH0p23cOFCvfzyy3av/8svv+jhhx9O99PZExMTNWbMGI0YMcLu9Z977jl9/PHHFn/uzuDoc69gwYKpn7p+u/j4eD322GNpbteZM2f0/PPPm60REhKiGTNmWPwEcksWLFigrl27mn36+50mT55s8dPOcypvb2+L40FBQdlcyf+cP39eDRs21NixYxUdHW3zftaeVxYtWqQ6depo9erVNq+1bds23X///Zo5c6bZtr59+8rT09NsfPbs2VbXS0hI0C+//GI2Xr16dd1333021+UI27dvtzhevXp1q/vUqFHD4nhGz7u22LFjh65du2Y23q1bN508eVIjR45U3bp1FRISIi8vLxUtWlTNmjXTuHHjdPHixSwfHwAA3H2ckWXYIyoqSi1btszw9emuXbvUsmVLnThxIsvHvHLlilq3bq3NmzdbnXPjxg11795dO3fu1OzZs9WnT59076Nz586pY8eOVl+zZ/a+WrZsmR544AFFRkZman9bJSQk6OGHH9bTTz+d4fu8FH///bdat26tadOm2X289evX66GHHtK5c+fs3le69fPp0KGDli9fnqn9HSmnvadwlJMnT6px48ZauXJluvOOHDmirl27KjExMZsqc5yPPvpIr7zyim7evJnuvJx+/jo7l3OG5ORkPfHEE2lyrtatWys8PDxT6+XV8/Dq1atq2bKl5syZk+688+fPq1OnToqKisqmyjJn9erVqlWrlpYsWWLT/ISEBH3xxRdq0qSJ1Vz477//Vtu2bXXq1Cm768no3M8LrGWdkuW805nnkjPX3r17t5KSkszmlSlTRgEBAXatvWfPnjRrJSYmas+ePRbnWqs9MDBQZcqUMRtPSkqyuhYAAAAAAAAAAAAAAAAAAAAAuJpdjZYMw9Do0aMdWsD169fVsWPHDBsWWXL+/Pl0L1hbvXq1+vfvb3PzptstWbJETz31lMVthmFowIABOnv2rE1rbdy4UfPmzbO7BmfatGmTxfHZs2erSpUq+uyzz7Rv3z5du3ZN8fHxOnv2rP744w8999xzKlOmjH777bcsHf/y5cv68ccfzcZNJpOeffbZLK3tLLNmzbK5YdakSZN0/Phxu9Z/5ZVXbG6CNG7cuAwvArzTF198Ydf8rHDWude2bVuLj4/Nmzfrk08+Sf1+0KBBunr1qtm8r7/+WiVLlrS5lk8++cTmiyhnz56t7777zua1XcnahS516tTJ5kpuSbl42FEX+e3YsUO9evXKVFO4+Ph4hYeHm10AX7BgQXXs2NFs/ooVK3Tp0iWLa1nbltkLKrNi9+7dFsdLlChhdZ/ixYtbHN+1a1eW67H2HPTXX3+pQoUKeu+997R9+3ZdvXpVCQkJOnfunNauXasRI0aoTJkymjRpUpZrAAAAdw9nZBn2euGFF2y+4Pz06dOaPn16lo+5d+9e/f333xnOS0pK0qOPPqonnnjCpnVPnTpltXFyVpw8eVJDhw51+Lq3e+qpp/Tzzz/bvV9CQoIGDRqkP//80679vvvuu0y9L06xbds2bdmyJdP7O1JOe0/hKKtXr9bRo0dtmrt7927NmjXLyRU5XnbkQdlx/jo7l3OGL7/8Mk0Dcn9/f02ZMiXT6znyPDxy5IjDmuln1Z49e7Rt2zab5p45c0afffaZkyvKvAMHDqhLly66cuWK3ftu27ZNvXr1sthI55133snS80leZ+3cyJcvn+69916b5zviOS2nrV20aFGzDy6QpNjYWB06dCj1+0OHDll8jLm5ualYsWJW188Nz/UAAAAAAAAAAAAAAAAAAAAAcDsPeyb/+++/On36tNl43bp19fjjjyssLEze3t6KiorSsWPHtG/fPq1du1YRERFW13z33XctXmwYEBCgxx57TPfff79CQkJ0/PhxTZkyxeyii7Nnz+qFF17Q7Nmz04zfvHlT4eHhSkhIMFu7cuXKeuKJJ3TvvfcqMTFRO3bs0BdffGH2idHTpk1Tr1691LZt2zTjv/zyi9atW2fx9tSsWVPPPPOMypQpo9OnT2vy5MnatGlTpj8V3lkOHz5scXzhwoUZ7nvx4kV1795dkydP1uDBgzN1/ClTpli8OOrBBx9UhQoVMrVmdmnbtq3Cw8OVP39+LV68WBMnTjRrkJScnKw5c+botddes3ldwzDk6+urYcOGqXnz5jIMQytWrNCXX35p8ZPHX3jhBe3bt8/u+lu1aqVHHnlEpUqV0sWLF7V9+3bFxsbavY41zjz3JGnChAn6888/zW77qFGj1KlTJ61bt05Lly412y88PFw9e/a0+/a4u7tr0KBB6tChg7y8vLRx40Z9/PHHunbtmtnc1157TX379pWPj4/dx8kuS5cu1b///ms2HhQUpA4dOrigImn8+PFWP+09JCQkzXNBVFSU9uzZo19//VV79+41m28YhgYNGmTx94uPj4+eeeYZNW/eXB4eHtq4caM++eQTRUdHp5mXchH1oUOH5OHxv6fJ8PBwsyZzCQkJ+uWXXyz+LpwzZ47ZmKenp/r27Wv5jnCSxMREq82gChYsaHU/a9vOnz+f5ZqsPQctW7Ysw32vX7+uoUOH6vTp03r33XezXAsAAMj7nJFl2GP37t2aNm2axW0lS5bUyy+/rCpVquj8+fP69ttv7W7mk5H69evrueeeU2BgoObOnasZM2aYzbm9IVO/fv3Uq1cvXbt2TRMmTLB4Uf/MmTP1xhtvWDxecHCwateurbp16+qee+5RkSJF5OfnJy8vL8XHx+v8+fPavXu3pk+frgsXLqTZ97ffftORI0dUrly5rN1oC/744w+LzXHd3d3VpUsXde7cWUWLFlVkZKTmz5+vefPmpclykpKSFB4eriNHjsjT09OuYxcvXlxDhw5VrVq1lJycrH///Vfz5s2z2PjAEnd3d/Xv318PPvig8ufPrzNnzmjlypUKCAiwq46siIyMtDiemfcUly5dUnJystzc7Or/7lQVK1bUCy+8oHvuuUd79uzR2LFjLTZwnjVrlvr37+/QY6dkjOfOnbOYW9SsWVMTJ040Gw8KCrLrOHXr1tVjjz2mcuXKKSoqSnv37tXBgwfTzMmp5+/tnJXLOdrJkyc1YsSINGPvvfeewsLCMr2mI89DwzB04cIF5cuXL9P1OFrx4sX1yiuvqEqVKjp27JjefvttnTlzxmzerFmzHN5Acd68ealNZho3bmy2PTQ01GKjvjszwEGDBpnlTJIUFhamwYMHq0qVKvL09NT+/fs1ceJEs9cnK1eu1LfffqshQ4akGb+zIbgkFStWTMOGDVOVKlUUEBCg69ev6/Tp0zp48KDWr1+vPXv2mJ0b7du3T/2dM3XqVIuvT0aMGKEHH3zQbDwnZ/bWGkA+/PDDabI9yfk5mTOfLzOztoeHh4KDgy02/zp//ryqVKmS7trBwcFyd3e3u3ZH5IcAAAAAAAAAAAAAAAAAAAAA4Ax2NVq6ePGi2Zifn5/++uuvdBuLHD58WHPmzDH7g+wrV65YvFCoUKFC+uuvv1SxYsU040888YS6d+9u1uhi7ty5evvtt1W+fPnUsenTp+vEiRNma3ft2lVz585N8wf2Dz30kAYMGKC6deuaNXx55513zJq9fPXVVxZv5/33368///xT3t7eqWN9+/ZVp06dLDZ+caXMfKr27QzD0NNPP62aNWuqXr16du2bmJioL7/80uK2559/Pkt1OdvgwYP19ddfp37funVrBQYGauzYsWZzt27datfa7u7u+uOPP9JczPPggw+qefPmeuihh8zm79+/X+vWrbN48Y8148aNM7vIrFevXnbVmRFnnnuS5O3trVmzZqlu3bppPmU7NjZWjzzyiMUmQuXKlbN6wU1GfvjhB/Xp0yf1+zZt2qhTp066//77zRpgXbx4UT///LP69euXqWM52/nz5/Xkk09a3Pb666+75OK6qKgoffzxxxa31atXT4sWLVKhQoXSjHfp0kVjxozRH3/8keb3rSQtWbLE4ieme3h4aOXKlXrggQdSx9q0aaMePXqofv36Zo2Zjh49anYB7YMPPqgiRYqYXXg0e/Zss0ZLcXFxmj9/vlkdHTt2NLs9zmbpAr8U6T1333nfpoiKispyTVl9DpJuXaBau3ZtdevWLctrAQCAvM3RWYa9rGUIYWFh2rp1qwoXLpw61rt3b/Xt29esmXRm1atXT3/99Ze8vLwkSR06dNDhw4e1efNmi/Nfeuklffjhh6nft2zZUqVKlUrz3kuS/vnnH0VFRZk1eqlQoYIuX76cYQOhRx55JPW1+O1SGg47o1HLW2+9ZTZmMpk0Z84c9ejRI81437599dlnn5llFCdPntSMGTP0+OOP23zcevXqafny5Wb3la35h4+Pj5YsWaLmzZunGXd0s5+MWHsfkJn3FIZhKDo6WsHBwY4oLctq1aqldevWyd/fX9Ktx33NmjXVsmVLs7l3NoB3hEaNGkmSjh8/bnF7UFBQ6pzMevLJJ/XVV1+lOTe7d++eZk5OPn9TODOXc7QhQ4bo+vXrqd/ff//9euaZZ7K0piPPw/TWc4WSJUtq69atCg0NTR1r1qyZKleurKSkpDRzDx8+bPE5KCvq1KmT7nZvb+8Mz8Ply5dr06ZNZuMNGzbU8uXL0+Ru7du31xNPPKG6devq2LFjaea/9957GjRoUJpmdJZey8yePVtNmjSxWs/Fixc1b948FS9ePHWscOHCqa87Vq5caXG/8uXLZ/l3TnaaPXu25s6dazbu5+enkSNHmo07Oydz5vNlZtZOb/3b13Pm2gAAAAAAAAAAAAAAAAAAAACQk9j10fGWLoC6efOmIiIi0t2vQoUKGj16tDw9PdOMr1ixQjExMWbzn3/+ebMmS9KtC+BefPFFs/Hk5GQtXLgwzdjvv/9uNs/NzU2ff/652acYS1LZsmXVtWtXs/ENGzakuZAhNjZW69evN5snSZ988onZH5a7u7tnqsFLs2bNZBiG2df06dPtXsuSq1evpru9T58++v3337V8+XKNHj1afn5+ZnMSExM1fPhwu4/922+/6dSpU2bjVapUUevWre1eL7uEhIToo48+Mhu31qjIUrOh9PTp08di06ROnTpZbDgk3bqAx1ZNmzY1a7LkDM46925XtWpVTZgwwWx8x44dZhfLeHh4aObMmZlqItSoUaM0TZZS1K5dW+Hh4Rb3sfYzWbNmjcVzunTp0nbXlRmXLl1SmzZtdPLkSbNtLVq00Msvv5wtddxp+fLlFp8H/P399fvvv6fblKht27Zq1qxZmrEFCxZYnDtw4MA0TZZSVK1aVcOGDbO4z53PKx4eHnr00UfN5v311186e/ZsmrHFixdbvHBr4MCBFo8lyeLjw9qFtva4s4nU7SydkynufM5OcfuFopmV0XNQ27ZtNXfuXK1cuVIffPCBChQoYHHe8OHDzS64BAAAuJOjswx7LVu2zOL42LFj0zRZkm7lHp9//nm6jTHs8e6776Y2WUphrSmDn5+fxowZk2asUKFCZs1UpFuvXS29t3Bzc5PJZFJMTIzmzp2rxx57TA0aNFBoaKj8/f1Tt5tMJovrStLOnTttvXk2i4yMtNhcqlWrVmZNllIMHTpUvr6+ZuOWGqpa4+7urpkzZ2apGcirr75q1mTJGme+77T2viIz7ykkx7yvcJSJEyemNllK0aJFCxUsWNBs7uXLl3Xt2rXsKs0hypUrp88++yzDBko59fxN4chcztkZzY8//pjmd7+3t7e+/fbbNI1zMiMvn4fjxo1L02RJuvU8XKtWLbO51p6DXM1SJipJH374ocVcMn/+/BbzxZMnT2r37t1pxiy9lvnnn3/SradgwYJ68sknVa1atXTnZVbp0qUtnkdr1qxxyvEsWbx4sdWs7YsvvlDZsmXNxp2dkznzPM3M2umtn11rAwAAAAAAAAAAAAAAAAAAAEBOYtfVHRUrVjS7yCgxMVHVq1dX8+bNNWzYMH3++ef6448/bLrYYd26dRbHR44cmXrhzp1flhrRSLcaXdzOUjOk5ORklSxZ0ura3333ndk+hmGkWWvPnj1KSEgwmxcaGqp69epZrK1cuXKqXLmyxW2ukt4fyA8ZMkSzZs1S586d1bp1a7311lv66aefLM5ds2aNzpw5Y9exP/vsM4vjzz33nF3rZLeOHTtavCimRIkSFufb+6nNnTt3tnvb9u3bbV5/8ODBdtWTWc469+40bNgwtWvXLsN63nzzTavnZkac/TPJLqdOnVKjRo20Z88es21VqlTRvHnz5O7u7oLKrD8P9OzZU0WLFrV7vQ0bNlgct9TMK6Ntlh5/li6AS05O1ty5c9OMzZkzx2xekSJF1L59e6t1OIulRnkpLD2fZbQtM03L7pTec9CDDz6opUuXqmfPnmrZsqVefvllrVy50uI+R44csXjBPAAAwO0cnWXYIzIy0mKjYZPJpC5duljcp2DBgmratGmWj+3v72+xQU+xYsUszm/SpIkCAgJsnm/tPe8PP/ygsmXLqlevXpo2bZq2bNmiyMhI3bhxQ4ZhZFi3tYa7WbF+/XqLx16xYoXV96leXl6KjY012+fO/Ck9LVq0ULly5bJU+5AhQ7K0v6NYe1+RmfcUkmPeVzhCyZIlLTbllRyX97haeHi4WcM1a3Li+ZvC2bmco1y4cEHPP/98mrFRo0apUqVKWV47r56HXl5e6tatm8VtOe3nmx5rGdcDDzxg9blm1KhRFve587mmUaNGZnMGDx6smjVr6vHHH9eECRP022+/6e+//75rGlLPmjVLXbt21c2bN822vf7661ab5Ds7J3PmeZqZtdPbnl1rAwAAAAAAAAAAAAAAAAAAAEBOYlejJTc3N40YMcJsPDExUWvWrNEXX3yh5557Tu3atVNYWJiKFSumfv36adWqVRbX+++//zJXtQVnz55N/ff169cd+unyt68dGRlpcU6FChXSXePee+91WD2OEBQUZHXbK6+8YjbWsWNHVaxY0eJ8ey4y3LFjh8VGKAUKFNCjjz5q8zquUL16dYvj1i5CSExMtGv99B4j1rZZezxa0rBhQ7vqyQxnnnt3MplMmjZtmgoVKmR1TpMmTfT6669n+vjO/plkh7///lsPPPCADh06ZLbt3nvv1cqVKxUSEuKCym6x9jzQoEEDh65n7fdXetsuXLig5OTkNGNVqlRRnTp1zObOnj079d/Xrl3T4sWLzeY8+uijGX4KvDMEBgZa3RYXF2f3tvSeP2yV3hovvfSSTCZTmrGaNWuqVatWFufb8xwEAADuTo7OMuxx7tw5i+PFixe32NQohSMactxzzz0WG6paew9rLdew1qDF0nveiRMnqn///jp//rwdlabljOYZjsyfoqKidOPGDZvmZvV9eKlSpaw2uspu1l7DZ+Y9hclkSvd9SnaylvVIjst7XM3Wx2FOPX9TODuXc5TnnntOly5dSv2+Ro0aGj58uEPWduR5mN562a18+fLy9fW1uC2n/XzT46z/1yFJr732msVMac+ePZo6dapee+01devWTZUrV1ZISIjat2+vH374wWITorxg4sSJevTRRy02+Xn++ef13nvvWd3X2TmZM58vM7N2ettvX8+ZawMAAAAAAAAAAAAAAAAAAABATmJXoyVJeuGFF/T222/L09Mzw7n//feffvzxR7Vq1UoPPfSQYmNj02x35MU3ly9fdsq6d65trYlMep+ELEn+/v4OrSmrChQoYHE8KChI99xzj8Vt9913n8Vxey4i+eyzzyyODx482OoFNTmFtWY0jmqckt5jyNrjx56mRkWLFrW7Jns589yzJDQ0VM2aNbO6vVOnTnJzs/vXXCpn/0ycbevWrWrcuLFOnTpltq1mzZpat26dQkNDXVDZ/1y9etXieGYvxomOjrY4nt7vYGvbkpKSdP36dbPx8PBws7GtW7fq2LFjkqT58+ebPd9Z2y87eHh4WP2df/HiRav7XbhwweJ44cKFs1yTtXokqXbt2hbHHfEcBAAA7l6OzDLsYe39QXpNlmzZbgtrr6mt3QdZbXxz6tQphzQTubPZqSNk93vVFFl9H54d7+NtVaRIEYvjmXlPUaBAgSy9V3ek9BoPu6JRrjPY8jjKyedvCmfnco4QHR2dphGzu7u7vvvuO4fV6Mjz0GQypdu8PDvllfPQWf+vQ5Lq1aunX375xaaf2bVr17R06VL1799f1atX19GjRx1WV04wevRoPfvsszIMw2zbiBEj9Mknn6S7v7NzMmc+X2Zm7YSEBKuPzdtrt7b21atX021s5sz8EAAAAAAAAAAAAAAAAAAAAACcIVNXNY0aNUrHjx/X+PHj1bJlS5saYixcuFCvvPJKmrHg4ODMHN6i2//Y25Hr3rm2tYsdb9y4ke4aMTExDq0pq6pVq2ZxPL2LOa1ddGnpk6MtiYyM1E8//WQ27unpqaefftqmNVzJ3d3d4rjJZHLI+uk9hqw9fuy5+NbHx8fumuzlzHPPkl9//VU///yz1e2jR4/WoUOHMn18Z/9MnGnFihVq0aKFLl26ZLatSZMmWrNmTY64oM7aYyazF6dZ+z2V3u9ga9vc3d2VL18+s/E+ffrI29vbbHzOnDlp/nu7unXrqkqVKlZrcLaaNWtaHLfUhCujbbVq1cpyPdaegyTr51BWn4MAAAAclWXYI7MZgqWGn/ayt5GNtfe8tpo7d67FplQBAQH69NNPdezYMcXGxsowDBmGkdqoNDtk93vVFFl9H54d7+NtldPeUzhKeo97R+U9rmbL4ygnn78pnJ3LOcKdjaaSkpJUp04dmUwms6/mzZtbXOP7779PM+/48eOp2xx5HpYrV85i5uEKeeU8dNb/60jx0EMPKSIiQlOnTlX37t1taqL2zz//qFu3bk5tgpZdkpOT9dRTT2ns2LFm20wmkz766CO9++67Nq3lzOe0nLb26dOnLTal8vX1VcWKFVO/r1ixosXnC8MwdObMGavr54bnegAAAAAAAAAAAAAAAAAAAAC4XaY/ErpYsWIaPnx46qed//fffzp27JiOHj2qTZs2acaMGWYXDk6dOlUfffRRaoOK0NBQi2u///77atiwoV313P5H4P7+/sqXL5/ZhYlBQUFatGiRXetKUqlSpVL/be2TeA8fPpzuGhltz25169a1OH7t2jWr+0RHR1sct7VZy6RJk3Tz5k2z8R49eqh48eI2rZGX/fPPP1abj1h7/Fj7pGlXcea5d6czZ85o0KBB6e4fGxurvn37avPmzfL09LT7+P/88486depkcVtO/pn89NNP6t+/v8XzrWvXrpo1a1aOuWDX2kVhW7Zs0ZAhQzK13uXLl83GDx06pLJly1rcx1ozrkKFClm8OD0kJESdO3fW3Llz04zPnj1bTz75pJYvX262T3h4uC3lO02dOnW0atUqs/E9e/ZY3Wf37t0Wx2vXrp3leqw9B0m3nocsXZyY1ecgAAAAyTFZhj2s5R6nT59WbGysfH19LW7/+++/7T6Wq23fvt3i+MSJEzVgwACz8cjISGeXlMraz6FPnz4aOnSo3evZ0twir6lTp47FcVe9p4Bj5eTzF/9j7Tzcu3ev1X04D7NPaGioLl68aDa+fPlyq8/31ljLF/39/RUeHp6aM0VFRenIkSOKiIjQrl279MMPP5g1vtm7d682bNigxo0b21VDTnLz5k09+uijFhvue3p6aurUqXr00UdtXs+ZOZkzny9r1qwpd3d3JSUlpRk/ceKEoqKiLDYRtbZ2jRo10jQ58/DwUI0aNbRlyxaLtYeFhZmNX7lyRSdPnjQbd3d3V40aNSweFwAAAAAAAAAAAAAAAAAAAABcLdONlu5UtGhRFS1aVA888ID69++vOnXq6IknnkgzJzY2Vv/884+qV68uSWrUqJG++OILs7VOnjypV155xeZjJyYmysMj7U1p1KiRli1blmYsKipKvr6+dl1IcufaNWvWlKenpxISEtLMO3funLZt22axecTRo0d14MABm4+ZHVq0aCEfHx/FxcWlGY+KitKxY8csNiTZuXOnxbWsNQe63c2bNzV58mSL255//vmMC74LzJ8/Xz169LC4bcGCBRbHrV244UrOOvduZxiG+vfvb7Ghzp127typN954QxMmTLD52Cnmz5+vl19+2eK2nPoz+eqrrzRs2DCLn1Q/aNAgTZo0Kc1FNK7WuHFjTZw40Wx87ty5eu+996xeEG3NAw88YPH37W+//ab27dtb3Oe3336zupY14eHhZo2W9u/fr7feesvs+cHb21t9+vTJqHSn6tKli8VzYPHixfr444/Nxk+cOKF9+/aZjYeEhKhZs2ZZrqdGjRoqXry4zpw5Y7Zt586datGihcVxS2x5DgIAALAmM1mGPYoUKaKSJUuaNT1ISkrSsmXL1LVrV7N9Ll26pLVr19p9LFe7dOmSxXFr7wOtvQ53hgceeEAmk0mGYaQZ379/f+o2W6X3XjUva9asmYKDg3X16tU043v27NGZM2csNtC21nC5W7duzigx17P2Xv3OhhrOkJPPX/xPxYoVVbFiRbOG0ZcvX9amTZssfnDBwoULLa7FeWidm5ubWa5my3nYqFEj7d+/32w8OjparVu3tvn49jzPBAUFqXbt2qpdu7Z69Oihxx57TOXKlTObt2vXLrNGS678nWOP69evq2vXrlq5cqXZNj8/P/3yyy9q166dXWs6Mydz5vNlvnz51KpVK/3xxx9pxg3D0JIlSyzmj/b8DujSpYvFRkuLFy/WQw89ZPPabdu2lb+/v8VtAAAAAAAAAAAAAAAAAAAAAOBqbvbuMHToUG3cuNHs4rQ7xcbGWhy/ceNG6r/btGlj8dOcJ0+ebPWPtG/377//6s0331SpUqXMtnXu3NniPo899liGn7qemJioVatWqXfv3ho6dGiabb6+vmrUqJHF/V588UXdvHkzzVhSUpKee+65dI9nyZo1a2Qymcy+Bg4caPdalgQHB6t79+4Wt3344YdmY0uWLDG7iEeSChcubFPznDlz5li83xs2bKh69erZUPH/HD9+3OJ944jmH640e/ZsrVu3zmx88eLFWrp0qcV92rRp4+yy7Oasc+92H3zwgf7880+z8VdffVX169c3G//www+1Zs2a9Au3YP369Zo9e7bZ+K5duzR16lSL+1j7mTRr1szi4/b48eN212XNW2+9paefftpik6WRI0fqm2++yXSTJUu1ly5dOosV37q/LF14ExMTo65du+rixYtW9/3zzz+1evXqNGOWLvqRpOnTp2vDhg1m4/v377fY6EmSOnXqZPXYrVu3VrFixczGLa3VpUsXBQcHW10rhbPuY0lq0KCBKlWqZDZ++PBhTZs2zWx85MiRFp/nH3nkEXl7e5uN2/t72d3d3erz2ccff2x27L1791q8oM7T09OuixUBAMDdy5FZhr2sXfz/xhtvKDo62mz8+eefN2uKnBvky5fP4vidr9klae3atfr000+dXNH/hIaGWswe9u3bp5EjR1p8D3W7ixcv6uuvv1bNmjW1fv16Z5WZZc583+nj46PevXubjScnJ2vEiBFm41OmTNGxY8fMxqtUqWKxSbkklS5d2mL9dwtr51BERESGj1FnHTsnnL/OkB0ZjbNYey/9xhtvKDExMc3YihUrLP4M8+fPbzU/yc33jaNYOh/OnTunmJiYdPezlok+//zz+vfff9PdNzk5WZs2bdKgQYMsrjN+/Hj9+uuvio+PT3cde17HWDvvjx49mu4xUmRHRn/x4kW1aNHCYiZUoEAB/fnnn3Y3WZKcm5M5+/kyPDzcbEySxo4da/YYPXDggGbOnGk218PDQ/369TMb79+/v8XseMaMGfr777/TjMXExOjdd9+1WIu1GgEAAAAAAAAAAAAAAAAAAAAgJ7Dto5FvM3XqVE2aNEmFChVSixYtVL16dZUrV07BwcHy9PTU5cuXtW7dOk2aNMni/rd/Ym9ISIiGDRum999/P82cxMREPfTQQ2rcuLF69uypkiVLKigoSFFRUTpz5oz27NmjdevWWWz8kyI8PFzjxo3TyZMn04zv3btXZcuWVd++fdWwYcPUeq5cuaLDhw9r165dWr16deonDg8YMMBs7aeeesriRSrr169XgwYNNGzYMJUuXVqnT5/W5MmTtXHjRqt1utKIESP0888/mzWHmjRpkqKjo9WrVy/5+vpqw4YN+uCDDyyu8fLLL8vNLeN+XZ999pnF8cw0ocqrkpKS1LZtWz377LNq3ry5DMPQihUr9MUXX1icX7VqVbNPIs8JnHnuSbeaHI0aNcpsvFq1aho7dqwiIiJUq1atNBcWJScnq3///tq7d69NDW9u169fP61bt04dOnSQl5eXNm7cqI8//tjihU0FCxZUz5497VrfUV588UV98sknFrf16dNH7dq1y/CC4KCgIFWrVs0Z5aV7zBdeeEHvvPOO2bbNmzerYsWKCg8P1/3336+QkBBFRUVp3759WrBggbZt22Z28VP79u1Vs2ZN7d69O814YmKiWrduraefflotWrSQu7u7Nm3apE8++cTixWZlypTRI488YrVud3d39e/fX+PHj08zbumiq5xycdHYsWPVo0cPs/HBgwdr//79at26teLi4jR9+nTNnz/fbF5AQIBee+01h9Xz7LPPatKkSbp8+XKa8cWLF6tDhw56/PHHFRISol27dmnChAlmF4xK0qBBg+w+pwEAwN3JkVmGvZ5++mlNmTLFbPzgwYOqW7eunn/+ed177706f/68vv32W61atSrTx3KlatWq6bfffjMbf/XVV3XmzBk1adJEkvTHH39o8uTJZlmEs40ZM0bt27c3Gx83bpzmzp2r8PBwlStXToULF1ZMTIzOnz+v/fv3a8uWLdq8ebPTG93kBq+99pp++OEHs0YOM2bM0NWrVzVw4ED5+flpxYoVVhvxvPfee9lQae4UHByswMBAswZsZ86cUXh4uLp37678+fOnjlerVk1BQUEOOXZOP39zi4CAAItN1C3ZtWuXnn32WbPxBx98ME0zlqJFi6bZ/tRTT2nixIk6c+ZMmvE///xTLVq00NChQ1WgQAFt2rRJEyZMsHjsMWPGWGyijFvCwsK0b9++NGOJiYl6+OGH9fjjj6tQoUKpTeAqVKigwoULS7rVWLF+/frasmVLmn1Pnz6tKlWqqHv37mrRooVKlCghT09PXb16VUePHtXu3bv1559/6vz585Kkpk2bmtW0Zs0avf766/Lz81OTJk1Uu3Zt3XvvvSpYsKD8/PwUHR2tvXv36quvvrJ4myy9jgkLC7M496uvvlKhQoVUtWrV1A/J8PHxUZ06ddK72xzu/Pnzatq0qcX/B+Tt7a3x48crISEhw7zz9p/R7ZyZkznz+bJ79+4Ws8+///5b999/v1544QWVKFFCe/fu1fjx4y3+vh42bJhCQ0PNxosVK6annnrK7P9HxMXFqWnTpho+fLhq1KihM2fO6OOPP9bhw4fN1qhTp466du1qsXYAAAAAAAAAAAAAAAAAAAAAyBEMO3l7exuSMvVVvXp1s/Wio6ON6tWrZ3rNlC9LVqxYYXh6emZp3QEDBpitm5SUZDRq1CjLNUsyVq9ebbH21atX21xPVrz99tuZrr1mzZrGjRs3MjzGunXrLO5fsmRJIyEhwe6aIyIiLK7XtGnTTNwD5saMGWNx/WnTplndx9L8sLAwi3ObNm3qkMfOihUrLK4fFhZm8zniLM4692JiYoyKFSuazfX09DR27tyZOu+zzz6zuGavXr0s1jtgwACL800mk101f/vtt1bvE2s/94iIiKze3YZhWP+52/OV3jlkz2PcXtevXzfq1KmTqZotnZdbt241fH19M30/eHh4GCtXrsyw7kOHDmW4VokSJYykpCSb7gdn3scpunXrlun75auvvrK6bmZ/L8+YMSPT9ZQsWdKIjIx06P0DAADyLkdnGdOmTbM4d8yYMRaPHx4ebtcxrb0XsfT6197XYvbWbu390p15xsGDBw03Nzebb2NAQECmXkNmxcCBAzP9OLB2uw0jcznC7RyVczj7fadhGMbnn3+e6fvu4YcfTndtZ+YZmcnZsuP+vFObNm0y/VjMSr3OPn/t+dk6O5fL6n3lKFnJfufPn293ZpXy1bBhw3RzCmfeN5n5XWfrc5AjDR482Ob7887H5d69e43AwMBM/560dn+0bds20+t5eHhYzE9Onz5t8+PI0vnk7Ize2jli71d6vzuclZMZhnOfL7dv3254eXllau2yZcsa169ft7p2dHR0pnNmb29vY9euXenWDgAAAAAAAAAAAAAAAAAAAACu5qZs4uHhoc8++8xsPCAgQIsXL1aVKlUcfsxWrVrp+++/T/3kZUdxc3PTjBkzzD5R3JqKFSuqffv2Dq3BUd544w0NHTrU7v3Kly+vRYsW2XTfWvq5S9LTTz8tDw8Pu4+dV7344os2z33ttdfUqlUrJ1aTNc4691544QWLn2I+cuRI1apVK/X7YcOGqUWLFmbzfvrpJ82YMcPm440dO9bm29CnTx89/vjjNq+N//H399fixYtVu3Zth6xXt25dzZ49W/7+/nbv6+Xlpe+++04tW7bMcO69996rhg0bpjunf//+cnPLtqfaDP3444823bY7jR49Wk899ZTD6+nXr5/Gjx9v935FihTRokWLVLhwYYfXBAAAcDtrWYa9PvnkE1WvXt2muffcc4+GDBlicZvJZMpyLc5SqVIlPf300zbN9fX11bRp05xckblvvvlGPXv2zPbj5iXDhg3TiBEj7N6vTZs2+v77751QUd4yaNAglxw3N5y/+J+HHnpIkyZNsvs5oWbNmlq4cGGOyilyoieeeCLTz7fVqlXT77//rpCQEAdXlXljxoyxmJ8UL148x/4/i+zizJzMmc+XtWvX1i+//CIvLy+71g4LC9PKlSvTzUwDAgK0atUqlSxZ0q61vb299dtvv6lmzZp27QcAAAAAAAAAAAAAAAAAAAAA2c3uqypKlSpl90FKlSqlxYsXq1mzZha3lyhRQtu2bdOLL74oPz8/u9auVq2aJkyYYHV7nz59tG3bNjVt2tSudb28vNS5c2eFh4db3F6mTBmtWbMmwwZRTZo00apVq1SoUCG7jp9dTCaTvvzyS3355ZfKnz9/hvPd3NzUr18/bd++XcWLF89w/smTJ/Xbb7+Zjfv5+Wnw4MGZqtmanHzBqS2GDRumKVOmpHuhg4eHh8aMGaNx48ZlY2WZ4+hzb/78+frmm2/M5t93330aOXJkmjGTyaRp06YpMDDQbP6wYcMUERFhUy0PPPCAli5dmuFjfciQIXY1cMorHHnOFS5cWJs2bdIbb7xh8edmbw2dO3fWtm3b1KRJE5vXql27ttavX6/+/fvbvI+154gUAwcOtHmt7ODr66tFixbp9ddfl7e3d4bzixQpohkzZuitt95yWk3Dhw/X3Llzbb6Aq0OHDtq1a5fNjQoAAAAk52QZ9ggKCtKqVasyXKtBgwZatWqV1dfEwcHBWa7FmT7++GMNGDAg3TmhoaFasmSJwxqt2sPT01Nz587VN998o2LFitm1b7FixfTiiy+qatWqTqou93j33Xf1/fffq0iRIhnO9fb21ogRI7RgwQL5+PhkQ3W5W48ePRyel9kqp5+/SGvIkCFatGiR7rnnngznurm5aciQIVq9erUKFCiQqePl9tzVHnXr1tU777yT6f2bN2+uPXv2qHPnznY1tXJzc1OrVq30wgsvmG0rUaKE3T+DfPny6cMPP9Qbb7xhdc6kSZNsegzlVc7OyZz5fNmxY0etXbs2zYcPpKdHjx7auHGjypQpk+Hce+65R5s2bVL37t1tWrtWrVpau3atHnzwQZvmAwAAAAAAAAAAAAAAAAAAAIAredi7w+HDh/XPP/9o3bp12rFjhw4ePKgTJ07o0qVLunHjhry8vJQvXz6VLl1a1apV04MPPqjOnTtn+Om6vr6++uijj/TGG29ozpw5WrdunXbt2qWLFy/q6tWr8vT0VFBQkEqXLq1KlSqpQYMGatmypU0XAlSpUkVr1qzR7t279euvv2rTpk06fPiwrly5ohs3bsjf318FChRQhQoVVLVqVTVt2lRNmzbNsNlHhQoVtGvXLk2dOlVz5szR/v37FR0drcKFC6tWrVp65JFH1KtXr1xxIcrQoUPVp08fzZ07V4sWLdLBgwd1/vx5JSQkKH/+/CpfvryaNWumfv36qVy5cjav++WXXyopKclsvH///pn+ZO/Dhw9bHO/Xr1+m1stJnnjiCbVu3Vpff/21Fi9erJMnTyo+Pl7FihVT69at9dRTT+Wq5iKOOvf+++8/PfHEE2bre3l56fvvv5eHh/mvslKlSumzzz4za4QTHR2tRx99VH/99Zfc3d0zvA1NmzbV/v37NWXKFP3yyy86evSorl27ptDQUDVp0kSDBw9Wo0aN7LxncpfsOuc8PT01duxYvfrqq5o7d67Wrl2rHTt26MKFC7p69arc3NxUoEABlStXTg0aNFDbtm3TbeRVqVIlrV27Vlu3btVvv/2m9evX69ixY7py5YqSk5MVEhKiUqVK6YEHHlCnTp3UvHlzu2vu1auXnnvuOcXGxppte+CBB1S+fHm713Q2Hx8fvffeexoyZIjmzp2rpUuX6tixYzp//rw8PDxUpEgRVa1aVQ899JC6d+9uV+OrzOrZs6c6dOigX375RQsXLtTu3bsVGRmp2NhY5c+fX6VLl1aTJk3Up08fmy8gAwAAuJ2zsgx7FCxYUH/++ad+/vlnff/999q5c6cuX76sggULqmrVqurbt6/69u0rd3d3HTt2zOIaObWJcwoPDw9Nnz5djzzyiL7++mtt2rRJFy9eVHBwsMqUKaOuXbvqiSeeUMGCBXX8+HGX1Tlo0CANHDhQ8+fP16pVq7Rlyxb9999/unLligzDUEBAgIoXL66KFSuqdu3aatGihe677z67Gmbkdf3791eXLl1SX8Pv379fkZGRunnzpgoXLqyyZcuqffv2evjhhxUWFpbhetevX9fZs2fNxvNC1mOvr7/+Wl26dNH06dO1bds2RUZG6saNG04/bm45f/E/7du3V8uWLTV//nzNnz9fO3bsSH28FCpUSKVKlVLbtm318MMPq1KlSjat+e+//5qNNW3aNFMNC3OzESNGqFmzZvrmm2+0adMmnT17VtevX7d5/5IlS+r333/XkSNH9PPPP2vDhg06ePCgLl++rOvXr8vPz08hISEqV66cqlSposaNG6t58+YqWLCgxfW+/fZbvffee1qzZo22b9+uvXv3KiIiQpGRkYqJiZHJZJK/v7+KFSumypUrq2XLlurRo4fV9W6vc+fOnZoyZYoWLlyogwcP6urVq0pISLDr/srNnJ2TOfr58nYNGjTQ9u3btWTJEv3+++/avHmzzp07p+joaBUsWFDFixdXixYt1KNHD9WtW9eutYsXL6558+Zp+/btmjdvnlatWqUzZ87o4sWLCgwMVGhoqBo0aKDOnTurQ4cOvEYCAAAAAAAAAAAAAAAAAAAAkGuYDMMwXF0EYI9XXnlFH374YZqxdu3aaenSpS6qCLndwIED9f3335uNr169Ws2aNcv+gnKYL7/8Us8880yaserVq2v79u3y9PR0UVUAAABA3nTlyhWVLl1a0dHRaca9vLx0+fJl+fv7u6gywHkWL16sjh07phkrWrSoDhw4kOlG3QDsc+DAAVWtWjXNmL+/v/bu3auyZcu6qCoAAAAAAAAAAAAAAAAAAAAAAADH4WNmkeusXLkyzfdBQUGaMmWKi6oB8r47zzkPDw9Nnz6dJksAAACAHd5//31dvHgx3TnR0dF65JFHzJosSVLTpk1psoQ86873nZL09ddf02QJyEaWzsNx48bRZAkAAAAAAAAAAAAAAAAAAAAAAOQZHq4uALDHhQsXtGfPnjRjH3/8sUqUKOGiioC8LSkpSatXr04z9vrrr6tWrVouqggAAADInYYPH66RI0eqcePGatKkiapUqaICBQrIMAydP39e27Zt06xZsxQZGWlx/5EjR2ZzxUD2WbFiRZrv+/Xrp06dOrmoGuDudOd52LRpUz3zzDMuqgYAAAAAAAAAAAAAAAAAAAAAAMDxaLSEXGXlypUyDCP1+3bt2umxxx5zYUVA3rZ161ZFRUWlfl+9enWNGjXKhRUBAAAAuVdiYqJWr15t1sw0I48//riaNm3qpKoA1zp79qwOHDiQ+n3RokX12WefubAi4O6TkJCgtWvXpn7v7++vqVOnymQyubAqAAAAAAAAAAAAAAAAAAAAAAAAx3JzdQGAPW7/ZPWgoCBNmTLFhdUAed/t55yHh4emT58uT09PF1YEAAAA3F169+6tr7/+2tVlAE6zcuXKNN9//fXXCgkJcVE1wN1p06ZNun79eur348aNU9myZV1YEQAAAAAAAAAAAAAAAAAAAAAAgOPRaAm5ytSpU2UYhgzD0NWrV1WiRAlXl5QnrFmzRiaTKUtfb775pqtvBpxg9OjRqedcQkKCatWq5eqSAAAAgFzJ19fXrvmlS5fWjz/+qNmzZ8vd3d1JVeVsAwcOzPJ71ePHj7v6ZiAD/fv3T33faRiGOnXq5OqSbEKWgrykSZMmac7DYcOGubokmxw/fjzL5+HAgQNdfTMAAAAAAAAAAAAAAAAAAAAAAEA28XB1AQAAAAAAAHndhQsXtHz5cq1du1a7du1SRESELl26pLi4OOXLl09BQUEqW7as6tSpo9atW6t169Zyc6M/NgAAAAAAAAAAAAAAAAAAAAAAAAAAjkCjpbtUcnKyzp49q4CAAJlMJleXAxeLiYnJ8hrx8fGKjo52QDXZ7/PPP9fnn39ucVtuvU2wzjAMXbt2TcWKFXPYheuGYSghIUHJyckOWQ8AAAB5j7u7ux588EE9+OCDNs2/efOmkyvKHm5ubvL09CR7yIXIjtJ3t2cpQE5w7dq1LK+RkJBg8Tx0dH5kGIYSExOVlJSU5bUAAACAvITsKHcjPwJwt+JvjwAAAIDs4+7uLg8PD7KHXIjsCMDdiuwIAAAAyD6Z/dsjk2EYhpNqQg52+vRplSxZ0tVlAIDLnDp1SiVKlMjSGjdu3FBUVJSuXbvGhXIAAACAFe7u7goICFBQUJD8/PxcXQ5sRHYEAFnPjwzD0JUrV3T16lXFx8c7sDIAAAAg7yA7yr3IjwDc7fjbIwAAACB7eHt7Kzg4WCEhITTsyUXIjgDc7ciOAAAAgOyRmb898nByTcihAgICJN16wxYYGOjiagAg+0RHR6tkyZKpvwcz69q1azp9+rQ8PT0VHBwsf39/ubm58T9vAAAAgP9nGIaSk5MVExOj6OhoXb16VSVKlMjya3FkD7IjAHczR+VHkZGRunLligICAlSoUCE+aRUAAAC4DdlR7kd+BOBuxd8eAQAAANnDMAwlJiYqKipKkZGRunnzpkJDQ11dFmxEdgTgbkV2BAAAAGSPrPztEY2W7lIpb6gCAwMJrADclbISLN24cUOnT59WYGCgihUrRkgFAAAApMPf31+FChXS2bNndfr0aYWFhdncIRyuQ3YEAFnLj6KionTlyhUVLVpUwcHBjisKAAAAyGPIjnIv8iMAdzv+9ggAAADIHgEBAbpy5YrOnTsnX19fBQUFubok2IDsCMDdjuwIAAAAyB6Z+dsjt2yqDQCAPCMqKkqenp6EVQAAAICNTCaTihUrJk9PT0VFRbm6HAAAnC46Olp+fn40WQIAAABsQHYEALjb8LdHAAAAgH1CQkLk5+en6OhoV5cCAIDTkR0BAAAA9rH3b49otAQAgB0Mw9C1a9cUGBhIWAUAAADYwWQyKTAwUNeuXZNhGK4uBwAAp0lOTlZMTIzy5cvn6lIAAACAXIPsCABwt+BvjwAAAIDMyZcvn27cuKHk5GRXlwIAgNOQHQEAAACZY8/fHtFoCQAAOyQkJCgpKUn+/v6uLgUAAADIdfz8/JSUlKSEhARXlwIAgNMkJibKMAz5+Pi4uhQAAAAgVyE7AgDcDfjbIwAAACBzfHx8lJycrMTERFeXAgCA05AdAQAAAJln698e0WgJAAA7pHwChpsbT6EAAACAvdzd3SWJT5YDAORp5EcAAABA5pAdAQDuBmRHAAAAQOakvIYmOwIA5GVkRwAAAEDm2fq3R7zaBgAgE0wmk6tLAAAAAHIdXkcDAO4mPO8BAAAA9uE1NADgbsLzHgAAAGAfXkMDAO4mPO8BAAAA9rP1dTSNlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQJ5FoyUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJBn0WgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADkWTRaAgAAucLNmzdVvnx5mUwmzZs3z9Xl5FrTp0+XyWSSyWTS8ePHXV1Ojvfmm2+m3l9AipTHxJtvvpntx+7QoYNMJpPGjBmT7ccGAAAAgJyO/MgxyI/sQ34ES8iPAAAAACDnITtyDLIj+5AdwRKyIwAAAADIeciOHIPsyD5kR7CE7AgAnI9GSwAAIFf47LPPdOTIEVWtWlXdu3c32z5w4ECZTCYNHDjQ4v4pbzAtffn6+qpkyZLq1KmTZsyYocTExHRrKV26tMV1PD09VbBgQTVs2FCvv/56rgyEMrofHSElNCtdurTTjoHs1axZM6cHOCnhYbNmzZx2jJwi5XfKmjVrzLaNGjVKkvThhx/q9OnT2VwZAAAAAORs5EfZg/wImUF+5FjkRwAAAABgP7Kj7EF2hMwgO3IssiMAAAAAsB/ZUfYgO0JmkB05FtkRANBoCQ5gGIaSEpJdXQYAIA+7du2aJkyYIEl64403HN6lOS4uTqdPn9aiRYs0YMAA1a9fX5GRkXavk5iYqEuXLmnz5s0aP368KleurBkzZji0VlhH13PcDRo0aKDWrVvrxo0beu+991xdDgAANiE7AgBkB/Ij2IL8CHcD8iMAQG5DdgQAyA5kR7AF2RHuBmRHAIDchuwIAJAdyI5gC7Ij3A3IjgDcLWi0hEwzDEMnD1zSvPHb9f2IDbp2Oc7VJQEA8qhJkybp0qVLKlWqlHr27JmlterUqaN9+/al+dq0aZOmTJmiGjVqSJJ27typHj16ZLhWsWLF0qyzdetWzZo1Sw8++KAkKTY2Vo899pg2bdqUpZodaeDAgTIMQ4Zh0JkbyKVeeuklSdJ3332n//77z8XVAABgHdkRACA7kR85DvkRkPuRHwEAcgOyIwBAdiI7chyyIyD3IzsCAOQGZEcAgOxEduQ4ZEdA7kd2BOBuQKMl2O32sGrhxD06f/KaYq8lKO56gqtLAwDkQUlJSfriiy8kSX369JGbW9Zevvj7+6tq1appvho0aKAnnnhCmzZtUsWKFSVJ69evzzBo8vT0TLNO3bp11adPHy1ZskQvvvhiav3vvvtulmoGgNu1atVKhQsX1s2bN/X111+7uhwAgA2+/PJLlS5dWj4+Pqpfv762bt1qde6UKVPUuHFjhYSEKCQkRK1atTKbbxiGRo8eraJFi8rX11etWrXSv//+m2bO5cuX1bdvXwUGBio4OFiPP/64rl+/7pTbdyeyIwBAdiM/AoC0yI8AADkZ2REAILuRHQFAWmRHAICcjOwIAJDdyI4AIC2yIwB3AxotwWYpYdVP727Twol7dOHktf/f4Nq6AAB524oVK3Tq1ClJUt++fZ16LF9fXz399NOp32/bti3Ta40dO1be3t6SpNWrVys5OTnL9QGAJLm7u6tXr16SpGnTpskweEEOADnZTz/9pBdffFFjxozRzp07VaNGDbVt21bnz5+3OH/NmjXq06ePVq9erU2bNqlkyZJq06aNzpw5kzrn/fff1+eff67Jkydry5Yt8vf3V9u2bRUX979Pbuvbt68OHDigFStWaNGiRfrrr780ePBgp97WlOzo53HbyY4AANmK/AgA0iI/AgDkRHdeJEd2BADILmRHAJAW2REAICciOwIAuArZEQCkRXYE4G5AoyXY5NTfl1PDqkunr0uSeF4EAGSHuXPnSpLKly+vatWqOf14ZcqUSf13fHx8ptfx8/NT2bJlJUk3btzQpUuXslzbnX777Td16dJFJUqUkLe3twICAlS2bFk1btxYo0aN0tatW832mT59ukwmk0wmk44fP+7wmhzFntu2Zs0amUwmhYeHp46VKVMm9XamfK1Zs8bsOKdPn9bTTz+tsmXLysfHR8WKFdNDDz2klStXOu22HT9+PLWm6dOnS7oVzHbq1EmhoaHy9vZWmTJl9NRTT+n06dPprrV//3698847atu2bep9lS9fPpUvX14DBgzQ5s2b093/zTffTK1FkuLi4vTBBx/ovvvuU0BAgAICAlSvXj198cUXSkxMdMjtd5YrV65o2rRpevTRR1W5cmXly5dPXl5eCg0NVdu2bfXNN9/o5s2bNq01a9YsNWvWTCEhIcqXL5+qVq2qMWPG6OrVq1b3uXHjhgICAmQymWwK1zdt2pR633/11Ve23sxU3bt3lySdPHlSGzZssHt/AED2+fjjjzVo0CCFh4ercuXKmjx5svz8/DR16lSL82fOnKmhQ4eqZs2aqlixor799lslJydr1apVkm79UdGnn36qN954Q507d1b16tU1Y8YMnT17Vr///rsk6e+//9ayZcv07bffqn79+mrUqJEmTpyoOXPm6OzZs065nbdnRyl/6ER2BADILuRH1pEf3UJ+RH4kkR8BAOBKt2dH50+QHQEAshfZkXVkR7eQHZEdSWRHAAC4EtkRAMCVyI6sIzu6heyI7EgiOwKAvMbD1QUgd1j302FdOXfD1WUAAO5Cq1evliQ1aNAgW4534sSJ1H+XKlUqS2t5eXml/tvT0zNLa90uKSlJffr00c8//5xm/ObNm7p+/boiIiK0fv16LV26VNu3b3fYcbNDdt62devWqWPHjoqOjk4d+++//7Rw4UItXLhQb775ZpbWt9Xrr7+u8ePHpxk7fvy4Jk+erF9++UVr165VpUqVzPZbs2aNmjdvbjZ+8+ZNHTlyREeOHNGMGTP02muvady4cRnWERkZqXbt2mn37t1pxrdt26Zt27Zp+fLl+v333+XmljN7tdaqVSvN+ZsiMjJSy5cv1/LlyzV58mQtWbJEoaGhFtdITEzUI488Yvb4O3DggA4cOKAff/zRapjp5+enLl266Mcff9T8+fMVExMjf39/q/XOnDlTkuTh4aGHH37Y1puZqm7dunJ3d1dSUpKWLl2qRo0a2b0GAMD5bt68qR07duj1119PHXNzc1OrVq20adMmm9a4ceOGEhISlD9/fklSRESEzp07p1atWqXOCQoKUv369bVp0yb17t1bmzZtUnBwsOrUqZM6p1WrVnJzc9OWLVvUtWtXs+PEx8en+R+2t79GsgXZEQDAlciPzJEfkR9J5Ed3Ij8iPwIAuA7ZEQDAlciOzJEdkR1JZEd3IjsiOwIAuA7ZEQDAlciOzJEdkR1JZEd3IjsiOwKQt+TMZxvkOI17VVDhsIBb35hcWwsAwFxSsqFNRy9p/u4z2nT0kpKS88ZHOJw+fTq1e3XdunWdfrzY2Fh9+eWXkiR/f/80F6/bKzExUf/++6+kWxe+BwcHO6JESdKkSZNS31A3atRI06dP17p167Rz506tWLFCH330kVq3bi13d3eHHTO7ZOa21a1bV/v27dM777yTOvbHH39o3759ab5ufwydPHkyNaxyc3PTk08+qZUrV2rbtm367rvvVL58eb355ptavHixU2/vlClTNH78eDVt2lSzZs3S9u3btXLlSvXv31+SdOHCBT322GMW901MTJS/v78efvhhTZ48WWvWrNHOnTu1bNkyffTRRwoLC5MkjR8/XtOmTcuwlm7duungwYN69tlntWLFCu3YsUOzZs1KDcsWLlyoKVOmOOiWO15SUpLq16+vsWPHatGiRdq2bZs2bNigH3/8Ue3atZMk7dq1S71797a6xssvv5z6+Lv33nv13Xffadu2bVq5cqWGDBmi48ePq1evXlb3T+kIHhMTo/nz51udl5iYmHqctm3bqmDBgnbfXj8/P1WpUkWStHbtWrv3BwBkj4sXLyopKUlFihRJM16kSBGdO3fOpjWGDx+uYsWKpb42TdkvvTXPnTunwoULp9nu4eGh/PnzWz3uuHHjFBQUlPpVsmRJm+pLkSY7AgDkSORHjkF+5HrkR+RHmUV+BADI67788kuVLl1aPj4+ql+/vsVPEb7dp59+qnvvvVe+vr4qWbKkXnjhBcXFxTmlNrIjAMj5yI4cg+zI9ciOyI4yi+wIAJDXkR0BALKC7MgxyI5cj+yI7CizyI4AII8xcFeKiooyJBlRUVE275OcnGyc2H/RmPveVuOLIavMvk4duuzEigHAMTLz++92sbGxxsGDB43Y2FgHV5Z5S/edNRq8t9IIG74o9avBeyuNpfvOurq0LPvpp58MSYYkY926dVlaK2WdOnXqGPv27UvztWXLFuPbb781atWqZUgyTCaT8eWXX1pdKywszJBkhIWFWZ3z0UcfpR7z8ccfz1Ltd2rcuLEhyahfv76RkJBgdd6lS5fMxqZNm5ZaV0REhEPrcoTsum09evRInTtr1iyz7dHR0UaNGjVS5zjyZXNERESadQcNGmQkJyebzXviiSdS5+zcudNs+4ULF4wrV65YPU58fLzRunXr1MdqYmKi2ZwxY8akHsPT09NYvXq12ZxLly4ZRYoUMSQZ1atXt+u2ZqfDhw+nu33q1Kmpt3XlypVm2/fu3Wu4ubkZkoz77rvPuHbtmtmc77//Ps3PbsyYMWm2JyQkGIULFzYkGR06dLBay9KlS9N9/NkqPDzckGT4+flZfAwBQE6UE19PO9OZM2cMScbGjRvTjL/yyitGvXr1Mtx/3LhxRkhIiLFnz57UsQ0bNhiSjLNn077e79mzp/Hwww8bhmEY7777rlGhQgWz9QoVKmR89dVXFo8VFxdnREVFpX6dOnUq09nR7LFbLGZH509E27wWALgS+VHuQn5kGfkR+ZFhkB/difyI/AhAzpcTX0vnFnPmzDG8vLyMqVOnGgcOHDAGDRpkBAcHG5GRkRbnz5w50/D29jZmzpxpREREGH/88YdRtGhR44UXXrD5mPa+d0rJjqa8uJbsCECuRnaUu5AdWUZ2RHZkGGRHdyI7IjsCkPPlxNfSuUVuyo5mjNxAdgQgVyM7yl3IjiwjOyI7MgyyozuRHZEdAcgdbH097SbARiaTSaWqFFCP1+qo07AaKlQqbbfwP6bs16m/L7uoOgC4Oy3b/5+e+nGn/otK++kQ56Li9NSPO7Vs/38uqswxTp8+nfrvwoULO2TN7du3q1q1amm+6tevryeeeEK7du1SmzZttGrVKg0dOtTutWNjY7V//3698sorGj58eGrdI0aMcEjtKc6dOydJuv/+++Xh4WF1Xv78+R163OyQHbft3Llz+u233yRJHTt2VJ8+fczmBAQE6Jtvvsn0MWxVtGhRTZw4USaTyWzbyy+/nPrvdevWmW0vWLBguh3nvby89MEHH0iSTpw4od27d6dby7Bhw9SsWTOz8fz58ys8PFyStG/fPkVFRaW7jquUL18+3e3h4eGqWbOmJOn333832z558mQlJydLkr755hvly5fPbE7//v314IMPWj2Gh4dHaufw5cuX69KlSxbnzZw5U5KUL18+de7cOd2605Pye/HGjRup5w4AIGcpWLCg3N3dFRkZmWY8MjJSoaGh6e774Ycfavz48Vq+fLmqV6+eOp6yX3prhoaG6vz582m2JyYm6vLly1aP6+3trcDAwDRf9krJjnqNrKsqjYvdtsHupQAADkR+ZD/yo5yN/Oh/yI/sQ35EfgQAednHH3+sQYMGKTw8XJUrV9bkyZPl5+enqVOnWpy/ceNGPfDAA3rkkUdUunRptWnTRn369NHWrVudVmNKdlS9eQlJko+/5/9vcNohAQA2IDuyH9lRzkZ29D9kR/YhOyI7AoC8LDdlR22eqHLre7f/f31DdgQALkV2ZD+yo5yN7Oh/yI7sQ3ZEdgQgb6HREuyWEl71fP1Ww6WQUD+ZTFLc9QQt+Gy31v10WIk3k1xdJgC4nGEYunEz0Wlf1+ISNGbBARmWjv3//31zwUFdi0twah2GYakCx7hw4ULqv0NCQpx2nNutXr1aEydO1KlTpzKce+LECZlMptQvPz8/VatWTR9++KESExPVrFkzrV69WmXLlnVojUWLFpUkLVy4UBcvXnTo2q6WHbdt9erVSkq69VolJYixpF69eqpSpYpTakjRo0cPeXt7W9x27733poYmx44dy3Ct+Ph4nTx5UgcPHtT+/fu1f//+NOfnnj170t2/b9++VrfVrl1b0q3faxERERnW4mqGYejcuXM6fPhw6n2xf/9+FS9eXJLl+2LlypWSpGrVqqXeXksee+yxdI+dcj8mJCRo7ty5ZttjY2NTA7MuXbrIz8/Ppttkye3BLYEVAORMXl5eql27tlatWpU6lpycrFWrVqlhw4ZW93v//fc1duxYLVu2THXq1EmzrUyZMgoNDU2zZnR0tLZs2ZK6ZsOGDXX16lXt2LEjdc6ff/6p5ORk1a9f31E3zyqTyaTGvSsoOPTW85xvPk/5BXrJN8DT6ccGgNzE2dlRTsmPnJkdSeRH1pAfZQ35kWXkR+RHAICc6ebNm9qxY4datWqVOubm5qZWrVpp06ZNFve5//77tWPHjtSL444dO6YlS5aoffv2Vo8THx+v6OjoNF+ZEVTo1nNbSFE/dRpWQ4VLBZAdAYAFd0t2xN8ekR05GtnR/5AdZR7ZEQAgL8lt2VFw4VvPbUayoXZDqpIdAYAVZEeOQXZkGdlR1pAdWUZ2RHYEADmJ9XaLQAZSGi71qZxf8TcStWXBMe1fe0Z7V5/Wqb8vq1V4ZRUOC3R1mQDgMrEJSao8+g+XHd+QdC46TtXeXO7U4xx8u638vJzzkuLy5cup/3ZUYNW0aVOtWbMmzVhCQoLOnDmjJUuWaMyYMfrtt9+0ZcsWrVq1ShUrVszUcYKCgvT000+rcuXKDqg6rQEDBuivv/7SkSNHVK5cOXXr1k2tW7dW48aNVaJECYcfLztlx23bt29f6r/r1q2b7tx69erpwIEDDjmuJRk9vkJCQnT9+nVdu3bN4vaYmBh9/vnnmjNnjg4cOJAaxFmSUQCYXi23ByPWaskJFi9erEmTJumvv/5Kt84774v4+Hj9+++/kmx7TKSnfv36uueee3T06FHNnDlTTz31VJrtCxYs0PXr1yWlHxLa4vbfizExMVlaCwDgPC+++KIGDBigOnXqqF69evr0008VExOT+j/O+vfvr+LFi2vcuHGSpAkTJmj06NGaNWuWSpcunfo/JfLly6d8+fLJZDLp+eef1zvvvKPy5curTJkyGjVqlIoVK6YuXbpIkipVqqR27dpp0KBBmjx5shISEvTMM8+od+/eKlasWLbcbnd3NzXpXUELPt2t2OsJ6vlaHeUL8cmWYwNAbuHq7EjKnvzImdmRRH5kDflR1pAf2V8L+dH/kB8BALLbxYsXlZSUpCJFiqQZL1KkiA4dOmRxn0ceeUQXL15Uo0aNZBiGEhMT9eSTT6b7icfjxo3TW2+9leV6gwr5SpKiL8apVJUCKlk5v5ITDbl78nmBAHC7uyU7kvjbI2vIjjKH7CgtsiP7kB0BAPKi3JYdeft5ytvfQ/ExiQoq5Kcer9UhOwIAC8iOHIPsyDKyo6whO7K/FrKj/yE7AoDsQcqALDOZTPLx91TTPveq4zM15BfopSvnbuiXCTu0fUmEkpOSXV0iACCX8vH534XYsbGxTjuOp6enSpcuraFDh2rNmjXy9PTU2bNn9cQTT6S7X7FixbRv377Urz///FMTJkxQaGiooqKi9PDDD+unn35yeL2PPfaYRowYIQ8PD0VFRWnatGl65JFHVLJkSZUrV04vvfSSTZ2kc6LsuG23B6GFCxdOd+6d/1PR0TLqCu3mduvluqUg6vjx46pWrZpGjBihvXv3phtWSRmfQ+nVklKHtVpczTAMPfHEE+rYsaMWL16cYah2531x5cqV1C7qjnhMpARRGzdu1PHjx9NsmzlzZupxbv90oMy4/XZ4evJJPQCQU/Xq1UsffvihRo8erZo1a2r37t1atmxZ6nPKyZMn9d9//6XOnzRpkm7evKkePXqoaNGiqV8ffvhh6pxXX31Vw4YN0+DBg1W3bl1dv35dy5YtS/P6eebMmapYsaJatmyp9u3bq1GjRvrmm2+y74ZLKlkxv+6pVUgypI2/HHHqpwoBAO5e5EeWkR+RH0nkR7cjPyI/AgCktWbNGr333nv66quvtHPnTv36669avHixxo4da3Wf119/XVFRUalftnzSsiUpjZZirsYrMSFJJpOJC+UAAE5DdmQZ2RHZkUR2dDuyI7IjAEBarsyOJCmoYEqj7liyIwCAU5EdWUZ2RHYkkR3djuyI7AhA3uO8jxDGXSmsagH1GV1fa2Yd0tGdF7RlQYSO77ukVuGVFVw4/RdkAJDX+Hq66+DbbZ22/taIyxo4bVuG86aH11W9MvkznJdZvp7uTlu7UKFCqf++fPmyAgICnHasFFWqVFH79u01f/58bdiwQYcPH1aFChUszvX09FTVqlXTjDVv3lyPPvqo6tWrpzNnzmjw4MFq2LChSpUq5dA63333XQ0ePFgzZ87UqlWrtHnzZt24cUNHjx7Vxx9/rIkTJ+rzzz/Xk08+6dDjZofsvG0mk8kBFbtGv379FBERIZPJpPDwcPXu3VuVKlVSoUKF5OXlJZPJpOTkZLm73zpH83Jjg6lTp+q7776TJNWsWVPPP/+86tevr+LFi8vPzy/1Pujfv79++OGHdO8LRzwm+vbtq7fffluGYWj27Nl6/fXXJd36PfbHH7c+NaJXr17y8Mja27Hbw9fg4OAsrQUAcK5nnnlGzzzzjMVtd35qzZ3/s8MSk8mkt99+W2+//bbVOfnz59esWbPsKdMp7u9eTsf3X9KZw1d1dOcFlaud/v8cAoC7ibOzIyln5EfOzI4k8qP0kB+RH5Ef/Q/5EfkRAORlBQsWlLu7uyIjI9OMR0ZGKjQ01OI+o0aNUr9+/VL/gL9atWqKiYnR4MGDNXLkyDR/zJzC29tb3t7eWa7XJ5+nPH3clRCXpOiLccpf1D/LawJAXnS3ZEcSf3tEduR4ZEe2ITv6H7IjsiMAyMtyW3Yk3WrUff7ENUVdcF7DCwDI7ciOHIPsyDqyI7IjsqP/ITsiOwKQ99DSGQ7nk89TbQdVVavwyvLycVdkRLR+emer9v91Jk+/UAKAO5lMJvl5eTjtq3H5Qioa5CNrb61MkooG+ahx+UJOrcOZb/hvD6yuXLnitOPcqWLFiqn/3rdvn937FytWTJMnT5YkRUdHa+TIkQ6r7XZhYWEaMWKEVq1apatXr2rDhg167rnn5OPjo4SEBA0dOlS7du1yyrGdzZm3LSQkJPXfd/5PwztltN1VDh06pPXr10uSRowYoe+++06tW7dWiRIl5O3tnXpe3h5o5GVTpkyRJJUrV04bN27UgAEDVLFiRQUEBKSGVZL1++P2sMcRj4kKFSqoTp06kpSmwcW8efN08+ZNSf/rHp4Vt/9eLFmyZJbXAwDAGQIL+uq+tmGSpA3z/lXCzZz3KSMA4CrOzo5ySn7k7D8WIT9KH/kR+ZFEfiSRH0nkRwCQl3l5eal27dpatWpV6lhycrJWrVqlhg0bWtznxo0bZhfEZdcfQZtMJgUW9JUkRXOxHABYdbdkR/ztkWVkR1lHdpQ+sqO0yI7IjgAgL8tt2ZEksiMAsAHZkWOQHaWP7IjsSCI7ksiOJLIjAHkPjZbgFCaTSffWD1Xv0fVV/N5gJd5M1tpZ/2jxl3sVExXv6vIAIE9wdzNpTKfKkmQWWqV8P6ZTZbm75d7Ox9WqVUv99+HDh7PtuImJiRb/bY+OHTuqUaNGkm69YT148KBDarPG09NT999/vz799NPUN8iGYWjevHlOPW52sPW22Rqe3v642rYt/e76GW13lQMHDqT+u1evXlbnbd++PTvKcbmU++Ohhx6Sr6+vxTmGYWjnzp0Wt/n4+Kh8+fKSHPeYSAmk9u/fr71790qSZs6cKUm65557VL9+fZvWSU/K78UyZcrIz88vy+sBAOAs97UppYD8Prp+JV47l51wdTkAcFchP3Ie8qOchfzIHPlRWuRH5EcAkNe9+OKLmjJlir7//nv9/fffeuqppxQTE6Pw8HBJtz49NeWTTCWpU6dOmjRpkubMmaOIiAitWLFCo0aNUqdOndL8MbCzBBW69XwcxcVyAOBSZEfOQ3aUs5AdmSM7SovsiOwIAPK63JYdBaZkRxfJjgDAlciOnIfsKGchOzJHdpQW2RHZEYC8h0ZLcKqA/D7q/FwtPdCjnNw93HRi/yXNeXurju467+rSACBPaFe1qCY9ep9Cg3zSjIcG+WjSo/epXdWiLqrMMerUqSMfn1u3LTuDg9vf5Gel2+6oUaMk3frUj3fffTfLddmqZcuWqf++ePFith03O6R321IeK5IUH2+9sWPz5s1T/yff999/b3Xetm3btH///syW6lS3B6kxMTFW56V0qM/rUu6P9O6L+fPn67///rO6vVWrVpJufRpAel3np06dalNNvXv3Tn2czZw5U6dPn9a6deskOaYruPS/31WOCL8AAHAmDy93PdCjnCRp1/KTiuaPoAAgW5EfOQf5Uc5FfnQL+VFa5EfkRwCQ1/Xq1UsffvihRo8erZo1a2r37t1atmyZihQpIkk6efJkmue5N954Qy+99JLeeOMNVa5cWY8//rjatm2rr7/+OlvqDSrIxXIAkFOQHTkH2VHORXZ0C9lRWmRHZEcAkNfluuyIJt0AkGOQHTkH2VHORXZ0C9lRWmRHZEcA8h4aLcHpTG4m1WxVSj1fr6MCJfIpLiZBy77er1XTDyo+NnPdVgEA/9OualGtH95Cswc10Ge9a2r2oAZaP7xFrg+rJMnLyyv1jdjWrVuz5ZiLFy/W2rVrJUkFCxZUvXr1Mr1WmzZtVKdOHUnSTz/9pCNHjjikxh9//DHdjuXLly9P/XeZMmUccswUb775pkwmk0wmk6ZPn+7QtaWs3baiRf/3mD969KjVNYoWLarOnTtLkhYsWKC5c+eazbl+/bqGDBlic93ZLaWLtSSrP4dJkyZp/vz52VRR+gYOHJj6uFmzZo3D10+5PxYuXKjLly+bbT969KiefvrpdNcYMmRIanf5wYMHWwy/Zs6cqSVLlthUU2hoqFq0aCFJmj17tmbNmiXDMCQ5JrA6duxYamjbpk2bLK8HAICzla1VSCUqhigpMVkb5jnmdTEAwHbkR45FfpQ+8qOcgfwoLfIj8iMAuBs888wzOnHihOLj47Vly5Y0f/C6Zs2aNK8JPDw8NGbMGB05ckSxsbE6efKkvvzySwUHB2dLrYH/f7FcNBfLAUCOQHbkWGRH6SM7yhnIjtIiOyI7AoC7QW7KjlIaLV2/FKfkpORsOSYAwDqyI8ciO0of2VHOQHaUFtkR2RGAvMfD1QXg7lGgeD71fK2Oti6K0K4/TujQ5nM6c/iqWg6spOIVQlxdHgDkau5uJjW8p4Cry3CKzp07a+3atdq6dauuXbumgICALK0XExNj1u05ISFBZ86c0eLFi/Xtt9+mjo8bN04eHll7uTRy5Eh17dpVSUlJGjdunL777rssrSdJ/fr108svv6xu3brp/vvv1z333CMfHx9FRkZqxYoVmjRpkiQpX758DutAnF2ycttq1aolHx8fxcXFadSoUfL09FRYWJjc3G71Fi1evLh8fW/9j7ePPvpIK1as0LVr1/TII49o7dq16tGjhwIDA7V3716NHz9ehw8fVp06ddJ0is8patWqpapVq2r//v36+uuvdeXKFfXr109FixbV6dOn9eOPP2revHl64IEHtGHDBleX63T9+/fXK6+8orNnz6phw4YaPny4qlatqri4OP3555/69NNPFR8fr/vuu087d+60uEaNGjX09NNP64svvtD27dtVp04dDR8+XNWqVVNUVJR+/vlnffPNN3Y9Jvr27asVK1bo1KlTGjdunKRbn3hQoUKFLN/mVatWSbr1P7M7duyY5fUAAHA2k8mkRg+X10/vbNOx3Rd06uBllayc39VlAcBdhfzIduRHORv5kW3Ij9IiPyI/AgDkLCkXy0VfpNESAOQUZEe2IzvK2ciObEN2lBbZEdkRACBn8Q/ylruHm5ISk3XtcnxqlgQAcB2yI9uRHeVsZEe2ITtKi+yI7AhAHmTgrhQVFWVIMqKiouze98befcbx/gOMG3v3Zfr4Z/69YswYucH4Ysgq44snVxnr5/1rJN5MyvR6AGCrrPz+MwzDiI2NNQ4ePGjExsY6uDJYc/HiRcPb29uQZHz//feZXkeSzV+enp7GhAkTrK4VFhZmSDLCwsIyPG5ycrJRpUqV1HVPnDiR6dtgz20JCgoyli5darbvtGnTUudERETYfexXX301df8FCxZk+bbcKSu37c767vxavXp1mrmrV682AgICrM4fPXq0MWbMmNTvHSUiIiJ1zWnTpqU7N+WxNmDAALNtu3btMkJCQqzWX61aNePs2bOp348ZM8ZsDVtv3+rVq63ej7Z4+OGHU/ffu3ev3ftn5ObNm0abNm2s3he+vr7G3LlzjQEDBqR77t68edPo1q2b1XXKlCljHD16NN379HbR0dGGr69vmjU++eQTh9zmZs2aGZKMDh06OGQ9AMguvJ7OPbL63smav376x/hiyCpj5phNRmIiWRCAnIn8KPchP8rcbSE/Ij8iPyI/AoCchtfSuUtW3jtFXbhhfDFklTHp6dVGclKyE6oDAOchO8p9yI4yd1vIjsiOyI7IjgAgp+G1dO6S1fdOM8dsMr4Ysso4efCSgysDAOciO8p9yI4yd1vIjsiOyI7IjgAgJ7L19fStNomAHaLmz9eNLVsUtWBBptcoVi5Yvd6op0oPFJUMafeKk/p5/DZdPH3dgZUCAPKCAgUKqFu3bpKkWbNmOeUY7u7uyp8/v+rVq6fhw4fr4MGDevXVVx2ytslk0ogRIyTd6kA+YcKELK+5f/9+TZgwQZ06dVLlypVVoEABubu7Kzg4WA0aNNCYMWP0zz//qF27dlk+1p02bdokSapQoYI6dOjg8PWzetvGjx+vKVOmqHHjxsqfP7/c3d2tHqtZs2Y6cOCAnnrqKYWFhcnLy0tFihRRhw4dtGzZMr311lsOv32OVLNmTe3evVtPPvmkwsLC5Onpmfo4/vDDD7V161YVLVrU1WVKkjZv3ixJatmypapVq+bw9T09PbV48WJ9/vnnqlOnjvz8/OTr66ty5crpySef1M6dO9WzZ0+b1vnll1/0ww8/qHHjxgoKCpKfn58qVaqkESNGaMeOHSpbtqzNdQUEBKhTp06p37u7u6t3796Zuo23O3PmjP766y9J0tChQ7O8HgAA2alexzLyDfDUlXM3tG/1aVeXAwDII8iPzJEfkR9J5Ee3Iz8CACBnyRfiLTc3k5ISk3X9aryrywEA5HFkR+bIjsiOJLKj25EdAQCQ8wQV8pUkRV2IdXElAIC8juzIHNkR2ZFEdnQ7siMAyHtMhmEYri4C2S86OlpBQUGKiopSYGBghvMTzpxR4pWrSrx0UWdfelnJ16/LPX9+lZzyjWRIHiHB8ixePFO1ROy5oNU/HlLstQS5eZhU/6GyqtmqlNzcTJlaDwDSY+/vvzvFxcUpIiJCZcqUkY+PjxMqhCVbtmxRgwYN5O7urqNHjyosLMzVJd2V4uLiFBwcrPj4eH3//ffq37+/q0tCLnD8+HGVKVNGkrR27Vo1adLExRXlfu+8845GjRqlSpUq6cCBAzKZeN0MIPfg9XTukdX3Tuk5uOGsVv9wSF4+7ur7dkP5BXo5dH0AyCryo9yJ/ChnID9CZpAfOR75EYDcitfSuUtW3zv9MGqToi/EqssLtVT83hAnVAgAzkF2lDuRHeUMZEfIDLIjxyM7ApBb8Vo6d8nqe6d1Px3W3tWnVat1Kd3fvZwTKgQA5yA7yp3IjnIGsiNkBtmR45EdAcjNbH097ZaNNSEXO9KylY736KHTQ55U8vXrkqSky5d1vHsPHe/RQ0datsr02mVqFFLvUfVVunpBJSca2vTrUf3+8U5FX6TrOADglvr166tbt25KSkrSuHHjXF3OXWvLli2Kj4/XPffco759+7q6HOQSa9eulSQ1bdqUsMoBrl+/rk8//VSSNGbMGMIqAECuVKlhURUOC9DNuCRt+v2oq8sBAOQR5Ec5A/kRMoP8yLHIjwAAuUVQIV9JUhR/HwQAyAZkRzkD2REyg+zIsciOAAC5RSDZEQAgG5Ed5QxkR8gMsiPHIjsCcLeg0RJsUuyD9yV3d6vb/erXV8zWrTKSkzO1vl+gl9o/VU3N+1WUp7e7/jsSpTnvbNXfG/+TYRiZLRsAkIe899578vDw0LRp03T69GlXl3NX+uuvvyRJI0aMkHs6rwuA26U8bkaPHu3iSvKGL7/8UpcuXVK9evX08MMPu7ocAAAyxeRmUuNeFSRJhzb+p8iIaBdXBADIK8iPXI/8CJlBfuRY5EcAgNwiqOD/Xyx3gYvlAADZg+zI9ciOkBlkR45FdgQAyC1Sm3STHQEAsgnZkeuRHSEzyI4ci+wIwN3CZNDF5q4UHR2toKAgRUVFKTAw0KZ9Yg8c0PHuPdKd41GkiAIffFCBHTvKp0rlTHUqjLoQq1XTD+q/o1GSpDI1Cqr5oxXlG+Bl91oAcKfM/P67XVxcnCIiIlSmTBn5+Pg4oUKk54cfftDRo0fVpk0b3X///a4uBwCy3VdffaXz58+rW7duql69uqvLAQC78Xo698jKe6fYfft1/sMPVfjll+VbrarVeaumH9ShzedUOCxAPYbXkcmNT7wAkDOQH+Vu5EcA7nbkRwByM15L5y5Zfe+0a8VJbfzliMrVLqy2g6xnSACQ05Ad5W5kRwDudmRHAHIzXkvnLll973TlXIxmvblFnt7uGvRpk0xdnwYArkB2lLuRHQG425EdAcjtbH097ZGNNSGvMJkkw0j9b5HRoxS3/4CurVihxMhIXZ4+XZenT5dXWJgCO3RQYMcO8i5b1ublgwr5qstL92nX8hPaujBCEXsu6tyxLWrRr5JKVy/oxBsGAMjp+vXr5+oSHOLMmTO6cuWK3fv5+/urTJkyTqgI9oiIiFBMTIzd+4WEhKh48eJOqAh3k6FDh7q6BAAAMhQ1f75ubNmiqAUL0m201KDrPTq6+4LOn7imQ5v/U6X7i2VjlQCAvIr8iPwoJyA/giuRHwEAcougQr6SpOiLsS6uBABwNyE7IjvKCciO4EpkRwCA3CKwgK9kkhLikxR3PUG+AV6uLgkAcBcgOyI7ygnIjuBKZEcA7hY0WoLNPAoUkHvBgvIMDVVwjx66Om+eEs6dU0CLFsr/yCNKHjNaMevWKWrxYl1fvUY3T5zQxa++0sWvvpJ3pUoK6tBege3by7NYxhfNubmZVLtdaZWqUkArpx3U5bMxWvzVXlVuXEwPdC8nLx8eugCA3GvkyJH6/vvv7d6vadOmWrNmjeMLgl3Cw8O1du1au/cbMGCApk+f7viCAAAAcoCEM2eUeOWqZJKiFy2SJEUvXqygLp0lQ/IICZbnHf/zzj/IW3Xbl9HGX49o029HVbZWYXn7kvkAACCRH+V25EcAAAAZS2m0FHWBRksAANiL7Ch3IzsCAADImLunm/IFe+v6lXhFXYil0RIAAHYgO8rdyI4AAHA+rlyCzTxDQ1Xuz1UyeXrKZDIpuNfDMhIS5OZ1K6xy8/ZWQKtWCmjVSknXY3T9z1WKWrxYMRs2Kv7vv3X+7791/sOP5Fu7tgI7tFdgu3byyJ8/3WMWKhmgnq/X0eb5x7Rn5SkdXHdWpw9dUauBlVX0nqDsuNkAAAAAAADIwJGWrczGki5f1vHuPVK/r3Tob7M51VuU0MENZ3U18oa2LYpQo57lnVonAAAAAAAAcoaAAj6SpPgbiYqLSZCPv6eLKwIAAAAAAEBOEljQN7XRUmhZriEDAAAAAACOYTIMw3B1Ech+0dHRCgoKUlRUlAIDA516rMQrV3Ttj+WKXrxYN7Zvl1Iecu7u8m/YUIEdOiigdSu558uX7jqn/7miVdMP6vqVeJlM0n1tw1S3Yxm5e7g5tX4AeUtWf//FxcUpIiJCZcqUkY+PjxMqBAAAAPIuXk/nHva+d4pauFBnX3tdSkoy3+jurmLjxymoUyeL+544cEmLJu6Rm5tJvd6op/zF/LNaPgBkCfkRAAAA4Bq8ls5dHPG3R1NfXa/Y6Jvq+XodFQ5z7t8vAYCjkB0BAAAArsFr6dzFEdnRnzP+1t8b/1O9TmVUt0MZB1cIAM5BdgQAAAC4jq2vp+lQk0N8+eWXKl26tHx8fFS/fn1t3brVpv3mzJkjk8mkLl26OLfALPAICVFI714K+2GGyq3+U4VffVU+VapISUmKWb9e/73+uv69/wGdfvY5Rf+xXMlxcRbXKXFviHqPqqd764fKMKQdy05o3oTtunw2JptvEQAAAAAAAG4X1KmTSs/9yeK20nN/stpkSZLCqhRQ6eoFlZxsaN3cw6IvPAAAAAAAwN0hqKCvJCnqQqyLKwEAAAAAAEBOE1iI7AgAAAAAADgejZZygJ9++kkvvviixowZo507d6pGjRpq27atzp8/n+5+x48f18svv6zGjRtnU6VZ5xkaqgKPhavML/NUdukSFRz2jLzKlpVx86auLV+uM889p38faKSzw1/T9XXrZCQmptnf289TrcIrq+2gqvL299DFU9c1971t2rPqlIxkLsIDAAAAAABwOZMpzbc3IyIy3KVRz/Jy93DT6UNXFLH7orMqAwAAAAAAQA4SxMVyAAAAAAAAsCIlO4omOwIAAAAAAA5Eo6Uc4OOPP9agQYMUHh6uypUra/LkyfLz89PUqVOt7pOUlKS+ffvqrbfeUtmyZbOxWsfxLlNGhZ5+WmUXL1KZ335VgScel0fRokqOiVHU/Pk6NWiw/m3SVOfefls3duyQkZycum+52oXVZ1R9laqcX0mJyVr/879a8PluXbsc58JbBAAAAAAAcPfyKFBA7gULyqdKFRUZM1pu+fJJks5/8KESr1xJd9+gQr6q2bqkJGn9vH+VeDPJ6fUCAAAAAADAtQJTLpa7yMVyAAAAAAAASIsm3QAAAAAAwBlotORiN2/e1I4dO9SqVavUMTc3N7Vq1UqbNm2yut/bb7+twoUL6/HHH7fpOPHx8YqOjk7zlVOYTCb5VKqkwi+/rHKrVips5o8KeaSP3PPnV9Lly7oya7ZO9H1UR1q2UuQHHyju4EEZhiH/YG91HFZDTftUkIenm04fuqI5Y7fq8NZzMgzD1TcLAAAAAADgruIZGqpyf65S6Z/nKn+fPrpn5Qp5lCypxMhInXnhRRmJienuX7tdaeUL8da1S3HateJkNlUNAAAAAAAAV0m5WC6ai+UAAAAAAABwh8CCt7KjG9E3lcCHtgEAAAAAAAeh0ZKLXbx4UUlJSSpSpEia8SJFiujcuXMW91m/fr2+++47TZkyxebjjBs3TkFBQalfJUuWzFLdzmJyc5Nf7doKHT1a5f9aq5JTpiioSxe5+fsr8b//dPm7qYro1l3HOnTUhS+/VMKJE6ratIR6vVFPhUsH6mZsolZMPajl3x1QXEyCq28OAAAAAADAXcXNy0smk0mS5BEcrJJffiGTn59ubN6s8x98mO6+nt7uur97OUnSzmUndO1ynNPrBQAAAAAAgOukNFqKotESAAAAAAAA7uDj7ylvPw9JNOoGAAAAAACOQ6OlXObatWvq16+fpkyZooIFC9q83+uvv66oqKjUr1OnTjmxSscweXgoX+NGKjZ+nMpvWK/in32mgDZtZPLy0s1jx3Rx4hc62u5BRXTvoaTFP+mhfsVVr1MZmdxMOrL9vOa8vUUnD15y9c0AAAAAAAC4a/lUqKBi48dJki5//72iFixId3652oVVrHywEhOStWHekewoEQAAAAAAAC4SWPBWo6XrV+OVlJDs4moAAAAAAACQ06TkRzTqBgAAAAAAjkKjJRcrWLCg3N3dFRkZmWY8MjJSoaGhZvOPHj2q48ePq1OnTvLw8JCHh4dmzJihBQsWyMPDQ0ePHrV4HG9vbwUGBqb5yk3cfHwU2LaNSnz+mcpv3KCi48fJv3Fjyd1dcQcO6Pz77+tYq5YqPGeM2tS8rKCC3oqJuqmFn+/RX3MOK+FmktW1DcPgj7UAAAAAAACcJLBNGxV4cogk6b9RoxV74IDVuSaTSY17lZfJJB3deV6n/7mSXWUCAAAAAAAgm/kGeMrD210ypOhLXCwHAAAAAACAtIIK3Wq0FH2R7AgAAAAAADgGjZZczMvLS7Vr19aqVatSx5KTk7Vq1So1bNjQbH7FihW1b98+7d69O/XroYceUvPmzbV7926VLFkyO8t3Cfd8+RTcpYtKTflG5df9pSKjR8m3dm3JMHRj2zYlfPyGai4YptLGv5KkfWtOa+672xR5PFqSFLtvv04MGKgbe/fp5IFLmjd+u74fsUHXLse58mYBAAAAAADkWYWGDZN/0yYy4uN1etgwJV6+bHVuwRIBqtqkuCRp3U+HlZxEg2wAAAAAAIC8yGQyKajgrYvloi5wsRwAAAAAAADSCixEdgQAAAAAABzLw9UFQHrxxRc1YMAA1alTR/Xq1dOnn36qmJgYhYeHS5L69++v4sWLa9y4cfLx8VHVqlXT7B8cHCxJZuN3A4/8+ZX/kUeU/5FHlHD2rKKXLlXU4sWKP/i3yq79VEEhlfR3pX66Gin9MmGb6rQLU/E983XqcLQ2TInQlYQLkkmSIcVdT1BAfh9X3yQAAAAAAIA8x+TuruIffKDjPR/WzRMndOb5F1Tqu29l8vS0OL/eQ2V1eHukLp+N0f6/zqh687zfXBwAAAAAAOBuFFTIV5fOXFf0RS6WAwAAAAAAQFpB/99oKZpGSwAAAAAAwEHcXF0ApF69eunDDz/U6NGjVbNmTe3evVvLli1TkSJFJEknT57Uf//95+Iqcz7PYsVU4PHHVfbXX1V2yWIVHDpURQNvqP7Wd1X4/E4Zhknblp7UglP3aU+NZ3Tlpt+tHQ3X1g0AAAAAAHA3cA8MVIkvv5Cbn59ubN2qyPc/sDrXx99TDTrfI0naujBCsdduZleZAAAAAAAAyEaB/3+xXBQXywEAAAAAAOAOQQX/PzuiSTcAAAAAAHAQGi3lEM8884xOnDih+Ph4bdmyRfXr10/dtmbNGk2fPt3qvtOnT9fvv//u/CJzEe+yZVXo2WEqu2ypys/5XkX/Wy+f2IuSpGR371uTTDz8AQAAAAAAspN3uXIq9v4ESdKVH37Q1XQyrcqNiqlgyXyKv5GozQuOZVOFAAAAAAAAyE5B/99oKZpGSwAAAAAAALhDSpPua5filJxsuLgaAAAAAACQF9BpBnmayWSSb9UqinjgGcX5FnR1OQAAAAAAAHe9gFatVHDoUEnSudFjFLtvv8V5bm4mNe5VQZJ0cP1ZnT8RnW01Av/H3n2HN1X3bQC/T9Kk6d50AB3svWkBZSOogMoWUYaCgKCv4kQUUVRQeAQFBGUjGwQEZBfKnmW3ymwZBUoXSWfaJuf9ozRS2nQmPUl7f64rz5Pk/M7vfE+I6cmdnG+IiIiIiIiIqHw4e6oAAGo2WiIiIiIiIiIioqc4uNpCZiNArxORkpghdTlEREREREREVAGw0RJVCp3eagHPKjY5N0S9tMUQEREREREREVVynuPHwbFzZ4iZmbj77rvIjo8vcJxfLVfUbu0NiMDhdVchivxlOiIiIiIiIiKiisTFyw4AoInPgKhn9kNERERERERERP+RyQQ4e+TkR+p4NuomIiIiIiIiorJjoyWqFKrXd0fvge5oemEunJLvSF0OEREREREREVGlJshk8PvxByiDgpD94AFi3v8AYlZWgWPb9a0FG1s5HtzU4Oqp2HKulIiIiIiIiIiIzMnRXQVBJkCXrUeqWit1OUREREREREREZGEMjbrj2GiJiIiIiIiIiMqOjZao0lB4eqKKPA7PZu5Ah0aPINM9/nKWyF/DIyKyBpmZmahduzYEQcDGjRulLsfiTZkyBYIgQBAEqUuxanwc/xMdHW14LJYtW1au2xZFEY0bN4YgCFi6dGm5bpuIiIjMR+7khGrz5kLm4IC0M2cQO/2HAsc5utmi1QsBAIBjm64jMyO7PMskIiIrwvyoZJh7mAYfx/8wPyIiIqLSkMtlcHK3BQCoebIcERGZEbOjkmHmYRp8HP/D7IiIiIhKy/lxoyVmR0REZE7MjkqGmYdp8HH8D7MjIiIqT2y0RJWGwscHtfaHImjDejQe3xevjK8P6HWAIEAh18HOSSF1iUREVIiff/4Z169fR6NGjdCvX798y4cPHw5BEDB8+PDyL66S6tSpEwRBwJQpU8y2jdzAqFOnTmbbRlkEBgaaPcCpLM/tJwOx6OjoPMsEQcCkSZMAAJMmTUJqaqoEFRIREZE52NaoAb8ZPwIAklatwqM/NxU4rllXfzh72SFNnYkzO6LLsUIiIrImzI8sD/Mj5kemxPyIiIio4nJ5fLKcJp4nyxERkfkwO7I8zI6YHZkSsyMiIqKKy8XzcXbERktERGRGzI4sD7MjZkemxOyIiIiexEZLVKnIlEpDZ0/fpoFoUjsLACBmpCM75q6UpRERUSGSk5Pxww8/AAC++OILdmkmqoQGDhyIunXr4v79+5g3b57U5RAREZEJOXXpAs93xwMAHkyZgvSLF/ONkStkaD+gNgDgQugdPIpNK9caiYjI8jE/IiLmR0RERNbL2cseAKDmyXJERGQmzI6IiNkRERGR9cpt0q1mk24iIjITZkdExOyIiKhyYaMlqtTavt8DTuIjZCsccWBWGES9XuqSiIioAPPnz0dCQgL8/f0xYMAAqcshIgnIZDJ88MEHAICZM2ciIyND4oqIiIjIlDzHjoVjt64Qs7Jw9933kB0Xl29MYBNPBDTygF4n4vD6axBFUYJKiYjIUjE/IiLmR0RERNbLxTPnZDkNGy0REZGZMDsiImZHRERE1svZ67/siN8XIiIic2B2RETMjoiIKhc2WqJKzUYhR7eRTQFRj3uKGrg0Z5PUJRER0VN0Oh3mzp0LABg8eDBkMh6+EFVWAwYMgEKhQFxcHNauXSt1OURERMU2b948BAYGQqVSISQkBKdOnTI6NiIiAv369UNgYCAEQcDs2bPzjcld9vRl3LhxhjGdOnXKt3zMmDHm2D2TEGQy+E2fDmWNGsiOjcXd/3sfYmZmvnHPDqgNmVzA7YgE3LqUIEGlRERkiZgfEVEu5kdERETWydlLBQBQs9ESERGZAbMjIsrF7IiIiMg6OXvkZEeZGTpkpGZJXA0REVU0zI6IKBezIyKiyoNHfFTp+bWuifrV0wAAJy/IkXz9tsQVERHRk/bu3Ys7d+4AAIYMGSJxNUQkJXd3dzz//PMAgMWLF0tcDRERUfGsW7cOEyZMwFdffYWzZ8+iadOm6NGjBx4+fFjg+LS0NNSoUQPTp0+Hj49PgWNOnz6N+/fvGy579+4FgHy/ojNq1Kg843788UfT7pyJyR0dUW3eXMgcHZF+9iweTJuWb4yrtz2adq0OADi84Rp0WfryLpOIiCwQ8yMiysX8iIiIyDq5eNkBANTxbLRERESmx+yIiHIxOyIiIrJONko5HFxtAbBRNxERmR6zIyLKxeyIiKjyYKMlIgDtP3oBDno1MpUuOPDDLoiiKHVJRET02Pr16wEAtWvXRuPGjcs837Zt29C/f39Uq1YNtra28PDwQNu2bTF9+nSkpKQYXW/ZsmUQBAGCICA6OhparRazZ89GmzZt4OnpCUEQMGXKFMP4zMxMbNu2DePHj0fr1q3h5uYGhUIBDw8PhISEYMqUKYiPjy9WzVqtFr///jt69uyJqlWrwtbWFg4ODmjYsCFGjhyJ3bt3l/pvV0ZGBubOnYuuXbvCx8cHSqUSVapUQbdu3bB48WJkZ2eXat7yotPpsGzZMvTo0cNQv4uLC2rXro2uXbvi+++/R2RkpNH17969i3HjxqFGjRpQqVTw8/PDSy+9hH379pXjXpTN/fv38euvv6J///6oXbs2HBwcYGtri6pVq+Lll1/GunXroNcX3YBAp9Ph119/RUhICJydneHi4oIWLVpg5syZ0Gq1Rte7desWZDIZBEHApEmTitzOmjVrDP8t7dixo0T7CgD9+vUDABw9etQQZhMREVmyn376CaNGjcKIESPQoEEDLFiwAPb29liyZEmB41u3bo0ZM2bg1Vdfha2tbYFjvLy84OPjY7hs374dNWvWRMeOHfOMs7e3zzPO2dnZ5PtnarZBQfCbOQMQBDxasxZJGzbkG9PqxUDYuyihiUvH+VA2zCYiIuZHAPOjwjA/Yn5EREREls/ZM6fRkjY1G9q0LImrISKiiobZEbOjwjA7YnZERERE1iG3UbeGjZaIiMjEmB0xOyoMsyNmR0REVDHZSF0AkSVQqBTo/EY9bF8ZgzvyWvh34VbUf/tlqcsiIiIABw4cAAC0adOmTPNkZGTgtddew+bNm/Pcn5iYiBMnTuDEiROYM2cO/v77bzRr1qzQueLj49GnTx+cP3/e6Ji3334by5cvz3d/YmIiTp06hVOnTmHu3Ln466+/8Mwzzxid5/z58+jbty+ioqLy3J+ZmYnIyEhERkZi8eLFiIqKQmBgYKF1P+3ChQt4+eWXcevWrTz3x8XFITQ0FKGhofjtt9+wbds2eHt7l2ju8pCSkoIXX3wRhw8fznN/VlYWNBoNrl+/jv379+Ps2bPYuHFjvvUPHz6MXr16QaPRGO67f/8+tm3bhm3btuUJIC2VTqdDtWrVCgyk7t27h61bt2Lr1q1YvHgxNm3aBEdHxwLnMfZYnjt3DufOncOaNWuwaNGiAtcNCAjAM888gyNHjmDNmjX47rvvCq151apVAHIaRHTv3r04u5lH7muBKIrYtWsXRo0aVeI5iIiIyktmZibCw8MxceJEw30ymQzdunXD8ePHTbaNlStXYsKECRAEIc+yVatWYeXKlfDx8UHv3r3x5Zdfwt7e3iTbNSenTp3g9d67iPv5F8R+MxWq2rVh98QxulJlg3Z9a2Hf0kic2RGNuiE+cHRTSVcwERFJjvkR8yNjmB8xP2J+REREZB2UKhvYOSmQnpwFTXwGvPwVUpdEREQVCLMjZkfGMDtidsTsiIiIyHo4e9nh3rVHULPREhERmRizI2ZHxjA7YnbE7IiIqOKSSV0AkaUIaF8ftb2TAQDHjmcj7fZ9iSsiIiqGA9OAgz8WvOzgjznLrdjdu3cRHR0NAGjdunWZ5ho2bJghrGratClWrFiB06dPY/fu3RgxYgQEQcC9e/fQtWtXxMTEFDrXW2+9hQsXLmDo0KH4+++/ER4ejs2bNyMkJMQwJjs7GzVq1MCHH36IdevW4fjx4zh9+jQ2btyIMWPGQKlUIiEhAX369MHDhw8L3M4///yD9u3bG8KqPn36YN26dTh9+jROnDiBFStW4PXXX4eDg0OJH4/r16+jY8eOuHXrFpydnTFx4kRs3rwZZ86cwe7duzFu3DjY2Njg9OnTePnll5GVZXm/HDtlyhRDwNKrVy+sWbMGR48eRXh4OHbu3Invv/8e7dq1y9dwAABu375tCKtkMhnGjBmDffv24fTp01i8eDFq166NKVOm4O+//y7v3SqR3I7wXbp0wYwZM7Br1y6Eh4cjLCwMS5YsQdu2bQEAe/fuxbhx44zO8/rrrxsey+DgYKxZswZnzpzB33//jQEDBuDs2bMYPXq00fWHDBkCAIiKisKxY8eMjktISMCePXsAAAMHDoSNTcn7vtapUweurq4AgIMHD5Z4fSIiovIUHx8PnU6X78M/b29vPHjwwCTb2LJlCx49eoThw4fnuf+1117DypUrceDAAUycOBF//PEHXn/9daPzaLVaaDSaPBcpeYweDafnnoOYlYW7776HrKeOmesEe8OnhguyM/U4tumGRFUSEVkJ5kfFxvwoL+ZHzI+exPyIiIjI8s2bNw+BgYFQqVQICQnBqVOnjI7t1KmT4Zdcn7z07NmzHCvOy8XLDgB4shwRUXljdlRszI7yYnbE7OhJzI6IiIgsn9VnR5452ZGG2RERUflidlRszI7yYnbE7OhJzI6IiMjiiFQpqdVqEYCoVqulLsWiaFMyxMUjN4tzR4eKf4/5TdTr9VKXREQmVtbXv/T0dDEyMlJMT083cWWlFPaDKH7lnPP/xbnfyqxbt04EIAIQDx8+XOp5tm/fbpina9euolarzTfm999/N4wZOHBgvuVLly41LAcgLlq0qNBtXr9+vdC/IxcvXhQdHR1FAOIXX3xR4JgWLVqIAESZTCauWbPG6Fzx8fFiWlpanvu++uorQ60FadeunQhAbN68uRgXF1fgmJ07d4oymUwEIP7+++9Gty+V6tWriwDE/v37FzouISEh3339+/c3PD6rV6/Ot1yj0YhNmzbN829uifR6vXjt2rVCx0yePFkEIAqCIF69ejXf8if/+3jxxRfFrKysfGO+/vrrPI/F0qVL8yyPj48XFQqFCEAcN26c0Vrmz59vmOPYsWPF28kCdO7cWQQg1qtXr9RzEBGRNCzueNrMYmJiCvy79/HHH4vBwcFFrh8QECDOmjWr0DHdu3cXe/XqVeRcoaGhIgDx+vXrBS5/8vjxyYuU2VF2cop4vWdPMbJuPTFq0Kui7qnj+Ie3NOLcMaHi3NGhYszVJGmKJKIKifmRdWF+xPyoMMyPmB8xPyIisi4WdyxtRdauXSsqlUpxyZIlYkREhDhq1CjR1dVVjI2NLXB8QkKCeP/+fcPl8uXLolwuz/c3vDCm/u7RniWXxbmjQ8UzO6NMMh8RkbkwO7IuzI6YHRWG2RGzI2ZHRETWxeKOpa1IRciOrp56IM4dHSr+OeOMSeYjIjIXZkfWhdkRs6PCMDtidsTsiIjI+hT3eFoGIjJQOtiiw4AaAIAosRZurNwlcUVEZNVEEchMNe+l7Tigw8fAge+A/d/m3Lf/25zbHT7OWW7uGh53JjaHu3fvGq5XqVKl1PPMmzcPAKBQKLB06VIolcp8Y0aNGoVu3boBADZt2oT79+8bna9Lly546623Ct1mzZo1C+xInatx48YYOXIkAGDLli35lu/Zswdnz54FALz33nt49dVXjc7l4eEBOzu7Qut50uHDhw3dm5cvXw5PT88Cxz3//PPo378/AGDZsmXFnr+8PHjwAADQvn37Qse5u7vnWy+3S3yvXr0wePDgfOs4OTnh999/N1Gl5iMIAmrVqlXomMmTJ8PT0xOiKGLr1q35lv/6668AAFtbWyxcuLDAbt1ffPEFGjVqZHQbHh4eeP755wEA69evR3Z2doHjVq1aBQCoUaOGoWt5aeS+HkRFRRm6oxMREVkiT09PyOVyxMbG5rk/NjYWPj4+ZZ7/1q1b2Ldvn+G4sjC5v2Jz/fr1ApdPnDgRarXacLlz506Z6ysruaMDqs+bB5mzM9LPn0fst9/lWe7l74QGz/oBAA6tuwq9nscFRGRlyiM7soT8yMzv25gfMT8qDPMj5kfMj4iIqLL46aefMGrUKIwYMQINGjTAggULYG9vjyVLlhQ43t3dHT4+PobL3r17YW9vjwEDBpRz5f9x9sw5XtXEpUtWAxGRRaks2RG/e2QUsyPzY3bE7IjZERERVRbMjoiIKiBmRybB7IjZUWGYHTE7YnZERFRx5f9rRFTJ1ereBFf3/4moR244vD8Z1XokQFXFQ+qyiMgaZaUB3/uV3/YOzci5GLttLp/fA5QOZpk6Li7OcN3Nza1Uc2RnZ+PgwYMAgO7du6N69epGx44aNQr79u1DdnY2wsLCCgwyAGDIkCElriMpKQmJiYnIyMgwvMF2dXUFAERGRiIrKwsKhcIwfvv27Ybr77//fom3V5jc0KJu3bpo3LhxoWM7dOiA9evX4/Tp08jOzi4wzJCKr68vbt++jXXr1mHkyJGwt7cv1noHDhyATqcDAIwYMcLouODgYDRs2BAREREmqbc86PV6PHjwAMnJycjKyjLcX61aNcTHx+PChQt5xut0OoSFhQHI+e/Dz6/g1yyZTIZhw4bh448/NrrtIUOGYNu2bYiLi8PevXvxwgsv5Fl++/ZtHD16FADw2muvlWb3DHJDSK1Wi0ePHpX69YGIiMjclEolWrZsidDQULzyyisAcv5eh4aGYvz48WWef+nSpahSpQp69uxZ5Njz588DyDmGKoitrS1sbW3LXJOpKQMCUPV/M3Hn7dF4tH49VA0bwm3QQMPyNi/VwI3wh0i4m4LII/fQqENVCaslIiqh8s6OAGnyIzNmRwDzo1zMjwrG/Cg/5kdEREQVT2ZmJsLDwzFx4kTDfTKZDN26dcPx48eLNcfixYvx6quvwsHB+LG7VquFVqs13NZoNKUvugAuXjlf0FfH82Q5IiIAlSc7Avjdo2JidmR6zI7yY3ZERERU8VS07ChVnYnsTB1slHKTzk9EZHWYHZkEs6MczI4KxuwoP2ZHRERUUVjOEQeRBeny2QtY+fE+pNl64tDUTeg+Z5TUJRERVUqJiYmG66V9Q3rz5k2kpaUBAEJCQgod++Tyy5cvGx3XpEmTYm370qVLmDVrFnbu3GnoYl0QvV6PpKSkPN3Pz507BwDw9/dHQEBAsbZXXGfOnAEAXLlypdDu5U/KyspCYmJimTq0m9qwYcMwdepUHDt2DEFBQRgwYAC6du2KZ599Fl5eXkbXu3TpkuF669atC91GcHCwxQdWoihi1apVWLx4MU6ePIn0dONfPo+Pj89z+8aNG4b/PorzWBTmpZdegpOTE5KTk7Fq1ap8gdWaNWsMYW1pQt8nPfl6kJqaysCKiIgs2oQJEzBs2DC0atUKwcHBmD17NlJTUw0fnA0dOhRVq1bFtGnTAOR8uSkyMtJwPSYmBufPn4ejo2OeXwTR6/VYunQphg0blu9DxRs3bmD16tV48cUX4eHhgYsXL+KDDz5Ahw4din0sa0kc27eH1/vvI27WLDz49lvY1q4N+xbNAQB2TkoE966Bw+uu4sRfN1CrZRWoHBRFzEhERBUJ8yPmR4VhfpSD+RHzIyIiqtji4+Oh0+ng7e2d535vb2/8+++/Ra5/6tQpXL58GYsXLy503LRp0/D111+XqdbCuHg+brQUx0ZLRERkOsyOmB0VhtlRDmZHzI6IiKhiqyjZka2DDZR2NshMz4Y6Ph0efo5m2xYREVUezI6YHRWG2VEOZkfMjoiIKiI2WiIqgMrVHs/28kPoTg2uZwai9sb9COrfReqyiMjaKOxzumaXhyOzcrqAy5WALhPo8DHw7Afls21F8boxl4ZKpTJcT09Ph5OTU4nneDL0Kips8fHxKXC9pxXnzfHixYsxZswYZGdnF6NK5AsZcoMFX1/fYq1fEg8fPizVernBhqX48ssvERMTg6VLl+Lhw4eYN28e5s2bBwBo2LAh+vXrh3feeSffB4MleU48va6lycjIQN++fbFz585ijX/6eWbKx8LOzg59+vTBihUrsGXLFqSlpeXp1r5q1SoAQIsWLVCvXr1i1WvMk/vxZEd9IiIiSzRo0CDExcVh8uTJePDgAZo1a4Zdu3YZ/rbevn0bMpnMMP7evXto3ry54fbMmTMxc+ZMdOzY0fCLHgCwb98+3L59G2+++Wa+bSqVSuzbt8/Q1Kl69ero168fvvjiC/PtqJl5vD0KGZGRSN69G3f/7z0EbfwTCu+c45dGHfwQcTgGifdScXLrTXQcXFfiaomIiqk8syNAuvzIjNkRwPwIYH5UGOZHzI8A5kdERERFWbx4MRo3blzkl5cnTpyICRMmGG5rNJpCf5W5pJy9chotpSRpocvSQ66QFbEGEVEFV1myI4DfPTKC2ZH5MTtidgQwOyIiIiqKpWRHgiDAxcsOcbeToYljoyUiImZHpsHsiNlRYZgdMTsCmB0REVVUbLREZES9l1vhyqGNuJvqjkPbY1G1yyMo3V2lLouIrIkgAEoH82/n4I85YVXnSUDHT3JuH/guJ7zq+In5t29GT3Z3TkxMLFVg9aTidsEuilwuL3T5v//+awirqlSpgo8//hhdunRBYGAgnJycDG+wlyxZgrfeegsADB2Ty4NOpwMANG3aFCtXriz2elWrVjVXSaWiUCiwePFifPjhh1izZg3279+PM2fOIDMzExEREYiIiMBPP/2ElStX4uWXXy5wDlM9J6Ty3XffGcKqjh07Yty4cWjRogV8fHxgZ2dnaNrQoUMHHD58uNDnmSkeiyFDhmDFihVITU3FX3/9hcGDBwMAIiIiDB3Zy9oVHMgbtLm4uJR5PiIiInMbP348xo8fX+CyJ5snAUBgYGCxjg27d+9udFz16tVx8ODBEtdpyQRBgN/33yE6Kgraq1dx9713EfDHH5AplZDJZegwqA62zDqHiEMxaNjeD57VyvbegYioXJRXdgQwPyoB5kc5mB/9h/nRf5gfERERWSZPT0/I5XLExsbmuT82NjbPF/YLkpqairVr1+Kbb74pcju2trawtbUtU62FsXdWwsZWjmytDsmJGXD1Nm/TViIii8fsyCSYHZkHs6P/MDv6D7MjIiIiy1RRsiMAcPbMabSkjksvejARUUXH7MgkmB2ZB7Oj/zA7+g+zIyIisiRstERUiG4Te2DVxINIUXnjyLd/ostPb0ldEhFRXrnhVG5YBfz3/we+y3vbCj0ZWCUlJSEgIKDEc7i7uxuuP/0B0dMePHhQ4HoltWzZMmRnZ0Mul+PgwYNGuyAX1n3c09MTAHD//v1S12GMh4cHACAlJQWNGjUy+fzlrUGDBpg6dSqmTp2KjIwMHDlyBKtXr8aKFSuQkpKCwYMH48aNG4Yu6092do+NjS3011KKes5ISRRFLFq0CADQvn177N+/3xBQPc3Yc+3px6IwxXksunbtCm9vb8TGxmLVqlWGwCq3K7hMJsOrr75a5DxFSUpKApDTzfzJXxAgIiKiik3m4IBqc+cgasBAZFy4iAfffAPfqVMhCAKq1nVDrZZVcD38IQ6vu4ZXJjS3+g8niYhMhvlRkZgf5cf8iPlRLuZHRERElk+pVKJly5YIDQ3FK6+8AgDQ6/UIDQ012vw714YNG6DVavH666+XQ6WFEwQBLp4qJMSkQh2XzkZLRETlhdlRkZgd5cfsiNlRLmZHRERElq+iZEcA4OJlBwDQxGdIXAkRUSXC7KhIzI7yY3bE7CgXsyMiIrJUBf9FIyIAgIOnE9p1zXnD8m9KddzdcVTiioiInqLX5Q2rcnX8JOd+vU6aukykcePGhutXr14t1Rw1atSAvX3Ol3BPnjxZ6NhTp04ZrpclyImIiACQ03nbWFgFAGfOnDG6rEWLFgCA27dv49atW6WupSDNmzcHANy8eTNPSFcRqFQqdOvWDUuWLMGMGTMAAOnp6di+fbthzJPPq9OnTxc6X1HLpZSYmGj49xswYIDRsColJQVXrlwpcFnNmjVhZ5fzoaMpHgu5XG4IpPbs2YOEhASIoog1a9YAADp37gw/P78i5ylK7utBw4YNyzwXERERWRelvz+qzpwJyGRQb/wTj9auNSxr168WbBQy3Lv2CNfPPJSwSiIiC8P8qEjMj/JjfsT8KBfzIyIiIuswYcIELFy4EMuXL8c///yDsWPHIjU1FSNGjAAADB06FBMnTsy33uLFi/HKK68YvvAuNWfPnOMOdVy6xJUQEVUizI6KxOwoP2ZHzI5yMTsiIiKyDhUlO8pttMTsiIioHDE7KhKzo/yYHTE7ysXsiIiILBUbLREVoeGgtvC1TYAos0HY+ihkp6RKXRIR0X86TzTe+bvjJznLrVirVq0MXX9LGxzY2NigY8eOAIC9e/fi7t27Rsfmdlm2sbFBp06dSrU9AMjOzgYApKYa/5tx//59bN261ejy3r17G67PmjWr1LUU5KWXXgKQ01n6559/NunclqRr166G6/Hx8YbrnTt3hlwuBwAsX77c6PqnT5/G5cuXzVdgGeU+z4DCn2uLFi3KM/ZJTz7X9+zZY7QTvV6vL/SxetKQIUMAAFlZWVi/fj2OHTuG6OjoPMvKQqPRGAK4kJCQMs9HRERE1sex/bOoMuEDAMCD775H2uMPgp3cVWjxfM6vCR398zqytNb9AT4RkckwPyoS86P8mB8xP8rF/IiIiMg6DBo0CDNnzsTkyZPRrFkznD9/Hrt27YK3tzeAnC/JP/13/MqVKzhy5AjeeustKUoukPPjk+U0PFmOiKj8MDsqErOj/JgdMTvKxeyIiIjIOlSY7Mgz59heE8/siIio3DA7KhKzo/yYHTE7ysXsiIiILBUbLREVQRAEdP2kG2x0GVCr/HDs2/VSl0REVGkolUrDG9Inu3aX1Lhx4wAAmZmZeOutt5CVlZVvzJIlS7Bnzx4AQN++feHr61vq7dWuXRsAcO3aNRw7dizf8rS0NLz22mtITzf+IU+3bt3QsmVLAMCcOXOwdu1ao2MTEhIKnetp3bt3R3BwMABgxowZWL++8L9tly5dwrZt24o9f67hw4dDEAQIgoCwsLASr1+YxMREbNu2DaIoGh2T++8JAEFBQYbrvr6+ePnllwEAW7duLXD/U1JSMHr06DLX2alTJ8NjkBvamIqXlxdcXV0BAGvWrIFWq8035vTp0/jyyy8LnWfs2LEAAK1Wi9GjR0Ony9+QYNq0abh06VKx6mrdurXhv4FVq1Zh9erVAHK6tvfr169YcxTmzJkzhn/37t27l3k+IiIisk7ub70F5xdfALKzcff/3kfW419Mad7dH86eKqQ+0iJ8V7S0RRIRUblgfsT8yBjmR8yPAOZHRERUuYwfPx63bt2CVqvFyZMn83zxNywsDMuWLcszvm7duhBFEc8991w5V2qci2dOoyU1T5YjIiITYXbE7MgYZkfMjgBmR0REVLlUhOzI0KQ7Ph16vfHjOCIiouJidsTsyBhmR8yOAGZHREQVGRstERWDS1U3tG7nAACISPDF/QNnJK6IiKjyyA0WTp06heTk5FLN0bNnTwwYMABATojRpk0brFq1CuHh4di3bx9GjhyJkSNHAgDc3d3x008/lanmN954A0BON+WePXvi+++/x6FDh3Dq1CnMnz8fzZo1Q1hYGJ555plC5/njjz/g6OgIvV6PwYMHo1+/ftiwYQPCw8Nx6tQprF69GsOHD0dAQABiY2NLVOPq1avh7u4OnU6HQYMG4aWXXsKqVatw6tQphIeHY+fOnfj+++/Rtm1bNGnSBAcPHiz142EOGo0GL730EmrUqIEPP/wQ69evx8mTJxEeHo7t27dj9OjR+PTTTwEAVatWRa9evfKs/7///Q9OTk4AgNdeew3jxo3DgQMHEB4ejqVLl6Jly5Y4d+4cWrVqVe77VlwymczQafvixYt49tlnsWbNGpw5cwahoaH48MMP0aFDB6hUKtSpU8foPL179zZ0ot+2bRueeeYZrFu3DmfPnsWuXbvw6quv4osvvijRY5Fb17Fjx7Bq1SoAQK9eveDs7Fza3TUIDQ0FAHh6euLZZ58t83xERERknQRBgO+338K2bl3oEhJw9933oNdqYaOQ45n+OR+endt7G+q4NIkrJSKi8sD8iPlRQZgfMT9ifkRERGR9XB6fLKeOY6MlIiIyHWZHzI4KwuyI2RGzIyIiIuvj6KaCTC5ArxORkpQhdTlERFRBMDtidlQQZkfMjpgdERFVcCJVSmq1WgQgqtVqqUuxGnq9Xlw3br04d3SouGrYMjE7LV3qkoioFMr6+peeni5GRkaK6el8DSgv8fHxoq2trQhAXL58eannSU9PF/v06SMCMHrx8/MTz507V+D6S5cuNYyLiooqcntff/11odv68MMPizXnmTNnxOrVqxc6V0Hrf/XVV4Zlxly5ckVs1KhRkXMDEL/++usi9/lpAwcONKx/8eLFEq9fmKioqGLV7evrK545c6bAOQ4cOCA6OTkZXXfy5MnFehwLExwcLAIQFQqFmJCQUJZdLtCjR4/EZs2aGd0Hd3d38eDBg2LHjh1FAGLHjh0LnEej0YjPPPOM0XmaN28uhoeHG24vXbq00LquXbuWb47NmzebZJ+DgoJEAOK4ceNMMh8REZUvHk9bD2vJjrR37ohXgkPEyLr1xJjPJop6vV7U6/XiX7PPinNHh4rb512QukQiskLMj6wP8yPmRwVhfpSD+REREVkTHktbF3PkR0mxqeLc0aHi/PEHRL1eb7J5iYhMidmR9WF2xOyoIMyOcjA7IiIia8Jjaetiru8erZx8XJw7OlS884/pj42IiEyB2ZH1YXbE7KggzI5yMDsiIiJrU9zjaRmIqFgEQcBzEzpAps9Ekqo6Tk1bL3VJRESVgoeHB/r27Qsgp5t1aalUKmzatAlbt25F37594efnB6VSCTc3N4SEhGDatGm4cuUKmjVrZpK6J0+ejL///hvdu3eHm5sblEolqlWrhr59+2LPnj2YOXNmseZp2bIlrly5gl9++QVdunRBlSpVYGNjA0dHRzRu3Bhvv/02QkNDERgYWOIa69Spg/Pnz2P16tXo168f/P39YWdnB6VSCV9fX3Tq1AlffPEFwsPDMXny5BLPf+LECQBA165d0bhx4xKvX5iAgACcOnUKU6ZMQffu3VG3bl24urrCxsYGnp6e6NChA2bMmIF///0XLVu2LHCOTp06ISIiAmPHjkVAQACUSiW8vb3Rs2dP7Nq1C19//XWZaszIyMD58+cBAEOHDoW7u3uZ5iuIi4sLjh49iqlTp6Jx48ZQqVRwdHRE/fr18dFHH+HChQvo0KFDkfM4OTkhLCwMc+bMQevWreHo6AgnJyc0a9YM06ZNw7Fjx0pUf61atRAcHGy47ebmhhdffLFU+/ik48ePIyoqCgAwduzYMs9HRERE1k9ZrRqqzvoJkMmg3rwZSatWQxAEPDuwDmQyAdEX43ErIkHqMomIyMyYHzE/KgjzoxzMj4iIiMiaOHmoIMgE6LL0SFNnSl0OERFVEMyOmB0VhNlRDmZHREREZG2cPe0AAOq4dIkrISKiioLZEbOjgjA7ysHsiIiIKipBFEVR6iKo/Gk0Gri4uECtVsPZ2VnqcqzKyfn7cOaCDPLsDPQbWQ1ebZpIXRIRlUBZX/8yMjIQFRWFoKAgqFQqM1RIBTl58iTatGkDuVyOGzduICAgQOqSqAjR0dEICgoCABw8eLBYoUlFExYWhs6dO8PGxgZXrlxBjRo1pC7J6o0cORKLFy9Gjx49sGvXLqnLISKiUuDxtPWwtuwoYclSPPzxR8DGBgFLl8C+dWsc2XgNF/bdgau3PV79MhhyG/acJ6LiYX5knZgfWR/mR8yPzIH5ERGRdeOxtHUxV370xxfHoInPQJ8PW8CvtqvJ5iUiMhVmR9aJ2ZH1YXbE7MgcmB0REVk3HktbF3NlR4fWXsWlsLto0SMAbfvUNNm8RESmwuzIOjE7sj7MjpgdmQOzIyIi61fc42meXURUQsGju8JdSITORoX9v4VDn8lf0CMiMreQkBD07dsXOp0O06ZNk7ocKoaDBw8CADp27Fgpwyrgv8dgyJAhDKtM4Pbt21ixYgUAlLlrOxEREVU87iOGw7lXLyA7G3f/731k3b+P1j2DYOekwKPYNFzcf1fqEomIyMyYH1kf5kfMj0yN+REREVHF4OxpBwBQx6VLXAkREVUkzI6sD7MjZkemxuyIiIioYnD2zDlJktkRERGZErMj68PsiNmRqTE7IiKqXNhoiaiEBJmAbu+1gUyfhXjbAITP3Ch1SURElcL3338PGxsbLF26FHfv8iRpS3fo0CEAwOTJkyWuRDqHDh2CXC7HpEmTpC6lQpg2bRqysrIwYMAAhISESF0OERERWRhBEOA79RvY1q8PXWIi7o5/Fwoh2/DLdaf/jkKqWitxlUREZG7Mj6wL8yPmR6bG/IiIiKhicPbKabSkiefJckREZFrMjqwLsyNmR6bG7IiIiKhicGF2REREZsLsyLowO2J2ZGrMjoiIKhcbqQsgskZe9auhSf1LOH8FOHvDCbUuXIFb07pSl0VEVKHVrVsXS5YswY0bN3D79m1Uq1ZN6pKoEIsXL8bixYulLkNSoaGhUpdQYYiiiICAAHz11Vd48803pS6HiIiILJTMzg7V5sxBdP/+yIiIwIOvpqDu99/j8qF7eBitwfHNN9BteAOpyyQiIjNifmRdmB8xPzIl5kdEREQVh4tnzsly6jieLEdERKbF7Mi6MDtidmRKzI6IiIgqjtwm3eq4dIiiCEEQJK6IiIgqCmZH1oXZEbMjU2J2RERU+bDRElEptXm3O6LGbYZa4Y79Px9B34W1IMjlUpdFRFShvfHGG1KXQEQSEAQBn332mdRlEBERkRVQVquKqrNn4fZbI6H+6y+oGjZEh0EvY+MPZ3DlxAM06lAVPjVcpC6TiIjMiPkRUeXE/IiIiKjicHl8spwmno2WiIjI9JgdEVVOzI6IiIgqjtwm3Znp2dCmZkPlqJC4IiIiqkiYHRFVTsyOiIgqH5nUBRBZK7mNHN3GtISg1+GBMggXfv5T6pKIiIiIiIiIiCo9hzZt4P3JxwCA2B9+gGPsP6jXzhcAcGjtVYh6UcryiIiIiIiIiIioEM6PGy2p49hoiYiIiIiIiIiI8rJRyuHgogTA/IiIiIiIiIiISoeNlojKwKd5EBoEZQAATkXYQnMlWtqCiIiIiIiIiIgIbkOHwvml3oBOh5gPPkCrEHsoVXLE3U7GP8fuS10eEREREREREREZ4eKZ02gpIyULmenZEldDRERERERERESWJrdRtyaejZaIiIiIiIiIqOTYaImojJ6d8AIc9Y+QpXDC/hl7IYqi1CUREREREREREVVqgiDA95tvoGrQALqkJCRM/ACtelQDABzfcgPatCyJKyQiIiIiIiIiooIo7WygclQAANRxPFmOiIiIiIiIiIjycnncaInZERERERERERGVBhstEZWRja0Nuo5oBIh6xNjURMT8LVKXRERERERERERU6clUKlSbOwdyd3doI/+BZ+jvcPOxR0ZKFk5tj5K6PCIiIiIiIiIiMoInyxERERERERERkTHOno+zo3hmR0RERERERERUcmy0RGQC1drWQV2/FADAiTMiUqNjJK6IiIiIiIiIiIgUfn6oOmsWIJcjZftWNHWNBgBcCotBQkyKtMUREREREREREVGBck+W0/BkOSIiIiIiIiIiekpuk24Nm3QTERERERERUSmw0RKRiXT45EXY69TQKl1xYNoOiKIodUlERERERERERJWeQ0gwvD/7DAAgW/gt/P1lEPUiDq+/xvyGiIiIiIiIiMgC5Z4sp+bJckRERERERERE9BRnZkdEREREREREVAZstERkIko7JToNrg0AuCXUxNVlOySuiIiIiIiIiIiIAMDt9SFweeUVQKeD/64fIbcREHMlCTfPxUldGhERERERERERPSW30ZImnifLERERERERERFRXrnZUeojLbIzdRJXQ0RERERERETWho2WiEwoqEsj1PR4BAA4eigN6fcfSlsQERERERERERFBEAT4fD0FqkaNoHwYhaBHJwEARzZeQxa/cEVEREREREREZFGcH58sp45joyUiIiIiIiIiIspL5aCAUiUHAGjiMySuhoiIiIiIiIisDRstEZlY509fgEqXjHRbDxz89i+pyyEiIiIiIiIiIgAyW1tUm/ML5B4eqHp2NeyEdKQkanFu9y2pSyMiIiIiIiIioie4PG60lJKYAV22XuJqiIiIiIiIiIjIkgiCYGjUrYlno24iIiIiIiIiKhk2WiIyMVtnO7R/pToA4EZ2EG6u2ydxRUREREREREREBAAKX19U+3k25DIRNS+vAgCc3XObX7oiIiIiIiIiIrIg9s5K2ChkEEUgOSFD6nKIiIiIiIiIiMjC5DbqVsfxOz9EREREREREVDJstERkBnV6tkCAUyIgyHBoZzwyE5KkLomIiIiIiIiIiADYt2oF74mfwSvuHFwfXYUuS49jf16XuiwiIiIiIiIiInpMEAQ4554sxwbZRERERERERET0FGdPZkdEREREREREVDpstERkJl0mPg+lLhWpqio4NHWT1OUQEREREREREdFjbq+9Btd+fVHn2gYIog43zsXhzr+JUpdFRERERERERESP5Z4sp4njyXJERERERERERJSXixezIyIiIiIiIiIqHTZaIjITe3dHPNOjCgDgaro/bv91SOKKiIiIiIiIiIgIAARBgM/kyfCs6YmqMYcBAIfXXIFOp5e4MiIiIiIiIiIiAv47WU4dz5PliIiIiIiIiIgoL+fc7IiNloiIiIiIiIiohNhoiciMGvQPQVW7BIiCHGGb7yBTnSx1SUREREREREREBEBma4tqc35BLc1xKDKTkRSbjkthd6Uui4iIiIiIiIiI8F+jJQ1PliMiIiIiIiIioqe4eD7OjhLSodeLEldDRERERERERNaEjZaIzKzbJ91go0tHssoXx77dKHU5RERWKzMzE7Vr14YgCNi4ka+npbVs2TIIggBBEBAdHS11ORZvypQphseLKg5T/bt26tQJgiCgU6dOpilMAqdPn4YgCHB3d0diYqLU5RAREZU7hbc3gmb/gBq3/wYAnNp0BWmazDxjRFGELksvRXlERFRCzI9Mg/lRyTA/qpiYH/2H+REREUnF+XGjJTUbLRERkYkwOzINZkclw+yoYmJ29B9mR0REJBVHdxVkcgH6bBGpj7RSl0NERBUAsyPTYHZUMsyOKiZmR/9hdkREloqNlojMzNHXDW06OAMAItV+uLf3pMQVERFZp59//hnXr19Ho0aN0K9fv3zLhw8fDkEQMHz48ALXz31zWtDFzs4O1atXR+/evbFixQpkZ2cXWktgYGCB8ygUCnh6eqJt27aYOHGiVQZCRT2OppAbmgUGBpptG1S+coObKVOmmG0buSGTNYdDUinssWvdujV69OiBpKQks/77ERERWTL7Fi3Q/K0ucEq+jSydHAdn7satYcORdvESbkckYOP0M1j++VEkJ2ZIXSoRERWB+VH5YH5EpcH8yLIxPyIiIkvk4pnTaEkTnw5RFCWuhoiIKgJmR+WD2RGVBrMjy8bsiIiILJFMJsDJQwUA0LBRNxERmQCzo/LB7IhKg9mRZWN2RETWiI2WiMpBk9efhbciHqJMgQOrriI7jSFeRSOKInRZeqnLIKqwkpOT8cMPPwAAvvjiC5N3ac7IyMDdu3exfft2DBs2DCEhIYiNjS3xPNnZ2UhISMCJEycwffp0NGjQACtWrDBprWQcu54Tlc7kyZMBAL/99hvu3LkjcTVERETScH91EFpUjwcA3Iy1w5W7KmxZGIVtcy7g4e1kpCdnISMlS+IqiYioMMyPqDiYHxGVDvMjIiKSgpOHCoIAZGfqkabJlLocIiKycsyOqDiYHRGVDrMjIiKSSm6jbnU8z9EiIqKyYXZExcHsiKh0mB0RkSVioyWiciAIAp77uAvkOi0eqari5PfrpS6Jyij90mXcGjYcaRcv4XZEAjZOP4Plnx9FcmKG1KURVUjz589HQkIC/P39MWDAgDLN1apVK1y6dCnP5fjx41i4cCGaNm0KADh79iz69+9f5Fx+fn555jl16hRWr16NF154AQCQnp6ON998E8ePHy9TzaY0fPhwiKIIURTZmZsqrSlTphj+OyCgXbt2aNOmDTIzMzFjxgypyyEiIpJE9r17CBrUFe4ZtwFBhmu1ByIp0z5nIQ8ZiIisAvMj02F+RMT86GnMj4iISApyGxkc3VQAAHUcT5YjIqKyYXZkOsyOiJgdPY3ZERERScXZ63GjJWZHRERURsyOTIfZERGzo6cxOyIiS8RGS0TlxMXfE61a2wIALsZWQeyRCxJXRGXxaMtfuHNVgy0Lo7BtzgU8vJ2M9OQsZKRkSV0aUYWj0+kwd+5cAMDgwYMhk5Xt8MXBwQGNGjXKc2nTpg1GjhyJ48ePo169egCAI0eOFBk0KRSKPPO0bt0agwcPxo4dOzBhwgRD/d99912ZaiYiMrfXXnsNQE6HfY1GI3E1RERE5e9U/3H4c8Y5JKr8gdwPtQRGp0RE1oL5ERGR+TE/IiIiKeSeLKfhyXJERFQGzI6IiMyP2REREUnBhdkRERGZALMjIiLzY3ZERJaGZwsRlaOWIzvDQ5YAvdwWBxafh16rlbokKoGsmBikXbqMazvOYt+16rjQdDySMu1zFrKxKJHZ7N27F3fu3AEADBkyxKzbsrOzw7hx4wy3T58+Xeq5pk6dClvbnAZ7Bw4cgF6vL3N9RETmMmjQIMjlciQnJ2PDhg1Sl0NERFTubj4zHsnOgTk3BEHSWoiIqOSYHxERmR/zIyIikkLuyXLqeJ4sR0REpcfsiIjI/JgdERGRFJw9H2dHbLRERERlwOyIiMj8mB0RkaVhoyWiciTIBDz3wbOQ6TORYFsdp37YKHVJVAh9RgZSrtxAzK6j+GfhNuwcNQ+rfrqKPVsfQWNXNWeQkPdlVJ+ZKUGlRBXb+vXrAQC1a9dG48aNzb69oKAgw3VtGRri2dvbo0aNGgCAtLQ0JCQklLm2p23evBmvvPIKqlWrBltbWzg5OaFGjRpo3749vvzyS5w6dSrfOsuWLYMgCBAEAdHR0SavyVRKsm9hYWEQBAEjRoww3BcUFGTYz9xLWFhYvu3cvXsX48aNQ40aNaBSqeDn54eXXnoJ+/btM9u+RUdHG2patmwZgJxgtnfv3vDx8YGtrS2CgoIwduxY3L17t9C5Ll++jG+//RY9evQwPFaOjo6oXbs2hg0bhhMnThS6/pQpUwy1AEBGRgZmzJiBFi1awMnJCU5OTggODsbcuXORnZ1tkv03h4Ie002bNuHFF1+En58fbGxs0KlTJ8P4p/fbmBMnTmDAgAHw8fGBSqVCUFAQ3n77bVy5cqXYtWVnZ+OXX35BcHAwnJ2d4erqilatWmHWrFnIzMwssHZjtmzZggEDBsDf3x8qlcow19dff42kpKRi11SQKlWqoH379gCANWvWlGkuIiIia9TprRbwrGKTc0Pkh81ERNaG+ZFxzI9yMD9ifsT8iPkRERFZp9xGSxqeLEdERGXA7Mg4Zkc5mB0xO2J2xOyIiIiskyE7YpNuIiIqA2ZHxjE7ysHsiNkRsyNmR0RU8dhIXQBRZeNR2xfNGl3E2Ujg/G1X1A6PhEfLBlKXVemIWVnIiHkA9c37UN+OR/IDNVISMpCSrEOaVoZ0vS0ybJyRrXB4vIYD4N/tvwmMHOBumXYMDtmJcFJmwtlFDldfR7gFecKzYQAcavhDUCjMv3NEFcyBAwcAAG3atCmX7d26dctw3d/fv0xzKZVKw3WFCf/71+l0GDx4cL7uvZmZmUhJSUFUVBSOHDmCnTt34syZMybbbnkoz307fPgwevXqBY1GY7jv/v372LZtG7Zt24YpU6aUaf7imjhxIqZPn57nvujoaCxYsAB//vknDh48iPr16+dbLywsDJ07d853f2ZmJq5fv47r169jxYoV+OyzzzBt2rQi64iNjcXzzz+P8+fP57n/9OnTOH36NPbs2YMtW7ZAJrPsXq2iKGLo0KH4448/yjTPrFmz8NFHH+Xp6h8dHY2FCxdi9erVhjC9MBqNBj169MgXHIaHhyM8PBxr167Fb7/9VuQ8SUlJ6N+/P/bv35/nfq1Wa5jr119/xV9//VWm18o2bdogLCwMhw8fRmpqKhwcHIpeiYiIqIKoXt8dvQe64+yoybgZ1BvJzgFSl0RERCXA/Cg/5kfMjwDmR8YwP2J+RERE1sPZM+dkOTUbLRERURkwO8qP2RGzI4DZkTHMjpgdERGR9XB+3GhJm5aNjNQsqBx4vg4REZUcs6P8mB0xOwKYHRnD7IjZERFVDGy0RCSB4HHPIWrcn0iy8cD+eSfQ77fakFXiBjyiKEKfLUKuMM0BsKjXI/NBHDRRMVBHxyP5/iMkx6chNTkbqekC0nVKZMidkKl0fryG6vHlMdu889notbBDOuQKAWl6O2SKSkDUA0L+erMVDlArHKAGgBQA1x5f9tyCMvMiHHQaONlmwtlNAVdfJ7jX8IJH40DY+VeFIJebZP+JKpK7d+8aule3bt3a7NtLT0/HvHnzAAAODg7o1q1bEWsYl52djWvXrgEAXFxc4OrqaooSAQDz5883BDrPPvssRo4ciZo1a8LBwQEJCQm4ePEidu3aBbVabbJtlpfS7Fvr1q1x6dIl/PXXX/jiiy8AALt374afn1+euZ/s+n779m1DWCWTyfD222+jf//+cHFxwcWLFzF9+nRMmTIFrVq1Muv+Lly4EMeOHUPHjh0xevRo1KlTB48ePcKKFSuwYsUKxMXF4c0338Tx48fzrZudnQ0HBwf07NkTXbp0Qb169eDs7IyHDx8iIiICv/zyC27duoXp06ejTp06eTqnF6Rv376IjIzEe++9h969e8Pd3R1XrlzB1KlT8c8//2Dbtm1YuHAhRo8eba6HwyRmz56Nixcvon379hg7dqzhMS1JJ/zNmzdjwoQJAHL++/30008NncX379+PH3/8EUOGDIGXl1eh87z66quGsOqZZ57Bu+++i1q1aiEuLg4rV67EqlWrMGbMmELn0Gq16NatG86ePQu5XI7XXnsNL774IoKCgpCVlYVDhw7hp59+wsOHD/Hiiy/i3LlzCAgoXWOI4OBgADmh5/Hjx8v0GkhERHnNmzcPM2bMwIMHD9C0aVPMmTPH8Lr7tIiICEyePBnh4eG4desWZs2ahffffz/PmClTpuDrr7/Oc1/dunXx77//Gm5nZGTgww8/xNq1a6HVatGjRw/8+uuv8Pb2Nvn+VRQKT09UkcfBL3MHUhsNxuGLjhBlNgBEAIX/oggREUmH+VHBmB8xPwKYHxnD/Ij5ERERWQ+XxyfLaeLZaImIiEqH2VHBmB0xOwKYHRnD7IjZERERWQ+FUg57FyXS1JnQxKez0RIREZUYs6OCMTtidgQwOzKG2RGzIyKqIESqlNRqtQhAVKvVUpdSaT24eEucN2q3OHd0qHjmh7VSl1Ou0i5eEqOHDhNTL1wUb12OF9d/f0pc/NEhUZOQXuS6er1ezIxPEBNPXxRvbggVz8/eKB6ZtFzcNW6h+OebC8WVQ5eLC4dvFOe9vUecOzq0yMuvo3aJS0dtEte9s17c/vEGMez7reKZRfvFa7vOiw//vS9mpGbm2X7qpUvi4TZ9xOWDl+TM8dR2IkOviZc3HBcPz9gubvt4g7h6zAbx95Hbiqxj4fCN4uphS8Rto38XD01cJl6cs0m8u/OomH4nRtTrdOb6p8jzuGZnmn87lqCsr3/p6eliZGSkmJ5e9PO1vD1MfSjOOzdPfJj6UOpSTGbdunUics5qFg8fPlymuXLnadWqlXjp0qU8l5MnT4qLFi0SmzdvLgIQBUEQ582bZ3SugIAAEYAYEBBgdMz//vc/wzbfeuutMtX+tPbt24sAxJCQEDErK8vouISEhHz3LV261FBXVFSUSesyhfLat/79+xvGrl69Ot9yjUYjNm3a1DDGlIfNUVFReeYdNWqUqNfr840bOXKkYczZs2fzLY+LixOTkpKMbker1YrPPfec4bmanZ2db8xXX31l2IZCoRAPHDiQb0xCQoLo7e0tAhCbNGlSon0tL08/pkOHDi3wMc315H4/TavVin5+fiIA0cXFRYyMjMw35tKlS6Kzs7Nhjo4dO+Ybs2XLFsPyvn37iroC/p7PnDkzT91Lly7NN+bzzz8XAYiurq7imTNnCtyf6Oho0dfXVwQgvvbaa0b3uyi3bt0y1DJ9+vRSz0NEVBhLPp42l7Vr14pKpVJcsmSJGBERIY4aNUp0dXUVY2NjCxx/6tQp8aOPPhLXrFkj+vj4iLNmzco35quvvhIbNmwo3r9/33CJi4vLM2bMmDFi9erVxdDQUPHMmTNimzZtxHbt2hW77sqaHem0WsNxxJllh8W5o0PFeaN2i4smhInJiZXneUtU2TE/si7MjwrG/Ij5kSgyP3oS8yPmR0RkHSz5WJryK4/8KCMty/C9Cm268WM/IqLyxOzIujA7KhizI2ZHosjs6EnMjpgdEZF1sORjacqvvL579OePZ8S5o0PFq6cfmHU7RETFxezIujA7KhizI2ZHosjs6EnMjpgdEZH1KO7xtA2ISBLejf3RuNZFXLxpg/ArdqgVcQMuDWtKXVa5eLTlL9y5qsHRhVFIyooDBAAikJGSBTtFFlKjYqCOfgjN3QQkP0xBSlImUtNEpGXaIEOwR4bSBaIst9O82+MLAMXjy2OCqINKTIO9TSbs7QFHFyWcvBzg7OcGl8AqcA70gp2TLQRBKHbtCk9PVJHHwS9zB9KbDMa58EyoFVUMyz1recPLv1a+9TJSM5F45R4S/o1B0p1EqOMyoEkRkKK3R7ZMBa2tG7RwQyIAJD6+XM4ANkdCpT0KR6TAyV4HFw8lXKu5wKOWL9wbBkLh7VWi+nOlX7qMhzNnwuvDDxEv98PJrTeRnJiBARNbw8ldVeL5yDLEpcdh/oX56FS9E7zsC+9Way3u3r1ruF6lSpVCRhbfmTNn0LhxY6PLu3fvjs8++wydO3cu8dzp6em4ceMGli9fjtmzZwPIqfvzzz8vbbkFevDgAQCgXbt2sLExfjjn7u5u0u2Wh/LYtwcPHmDz5s0AgF69emHw4MH5xjg5OeH3339HSEhIqbdTHL6+vpgzZ06Br+UfffQRFi1aBAA4fPgwmjdvnme5p6dnoXMrlUrMmDEDzZo1w61bt3D+/Hm0bNnS6Ph3333X0P36Se7u7hgxYgSmT5+OS5cuQa1Ww8XFpRh7Jw1XV1fMnTu3VH8fAeCvv/7CvXv3AABffvkl6tevn29Mo0aNMGnSJHz66adG51mwYAEAwM7ODgsWLIBMJss3ZsKECVi9ejXOnj1b4BwpKSmGXyuYOnWq0X+/gIAAfPnll3jnnXewYcMG/P7773BwcCh8Rwvw5OvszZs3S7w+EREV7KeffsKoUaMMv9KxYMEC/P3331iyZAk+++yzfONbt25t+FWcgpbnsrGxgY+PT4HL1Go1Fi9ejNWrV6NLly4AgKVLl6J+/fo4ceIE2rRpU9bdqrBkSqXherPX2+HisW1IkzkhSHcFjm4dJayMiMg0mB8VD/Mjy8b86D/Mj0qH+RHzIyIish62djZQOSiQkZoFdVw6vKo7SV0SEVGFxuyoeJgdWTZmR/9hdlQ6zI6YHRERkXVx9rLD/RtqqOPSpS6FiKjCY3ZUPMyOLBuzo/8wOyodZkfMjoioYmCjJSIJtZ3wAqLf2QyNwh2hP4Whz8IgCAUczFQEWTExyEpMQsydTBy75o+Upm2BTL2hyRIAbJ28G5kKB+jlto/Xcnl8ASAHYPfEhKIetvrHTZRUIhydbeDoaQ9nX1e4BHjBJcgb9u72kMlKd7BqjMLHB7X2h0JQKCAIAurr9bh9KQ6nd9xGSpIWdk6KAtdTOSjh1yIQfi0C89wviiLSNVok/HMXiVfvIenuI6jjtdCkypAqOkAnUyJD5YEMeCBeDyDu8eVcCoR1F2CXmQgHIRXODno4e9jCrborPOr4wbVhEJQext/MFdbsio2WTEcURaRnl19gn5GdYfj/tKy0ctuunY1dqd8YFiUuLs5w3c3NzSzbeNqBAwfg4OCAWrVqoXr16oWOvXXrVqH73qlTJ8ybNw81atQwaY2+vr64du0atm3bhs8//7zI4MKalMe+HThwADqdDgAMDQ8KEhwcjIYNGyIiIsLkNeTq378/bG1tC1xWt25dODo6IiUlpVjhgVarRWxsLFJSUqDX6wHkvA7lunDhQqGB1ZAhQ4wuy11PFEVERUWhWbNmRdYjld69e8PJqfRfst+3bx8AQBAEDBs2zOi4ESNG4LPPPsvzGOfKzs7GwYMHAQDPP/88vLwK/hBBEAS88cYbRgOrgwcPQq1WA8h5rhSmQ4cOAICsrCyEh4cbbpeESqWCnZ0d0tPTDeExERGVTWZmJsLDwzFx4kTDfTKZDN26dcPx48fLNPe1a9fg5+cHlUqFtm3bYtq0afD39wcAhIeHIysrC926dTOMr1evHvz9/XH8+PECGy1ptVpotVrDbY1GU6b6KgK5XIaWXX1xeH8KriX7ovU/N+BUv3I0ySai8lHe2REgTX5kzuwIYH5kDPOjsmF+VDDmRzmYHzE/IiKyVPPmzcOMGTPw4MEDNG3aFHPmzEFwcLDR8Y8ePcKkSZOwadMmJCYmIiAgALNnz8aLL75YjlUXzdnLDhmpWdDEs9ESEVUulSU7AvjdI2ZHpsXs6D/MjkqH2RGzIyKiiqqiZkcuXjknGmnYaImIKhlmR6bB7KhgzI7KhtlRwZgd5WB2xOyIiCwDGy0RScjGRo6uo5phy6Io3FcE4dK8LWjybl+pyzKLEwP+D1drDUCGvRdg55dzp5C3qVSG6r/GQApdOuxlGbBX6eDgZAMndzs4+TjDOcALrjV94OjlCLlcmqZUMqXyv+syGQKbeiOgSRXos0XIFSWrSRAE2LuoYN+mFqq3qZVnmSiKSEtMQ/w/d5B47UFOE6aETCSny5EqOkIvUyBN5YU0eCEuG0Ds48sZNWT607DTJsJRngYnR8DFSwVnVxu4eNohxdYTp65Vh6aAZldkWunZ6QhZbd6uwgUZtsv4GyxzOPnaSdgr7M0yd2JiouG6qQKrjh07IiwsLM99WVlZiImJwY4dO/DVV19h8+bNOHnyJEJDQ1GvXr1SbcfFxQXjxo1DgwYNTFB1XsOGDcOhQ4dw/fp11KpVC3379sVzzz2H9u3bo1q1aibfXnkqj327dOmS4Xrr1q0LHRscHGzWwKqo55ebmxtSUlKQnJxc4PLU1FT88ssvWLt2LSIiIgxBXEHi4+NLXcuTndiN1WIpmjRpUqb1c58fQUFBhQamXl5eCAwMRFRUVL5lN27cQHp6zocWhYWEANCqVSujy86cOWO47uvrW+g8TypL2OTm5ob09HSkpqaWeg4iIvpPfHw8dDodvL2989zv7e2Nf//9t9TzhoSEYNmyZahbty7u37+Pr7/+Gu3bt8fly5fh5OSEBw8eQKlUwtXVNd92jf2dmDZtGr7++utS11RRNerfGuf2/4UUhTNO/boXXeew0RIRmY5U2RFQvvmRObMjgPmRMcyPyob5UclrYX6UH/MjIiIqT+vWrcOECROwYMEChISEYPbs2ejRoweuXLlS4C8wZ2Zm4rnnnkOVKlWwceNGVK1aFbdu3cqXJ1kCFy87PIzWQM2T5Yiokqks2RHA7x4Zw+yodJgd5cXsqOSYHTE7IiKqiCpyduTsmdNoidkREVU2zI5Mg9lRwZgdlQ2zo5LXwuwoP2ZHRETmxUZLRBLza10L9XZF4J8YJ5w8J0ONG3fgWLPwTrTWIjs5BdfXh+HqyQe403jMf42VjHTRfeY5d/i3rA5nP1fYKOXlWGnZCYIAucK0nZEFQYCDhwMcnq2HgGfzvokQ9SKS41KQEHELiTceIilGDU1iFpIzbJCKnCZMqXbeSAUQmwkg5vEFAJAB2FV9vBFpmlURFZdKpTJcT09PL1O338IoFAoEBgbinXfeQceOHdG8eXPcu3cPI0eOxJEjR4yu5+fnh927dxtux8XF4fTp05g1axYePHiAgQMHYs2aNRg0aJBJ633zzTdx48YN/Pjjj1Cr1Vi6dCmWLl0KAKhZsyZefvlljBs3zuQdyctDeezbk0FoQR8OPunppgimZm9feNgrk+W8ThcUREVHR6NLly4FBiYFyQ1QSlNLbh3GarEkZQ23c58fRT03gJznR0GPf1JSkuG6sa7gxVn+8OHDImsoSFpa6X8dIvd5olAoSj0HERGZ3wsvvGC43qRJE4SEhCAgIADr16/HW2+9Vao5J06ciAkTJhhuazSaIn8ppzKQyQQEvxiA/TuScC29Olqej4RrM9N/KE1ERKXH/KhgzI+YHwHMj4xhfsT8iIioIvrpp58watQow6/iLliwAH///TeWLFmCzz77LN/4JUuWIDExEceOHTO8pgcGBpZnycXm4pVzspyGJ8sREVEpMDsqGLMjZkcAsyNjmB0xOyIiqogqRXYUz+yIiIhKjtlRwZgdMTsCmB0Zw+yI2RERVQxstERkAdp/8iJuj9+GVKUr9v+wG71/ewuCkWZElk6fmYm7O47hn9DruJPqAa3SBZDlvKkQxGyIgg0g6gts8FO1dU24+5vnzWhFI8gEOHs7wdm7EYK65F2m14vQ3HuE+MjbSLrxEEn3kqF5lI2HmW4QhccNrKz0+WVt7GzscPK1k2bdRnx6POLTc7r9Xkm8gu9PfY/Pgz9HXfe6AABPO0942hnvbGsKdjZ2Zpv7yTdyiYmJZgusntSwYUO8+OKL+Ouvv3D06FFcvXoVderUKXCsQqFAo0aN8tzXuXNnvP766wgODkZMTAzefvtttG3bFv7+/iat87vvvsPbb7+NVatWITQ0FCdOnEBaWhpu3LiBn376CXPmzMEvv/yCMWPGmHS75aE8981a/94CwBtvvIGoqCgIgoARI0bg1VdfRf369eHl5QWlUglBEKDX6yGX57z2i6IoccXlI3d/y8oSnhtPhoNnz54tdohU2i76er0earUaACzyV4eIiKyRp6cn5HI5YmNj89wfGxsLHx8fk23H1dUVderUwfXr1wEAPj4+yMzMxKNHj/K8phe2XVtbW9ja2pqspoqkXq9mOLNzCzQ2Ljj520H0mM9GS0RkGuWRHQHS50fmzI4A5keFYX7E/Ij5UcGYHzE/IiKqaDIzMxEeHo6JEyca7pPJZOjWrRuOHz9e4Dpbt25F27ZtMW7cOPz111/w8vLCa6+9hk8//dTo30qtVgutVmu4rdFoTLsjRjh75pzkoGajJSKqZCpLdgTwu0fMjkyP2VHxMDsqGLMjZkdERBVNRc+OchstpTzSIjtLBxuFdf3oOxFRaTE7Mg1mR8YxO2J2xOyoYMyOmB0RUcXARktEFkBhq0DnN+pj+6oY3JHVwD+LtqPBqN5Sl1Vsoigi/shZRG67iKhYFVLtvAHUAJSAjS4D/l7paPBCQ3i6ZuHc21/hZlBvJDsHAKIOEBhimppMJsC1mhtcq+XtjHrnn0QcXX0ZCXHZRptdZadnAGCzK1MRBAH2isK7/paVv8If/s45QYjKJucLpk2rNEUDj4px4u+TgVVSUhICAgLKZbv16tXDX3/9BQC4dOmS0cDKGD8/PyxYsAC9e/eGRqPBpEmT8Mcff5i8zoCAAHz++ef4/PPPkZWVhdOnT2P9+vX47bffkJGRgXfeeQchISFo3ry5ybdtbubctyc7R8fGxqJ69epGxz7dFMFS/Pvvv4au9Z9//jm+/fbbAsc92QWdiif3+VGcf3tjY558jsXFxRU6R2HLPTw8DNe9vLxKHUQVl1qthl6vBwCTh+xERJWVUqlEy5YtERoaildeeQVAzgcEoaGhGD9+vMm2k5KSghs3buCNN94AALRs2RIKhQKhoaHo168fAODKlSu4ffs22rZta7LtVhaCTECbPrWxZ9ND3MwOQsKJC/Bo01TqsoioAiiP7AhgfmQuzI+kx/yocMyPzIf5EfMjIiJLEx8fD51Ol+8Xb729vfHvv/8WuM7Nmzexf/9+DBkyBDt27MD169fxzjvvICsrC1999VWB60ybNg1ff/21yesvSu7Jcpp4NloiosqF2ZFpMDsqHLMjZkcAsyNTY3bE7IiIyNJU9OxI5aiAwlaOLK0OyQkZcPNxKPcaiIikwOzINJgdFY7ZEbMjgNmRqTE7YnZERJYhf5cNIpJEQIf6qF0lp2P78eOZSLv7QOKKiqb55zpOfL0Sa4Yvx/pValzWBCDVzhuCPhtV7RLQ5QVnvDWvB174vh8C2teD0ssLVeRxeDZzBzo1eQSX7ASpd6FSqV7fHS8NckfTC3PhlHwn505Rn2fMrukHcG3lrkrTPZYsX+PGjQ3Xr169Wm7bzc7OLvB6SfTq1QvPPvssAGD16tWIjIw0SW3GKBQKtGvXDrNnz8bq1asB5DTC27hxo1m3Wx6Ku2/F7eT85PPq9OnThY4tarlUIiIiDNcHDRpkdNyZM2fKo5wKJff5ERUVhYQE48cqcXFxiI6OLnBZzZo1oVLlfIgQHh5e6PYK+zd6MpA9evRoofOYwpOvsw0bNjT79oiIKosJEyZg4cKFWL58Of755x+MHTsWqampGDFiBABg6NCheX4xLjMzE+fPn8f58+eRmZmJmJgYnD9/HtevXzeM+eijj3Dw4EFER0fj2LFj6NOnD+RyOQYPHgwAcHFxwVtvvYUJEybgwIEDCA8Px4gRI9C2bVu0adOmfB+ACqLWcw3hJn8EvVyJk0uOSV0OERE9gflR8TE/Yn5UEOZHJcf8KAfzIyIi66bX61GlShX8/vvvaNmyJQYNGoRJkyZhwYIFRteZOHEi1Gq14XLnzp1yqdXZM+dEkeRELXQ6fRGjiYiI8mJ2VHzMjpgdFYTZUckxO8rB7IiIyLpZU3YkCAKcHzfqVsexUTcREZUMs6PiY3bE7KggzI5KjtlRDmZHRCQ1NloisiCdPusJO50GGUo3hH2/XepyCqR98BAXZm3AxhGLsHLWDYTf90OSXU7nSE95AtqGyPHmzA54ZdYA1H+5FWyUcsO6Ch8f1NofiqAN69Hwnb54beFA9BzbEFUCnGDvrISdk0Kq3ao0FJ6eTzW7in+8JKexUpqtJ/YcUWLLqMWIPx1hfCKySF52XhjbdCy87LyKHmwlWrVqZXjTV57BwZNvIAvrGl2UL7/8EkDOh03fffddmesqrq5duxqux8fHFzLS+hS2b7nPFQDQarVG5+jcuTPk8py/T8uXLzc67vTp07h8+XJpSzWrJ4PU1NRUo+MK+0CTCtatWzcAOaHoihUrjI5btmyZ0caENjY26NChAwBg165dRrt/i6JY6K8GdOvWDfb2OScP/PLLL2ZvhPjk62xISIhZt0VEZMnkcjkePnyY7/6EhATDMURJDBo0CDNnzsTkyZPRrFkznD9/Hrt27TL8Stzt27dx//59w/h79+6hefPmaN68Oe7fv4+ZM2eiefPmGDlypGHM3bt3MXjwYNStWxcDBw6Eh4cHTpw4keeXdWbNmoVevXqhX79+6NChA3x8fLBp06YS1085BEFA20E5H+hEowYehp2SuCIiotJhfmQ6zI8sF/OjHMyPzIf5UQ7mR0RElsPT0xNyuTzfL5rGxsbCx8enwHV8fX1Rp06dPHlX/fr18eDBA2RmZha4jq2tLZydnfNcyoODixJyhQyiXkRyQka5bJOIqLJidmQ6zI4sF7OjHMyOzIfZUQ5mR0RElqOiZ0cA4MJGS0RE5YLZkekwO7JczI5yMDsyH2ZHOZgdEZHU2GiJyIIoHWzRcUAQACBKXwPXVu6RuKIcuuQUXF22HdveXohlk07hyBUPxNrWgChTwEl8hOb1MvH6l80xaN4AtBjRESpnldG5ZEqloXOrTCZDYFNv9P+sFYZ+1w6ObsbXI9Mw3uzKGSpHG/i7PAJEPe7Z1MCG32/jwEdLkPHQeFdUsixe9l54p9k78LKvOIGVUqk0vGk6dap8TmT++++/cfDgQQA5HywFBweXeq7u3bujVatWAIB169bh+vXrJqlx5cqVhXYs37Pnv78fQUFBJtlmrilTpkAQBAiCgGXLlpl0bqBs++br62u4fuPGDaNz+Pr64uWXXwYAbN26FevXr883JiUlBaNHjy523eWtdu3ahuvG/h3mz5+Pv/76q5wqKtzw4cMNz5uwsDCpyynUK6+8YnguTZ06FVeuXMk3JjIyssgQOvf5k56ejjFjxkCvz/8Lyz/99BPOnj1rdA5XV1eMHz8eAHDs2DF88MEHBc6TKzY2FosWLSq0rsLkvs76+/ujbt26pZ6HiMjaGfuAQKvVQqlUlmrO8ePH49atW9BqtTh58mSeDwbCwsLy/D0PDAyEKIr5Lk/+DV27di3u3bsHrVaLu3fvYu3atahZs2aebapUKsybNw+JiYlITU3Fpk2bjH45ioonsH0deCoeQZQpcPKPcLN/mEREZA7Mj0yD+VHhmB9ZBuZH5sP8iPkREZGlUSqVaNmyJUJDQw336fV6hIaGom3btgWu88wzz+D69et5/m5cvXoVvr6+pc7AzEWQCXD2zDlZThPPk+WIiMyJ2ZFpMDsqHLMjy8DsyHyYHTE7IiKyNBU9OwIAl9zsiI2WiIjMitmRaTA7KhyzI8vA7Mh8mB0xOyIiy2AjdQFElFfN7k0RFLoRUWp3HAl9hOrdE6Cq4lHudYhZWbi78yj+2XsNd1LckWHrBshqAjJApU9BYHWgUd8W8G5YrczbEgQBcoVggqqpOGRPBNu5za4CmlSBPluEXCHD/fCbCFscjkR4IDIlEDc/PYBWTYHG416GTKGQsHKqrF5++WUcPHgQp06dQnJyMpycnMo0X2pqar5uz1lZWYiJicHff/+d583etGnTYGNTtsOlSZMmoU+fPtDpdJg2bRoWL15cpvkA4I033sBHH32Evn37ol27dqhZsyZUKhViY2Oxd+9ezJ8/HwDg6OiIIUOGlHl75aks+9a8eXOoVCpkZGTgyy+/hEKhQEBAAGSynN6iVatWhZ1dzgdp//vf/7B3714kJyfjtddew8GDB9G/f384Ozvj4sWLmD59Oq5evYpWrVrl6RRvKZo3b45GjRrh8uXL+O2335CUlIQ33ngDvr6+uHv3LlauXImNGzfimWeewdGjR6Uu16oolUrMmTMH/fv3R1JSEtq0aYNPP/0UnTp1MjS5+OGHHwAAtWrVMhpE9+3bF927d8eePXuwadMmdOjQAe+99x5q1aqFuLg4rFy5EitXrkRwcLAhKMptRvmkb775BgcPHsTJkyfx888/IywsDKNGjUKzZs3g4OCApKQkREREYN++fdi5cycaN26MkSNHlni/RVHEgQMHAAB9+vQp8fpERBXBL7/8AiDn9XjRokVwdHQ0LNPpdDh06BDq1asnVXlkAQRBQLs3mmHrkmjcsamF+7uOwu+FZ6Uui4iIwPyoIMyPmB8xPzIf5kfMj4iILNGECRMwbNgwtGrVCsHBwZg9ezZSU1MxYsQIAMDQoUNRtWpVTJs2DQAwduxYzJ07F//3f/+Hd999F9euXcP333+P9957T8rdMMrFyw5J91N5shwREZUKs6P8mB0xO2J2ZD7MjpgdERFZooqeHTl75Ryjqdmkm4iISoHZUX7MjpgdMTsyH2ZHzI6IyEKIVCmp1WoRgKhWq0u87sPUh+K8c/PEh6kPzVAZiaIopiWligtH/iXOHR0q7n53UbltV6/Xi3FHwsWDHy8Wlw9dKc4dHWq4LBi1Q/z70z/FqLBIUafTl1tNJA29Xi9eXHNEXDRyi+E5sGbYUvHO30ekLq3MyvL6J4qimJ6eLkZGRorp6ekmroyMiY+PF21tbUUA4vLly0s9D4BiXxQKhfjDDz8YnSsgIEAEIAYEBBS5Xb1eLzZs2NAw761bt0q9DyXZFxcXF3Hnzp351l26dKlhTFRUVIm3/cknnxjW37p1a5n35Wll2ben63v6cuDAgTxjDxw4IDo5ORkdP3nyZPGrr74y3DaVqKgow5xLly4tdGzuc23YsGH5lp07d050c3MzWn/jxo3Fe/fuGW5/9dVX+eYo7v4dOHDA6ONYHAMHDjSsf/HixRKvX5SSPKaiWLz9njFjhigIQoGPrb29vbh9+3axY8eOIgCxY8eOBc6RlJQkBgcHG/03at68uXjmzBnD7bVr1xY4j0ajEfv27Vus/z46d+5cnIcsn7CwMMMcp0+fLtUcRETFYcnH04GBgWJgYKAoCIJYvXp1w+3AwECxTp06Yvfu3cUTJ05IXWa5Ket7p4ps4//9Kc4dHSpuHj5f1OuZkRBVRMyPrA/zo9LtC/Mj5kfMj4xjfpQf8yMiKg88li6bOXPmiP7+/qJSqRSDg4PzZFkdO3bMd7xw7NgxMSQkRLS1tRVr1Kghfvfdd2J2dnaxt1ee+dHhdVfFuaNDxSMbrpp9W0RERWF2ZH2YHZVuX5gdMTtidmQcs6P8mB0RUXngsXTZVOTs6HZkgjh3dKi46qvjZt8WEVFRmB1ZH2ZHpdsXZkfMjpgdGcfsKD9mR0RUXop7PJ3TJpGoBOLS4zD/wnzEpcdJXUqFZedqj/a9fAEA17QBiN4UZtbtpVy5iVPf/IG1w5di3YpEXNIEItnOF4I+G76qRHTu4YQ35zyHF6f3RWDH+pDJ8netpIpFEAQ0fvUZvPHzC2gUkAqZPgsJKn9s/SsNO95ZiORrt6QukSoRDw8P9O3bFwCwevVqs2xDLpfD3d0dwcHB+PTTTxEZGYlPPvnEJHMLgoDPP/8cQE4H8tyOwmVx+fJl/PDDD+jduzcaNGgADw8PyOVyuLq6ok2bNvjqq69w5coVPP/882Xe1tOOHz8OAKhTpw569uxp8vnLum/Tp0/HwoUL0b59e7i7u0MulxvdVqdOnRAREYGxY8ciICAASqUS3t7e6NmzJ3bt2oWvv/7a5PtnSs2aNcP58+cxZswYBAQEQKFQGJ7HM2fOxKlTp+Dr6yt1mQCAEydOAAC6du2Kxo0bS1xN8Xz00Uc4cuQI+vbtiypVqsDW1hYBAQF48803cebMmWI9/11dXXHkyBHMmjULLVu2hKOjI5ycnNCsWTNMmzYNx44dy/McdXFxKXAeJycn/Pnnnzh8+DBGjhyJunXrwsnJCTY2NnB3d0fr1q0xbtw47NixA3v37i3V/ua+vrZu3RqtWrUq1RxERNYuKioKUVFR6NixIy5cuGC4HRUVhStXrmD37t0ICQmRukyyAO1G5PytjFHWwt0tBySuhoiIAOZHBWF+xPwIYH5kbsyPiIjI0owfPx63bt2CVqvFyZMn82RZYWFhWLZsWZ7xbdu2xYkTJ5CRkYEbN27g888/L/TYSErOXioAgDouXeJKiIjIGjE7yo/ZEbMjgNmRuTE7IiIiS1ORsyMXLzsAgCY+A6JelLgaIiKyNsyO8mN2xOwIYHZkbsyOiIikJYiiyAShhO7fv4/Q0FC4u7ujW7duUCqVhmWpqan43//+h8mTJ0tYYdE0Gg1cXFygVqvh7OxconXPPzyPN3a+gXW91qGBRwMzVUgAsPXDDbiT6gHHjIcYPPtFKF1L9m9VGO2Dh7iy9iCuX3iEWJvq0Mv/ex57yBNRu4UnGvQLhp2rvcm2SdYr6WYswuYcwr10DwCAIisFjas9QuuP+8HG0UHi6kqmLK9/AJCRkYGoqCgEBQVBpVKZoUIqyMmTJ9GmTRvI5XLcuHEDAQEBUpdUKWVkZMDV1RVarRbLly/H0KFDpS6JrEB0dDSCgoIAAAcPHkSHDh0krsiyrFy5Em+88QYA4Pr166hZs2a515CcnAx/f388evQIa9aswauvvlruNRBR5WGNx9M6nQ6XLl1CQEAA3NzcpC6n3JT1vVNFt+XDTYhJdYVPxjX0XTIKgoz97IkqEuZH1on5kWVgfkSlwfyocMyPiKgy4bG0dSnP/Cj6Ujz+nncRHlUd8OqXbIZORNJidmSdmB1ZBmZHVBrMjgrH7IiIKhMeS1uX8syO9Do9fnv3IPR6EcOmtYOjG58fRCQdZkfWidmRZWB2RKXB7KhwzI6IqLIp7vE0zwAqodOnT6NBgwYYN24c+vfvj4YNGyIiIsKwPCUlxeK7SJZGXFocIhMiseXaFozdNxYA8E/CP4hMiERkQiTi0uIkrrBi6vpZDyh0aUhRVcHhqX+WeT5daiquL/8b29/+DcsmncThfz1w37Ym9HIlHEU1mtXNxJBJzfDqvP5o+VYnNlkiA7ca3ugzawBe6O8JJ/0jZCkccTa2GlaP34Jry3eAPfvI3EJCQtC3b1/odDpMmzZN6nIqrZMnT0Kr1aJmzZoYMmSI1OWQlTh48CAAoGPHjgyrCrBmzRoAgJeXF2rUqCFJDXPnzsWjR4/QoEEDDBw4UJIaiIgsyfvvv4/FixcDyGmy1KFDB7Ro0QLVq1dHWFiYtMWRxXhmVFtA1OOBqjZurS/dL3MQEZFpMT+yDMyPqDSYHxWO+RERERHg4mUHAFDHZ/D7CUREVCrMjiwDsyMqDWZHhWN2REREBMjkMjh65Jw8qY5Ll7gaIiKyRsyOLAOzIyoNZkeFY3ZERFQwNloqoc8//xx9+vRBUlISYmNj8dxzz6Fjx444d+6c1KWZ1YarGzBo+yB8eexLpGSlAACmHJ+CQdsHYdD2QdhwdYPEFVZMDl7OaNvFDQBwJbka7u48XuI5xOxsxGw7iL3v/Y5l43Zg93E73JLVRrbCAbb6VNT1TUHfd2ph6IJX8MwHz8O1urupd4MqkBrdmmDIry+jdVM9bHTpSFb5Ys9xFTaPXIy4ExelLo8quO+//x42NjZYunQp7t69K3U5ldKhQ4cA5BwPyeVyiasha5H7vJk8ebLElZS/mJgYpKcb/8B20aJF2LFjBwBg6NChEAShvEozSE1NxU8//QQAmDFjBmQyvkUkItqwYQOaNm0KANi2bRuio6Px77//4oMPPsCkSZMkro4shVc9X/i7JgMATu28DVGnk7giIiICmB9ZAuZHVBrMj5gfERERFcXZww4QgGytDunJWVKXQ0REVorZkfSYHVFpMDtidkRERFQchkbdbLRERESlxOxIesyOqDSYHTE7IiIqDUHkz3yViLu7O06cOIE6deoY7ps+fTp+/PFH7N69G/7+/vDz84POwk+u0mg0cHFxgVqthrOzc5Hj49LiEJceh4zsTHxy8HPEpt+BrcwO3z/7Hao5V4WXnRe87L3KofLKRxRFbH5/A+5rPeGccR+D5/aBjaN9vjH6bBFyhcxwO/HkBURuDkfUfSWS7asaxsr1WlRzS0eD5+shsGN9yGTlf2BEFUNqQgoO/7QHN+KdAUEGmS4TdZ3uot0nL0PlY7mvByV9/XtaRkYGoqKiEBQUBJVKZYYKqTB//PEHbty4ge7du6Ndu3ZSl0NEVKhly5bhk08+wauvvopOnTohICAAer0eN27cwLp167BlyxYAgLe3NyIiIuDh4VHuNUZGRmL9+vVwd3fHe++9V+7bJ6LKxxqOp1UqFa5fv45q1arh7bffhr29PWbPno2oqCg0bdoUGo1G6hLLRVnfO1UGCVHxWDf9HERBju4hqag9orfUJRGRiTA/sm7Mj4jImjA/IiLKi8fS1qW886Plnx9FSqIWfT9uCd+aLmbfHhGRMcyOrBuzIyKyJsyOiIjy4rG0dSnv7Ojg6iu4fCgGLZ8PQJtXapp9e0RExjA7sm7MjojImjA7IiLKr7jH0zblWFOFkZGRkef2Z599BhsbG3Tv3h1LliyRqCrz8rL3QvjNbHy9LRKxmS/AIfB3aPXp+Gj/VHzefA5ebWG5TVWsnSAI6PZJN6yZcgIalS+OfbcBrV9riYczZ8Lrww8RL/fDya03kZyYgV6v+uDWjhO4cU2LBLtAQAgC7AFB1MFbpUa99v6o3bsDlLb8T5/KzsHDEc9/1xf3z0Xj4MIzSIA7/kmrgaiJB9GysQ5NxveBTKmUukyqYN544w2pSzCJmJgYJCUllXg9BwcHBAUFmaEiKomoqCikpqaWeD03NzdUrVq16IFUocTFxWHOnDmYM2dOgct9fX3x999/SxJWAUCDBg0wZcoUSbZNRGSpvL29ERkZCV9fX+zatQvz588HAKSlpfHXUSgPjyBPBHml4ma8M84ciEOt17MgKBRSl0VEVOkxP2J+ZAmYH1FJMD8iIiIqHhcvO6QkaqGJS2OjJSIiKjVmR8yOLAGzIyoJZkdERETF4+xlBwBQx6dLXAkREVkzZkfMjiwBsyMqCWZHRESlw24rJdSoUSMcO3YMTZo0yXP/Rx99BL1ej8GDB5dq3nnz5mHGjBl48OABmjZtijlz5iA4OLjAsZs2bcL333+P69evIysrC7Vr18aHH35o1oP4XZfvY+zKsxAByFS2AAB9pitkyiRMPfMBFLJf0a9ZPbNtv7JzruqO4LZ2OHZKRES8N7x+X4uEqxocXRiFpKw4ACIAARsX3IAorwrY56znJktCnRYeaNA3BPbuDlLuAlVgvs0DMWheACI2nsTJPbHIsHXH0avAP2+vwrP9aqJ67w5Sl0hkcSZNmoTly5eXeL2OHTsiLCzM9AVRiYwYMQIHDx4s8XrDhg3DsmXLTF8QWaxevXph/vz52L17NyIjIxEXF4fk5GS4urqifv366N27N8aMGQMnJyepSyUioieMGDECAwcOhK+vb07z427dAAAnT55EvXrMPiivdmM6Iuqb00i0D8S/i7ej/pg+UpdEREQVBPMj68b8iIqL+REREVHxOXvaIebKI6jjeLIcERERsyPrxuyIiovZERERUfG5PG60pGF2RERExOzIyjE7ouJidkREVHpstFRCQ4cOxcGDBzFmzJh8yz755BOIoogFCxaUaM5169ZhwoQJWLBgAUJCQjB79mz06NEDV65cQZUqVfKNd3d3x6RJk1CvXj0olUps374dI0aMQJUqVdCjR49S75sxOr2Ir7dFQnx8W8x2gjauK7KT68Ou+h+Q2cbhm9Mf4rn66+Bs62jy7VOOht1r4+rJQ4iX++BgejvomnYBMkVAAB7/D0S5Eg6iBjXr2KJR/2C4BUjTYZIqH0EQ0GhAG9TpmYnjv+xB5E0FElUB2LZdi8C/f8ez73eDc70aUpdJRERUrjw9PTFmzJgC3zsQEZHlmjJlCho1aoQ7d+5gwIABsLXNaTgtl8vx2WefSVwdWRqXam6o5ZeBaw8ccfaYBnWGZ0CuUkldFhERERFZCeZHRERExZd7spw6nifLEREREVHlwOyIiIio+Jw9mR0RERERUeXC7IiIqPQEURTFoodRaR09ehStWrUynJRXkJCQELRu3Rpz584FAOj1elSvXh3vvvtusU/ga9GiBXr27ImpU6cWa7xGo4GLiwvUajWcnZ0LHXv8RgIGLzxR4DKZ8iHsAhZAZpOGei4tsKr3QijlymLVQCVztO0ruFazL1Idqxkd07lfNdTvVhuCIJRjZUT5JUXH4eAvBxGT5g4AUGSloLFfIlp93B8KZ2kbspXk9a8gGRkZiIqKQlBQEFQ8eZaIiIiIqESs7Xg6IyPDKuo0h7K+d6pMkh8mY+UXx6CXKdCxfjwa/d9AqUsiojJifkREREREJA0eS1uX8s6Prp2JxZ5FEfCp4Yx+n7Qy+/aIiIxhdkREREREJA0eS1uX8s6OMjOysfD9QwCAkT+1h629wuzbJCIqCLMjIiIiIiLpFPd4WlaONVVKL7zwAmJiYowuz8zMRHh4OLp162a4TyaToVu3bjh+/HiR84uiiNDQUFy5cgUdOnQwSc1Pe5icYXSZPrMK0u+MgKhX4l/1WXx2+DPo9Dqz1FHZ3XxmfKFNlgDAq64vmyyRRXAL9MIrP/XHiwOrwEl8hCyFI87G+WPNu1txZck2iHq91CUSEREREREVSKfTYerUqahatSocHR1x8+ZNAMCXX36JxYsXS1wdWSKnKk6oG5gFADh7NhO61FSJKyIiIiIiIiIiqnhcvOwAAOp4499jIiIiIiIiIiKiykmpsoGdsxIAoI5Ll7gaIiIiIiIiIrJkbLRkZqIoFro8Pj4eOp0O3t7eee739vbGgwcPjK6nVqvh6OgIpVKJnj17Ys6cOXjuueeMjtdqtdBoNHkuxVXFqfDOt/qM6ki/MxQ2ggJ7b+3F1BNTi9xvKrlOb7WAZxWbnBsim9SQdQjq0ghD5r2M4OaAjS4DyXY+2HfKAZtHLkLcsfNSl0dERERERJTPd999h2XLluHHH3+EUqk03N+oUSMsWrRIwsrIkrUZ2wVyvRbJdn64OO8vqcshIiIiIiIiIqpwchstpWsykZmRLXE1RERERERERERkaVw8HzfqZqMlIiIiIiIiIioEGy1ZKScnJ5w/fx6nT5/Gd999hwkTJiAsLMzo+GnTpsHFxcVwqV69erG3FRzkDl8XFYRCxnjIG+KHDj9AJsjw57U/Mfvs7GLPT8VTvb47eg90R9MLc+GUfCfnTlEnbVFExSC3kaP16C54/YeOqOmpBkQ97itrYePSB9j//kJk3IuVukQiIiIiIiKDFStW4Pfff8eQIUMgl8sN9zdt2hT//vuvhJWRJbN3s0eD2jnXL0QIyFIXv8k5EREREREREREVzdZeAVuHnB8o08RnSFwNERERERERERFZmtxG3Zp4NloiIiIiIiIiIuPYaElinp6ekMvliI3N22gkNjYWPj4+RteTyWSoVasWmjVrhg8//BD9+/fHtGnTjI6fOHEi1Gq14XLnzp1i1yiXCfiqdwMAMNpsKTNbj5oObTG5zWQAwJLLS7D08tJib4OKR+HpiSryODybuQOdmjyCS3aC1CURFZuDuwOe/7YP+o6tDQ95IvRyJf7JqIlVkw7j/Iw10Gu1UpdIRERERESEmJgY1KpVK9/9er0eWVlZElRE1iJ4TBcodOlItfPGhV+2SF0OkcmJoghdll7qMoiIiIiIiKgSc/F8fLJcHE+WIyIiIiIiIiKivJy9mB0RERERERERUdHYaEliSqUSLVu2RGhoqOE+vV6P0NBQtG3bttjz6PV6aAtpUmJrawtnZ+c8l5J4vpEv5r/eAj4uqjz3ezvbwtdZhUfpWRj02wk0cemOD1p+AAD4KfwnbL62uUTbocIpfHxQa38ogjasR8N3+uK1hQPRc2xDVAlwgr2zEnZOCqlLJCqSb7MADJrbD526OUClS0aGrTuO3vDGurdX4/aWA1KXR0RERERElVyDBg1w+PDhfPdv3LgRzZs3l6AishYqJ1s0bJyTzVy8oYI2PlHiiojKJv3SZdwaNhxpFy/hdkQCNk4/g+WfH0VyYobUpREREREREVEllXuynJonyxERERERERER0VNccrOjeGZHRERERERERGScjdQFVHSCIBQ5ZsKECRg2bBhatWqF4OBgzJ49G6mpqRgxYgQAYOjQoahatSqmTZsGAJg2bRpatWqFmjVrQqvVYseOHfjjjz8wf/58s+7L84188VwDH5yKSsTD5AxUcVIhOMgdj9Iy8friU/jnvgav/n4CK0f2x6OGj7A0YimmHJ8CZ6UzugZ0NWttlYlMqfzvukyGwKbeCGhSBfpsEXIFe6eRdRAEAQ37h6B2ryyc+GUvIq7LkWgXgG07dQjcuQDPvtcNLg1rSV0mERERERFVQpMnT8awYcMQExMDvV6PTZs24cqVK1ixYgW2b98udXlk4VqP7ITI/9uDdJUnzv2yFW2+GS51SUSl9mjLX7hzVYOjC6OQlBUHCABEICMlC07uqiLXJyIiIiIiIjI1F0+eLEdERERERERERAVz9mSTbiIiIiIiIiIqGhstmZkoikWOGTRoEOLi4jB58mQ8ePAAzZo1w65du+Dt7Q0AuH37NmSy/xropKam4p133sHdu3dhZ2eHevXqYeXKlRg0aJDZ9iOXXCagbU2PPPd5ONpizagQvLH4FC7FqDF44QmsGPEm1JlqbLq2CR8f+hjzu81HiG+I2eurrARBgFxRdFMvIkujVCnQ4ZMX0fh2Ag7+HIaYVDdEow5ifopEI5/DaP1JPyhcnKUuk4iIiIiIKpGXX34Z27ZtwzfffAMHBwdMnjwZLVq0wLZt2/Dcc89JXR5ZOKW9Ek1a2uPMeeDyHSc0vx8LW19vqcsiKrasmBhkJSYh5k4mTlyrDk3TtkCm3tBkiYiIiIiIiEhKzl45J8tp4tIkroSIiIiIiIiIiCyNy+PsKCVJC12Wnj9mT0REREREREQFYqMlM0tOTi7WuPHjx2P8+PEFLgsLC8tz+9tvv8W3335b1tJMytVeiZUjQzB86Smcu/0IQxafxJLh46HWqhF6OxTv7X8PS3osQUPPhlKXSkQWyM3fA6/8rx+iwiJxeM2/SFa44lyCI669tw1t2juizpu9IcgYchMRERERUflo37499u7dK3UZZKVavNkBl8fvQIatG07/sh3PTntL6pKIiu1U/3G4XuMVpDj5A3ZVc+4UmMkQERERERGRZcg9WU4dnyFxJUREREREREREZGnsnBSwsZUjW6uDJiEdbj4OUpdERERERERERBaIjZZKYMWKFaVar1mzZmjSpImJq7E8LnYK/PFWCEYsPYXT0UkYviQcC4d/ipTMFJx8cBJj943FsheWoYZLDalLJSILFdSpAQLa10P4kkM4dyoVKXa+2HcGiDi6CM+OaIkqHVoaXVcUReizRYT0yLAAAQAASURBVP7qABERERERlUmNGjVw+vRpeHh45Ln/0aNHaNGiBW7evClRZWQtFEobNGvrihMns/FPrAda3o6BnX9VqcsiKpSYmYnbf4bicqO3kS1X5dwpCNIWRURERERERPSU3EZLKQkZ0Ov0kMn5/QAiIiIiIiIiIsohCAJcPO2QEJMCdRwbLRERERERERFRwdhoqQSWLl1aqvVGjBhRKRotAYCjrQ2WvxmMt5adwfGbCXhr6QXMe30yUrI+QURCBEbvHY0Vz6+Ar6Ov1KUSkYWSyWVoPaoTGvZLxeHZ+3A91gH3bWvhzz/iUOfP39Du45dhV80H6Zcu4+HMmfD68EPEy/1wcutNJCdmYMDE1nByV0m9G0REREREZKWio6Oh0+ny3a/VahETEyNBRWSNmr7+DC4e3440pTNO/bwTHf83UuqSiAqUdvMWIpaH4spNAWqHAED+xEJRZLMlIiIiIiIisigOLraQ28igy9YjOVFraLxEREREREREREQE5DTqTohJgSY+XepSiIiIiIiIiMhCsdFSCRw4cEDqEqyCvdIGS0e0xtt/hOPQ1TiM/SMCswZ/i/lZHyBaE423976N5S8sh7vKXepSiciC2bs7oMc3L6PZxds48PtpJMAN/2prI/rLI2hRV4sq6Tdw56oGRxdGISkrDhAAiEBGShYbLRERERERUYlt3brVcH337t1wcXEx3NbpdAgNDUVgYKAElZE1slHI0aJzFRw5mI5/H3mj5bVoONYOlLosIgCAmJ2Ne9vCcHHnVdzWVUO2IhBwAARRh6ouKajX0hUPZ8/BtdoDkG7vzYZLREREREREZDEEmQBnTxWSHqRBE5fORktERERERERERJSH8+O8SBOXIXElRERERERERGSp2GiJzEKlkOP3N1pi3KqzCP33Id5ffQ3fD/gev12fgGhNNN7Z9w4W91gMB4WD1KUSkYXzbuKPQXOqI3LzGZzYeQ8Ztu44Fg3Is92ga/oskKk3NFkiIiIiIiIqrVdeeQUAIAgChg0blmeZQqFAYGAg/ve//0lQGVmrxoPa4HzYFqQoXHBq7h50+fltqUuiSi7j7n1ELtuDK1eykegQBMjqATLATkxBvUb2aDrkGTi42yPrwQMIc+JQNW0TTqn6IEHmI3XpRERERERERAbOXnZIepAGdXw6qktdDBERERERERERWRQXz5wf7VbHp0tcCRERERERERFZKpnUBVDFpVLIMf/1lni+oQ8ydXpM3HAHbwR+BzdbN0QkROD/9v8ftDqt1GUSkRUQBAEN+7ZGnYg/oNQ+AgDobFSPF/JPGRERERERlZ1er4der4e/vz8ePnxouK3X66HVanHlyhX06tVL6jLJishkAlr1yDnd72pqVagvX5W4IqqMRL0eD3Yewp6xv+KPySdx/G71nCZLoh6+Dmr0GOSH4fN7o9273eDgbg8AUPj4oNb+UARtWI9eU3tCrsv58qGdXAt7ZyXsnBRS7hIRERERERFVci6edgAAdRxPliMiIiIiIiIiorycvZgdEREREREREVHh2J2iBDp37owuXbqU+LJixQqpS5eM0kaGOa81R++mfsjSifh6UzwGB3wDext7nHxwEp8e+hTZ+mypyyQiKxHdbgwybV2lLoMkkpmZidq1a0MQBGzcuFHqcgolCAIEQcCUKVOkLoXIqoWFhRn+ewoLC5O6HLIgnTp1giAI6NSpk9SlEBUoMDAQgiBg+PDh5b7tcePGQRAEDBs2rNy3XVFERUXB09OzyHGNGzfGnTt3yqEismYNXmkJZzyCzsYOJ+cfkLocqkQyH8bh4oxVWD9sEf7ckolrYj1kKp1hq09D49pZeP3rYPT9Xx/U6lwPMpmQb32ZUglBEODo7YLgtg4AAG0m8GIfFzi6qcp7d4iKjfkRUeXD/IiMYX5Elo75EVHp5Z4sp4nnyXJERFQyzI6IKh9mR2QMsyOydMyOiErP5YnsSNSLEldDRETWhNkRUeXD7IiMYXZElo7ZUdmx0VIJDB8+HMOGDSvxpWnTplKXLimFXIbZg5qhb4uq0OlFzNiaioHVJ0MhUyD0dii+Of4NRJHhFREVrdNbLeBZxSbnhqiTthgqdz///DOuX7+ORo0aoV+/fvmWDx8+XLIDw5J48g24OfFNvnnkvkk2Zxg5ZcoUvhGnfHLf/C5btsxs27CW11EqvvL4W7Bs2TLDdoq6mPP5+2QtgYGBZt2OJSjsNeHTTz+FUqnEH3/8gfDw8PIvrhKJjo5GVlaW1GWQhRNkAkJeqgkAuJHpj8QzlyWuiCoyURQRd+AE9r/7K1Z8egiHb/gi3qEWIMhQRfUIXV/2woj5L6LDhz3g4uNc7HmbD+8IdyEBerktDi88BVHHTIYsF/OjkmF+ZB7Mj0gqzI+oNJgfVVzMj6giyz1ZTh3HRktERFQyzI5KhtmReTA7IqkwO6LSYHZUcTE7oorM0V0FQSZAl6VHqjpT6nKIiMiKMDsqGWZH5sHsiKTC7IhKg9lRxVUZsiM2WiqB0jRZYqOlHHKZgJn9m+LV1tWhF4G5O4FX/D6FTJBh8/XNmBU+S+oSicgKVK/vjt4D3dH0wlw4Jd/NuZMNlyqF5ORk/PDDDwCAL774wuxhDxERmU5uEFYZQgQiS+Dv749hw4ZBFEV8+eWXUpdDRABqv9AEbrJH0MttcXLRUanLoQooOzEJkT+vxZ9Df8OGtcn4J6setLZuUOjTUT9Qi9c+b4YBs/ui3guNIZeX/CMBQSag6zshEPTZiFUG4dLczWbYC6KyY35ERGS9mB8RlS/mR2TtchstaeLS+cNuRERUbMyOiIisF7MjovLF7IisnVwug5O7LQBAE58mcTVERGQtmB0REVkvZkdE5auiZEc2Uhdgja5fvw5PT0+4urpCrVYjLi4OtWrVkrosiyeTCfi+T2Mo5DL8ceIWlux1xMBO72Jn7M9YGrEUripXvNnoTanLJCILp/D0RBV5HPwydyC9yWCcC8+EWlFF6rLIzObPn4+EhAT4+/tjwIABUpdTJH6hl4iIKqPdu3fDz8/P6PJq1aqVYzWV24cffoiFCxdi586dCA8PR8uWLaUuiahSEwQBIf3rYdf6B4jSByLu6Fl4PdNC6rLIyomiiEcnzuHiulO4keSGdLsqgENOPuKhUKNRlwDU69URNgq5SbZXpbE/GgScR8QdR5y6IEfN2/fh4O9rkrmJTIX5ERERkeVjfmQ5mB+RNXPyUAECkKXVIT05C/bOSqlLIiIiK8DsiIiIyPIxO7IczI7I2rl42UETnwF1XDr8artJXQ4REVkBZkdERESWj9mR5agI2REbLZVCeHg4wsLCMH/+fHz++efo0KEDGy0Vk0wm4JuXG0JpI8PiI1FYH+aLF58dgcMJSzErfBZclC7oV6ef1GUSkQVT+Pig1v5QCAoFBEFAfb0ety/F4fSO20hJ0sLOSSF1iWRiOp0Oc+fOBQAMHjwYMplM4oqIiIioIHXq1GEHeAtRt25dtGjRAmfPnsWcOXOwbNkyqUsiqvRqdK4Pz03/ID7bDSeWnUZvNlqiUspOTsGNVbsReTwW921rQpTVAewAG70WNarr0OzVEHjV9jLLtp+Z8Dyi3vsbaUoXHPrhb7wwb6RZtkNUGsyPiIiIrAPzI8vB/IismY1CDkdXW6QkaaGJT2ejJSIiKhKzIyIiIuvA7MhyMDsia+fsZQ/8kwRNfIbUpRARkRVgdkRERGQdmB1ZjoqQHfGIrxQGDRqExMRELFq0CAkJCRg0aJDUJVkVQRDwRc/6GNupJgBgx5G6aO6c01zpmxPfYO+tvVKWR0RWQKZUQhCEnOsyGQKbeqP/Z60w9Lt2cHRTSVwdmdrevXtx584dAMCQIUMkroaIiIjIOuQeN23YsAHJyckSV0NEgiCg7WtNAAB3hBq4v++ExBWRtdGcu4wjH/+OleO2Yt95N9yzqwdRpoCrXI1nOzpgxC/P4bkve5mtyRIAKOyUaN8/CABwMzsQ0ZsOmG1bRCXF/IiIiIio5JgfkTVz9rQDAKjj0iWuhIiIrAGzIyIiIqKSY3ZE1szZM+ecEmZHRET0/+zdd1wT9/8H8FfC3lsEBy60VnCLs+6qbbWOOlq31r3601qrtlU71LZaO5zVbx11711rFcWtKIrirgpOFBAEZEM+vz8oEcwgQMIl8Ho+Hmkx97m7d8LlcvcieZ8umB0RERERFZypZ0dstFRAbdq0Qdu2bXH79m2MHDkSt2/fVt5HupPJZJjSsQY+aecLADh+riHesHsbCqHA58c/x5knZySukIhMjUwmg5kF39ZKoi1btgAAfH194e/vX6hlBAUFQSaTQSaTISgoCEII/PHHH2jRogXc3Nzg6OiIgIAArF27Ns986enpWLZsGZo0aQJXV1c4ODigefPmypo0yVnXrFmzClWvoQ0ePBgymUzZvfXp06eYPHkyqlevDltbW5QrVw69e/fGtWvX8swXERGBCRMmoHr16rCxsYGnpyf69euHu3fv6rTeo0ePYtCgQahSpQpsbW3h6OgIf39/fPbZZ3jy5InWea9evYrvvvsOHTt2RPny5WFlZQV7e3v4+vpi0KBBOHtW+xfVZ82apfy9AEBqairmzZuH+vXrw8HBAQ4ODggICMCiRYuQmZmp0+ORWnR0NL755hs0b94cZcqUgYWFBVxcXNC4cWNMmTIFV65c0ThvREQEJk6ciFq1asHBwQG2trbw9fXFyJEjERYWpnW9r2/f58+fx0cffaT8vZQrVw4DBgzAjRs38n0MKSkpmDNnDurUqQM7Ozu4ubmhefPmWLFiBRQKRYGeD138+eefyvoPHcq/uefIkSMhk8lgZWWFuLi4PNP0vU3Gx8fj22+/Rb169eDs7AyZTGZ0nXxTU1Px22+/oXXr1vDw8ICFhQVcXV1Ro0YNvPPOO1iwYAEiIiKU43Me45o1awAA9+/fVz7m3Dd1zp49i169eqFs2bKwtrZG5cqVMWLECNy6dctgj2/16tXKmiIiIqBQKLB8+XI0a9YMLi4usLOzQ+3atTF79mwkJydrXI5CocCRI0cwefJkNG/eHO7u7rCwsICzszPq1q2LyZMn48GDB1prad26NWQyGVq3bg0AePz4MSZNmoRq1arBxsYGbm5u6NixIw4cOKDPp6DES0pKwubNmzFs2DDUrVsXTk5OsLCwgIeHB1q1aoX58+fj5cuXOi3rwIEDePfdd+Hh4QFbW1tUr14dkyZNwuPHj7XOV7VqVchkMjRv3jzfdTx+/BhmZmbZ589TpuhUV24ffJDd0Dg5ORm7d+8u8PxEpH8Vm/nC0yoWQm6GcxuvQAghdUlk5BQpKbi7ag92D1mM9Use4nJiNSTZloWZIgNVy7xEj3E10G9xd9T5qDEsrc2LpaZqHeuigv1zQCbHiT1PkJmYVCzrJcoP8yP9Y37E/Ij5EfOjwmB+xPzI1DE/IjIdTh5stERERLpjdqR/zI6YHTE7YnZUGMyOmB2ZOmZHRKaD2RERERUEsyP9Y3bE7IjZEbOjwmB2xOzI1DE7MjGCCmXmzJmib9++YubMmVKXUijx8fECgIiPj5e6FLHoyL/C5/N9wufzPeK9jcOE32o/0WhdI3El6orUpRFRCVTU/V9KSoq4fv26SElJ0XNlpEmlSpUEADFgwACt4wYNGiQAiEGDBqlMO3r0qAAgAIh//vlHdOnSRfnv128TJkwQQggRGxsrWrZsqXHc7NmzNdaSM0bdcULuWgwpZx1Hjx5VmZbzXPn4+IjQ0FBRtmxZtY/Rzs5OnDhxQgghRGBgoHByclI7zsXFRVy9elVjLSkpKeLDDz/U+FzmrGvPnj1q58/9nGm7TZ06VWMNM2fOVI57+vSpqFu3rsbldOnSRWRlZaldTqtWrTT+bvUlp9ZWrVppHLNu3TphZ2en9fnw8fFRO++aNWuElZWVxvnMzMzEnDlzNK479/a9ePFiYW5urnY5tra24tixYxqXExkZKWrWrKmxjo4dO4qDBw9q3ZYLKiEhQdjY2AgAYvDgwVrHpqenC1dXVwFAdOvWLc80fW+Tt2/fVu7rct9WrVqlHO/j46Nyn75p248+efJEvPnmm/k+5k8//VTtY9R2e92CBQuEXC7XuK/Yv3+/8rWo7XVSUKtWrVKu59q1a6Jdu3Yaaw4ICBAvX75UuxxdHretra3YsWOHxlpyP76TJ08Kd3d3jcuaN2+exuXo8/WjSe7nLTw83GDrKUgtmvZ/Oc+rtlvlypXFjRs3tK5n4sSJGuf38PAQ58+fV75mX389ffnllwKAkMlk+T5f8+bNUy43NDQ0zzRd9wk57/F9+/bVOq44laTj6fXr12vcF5QExpQdlSSPQyLEopGBYtGIQ+Lh3uNSl0NGKvH6bXF62nKxpv+a7O3lv9uaUTvF+VUnREpSurT1PY0Ty4btE4tGBooT01dLWouhMD8yPcyPCkfbOQPzI+ZHzI+YH6nD/Ij5UWEwP8p7Y36kHY+lTYuU+dH5v8LFopGB4tCqa8W+biIiZkemh9lR4Wg7X2B2xOyI2RGzI3WYHTE7KgxmR3lvzI6047G0aZEyO4p+mCAWjQwU/5vEz+YQUfFjdmR6mB0VjrbzBWZHzI6YHTE7UofZEbOjwmB2lPfG7Ch/uh5Py0EFdunSJZw7dw7r169HcHAwQkNDpS7JpI1tUw1fvlcTgBxXL3eGp4U/UjJTMCZwDO69uCd1eUREJiMl7CruDxqMlLCrUpeiN48ePVJ2mW3UqJFelvnVV19h79696NevH/bv34+QkBBs3LgRNWrUAAD89ttvOHz4MAYPHozTp09j9OjR+OeffxASEoI//vgD3t7eAIAZM2aodM42NcnJyejevTvS09MxZ84cnDp1CmfPnsWsWbNgaWmJpKQkDBgwAHfu3EG3bt3g4OCAX3/9FWfPnsXJkycxceJEyGQyxMXF4eOPP1a7DiEEevbsiU2bNgEAunTpgrVr1+LUqVM4c+YMfv31V1SsWBFJSUno2bMnLly4oLKMzMxM2NnZoXfv3li2bBmCgoJw8eJF/P333/jpp5/g4+MDAPj++++xatWqfB93jx49cP36dUyYMAGHDh1CSEgINmzYgJo1awIA9u7dixUrVhT2aTW4tWvXon///khKSoK1tTXGjx+Pv/76CxcvXsTx48exaNEidOjQAXK56qH+/v37MXjwYKSlpcHe3h4zZ87EiRMncObMGfz0009wd3dHVlYWpk+fjqVLl2qt4+DBgxg/fjxq1aqFlStX4vz58zh+/DgmTpwIuVyO5ORkDBgwAOnp6SrzZmZmonPnzsru4R06dMDOnTtx4cIF7NixA+3bt8fBgwfx5Zdf6udJ+4+DgwPef/99AMCOHTuQmpqqceyBAwcQGxsLAOjXr59K/frcJnv27InHjx9j/PjxOHToEC5cuJBnv2QMxo8fj+vXrwMA+vfvjx07duDs2bM4f/489uzZgxkzZqBOnTp55hkzZgzCwsLQtWtXAIC3tzfCwsJUbrnt3LkTkyZNgkKhgJOTE+bMmYPTp0/j9OnT+O6772BmZoZ+/frlezWBoho+fLjyagY57xU7d+5E06ZNAQDBwcH47rvv1M6bmZkJLy8vjBkzRrm/CwkJwa5duzBlyhTY29sjOTkZffv2zbeDfmRkJLp16wa5XI7vv/8eJ0+eRHBwMBYsWABnZ2cAwLRp04zm/WjIkCHw9vaGpaUl3N3d0aRJE3z55Zf5dssuLpmZmfD398cXX3yBnTt34ty5czh79iw2b96MDz/8EHK5HOHh4ejWrZvG/cMvv/yCn3/+GUD2Nr1w4UKcO3cOx44dw5QpUxAfH49evXpp7B6fsz8RQmDDhg1a682ZXqtWLZXXl64CAgIAAMeOHSvU/KVZYGAgpk+fjmHDhmHo0KF5bjn69u0LOzs7CaskU+Rd3wfetnGATI5z229ACCF1SWQkFOnpuL/hL+z7eDHW/XQbF2OrItGuPGQiEz6uieg6ohoGLOmKhoNbwNrWQtJa7T2d0bBx9tUfrz7zwPML1yWthwqG+ZFumB+9wvyI+RHzI+ZHumJ+xPxIF8yPmB8R6YuTR/Z5aUJ0isSVEBGVLMyOdMPs6BVmR8yOmB0xO9IVsyNmR7pgdsTsiEhfHN2zs6PUpAykpWRKXA0RUcnB7Eg3zI5eYXbE7IjZEbMjXTE7YnakC2ZHzI70yrD9nkqmffv2ievXrwshhLh165bYu3evxBUVnJSdwTVZfSpc+Hy+T/hM3S7eWttV+K32E223tBWPEx9LXRoRlSAluTN45Lffies13hCR32nuWG1qNm/erOyImdOhujBe7+L7yy+/qIyJjIwUDg4Oyq6eMplM7Ny5U2Xc5cuXlR1rc7qIvy5nPYbsHl0UOd1/AQh3d3dx584dlTGLFi3K0+XU19dXREVFqYz77LPPlOMuXryoMn358uUCgLCwsBAHDhxQW09sbKyoVauWACCaN2+uMj06OlrExcVpfDxpaWni7bffVnaDzczMVBmTu1OvhYWF2i65z58/F56engKAqF27tsb1SenJkyfC1tZWABBlypQRYWFhGsc+ePAgz7/T09OFt7e3ACDs7e3FpUuXVOaJiIgQXl5eys7F0dHRKmNyv5beffddkZaWpjLmu+++U45R1/049/Y1YsQItfUPHTo0z7r01dl4z549ymVu3bpV47g+ffoIAMLR0VFln6/vbVIul4uDBw8W+jEZWkpKirCwsBB4rfO3Os+fP1e5L/fVCLRJS0tTbqNOTk7Kc67cwsLChKOjo/K5M1RncABi7dq1KmNSU1OFn5+fACDc3NxERkaGypjw8HCRnp6ucT0PHz4U5cqVEwBE//791Y7J3cHax8dHPHr0SGXMiRMnhEwm0/p+VBxef97U3aytrcWyZcskqzHH7du3tU4/dOiQ8j3+f//7n8r0Z8+eKffBPj4+IjIyUmVMYGBgnismqOu0X79+fQFA1KpVS2MtN27cUC5D29Ua8vP1118rl/P06dNCL0efjPl4OsesWbOEXC4XAQEBomvXrqJbt255boWxaNEi4ePjI6ysrERAQIA4d+6cxrFXr14VPXr0UHaA//nnn1XGzJkzRzRs2FDY29sLDw8P0bVrV3Hz5s08Y9R1wx85cqTONRtjdlRSPL36UCwacUgsGhkowrcckrockljS3XARPOMPsa7/SrFoZKDytmrkbnH29yCRFG+c+0tFlkJsGLVFLBoZKLYO+Z9QaLi6kqlifmRamB8ZBvMj5kfMj5gfFQTzo1eYH6lifpQX8yPtjPlYmlRJmR89i4gXi0YGipWfFf4cgIiosJgdmRZmR4bB7IjZEbMjZkcFwezoFWZHqpgd5cXsSDtjPpYmVVJ/9uiPycfFopGBIup+giTrJ6LSi9mRaWF2ZBjMjpgdMTtidlQQzI5eYXakitlRXsyO8qfr8bRqu0DK13vvvafsHFm9enV07txZ4opKhkHNKmFOd3/IYIUHN/rCXl4OUclRGHloJJ6nPJe6PCKiAhNCQJGcbNBb2p27SL4QguSQECTs3w8ASNi/D8khIUi+EIK0O3cNXoMQwmDP4aNHj5Q/lylTRi/LbNy4MT755BOV+8uWLYvu3bsDAKKjo9G7d29069ZNZVzt2rXRokULAMCJEyf0UpOUvv32W1StWlXl/qFDh8La2hpA9vPx22+/wcPDQ2Xc6NGjlT+//nwIIfDDDz8AACZMmIBOnTqprcHFxQXz5s0DAJw6dQr//vtvnunu7u7KDrjqWFpaKue/f/8+QkNDNY4Fsjsct27dWuV+V1dXDBkyBAAQFhaG+Ph4rcuRwsKFC5XdZpcvXw4/Pz+NYytUqJDn3zt37lR2U/7yyy9Rt25dlXl8fHyUz2VycrLWrtbW1tZYtWoVLC0tVaZNmDBBeb+618mSJUsAAJ6ensoOu6/79ddf1W5zRdWpUye4ubkBANavX692zMuXL7Fnzx4AwAcffKB8LeTQ9zY5ePBgdOjQQcdHUPxiY2ORkZEBAGjZsqXWsa6uroVez+7du5Xb6FdffaU858rNz88PX3zxRaHXoasePXqgf//+KvdbWVlh3LhxAIDnz58ru6XnVqlSJVhYWGhcdvny5fHZZ58BAPbs2ZPv++jChQtRrlw5lftbtGiBxo0bA5D+/ahKlSqYPHkytm/fjuDgYAQHB2PTpk3o1asXZDIZUlNTMWrUKCxfvlzSOn19fbVOb9++vfLqAbt27VKZvmbNGuU++KeffkLZsmVVxrRt2xbDhw/Xup6c7uDXrl3D5cuX1Y7J2T/JZDL07dtX6/K0yX38dO/evUIvp7RZtmwZVq9ejXPnzmHXrl3YuXNnnltBbd68GZMmTcLMmTNx8eJF1KlTBx07dkRUVJTa8cnJyahSpQq+//57tdsZkN3tfezYsTh79iwOHTqEjIwMdOjQAUlJSXnGDR8+HJGRkcrbjz/+WOD6Sf88a5VHBcfsY83gfREQCoXEFVFxEEIgKyP7dy0yM/FoxyH8PXwR1s2+guBnlfDCzgcyoUB5xwS8O6AiBi3pgsYjWsHW0TqfJUtDJpeh7ejGkCmy8MyyMq4u3iV1SSapOLIjY8iPDJkdAcyPigPzo1eYHzE/ysH8KC/mR68wP1KP+dErzI+I9MPR3QYAkJyQjoy0LImrISIyjNKSHfGzR8yOmB0VL2ZHRcfsqOCYHb3C7Eg9ZkevMDsi0h8nj+z8KD46ReJKiIgMg9mRfjA7MjxmR68wO2J2lIPZUV7Mjl5hdqQes6NXmB3pj7nUBZiqmJgYuLu7S11GidO3cUVYmssxZdtlPL01EO7VlyMiIQKjD4/Gyo4rYW9pL3WJREQ6EykpuFW/QbGvNys2Dvf7qR5kG0qNiyGQ2doaZNnR0dHKn11cXPSyzA8//FDjtDp16ug87vjx4yZ34Pc6mUyG3r17q51mY2MDX19fhIWFwcXFBR07dlQ7rnLlynBwcEBiYqLK83H9+nXcvXsXANCzZ0+tteQ+CT5z5ozWk4q0tDQ8e/YML1++hOK/L6XnPuG7fPkyGjTQ/NrLOVFQJ2c+IQTCw8PVhjpS2rdvH4Dsk8OckypdHT58GED2733o0KEax/Xq1Qtjx45FfHw8Dh8+rDyxft3bb7+tMUh2cHCAr68vrl27prJdREZGKk/ye/fuDVsN+w97e3v07t0bixcvzvexFYSFhQV69eqFZcuW4cCBA3jx4oVK+LRz506kpGT/YVXb9pLDkNukMXBzc4OlpSXS09Oxdu1avPvuuzA31/+pZO5tdNCgQRrHDRkyBFOnTjXoH0x02U8A2QFA7dq1tS4rISEBz58/R3KuP/LkbPcJCQkIDw9HlSpV1M7r7OyM9957T2stZ8+elfT9qHv37hg0aBBkMlme+xs1aoQ+ffpg37596NGjBzIyMjBx4kS8//77GhvHFLfo6Gi8ePECaWlpyvtygnJ1QVLONuri4oKuXbtqXO7QoUOxdOlSjdM//PBDfPbZZ1AoFNiwYUOe448cGzduBAA0b94cPj4+uj0gNXKHyE+fPi30ckqb9PR0NGvWTG/LW7BgAYYPH678w9iyZcuwf/9+rFy5ElOnTlUZ36hRIzRq1AgA1E4HgL///jvPv1evXo0yZcogJCQkz3GVra2t0bzmKK/mI1tg87wriLapgrsb/ka1/u9KXRLpWUrYVUTNnw+PTz9FjJk3zu25h8SYZLzp8ADhd1IRa18VMHsTMAOsRRLe8LNBnY+awt7dTurSdeZZuyJqVgzF9Uf2OHcRqPowErYVvKQuy6RIlR0BxZsfGTI7ApgfGRrzI1XMj5gfAcyPXsf8KC/mR3kxP1LF/Iio6KztLGBla4605EwkxKTArRw/T0REJU9pyY4AfvbIlDE7UsXsiNkRwOzodcyO8mJ2lBezI1XMjoj0w9HdBk/vJSAhho2WiKhkYnakH8yODIvZkSpmR8yOAGZHr2N2lBezo7yYHalidqQfcqkLMEURERFo3ry51GWUWD0blMfPfepCrnBGzJ3BsIADbsTewISjE5CWlZb/AoiIqMSIjY1V/qyvwKp69eoap+U+adVlXGJiol5qkoq7u7vWLr45j7NatWoqJyLqxr3+fFy4cEH5c9OmTSGTyTTe7O1fffhZ3QF1UlIS5s6dizp16sDOzg4+Pj6oVasW/P394e/vj3r16inHxsTEaH3cb7zxhsZpuZ8PY/v9ZmRk4OrVqwCyOwJr+52okzNv5cqVtXbctrS0VD6fOfOoo+15BF49l68/j2FhYcqfc5pIaBIQEKB1emHlhBFpaWnYtm2byvQNGzYAALy9vdGmTRu1y9DnNplf4CE1Kysr9OnTBwCwbds2VKtWDVOmTMFff/2FFy9e6G09OdtG5cqVtTa19fDwQKVKlfS2XnWKup+4f/8+xo8fj0qVKsHJyQlVqlSBn5+fcvsYMWKEcqy27cPX1xdyuebTdk2vs+Lk5OSkdX/UuXNnzJgxA0D2FQf++OOP4ipNrVOnTqFPnz5wc3NDmTJlUL16deXvxd/fHytWrACg/veSs43Wq1dPa2hbt25dtVdNyJF737Jx40aV8PXcuXPKP/gUNdDOffyUlJRUpGWVJsOGDVO+FxRVeno6QkJC0L59e+V9crkc7du3x5kzZ/SyDgDKK5q8fmy3fv16uLu7w8/PD9OmTVN2tyfpuVXzRCW37P33hUPPIDIzJa6I9O3Frt14eDsBu1bcw96FlxF1PwEpSVkIeVouu8mSUMDLNh4denthyNLOaD6+vUk1WcrR/NNOsM2KR5qVM47/sE/qcqiUYn5kWMyPVDE/Yn4EMD96HfOjvJgf5cX8SBXzIzKUxYsXo1KlSrC2tkbjxo0RHByscezq1atVjrdev1KqsXN0twEAxEfzy3JERKQZsyPDYnakitkRsyOA2dHrmB3lxewoL2ZHqpgdkaGUuuzIg9kRERHlj9mRYTE7UsXsiNkRwOzodcyO8mJ2lBezI1XMjvRD/+3cSrirV6+iU6dOGDNmjNSllGhd65aDpZkc4zdewovwwXCsvALnn57HZ8c+w4LWC2Au56ZLRMZPZmODGhdDDL6e1Bs31HYC91m/DtY1axp8/TIbG4MtO/cfZFJSUuDg4FDkZWrqQgwgz0mBLuNyOgCbKm2PEXj1OHUdl5WVlef+qKioQtX1egOAiIgItG3bFuHh4TrNn9PRWRNdt4HXH4/UYmNjlSc1Xl5ehZofgMZu3rnldO3NHRq/rrDbRe5l5leLp6en1umFldNp9/79+1i/fj2GDRumnBYVFaXs/vvhhx+qDQv0vU3qK5A3pEWLFuHFixfYu3cv7t+/j3nz5mHevHmQy+WoX78+evfujREjRsDJyanQ6yjINurp6anz818YRdlPHDhwAD179tS5mYm27UPX15mxvx+NGDECM2bMgBACx44dwxdffCFJHbNmzcLXX3+t01h1vxddt1Fzc3O4urpq7cTdr18/BAYG4uHDhzh+/DhatWqlnLZ+/XoAr65kUBS5H4eFhUWRllWapKamYvny5Th8+DBq166t8twtWLBA52XFxMQgKytL5T3N09MTN2/e1Eu9CoUC//d//4fmzZvDz89PeX/fvn3h4+MDb29vXLlyBZ9//jlu3bqFHTt2qF1OWlpank75CQkJeqmPNGs6qjUivruA5zY+uLX6L7wxrGBXfiHjk/H4MTJi4/D4YTrO/FsBiXWaAukCkAH//QcWIhU1qpujbr8mcCrrKGm9+mBpY4m3PqiMg7ticTejMu7vOgafbq3yn5EAFF92BEibHxkyOwKYHxka8yNVzI+yMT9ifvQ65kevMD8qOOZHqpgflR4ZGRl4+vQpkpOT4eHhofXD5tps3rwZkyZNwrJly9C4cWP88ssv6NixI27duqVxm3R0dMStW7eU/y7oh6Wl5uRhg+gHiUiI4ZfliKhkKi3ZEcDPHpkyZkeqmB1lY3bE7Oh1zI5eYXZUcMyOVDE7ooIqrdkRwEZLRFRyMTvSD2ZHhsXsSBWzo2zMjpgdvY7Z0SvMjgqO2ZEqZkf5Y7eaAjh9+jQ6d+6MUaNGYfr06VKXU+K94++FpWZyjF0vQ+L9gbDzWYmjD49i1ulZ+Lb5tyYX0hFR6SOTySDL50BTL+vJCXVkMkAI5f9l1taQF8P6DSl39+LY2Fi9BFZUfHKfyO3du1fnTr6vnwgMGDAA4eHhkMlkGDJkCD788EPUrFkTHh4esLS0hEwmg0KhgJmZGQCodFilvIzpGEqqWmQyGfr27Yu5c+fi+PHjePz4McqVKwcA2LJlCzIzMwFo7sir720yZ5wxc3R0xJ49exAcHIwtW7YgKCgIoaGhyMrKwoULF3DhwgXMnz8fu3btQtOmTYu0LmPaRgsqJiYGffv2RXJyMuzt7TF58mR07NgRVatWhZOTk7Jb9JEjR9CuXTsApWOfVaZMGbi5uSEmJgaPHz+WpIbAwEBlWFWlShVMnjwZLVq0QMWKFWFnZ6fs9D1jxgx8++23Wpelj230gw8+wJgxY5CamooNGzYoA6usrCxs2bIFANCpUye4ubkVaT25/0iQ+woopN2VK1dQt25dAKpXyTDGfdTYsWNx9epVnDx5Ms/9ua9C4O/vDy8vL7Rr1w53795F1apVVZYzd+5cnUNd0g+Xiq6oVjYZ/0Y5IuREHKoPSIPcykrqsqgIzvUch3+r9USynRdgk318idf2G+9PbY6ylQv/Rz5jVK1TXVw/tBUPk9xwfNdDfPR2MsztTDuPKC7FlR0BzI/IeDE/Mk7GdNzL/Cgb86O8jGkbLSjmR+oxP1LF/KhkS0xMxLp167Bp0yYEBwcjPT0dQgjIZDKUL18eHTp0wIgRI/K9wmpuCxYswPDhwzFkyBAAwLJly7B//36sXLkSU6dOVTuPTCZTfojZFDnyy3JEVMIxO9IPZkemjdmRcTKm83JmR9mYHeVlTNtoQTE7Uo/ZkSpmR1RQpTE7cnLPzo4SmB0RUQnF7Eg/mB2ZNmZHxsmYzsuZHWVjdpSXMW2jBcXsSD1mR6qYHeWPjZYKoEOHDvj4448xZ84cqUspNd5+0xPLBzbAyLVA0sO+sC2/Drvv7oazlTM+bfipSb+ZERHpi7mbG8zc3WFRtiyce/bEi23bkPH0KcyLeIBjDHIHVnFxcfDx8ZGwGiqo3AfZzs7O8PPzK/Aybt68qWwaMH36dHz33Xdqx2nrYF1SuLq6Qi6XQ6FQIDIyslDzA8CzZ8/yHZvTzbawV03WJncX7Pxq0aXWwurXrx/mzp0LhUKBjRs3YvLkyQCADRs2AADeeOMN1K9fX2W+0r5NBgQEICAgAED2F0GCgoKwevVq7NixA1FRUfjggw9w9+5d2BTiqhE524Yuv3dDbhtFsW3bNrx48QIAsHPnTrRv317tuJK6fWgj9bnbihUrAGRvZ2fPns1zjJGbtt+Ni4sLnj59mu/2l5mZme/v2NHREZ07d8a2bduwbds2LFq0CBYWFggMDFQuX1NoXhBxcXHKnytWrFjk5ZUWR48e1duy3N3dYWZmprLdPHv2TC8fRBo3bhz27duH48ePo3z58lrHNm7cGABw584dtY2Wpk2bhkmTJin/nZCQgAoVKhS5RtKu6Zg2uDvjLF7YVMCNFftQa9wHUpdEBZQRG4uI7UG4ExyJcP8xEPL//hip4b3PzEz1yjMlQdvJ7bF+xhkkWHvj3Pdb0fzbQVKXRK9hfkTGivmRfjE/0i/mR4XD/Eg75keaMT/Ki/lRybVgwQLMnj0bVatWRZcuXTB9+nR4e3vDxsYGsbGxuHr1Kk6cOIEOHTqgcePGWLhwIXx9fbUuMz09HSEhIZg2bZryPrlcjvbt2+PMmTMa53v58iV8fHygUChQv359zJkzB7Vq1dI4Pi0tDWlpacp/JyQkFOCR65+TB78sR0SkL8yOyFgxO9IvZkf6xeyocJgdacfsSDNmR3kxO6KCKK3ZUU6T7pdxqcjKVMDMvGR+XoOIqDgwOyJjxexIv5gd6Rezo8JhdqQdsyPNmB3lxewof0wJCsDOzg6RkZGlonObMWldowxWDm4EizQ/pERmf9lszfU1+OPqHxJXRkRkHCzKlkW1I4GotHULXD7sg0pbt6DakUBYmPAVJHL4+/srf759+7aElVBh1KtXT/nzqVOnCrWMa9euKX/u06ePxnEXLlwo1PJNiYWFhTL0O3HiRIGPSXPmDQ8PR3R0tMZxGRkZuHTpUp559Cn36/r8+fNax+Y3vShq1aqFOnXqAHgVUoWHhyv/aKzpRJHb5CsODg7o0qULtm/fjgkTJgAAIiMjlYFeDl2DipxtIzw8HM+fP9c4Ljo6GhEREYUr2sBytg9XV1eNYRVQOraP3KKjoxETEwMA8Pb2lqSGnN9NmzZtNIZVgPbfTc42GhoaqryCgDqXL19Genp6vjXl7GdiY2Nx4MABAMD69esBZL++3n///XyXkZ+c4ycrKytUq1atyMujgrO0tESDBg0QGBiovE+hUCAwMLBIV1IQQmDcuHHYuXMnjhw5gsqVK+c7T2hoKADAy8tL7XQrKys4OjrmuZHhOZR1QvUK2R8yCzmfgqwUfjHQFGTGxeHOHztxYPhirJl0BP+EOOOeWc3sJktCkT0o5/+lhL2XCxoGZF+5LCzSA89DbkhcEb2O+REZK+ZH+sX8SL+YHxUd8yNVzI/UY36kHvOjkun8+fM4fvw4goOD8dVXX6Fjx47w9/dHtWrVEBAQgKFDh2LVqlV4+vQpunXrhhMnTuS7zJiYGGRlZcHT0zPP/Z6ensoPKb+uRo0aWLlyJXbv3o1169ZBoVCgWbNmePTokcb1zJ07F05OTsqb1E26ndyzPzwbz0ZLRERFxuyIjBWzI/1idqRfzI6KjtmRKmZH6jE7Uo/ZEemqtGZHto6WMLcygxBA4vNUSWshIjJ1zI7IWDE70i9mR/rF7KjomB2pYnakHrMj9ZgdacdGSwVw6tQpXLhwAUOHDpW6lFKneTV3rBkSAKuUAKQ+ew8A8OvFX7H19laJKyMiMg5yS0vlCYFMJoPc0lLiivSjYcOGsLbO/qKmIU9cyTDq16+P8uXLAwCWL1+O1NSC/5Eq9wlBUlKSxnHLli0reIEmqEuXLgCyT+h3795doHlzTp6FEFi1apXGcdu2bUN8fHyeefTJ29sbNWvWBABs3boVKRqaCSQlJWHLli16X39uOSeLly5dwo0bN5TBFQD07dtX7TzcJtVr166d8uecYCJHzn4895WK1Mm9jf75558ax61evdpom9/mbB+pqalQKNQ3V0hOTsbatWuLsyzJLV++XPk7a9WqlSQ15PxutL1uL126hHPnzmmcnrONxsbGYu/evRrHrVy5Uqea3n33XWVH/PXr1yM1NRU7d+4EAHTv3r1QHfZfl3P8VK9ePVhYWBR5eVQ4kyZNwooVK7BmzRrcuHEDo0ePRlJSEoYMGQIAGDhwYJ4rxqWnpyM0NBShoaFIT0/H48ePERoaijt37ijHjB07FuvWrcOGDRvg4OCAp0+f4unTp8r31bt37+Lbb79FSEgIIiIisGfPHgwcOBAtW7ZE7dq1i/cJoHw1GdMOZoo0JNp4I2zpHqnLIQ0yX7zA3VV78PeIxVgz8TAOnnfCPbOaSLN2hZkiHT4uiejQ0wsDRnuizuVFcEh8mD2jyJK28GJU/+M2cJE9R5a5NYIWn4LQcDxE0mF+RMaI+ZH+MT/SL+ZH+sP8KBvzI/WYH6nH/Khk2rhxI2rVqpXvOCsrK4waNcpgn1Fq2rQpBg4ciLp166JVq1bYsWMHPDw88Pvvv2ucZ9q0aYiPj1feHj58aJDadOXokf0aSHyeCkUWz0GJiIqK2REZI2ZH+sfsSL+YHekPs6NszI7UY3akHrMjMqSSkB3JZDI4uWe/h8THsFE3EVFRMTsiY8TsSP+YHekXsyP9YXaUjdmResyO1GN2pB0bLRVAtWrVcPLkSYSEhGDs2LFSl1PqNK7ihj8/bgzrpDZIi2kDAPj2zLf4J+IfiSsjIiJDsbS0ROPGjQEAwcHBEldTPCIiIiCTySCTydC6dWupyykSuVyO6dOnAwDu3buHgQMHaj1hTUhIwKJFi/Lc5+vrq/x59erVaudbunRpgcMbQxk8eLDy9xcUFKT35Y8bNw52dnYAgJEjR+Lq1asax75+1Zhu3bopO/LOnj0bYWFhKvM8fPgQkydPBgDY2toqG0Do2+jRowEAT58+xaeffqp2zMSJExEVFWWQ9ef46KOPlGH/+vXrsXHjRgDZfyCuUqWK2nmMdZts3bq1ctvTd9fse/fu4dixY1rH/PPPq2PyypUr55nm5eUFAIiKikJiYqLGZXTr1k059ttvv8WtW7dUxly/fh2zZ8/WufbilrN9JCcnqw1cs7KyMGzYMDx58qS4S1OrUqVKyu2mMCIiIpRXEtBk3759+OabbwAANjY2Gvcrs2bNUtai6bVVFDm/m5MnT+ZpVpMjOjoaAwYM0LqMQYMGKUOkSZMm4dmzZypjjh07huXLl+tUk6WlJXr27AkA2Lt3LzZs2KB8jWi6OkFBpKWl4cqVKwCADh06FHl5VHh9+vTB/PnzMWPGDNStWxehoaH4+++/lVeJe/DgASIjI5Xjnzx5gnr16qFevXqIjIzE/PnzUa9ePQwbNkw5ZunSpYiPj0fr1q3h5eWlvG3evBlA9vZ1+PBhdOjQAW+88QY+/fRTfPDBB1rDVpKOnZsdalbN/kNH6BUFMhNfSlwR5chMSMDdNXtwcORirPm/f/D3OXvclddEqrUbzBTpqOiciLd7eGLYorfReW5X+LavCZuyHihjFo0W6X+hde0XcMrUfMWTkkYml6Hd6ADIFFl4alkFV5cYx3kalXzMj1pLXU6RMD8K0vvymR/pF/Mj3TA/0h3zI1XMjzRjfkS6cnd3h5mZmco29+zZM5TV8WrSFhYWqFevntrtP4eVlRUcHR3z3KRk52wFubkMCoXAyzjtH5olIqLSi9lRa6nLKRJmR0F6Xz6zI/1idqQbZke6Y3akitmRZsyOSFelNTsCAEf37NdcQjQbLRERkXrMjlpLXU6RMDsK0vvymR3pF7Mj3TA70h2zI1XMjjRjdqSdudQFmBpvb28cO3YMnTt3lrqUUqmBjwvWDWuM/n8IpJslw9LlHD4//jnsLe3RzLuZ1OUREZEBdO3aFceOHUNwcDASExPh4OAgdUlUAKNGjcKhQ4ewc+dObN26FRcvXsTIkSMREBAAJycnJCQk4ObNmwgKCsKePXtgbW2NcePGKeevV68e/Pz8cPXqVfz++++Ii4vDgAED4OXlhUePHmHdunXYtm0bmjdvjlOnTkn4SItH2bJlsXTpUgwcOBBRUVEICAjA8OHD8c4776Bs2bJ4+fIlrl69ij179uDWrVu4e/eucl5LS0ssX74cXbp0QUJCApo3b47PPvsM7dq1g5mZGU6fPo3vv/9eGRLNnz8f7u7uBnkco0ePxqpVq3Dp0iUsXboU4eHhGDVqFCpUqICHDx9iyZIl+Oeff9CwYUNcuHDBIDUAQPny5dGqVSsEBQVh8eLFePHiBQDtJ4qlcZt88OAB2rRpgzfffBPdu3dHw4YNUa5cOQDZIefmzZuV4UzdunWVf2jI0axZ9nG6QqHAqFGjMH78+DzbVrVq1QBkb6MLFy5Ez549ERcXhyZNmuDzzz9H69atIYRAUFAQfvjhB+U82v5gL5XevXtj+vTpSEtLw5AhQxAaGoq3334bTk5OuHbtGhYuXIiQkJASs31ERESgTZs2aNq0Kbp06YI6deqgTJkyALKDzm3btmHbtm3KruDz589XbjvFbeDAgdi7dy+SkpLQqlUrTJ06FQ0aNAAAnD59GgsWLMDTp0/RtGlTnDlzRu0yPD098e2332Ly5MmIiIhAgwYNMG3aNAQEBCA1NRV//fUXfv75Z5QrVw7JycmIjo7Ot65+/fphxYoVSElJUQb4np6eebrtF9bx48eRkZEBILvTOElr3LhxeY5xcnv9j1yVKlXK9woI+U2vUKFCvn9sIOPSeFRb3Jx8FEnWnri8aA8aTFN/lRIyvMzERDzcfRy3T97H4xR3pNi4A7KagDVgpsiAt0sKqrepimpt34S5pZnK/BZly6LakUDILCwgk8lQU6HAg7BonP/rAV7GpcHGwbSu1FBQnrV98EaFUNx47IDgEAWqPXoKm/K6fTCTqCiYH5k25kf6xfxIv5gf6Yb5ke6YHzE/Yn5Er7tw4QK2bNmCBw8eID09Pc+0HTt26LQMS0tLNGjQAIGBgejWrRuA7H1qYGCgxkzqdVlZWQgLC8O7775boPqlJJfL4OhmgxfPkhEfk6L84hwREdHrmB2ZNmZH+sXsSL+YHemG2ZHumB0xO2J2RIZQWrMjAHD0yM6L4tloiYiItGB2ZNqYHekXsyP9YnakG2ZHumN2xOyI2ZEeCSqU5ORkqUsokvj4eAFAxMfHS11KoVx9/ELU+fqAqPHbR8JvtZ9otLaRuBx1WeqyiMgEFHX/l5KSIq5fvy5SUlL0XBlpEhMTI6ysrAQAsWbNmkIt4+jRowKAACCOHj2qcdyqVauU48LDwzWOmzlzpnKcOjnTZs6cWeBar1+/rpy/R48eBZ5fF4MGDRIAhI+Pj9ZxrVq1EgBEq1attI7z8fERAMSgQYPUTk9PTxejR48WMplM+dg03SpXrqwy/6VLl4SLi4vGefz9/cWTJ0+0Pu/5/c5y6LqtaNK7d2/l/FeuXCnw/LpavXq1sLGx0fpcavr9rl69WvmaUnczMzMTc+bM0bhuXbfv/Lafx48fixo1amiso0OHDuLgwYNF+n3oYsWKFXnWa25uLqKiorTOU5zbpK4CAgIEAGFhYSGeP3+ul2XmyP260HZ74403xL1791Tmz8rKEk2aNNE43+vmzZuncX9ha2sr9u3bp/P+qSB0fQ8IDw9Xjlu1apXK9JUrVwq5XK7x8fbp00ccPnxY67at6+Mr6nZUpkwZAUC4uroWan5dtw1bW1vx+++/a13WlClTlOP37NlTqHryM2TIEK37vl9++UWn53TChAkal+Pu7i6Cg4PzfW/MoVAoRIUKFfIs45NPPtHL4x08eLAAIGrVqqWX5emLMR9Pf/XVV+LChQtSl2E0TD07MkUnFxwQi0YGij8GbRZpsXFSl1OqZCQkivD1+8XBUYvFHwM3iUUjA5W3JcP/Frs+2ylu7Lss0tMyC70OhUIhMtOz9Fi18UpLThN/DNspFo0MFH+PXSF1OYXC/Mj0MD/SP+ZHmjE/Yn7E/EgV86O8mB+9wvyI+VFBlbZj6Y0bNwoLCwvRuXNnYWlpKTp37iyqV68unJycxODBgwu0rE2bNgkrKyuxevVqcf36dTFixAjh7Owsnj59KoQQYsCAAWLq1KnK8V9//bU4ePCguHv3rggJCREffvihsLa2FteuXdN5ncaQH+1dGCoWjQwUV48/kqwGIip9mB2ZHmZH+sfsSDNmR8yOmB2pYnaUF7OjV5gdMTsqKB5LF15pzY6uHH0oFo0MFPsW8/tmRFR8mB2ZHmZH+sfsSDNmR8yOmB2pYnaUF7OjV5gdMTsqDF2Pp+WgQrGx4VXQpFTL2wmbRzSHXfxAZL70RUpWCkYfHoM7ccbXHZCIiIrGzc0NPXr0AABs2LBB4moML3c30okTJ0pYif5YWFhgyZIluHz5MsaPHw9/f384OTnBzMwMTk5OqFu3Lj7++GNs27YNN27cUJm/bt26CA0NxahRo+Dj4wMLCwu4uroiICAA8+fPR3BwMLy8vCR4ZKrOnj0LAGjXrh38/f0Ntp5Bgwbh7t27+OKLL9CgQQM4OzvDzMwMLi4uaNKkCaZPn46///5b47w3b97EJ598gpo1a8LOzg42NjaoWrUqhg8fjkuXLmHatGkGqz2Ht7c3Ll26hO+++w5+fn6wsbGBs7MzmjRpgiVLluDAgQOwtLQ0eB09e/aElZWV8t8dOnSAh4eH1nmMbZtMTU1FaGgogOzux66urnpd/ltvvYWgoCBMmzYNbdq0QbVq1eDg4AALCwt4enqiQ4cOWLZsGUJDQ1G5cmWV+eVyOf755x98+eWXqFOnDuzt7SGTyTSub/LkyTh58iR69OiBMmXKwMrKCj4+Phg6dCguXLiA9957T6+PT9+GDBmCEydOoFu3bvDw8ICFhQW8vLzQqVMnbN68GZs2bYKZmZnUZeLevXvKKwEU9v2mQYMGWLduHcaOHYvGjRujYsWKsLW1haWlJTw9PdG2bVvMnj0b4eHhGDFihNZl5bz/Va9e3WC/45UrV2Lt2rV466234ODgoNy2BgwYgNOnT+OTTz7RaTm//vor9u/fj44dO8LV1RXW1taoVq0aJkyYgEuXLqFRo0Y61ySTyfDRRx/luU/b1Ql0lZqaqrza/ZgxY4q8vNLi0aNHeOedd1C+fHmMHj0aBw4cQHp6utRlUSnSaERbWGYlI8XaHZd+2yt1OSVeVlIS7m86gENjlmLtuH3Yf9wa/4o3kGLjAbkiA+Ud4tG2sxuGLWyPrj92wxvv1YaFZeHfw2UyGcwsSkccb2ljiRbdKgIA7mb44MHu4xJXRKUB8yPTx/xI/5gf6Q/zo/wxPyoY5kfMj5gfUY45c+bg559/xt69e2FpaYlff/0VN2/eRO/evVGxYsUCLatPnz6YP38+ZsyYoXwf+vvvv+Hp6Qkg+yqgkZGRyvFxcXEYPnw4atasiXfffRcJCQk4ffo03nzzTb0+RkNz9Mj+/FZ8dIrElRARkTFjdmT6mB3pH7Mj/WF2lD9mRwXD7IjZEbMjMoTSmh05/ZcdJcQwOyIiIs2YHZk+Zkf6x+xIf5gd5Y/ZUcEwO2J2xOxIP2RCCCF1EVT8EhIS4OTkhPj4eDg6OkpdTqHdiXqJj/53DEmui2Fm8xBu1h5Y/95alLMvJ3VpRGSkirr/S01NRXh4OCpXrgxra2sDVEjqnDt3Dk2aNIGZmRnu3r0LHx8fqUsymMGDB2PNmjVo06YNjhw5InU5VAARERHKk/Vjx46hZcuWEldEpUVQUBDatGkDc3Nz3Lp1C1WqVJG6JDIBq1evxpAhQ+Ds7Iz79+9Lel6YmpoKZ2dnpKWlYc2aNRg4cKBktZQU69atw4ABA+Dm5oaIiAjY29tLXZKSsR9PKxQKnDp1Cnv37sXu3bsRGRmJt99+G127dkXnzp31/kcBY1ZSsiNTc3bxIYSEmcE6LQ79f2wNKw83qUsqURQpKXi09zhuH7uHhy+dkWzjqZwmV2TCyzEJvi0rwfdtP1jaWEhYacmwe9JWPEp2g1PqE3y4uAfM7WylLklnzI9ME/MjMgXMj0gqzI+oMJgflWzGmh+VtmNpOzs7XLt2DZUqVYKbmxuCgoLg7++PGzduoG3btnm+3GaMjCE/uhz4ECe3/ouq9TzQaaThPkxORJQbsyPTxOyITAGzI5IKsyMqDGZHJRuzI9IHY8iOXkQlY/2MszC3kGPEb620ftmaiEhfmB2ZJmZHZAqYHZFUmB1RYTA7KtmMNTsCdD+eLh2X0DaArKwszJ8/HwEBAShbtixcXV3z3Kh4VCtjj60jWsPpxShkpZXB89RofPz3cMSkxEhdGhER6VHjxo3Ro0cPZGVlYe7cuVKXY1DHjh0DAMyYMUPiSqigcn53rVq1YlhFxSpn2+vXrx/DKtJZznbzySefSN5A5dy5c0hLS0PVqlX10hW7tFMoFJgzZw4A4LPPPjOqsMoUyOVyvPXWW/jxxx9x69YtnDt3Do0bN8bvv/8Ob29vtGzZEvPnz8fjx4+lLpVKqAbD2sAq6yVSrVxw4de9UpdTIihSU/Fw2z8IHL8Uf47cib1HLHArqwaSbTwhE5nwtotH647OGPprG3Sb3x213q/HJkt60vaz9jDPSkW8tTeCf9gmdTlUCjA/IlPA/IikwvyICoP5UcnF/Mh4uLi4IDExEQBQrlw5XL16FQDw4sULJCcnS1mayXD0sAEAxMekSFwJEREZO2ZHZAqYHZFUmB1RYTA7KrmYHVFJ4uBmDZkMyMxQIDkhXepyiIjIiDE7IlPA7IikwuyICoPZUclVUrIjNloqpK+//hoLFixAnz59EB8fj0mTJqFHjx6Qy+WYNWuW1OWVKpXc7bBlRHs4x4+FIt0Zj5MeYtjfo5CYnih1aUREpEdz5syBubk5Vq1ahUePHkldjkE8evQIEREReOutt9C6dWupy6ECOn78OACGjVT8jh8/DjMzM3zxxRdSl0Im5Pjx43B0dMQnn3widSnK/ef06dNhZmYmcTWmb+vWrbhx4wYqVqyICRMmSF2OyatZsyamTJmCU6dO4eHDhxg0aBBOnDiBjRs3Sl0alVAWVuao29gBAHD9iTNSHj2VuCLTpEhLw6NdgQicsAx/jtiOPYfNcTOjBpJsy0KmyISXXTxavu2IoT+3QfefuqNW9/qwYnMlvXPwckGDRlYAgCtP3PH84g2JK6LSgPkRGTvmRyQV5kdUGMyPSi7mR8ajZcuWOHToEACgV69e+OSTTzB8+HB89NFHaNeuncTVmQYn9/8aLUWnQAghcTVERGTsmB2RsWN2RFJhdkSFweyo5GJ2RCWJmZkc9q7WALLzIyIiIm2YHZGxY3ZEUmF2RIXB7KjkKinZkUzwUyaFUrVqVfz2229477334ODggNDQUOV9Z8+exYYNG6QuUauEhAQ4OTkhPj5e8i5w+vLkRQr6rNyDWKdfIDd/iVqu9bD6neWwNreWujQiMiJF3f+lpqYiPDwclStXhrU19y/Fbe3atbh79y46dOiAZs2aSV0OERERkdHZsGEDbt++jbZt2xrllSp4PG06SmJ2ZCoyM7Lw55h9SDFzgJ9jBFr9OFTqkkyCIj0dkQdO4taR23gYZ4+Xtt7KaTKRBU+7RPg2rYDq79aBtZ2lhJWWLkIhsHHMdsTBFWUz7qHHiqGQyY3/+g/Mj0wb8yMiIiIi7Yw5Pyptx9KxsbFITU2Ft7c3FAoFfvzxR5w+fRq+vr748ssv4eLiInWJWhlDfpSZnoXfJ2RfCXPovBawceA5PxEZHrMj08bsiIiIiEg7ZkekL8aQHQHA7l8u4dHNOLQbVBNvNPWSrA4iKj2YHZk2ZkdERERE2hlzdgTofjxtXow1lShPnz6Fv78/AMDe3h7x8fEAgM6dO+Orr76SsrRSy9vZBtuHdUXPlemIdfwV12IvYcyhiVjecSHM5dzUiYhKggEDBkhdAhFJLCoqClFRUQWez9LSEtWrVzdARWQsrl69Wqj5ypcvD2dnZ/0WQyShvn37Sl0CERWRuYUZ6rd0w6lT6bj13B0N7z2AXZWKUpclKSEEFJkCZhZ5G/SI9HQ8OXgKtw/fxoM4W7y0LQegOmD7X3Ml20T4NikH3/fqwcaeX7SUgkwuQ9tRDbBj6R08taiCa8t2w29Md6nLohKO+RERMT8iTZgfEWVjfmQ8XF1dlT/L5XJMnTpVwmpMk7mlGeycrZD0Ig3xMSlstERERPlidkREzI5IE2ZHRNmYHVFJ4+hhA9yMQ3x0itSlEBGRCWB2RETMjkgTZkdE2UpKdsTuM4VUvnx5REZGomLFiqhatSr++ecf1K9fH+fPn4eVlZXU5ZVaZRytsf3j3ui1Oh0x9otwPuok/i9wOn5r/z3kMuO/UjoRERERabdkyRJ8/fXXBZ7Px8cHERER+i+IjEZOI9yCWrVqFQYPHqzfYoiIiIqodt9mCD2xG0kWTji36BDaLvhY6pKKVUrYVUTNnw+PTz9FjJk3zu25h8TYVPSa1gj2DmaIPHQGtw7dxMPnNki0LQfA97/mSgqUsUlAtcbeqNG5HmwcmNMag7J1K6NGuSu4+cQB584rUPVJFGy8y0hdFhERlWDMj0gT5kdEZIwUCgXu3LmDqKgoKBSKPNOM8cp/xsjJwwZJL9KQEJ2CspWdpC6HiIiIiIwcsyPShNkREVHJ5ORuAwBstEREREREOmF2RJowOyIqWdhoqZC6d++OwMBANG7cGOPHj0f//v3xxx9/4MGDB5g4caLU5ZVqHg5W2DF0AD5YnYpou+U49uQAph51wA9tvoRMJpO6PCIiIiIiIiIiIq3kZnI0fNsbxwKTcDuhLBreuAvHmlWlLqvYvNi1Gw9vJ+DUinDEZUQDMgACOPnNZkTHypBoWx5Atf+aK2XBwzoRvgFeqNGlPmwc2VzJGL01+R3c/+QvpFi54PjcPei4cJjUJREREREREUnu7Nmz6Nu3L+7fvw8hRJ5pMpkMWVlZElVmWhw9bPDk3xf8shwREREREREREalw8shutJQQw+yIiIiIiIiIiLKx0VIhff/998qf+/TpAx8fH5w+fRq+vr7o0qWLhJURALjaWWLXkBHo/mcqom1W48DDLbA/6YQvmo9HcHgsohJTUcbBGgGVXWEmZ/MlIiIiIlMxa9YszJo1S+oyyAi9/iUUIiIiU1frgwBcOrwTCebOOLf0CN7+rWQ3Wsp4/BgZsXF4/DAdZ/+tgIQ6TYF0hbLJEgDcS60A2AIQCpSxSkC1Rp6o0aU+bJ1tpCyddGBpa4kWXSvi0L4XuJvugwd7T6Bil7ekLouIiEoo5kekCfMjIjI2o0aNQsOGDbF//354eXnx4mGF5OT+35fl2GiJiIiIiHTA7Ig0YXZERFQyOf7XaIlNuomIiIhIF8yOSBNmR0QlCxstFdLx48fRrFkzmJtnP4VNmjRBkyZNkJmZiePHj6Nly5YSV0hOthbYPXgCuq5NRrTlFmy9twI7LsQh/nl1WDifQ8aLxihrVwYzu7yJTn5eUpdLREREREREREbg0aNHcHZ2hr29fZ77MzIycObMGWY+VGxkchkCOvvg8P543Ekpj4ahN+FS9w2pyzKY4J5jcbfy+0h0rATYeGffKZPnGeNsnoCajTxQo2t92LG5ksmp3rk+rgduxeMUNxzfHoGP2jWEmS1/j0REREREVHr9+++/2LZtG6pVqyZ1KSbN0cMaABAfwy/LERERERERERFRXjlNulNfZiA9JROWNvwqJREREREREVFpJ89/CKnTpk0bxMbGqtwfHx+PNm3aSFARqeNgbYG9A6fBLrkTACDTZTvMHS/CyiMQMvNEPI1Pxeh1F/H31UiJKyUiIiIiIiIiKUVGRiIgIAA+Pj5wdnbGwIED8fLlS+X02NhYZj5U7Kp3rg9nWRwUZlY4u/yE1OUY1L2mY7KbLAEqDZZydJjSDvUHNWeTJRPWdnJ7mGWlId66HIJ/2Cp1OURERERERJJq3Lgx7ty5I3UZJs/J3RYAEB/NRktERERERERERJSXpY05rO0tALBRNxERERERERFlY6OlQhJCQCaTqdz//Plz2NnZSVARaWJtYQYR1wHpcU0gkwlYlflHOU389/+v915HlkKoXwARERERERERlXhTp06FXC7HuXPn8Pfff+P69eto06YN4uLilGOEYHZAxUsmk6FJj+oAgIjMiog5d0XiivQvMz4BF+esRXpc4qs7+VorsRzLuaBBg+wPMF5+7Ia4SzclroiIiIiIiKh4XblyRXkbP348Pv30U6xevRohISF5pl25UvIyAENx8shuyJwcn46M9CyJqyEiIiIiIiIiImOTkx8lsFE3EREREREREQEwl7oAU9OjRw8A2V9yGjx4MKysrJTTsrKycOXKFTRr1kyq8kiN4PBYRCXHQJbeADLzGFg4ZF8N0NzxEjL/G/M0yQHB4bFoWtVNukKJiIiIiIiISDKHDx/Gzp070bBhQwDAqVOn0KtXL7Rt2xaBgYEAoLbpNpGhVWnvB7dd2/Ecrji78iw6N64tdUl6kZmQiLDFu3D5pjmSbMoBVoBZVircoy8jyc4LLx0qAiILkJlJXSrpWYMR7XB7zHa8MHfF0UUn0X1FdcjkvCYEERERERGVDnXr1oVMJsvT0Hvo0KHKn3OmyWQyZGWxaZAurOzMYWljjvSUTCTEpMDN217qkoiIiIiIiIiIyIg4utvgWXgC4tloiYiIiIiIiIjARksF5uTkBAAQQsDBwQE2NjbKaZaWlmjSpAmGDx8uVXmkRlRiKiycz8HKIzDP/VZuJ2HldhIAkBbdDlGJLaUoj4iIiIiIiIiMQHx8PFxcXJT/trKywo4dO9CrVy+0adMG69atk7A6Ks1kMhmafuSHfeue4IGojGdBF+DZuqHUZRVaZkIiwpbsxpUbMry0KQfYAOaKVLz5hhnqdvVD5KC5MDcvi5TmH+FSSDriLcpIXTLpmVwuQ9uRDbBz2R1EWlTB9d/3oNboblKXRUREREREVCzCw8OlLqHEkclkcPKwQfSDRCREs9ESERERERERERHl5eSR/d2/+Bg2WiIiIiIiIiIiNloqsFWrVgEAKlWqhMmTJ8POzk7iiig/ZRyskfGiMTJfvgkAMLN+CGuvXQAAIeRIi+qIzIR6KONgLWGVRERERERERCSlKlWq4MqVK/D19VXeZ25ujq1bt6JXr17o3LmzhNVRaefT4g2U2RyGqAw3nF1/CV1NsNFSZsJLXF2yC5dvyPDSxvu/BktpqFlDjoAR7WDtYAUAsDsSCJmFBWQyGWoqFHgQFo3zfz3Ay7g02DhYSPwoSF+86lVGde/LuBXpiLPBmajSLRo2Xh5Sl0VERERERGRwPj4+UpdQIjm6Zzdaio/ml+WIiIiIiIiIiCivnEZLCcyOiIiIiIiIiAiAXOoCTNXMmTNhZWWFw4cP4/fff0diYiIA4MmTJ3j58qXE1VFuAZVdUdauDERqOShSyyErtQIAICPRFzKZAlZlDsLBOQIBlV0lrpSIiIiIiIiIpPLOO+9g+fLlKvfnNFuqW7du8RdFlEuzgfUBAI/klfH479MSV6O7zMSXCP1hPdaP24VTEd54aeMFM0Ua/KtlYOBPbdDy047KJksAILe0hEwmy/5ZLkelOp7oObUhBs5uBnsXNkovSVpOfgfWWQlItXLFibm7pS6HiIiIiIhIErdu3cK4cePQrl07tGvXDuPGjcOtW7ekLsvkOHlkZwb8shwREREREREREb3OMafRUgyzIyIiIiIiIiJio6VCu3//Pvz9/dG1a1eMHTsW0dHRAIAffvgBkydPlrg6ys1MLsPMLm8CAGS57k+P6YCMFw0gkymgcN+Iz/9ZIU2BRERERERERCS52bNnY+vWrWqnmZubY/v27bh3714xV0X0SrlGVeFl/RyQyXFuy3UIIaQuSausly9x+cf12DB2F06Fe+GlrTfMFOnwq5aOQfPboOXkjrBx0K1xkkwmg5kFo+ySxtLOCi3ez26KfyfVB4/2n5S4IiIiIiIiouK1fft2+Pn5ISQkBHXq1EGdOnVw8eJF+Pn5Yfv27VKXZ1Ic3bO/LBfPL8sREREREREREdFrnP5rtJQYm4asLIXE1RARERERERGR1PjtlEL65JNP0LBhQ8TFxcHGxkZ5f/fu3REYGChhZaROJz8vLO1fH2WdrCEyHZAW3Q4i0wnOyf1QRrSBTCZw8NlCjN33m9SlEhEREREREZEEzM3N4ejoqHW6j49PMVZEpKr5x40BoUCkZRU83H1M6nLUynr5Epfnrcf6MTtx8p4XEnMaLFVNx6AfW6HV5E6wcdStwRKVfDW6NEA5m+cQcjMEbQ1HVjK/EEtERERERKXHlClTMG3aNJw5cwYLFizAggULcPr0aUyfPh1TpkyRujyTkvNlufhonlcSEREREREREVFeto6WMLeQQygEEp+nSl0OEREREREREUnMXOoCTNWJEydw+vRpWFpa5rm/UqVKePz4sURVkTad/Lzw9ptlERwei6jElijjYI2Ayq6QoR0+2v4lrifvxfHnK/DxzjT8r9tkyGQyqUsmIiIiIiIiomIWExMDd3d3qcsgUsvTvyIq2AfjYZIrzu2+iwpdWxlNhpWVlIRrS3cj9EoWEm3LAbaAmSIdb1QTCBjRGrbONvkvhEqlNpPbYeOsc4i3LofgH7eh6awBUpdERERERERULCIjIzFw4ECV+/v374958+ZJUJHpcvyv0VLi81QoFAJyuXHkJUREREREREREJD2ZTAZHDxvEPklCQnQKnMvYSl0SEREREREREUlILnUBpkqhUCArK0vl/kePHsHBwUGCikgXZnIZmlZ1Q9e65dC0qhvM5DLI5XJs6jkb9R17AgCCE/5E/+3fQaFQSFwtERERERERERWniIgING/eXOoyiLRqNrI5IBSIsqqMe5sPSV0OspKSEPbTBmwYvR0n7pRFom05mCnS8WblNAz8sRVaT3mHTZZIK6dyrqhfP/uaEFceuSLu8m2JKyIiIiIiIioerVu3xokTJ1TuP3nyJN566y0JKjJd9i7WkJvJoMgSeBmXKnU5RERERERERERkZBzdsz+7Eh+dInElRERERERERCQ1c6kLMFUdOnTAL7/8guXLlwPI7m798uVLzJw5E++++67E1VFByWQyrOk+EyP2WONM3DpcSdqCXltSsbX3t5DL2Y+MiIiIiIiIqKS7evUqOnXqhDFjxkhdCpFW7tW9UMnlNCJeuOD8349RpVcWZGZmxV5HVlISri/bg9DL6UiwrQDYAmaKdFSvItBkZCvYuvDqf6S7BiPa4d+xO/DC3BVBvx1HtxXVIGMuS0REREREJdz777+Pzz//HCEhIWjSpAkA4OzZs9i6dSu+/vpr7NmzJ89Y0kwul8HR3QYvniUjIToFjm5s+kxERERERERERK84efzXaCmGjZaIiIiIiIiISjs2Wiqkn376CR07dsSbb76J1NRU9O3bF//++y/c3d2xceNGqcujQlr+/uf45C8bHIlegdtpe9B1Uyp29vkR5hJ8WY2IiIiIiIiIisfp06fRuXNnjBo1CtOnT5e6HKJ8NRvVEvfnXMJzax/cXnsQNQYXX+P3rORk3Fi2G6Gh6Yj/r8GSXJGBGpUVaDyqFezYYIkKwcxMjrbD62PH8nt4YlEFN1bsxZsju0pdFhERERERkUHlNPxesmQJlixZonYakH3xsKysrGKtzRTlNFqKj05B+TekroaIiIiIiIiIiIxJTqOlhGg2WiIiIiIiIiIq7XhJ6EIqX748Ll++jC+++AITJ05EvXr18P333+PSpUsoU6aM1OVREfz67gS85z0eABCR8Q86b/w/pGVkSFwVERGlp6fD19cXMpkM27Ztk7ocrWQyGWQyGWbNmiV1KUQmLSgoSPl6CgoKkrocMiKtW7eGTCZD69atpS6FSqjVq1cr9z8RERGFXs7gwYMhk8lQqVIlvdVW3B49egQrKytYWlri9u3bUpdjMB06dMCAAQMwZ84cqUsh0olLJQ9ULfMSAHAhKAaK9HSDrzMrORlXf96EjSO34NhtT8TbVoBckYE3KqZi4NwWaDvtHTZZoiLxalAFNcpmb9dnz2Yg5WmMxBWRKWJ+RFT6MD8iTZgfkaExP3qltORHhqBQKHS6scmSbpzcrQEACTH8shwREanH7Iio9GF2RJowOyJDY3b0CrMjMhaOOY2WmB0REZEGzI6ISh9mR6QJsyMyNGZHr0iVHbHRUhGYm5ujX79++PHHH7FkyRIMGzYMNjY2UpdFevD92yPQs+JkCCHD46wgvLtxLJKL4QtrRESk2a+//oo7d+7Az88PH3zwgcr0nAPCwYMHF39xBZD7BNyQeJJvGDknyYYMI2fNmsUTcVJRqVIlyGQyrF692mDrMJX9KOmuON4Lcgc7+d0Muf3mrsWUwyGpaHvuypcvjyFDhiAjIwOTJ08u/uKKiZ2dHSIjIyGEkLoUIp01G9MGckUGXliXx82VBwy2nqyUFFz7dWN2g6VbZRBvVzFPg6V209+FnZudwdZPpUvLKe/AOisRKVauODl3l9TlkAliflQwzI8Mg/kRSYX5ERUG8yPSFfMjMgU5X5aLj+aX5YiISD1mRwXD7MgwmB2RVJgdUWEwOyJdMTsiU+Dk/l92FJPKz4gREZFazI4KhtmRYTA7IqkwO6LCYHZEujLG7IiNlgrp+fPnyp8fPnyIGTNm4LPPPsPx48clrIr0aWabQRhY9QsIIUeUOINOG0cgMTVV6rKIiEqlxMRE/PDDDwCAL7/80uBhDxER6U9J6IxMVNpNmzYNFhYW2Lt3L4KDg6UuxyBOnTqFCxcuYOjQoVKXQqQzB28X+JbL/uJgyNlEZKWl6XX5WSkpuP7bJmwasQlBNzz/a7CUiRoVUjFgDhsskWFY2lmhRWdvAMC/KT54dOC0xBWRKWF+RERkupgfEZm+0pAf6ctvv/2m840Kxum/RksJMfxsDxERqWJ2RERkupgdEZk+ZkdkDBzcrCGTAZlpWUhOSJe6HCIiMjLMjoiITBezIyLTJ0V2ZF4saylBwsLC0KVLFzx8+BC+vr7YtGkTOnXqhKSkJMjlcvz888/Ytm0bunXrJnWppAdT3uoDa3NLLL/5NeLkIei08WPs/3AFnG1spS6NiKhUWbp0KZ4/f46KFSuiV69eUpeTL17lgoiISqODBw/C29tb4/Ty5csXYzVFM3jwYHbJz8XHxwcffPABNm3ahO+++w579uyRuiS9q1atGk6ePIlOnTph7NixWLx4sdQlEemk6dh2uDP9FBKsvXF12V7U+aRnkZepSE3FrRW7cTE4CS/sKgF2gFyRiWoVM9B0ZEvYezgUvXAiLWp0bYTrR7fiSaobjm2+gw9b14eZjbXUZZEJYH5ERERk/JgflVylIT/Sl59//lmncTKZDBMmTDBwNSWL43+NluKjUyCE4JcgiIgoD2ZHRERExo/ZUcnF7IiMgZm5HPYu1kiMTUVCdArsnKykLomIiIwIsyMiIiLjx+yo5JIiO2KjpQKaMmUK/P39sX79eqxduxadO3fGe++9hxUrVgAAxo8fj++//56NlkqQCU27w8bCCr+GfYEE+RV02jgYe/v8AQ87fqmMiKg4ZGVlYdGiRQCAjz76CHK5XOKKiIiISJ3q1auzA3wJ1rdvX2zatAn79+/HvXv3UKVKFalL0jtvb28cO3YMnTt3lroUIp3ZuTvgjUrpuPbAEpcuZaBWUjLM7QrXIFyRloZbK3bj0rmXiLOrBNh5QKbIhG+FDDQZ2RIOZZiFUfFp+2lbbPwmGC+sy+P8j9vQZGZ/qUsiI8f8iIiIyDQwPyrZSkN+pA/h4eFSl1BiOblnN1pKT8lEWlImrO0tJK6IiIiMBbMjIiIi08DsqGRjdkTGwNHDBomxqYiPSYFXNWepyyEiIiPB7IiIiMg0MDsq2Yo7O+IRXwGdP38es2fPRvPmzTF//nw8efIEY8aMgVwuh1wux/jx43Hz5k2pyyQ9G97wXUytNx9QWCLJ7Abe3TwQT+LjpC6LiKhUOHToEB4+fAgA6Nevn8TVEBEREZVOnTp1gpubGxQKBVatWiV1OQbj4uKCw4cPS10GUYE0HtMe5lmpSLL2xOXFews8vyItDTcXb8WmYetw5Ko74uwqZTdY8k7BgG+b4u2v3mOTJSp2ThXcUK9u9nUiLj90RlzYvxJXRMaO+RERERGR9EpLfkTGy9zSDHZOlgCA+OgUiashIiJjwuyIiIiISHrMjsgYOHlkN+pmdkRERLkxOyIiIiKSXnFnR2y0VECxsbEoW7YsAMDe3h52dnZwcXFRTndxcUFiYqJU5ZEB9a/bDrMCfgMU1kg1u4Mu2wYiIjZa6rKIiEq8LVu2AAB8fX3h7+9fqGUEBQVBJpNBJpMhKCgIQgj88ccfaNGiBdzc3ODo6IiAgACsXbs2z3zp6elYtmwZmjRpAldXVzg4OKB58+bKmjTJWdesWbMKVa+hDR48GDKZTNm99enTp5g8eTKqV68OW1tblCtXDr1798a1a9fyzBcREYEJEyagevXqsLGxgaenJ/r164e7d+/qtN6jR49i0KBBqFKlCmxtbeHo6Ah/f3989tlnePLkidZ5r169iu+++w4dO3ZE+fLlYWVlBXt7e/j6+mLQoEE4e/as1vlnzZql/L0AQGpqKubNm4f69evDwcEBDg4OCAgIwKJFi5CZmanT45FadHQ0vvnmGzRv3hxlypSBhYUFXFxc0LhxY0yZMgVXrlzROG9ERAQmTpyIWrVqwcHBAba2tvD19cXIkSMRFhamdb2vb9/nz5/HRx99pPy9lCtXDgMGDMCNGzfyfQwpKSmYM2cO6tSpAzs7O7i5uaF58+ZYsWIFFApFgZ4PXfz555/K+g8dOpTv+JEjR0Imk8HKygpxcXmbbOp7m4yPj8e3336LevXqwdnZGTKZDKtXry70YzWE1NRU/Pbbb2jdujU8PDxgYWEBV1dX1KhRA++88w4WLFiAiIgI5ficx7hmzRoAwP3795WPOfdNnbNnz6JXr14oW7YsrK2tUblyZYwYMQK3bt0y2ONbvXq1sqaIiAgoFAosX74czZo1g4uLC+zs7FC7dm3Mnj0bycnJGpejUChw5MgRTJ48Gc2bN4e7uzssLCzg7OyMunXrYvLkyXjw4IHWWlq3bg2ZTIbWrVsDAB4/foxJkyahWrVqsLGxgZubGzp27IgDBw7o8yko8V7ffx05cgS9evVChQoVYGFhkaer+evbgyY3btzA4MGDUaFCBVhbW6NChQro27cvzp8/X6Da/vzzT7Rq1QouLi6wt7eHv78/vvnmGyQkJKitXZOivNfmx8LCAl26dAEAbNq0qUjLMnY2NjZSl2DyopOjsSR0CaKTmZsUBxtnW9SqLgAAl2/IkBH/Uqf5FGlpuLlkCzYPW4fAMDfE2VWGTGTB1zsZ/b9tig4z3oODJxsskXQajmoHJxGLTHNbBP2afS5PpAnzI/1jfsT8iPkR86PCYH7E/MjUMT9ifiSFR48eYcmSJZg6dSomTZqU50YF55jzZbkYzfthIiIqfZgd6R+zI2ZHzI6YHRUGsyNmR6aO2RGzIzJ9OY2WEthoiYiIcmF2pH/MjpgdMTtidlQYzI6YHZk6Zkcmlh0JKhCZTCaioqKU/7a3txf37t1T/vvp06dCLpdLUVqBxMfHCwAiPj5e6lJMzr6bwcLvj8bCb7WfqPu/TuJW1BOpSzIpmVkK8df1W2L8gbnir+u3RGaWQuqSqJQp6v4vJSVFXL9+XaSkpOi5Mv1TKBQiMz1L6jKKrFKlSgKAGDBggNZxgwYNEgDEoEGDVKYdPXpUABAAxD///CO6dOmi/PfrtwkTJgghhIiNjRUtW7bUOG727Nkaa8kZM3PmTK21GFLOOo4ePaoyLee58vHxEaGhoaJs2bJqH6OdnZ04ceKEEEKIwMBA4eTkpHaci4uLuHr1qsZaUlJSxIcffqjxucxZ1549e9TOn/s503abOnWqxhpmzpypHPf06VNRt25djcvp0qWLyMpS/9pp1aqVxt+tvuTU2qpVK41j1q1bJ+zs7LQ+Hz4+PmrnXbNmjbCystI4n5mZmZgzZ47GdefevhcvXizMzc3VLsfW1lYcO3ZM43IiIyNFzZo1NdbRsWNHcfDgQa3bckElJCQIGxsbAUAMHjxY69j09HTh6uoqAIhu3brlmabvbfL27dvKfV3u26pVq5TjfXx8VO7TN2370SdPnog333wz38f86aefqn2M2m6vW7BggZDL5Rr3Ffv371e+FrW9Tgpq1apVyvVcu3ZNtGvXTmPNAQEB4uXLl2qXo8vjtrW1FTt27NBYS+7Hd/LkSeHu7q5xWfPmzdO4HH2+fjTJ/byFh4cbbD0FqUXT/i/3/mv69Ola95u6PK7Nmzdr3J+am5uL//3vf3nec9VJT08XXbt21fj79fX1FREREXlqV6eo77X5PXc5li1blmffVRimdDxd2hXl3OlazDXht9pPXIu5ZoDKSJ3UxBTx+7C9YtHIQHHu23Vax2alpYmbS7aIDf1XiEUjA8WikYFi8Yh/xN+z9ooXkcwKybg8Cr4jFo04JBaNDBTXf1f/PmYIzI9MD/OjwtF2zsD8iPkR8yPmR+owP2J+VBjMj5gfFYQpHUvrw+HDh4Wtra3w8/MT5ubmom7dusLZ2Vk4OTmJNm3aSF1evozxs0eHV10Ti0YGivP77+U/mIiokJgdmR5mR4Wj7XyB2RGzI2ZHzI7UYXbE7KgwmB0xOyoIUzqWJuPMjv698EwsGhkotv1wXupSiKgEY3ZkepgdFY628wVmR8yOmB0xO1KH2RGzo8JgdsTsqKB0PZ6Wgwps8ODB6NGjB3r06IHU1FSMGjVK+e+hQ4dKXR4Z2Hs1GuGXVr8DWQ7INH+E3nsGIuzpQ6nLMgl/X41Eix+OYOzmIBx9th5jNwehxQ9H8PfVSKlLIypRhBB4cO05tn1/AWumn0JibKrUJRXao0ePlN04GzVqpJdlfvXVV9i7dy/69euH/fv3IyQkBBs3bkSNGjUAAL/99hsOHz6MwYMH4/Tp0xg9ejT++ecfhISE4I8//oC3tzcAYMaMGSqds01NcnIyunfvjvT0dMyZMwenTp3C2bNnMWvWLFhaWiIpKQkDBgzAnTt30K1bNzg4OODXX3/F2bNncfLkSUycOBEymQxxcXH4+OOP1a5DCIGePXsqO4h26dIFa9euxalTp3DmzBn8+uuvqFixIpKSktCzZ09cuHBBZRmZmZmws7ND7969sWzZMgQFBeHixYv4+++/8dNPP8HHxwcA8P3332PVqlX5Pu4ePXrg+vXrmDBhAg4dOoSQkBBs2LABNWvWBADs3bsXK1asKOzTanBr165F//79kZSUBGtra4wfPx5//fUXLl68iOPHj2PRokXo0KED5HLVQ/39+/dj8ODBSEtLg729PWbOnIkTJ07gzJkz+Omnn+Du7o6srCxMnz4dS5cu1VrHwYMHMX78eNSqVQsrV67E+fPncfz4cUycOBFyuRzJyckYMGAA0tPTVebNzMxE586dld3DO3TogJ07d+LChQvYsWMH2rdvj4MHD+LLL7/Uz5P2HwcHB7z//vsAgB07diA1VfP+8cCBA4iNjQUA9OvXT6V+fW6TPXv2xOPHjzF+/HgcOnQIFy5cyLNfMgbjx4/H9evXAQD9+/fHjh07cPbsWZw/fx579uzBjBkzUKdOnTzzjBkzBmFhYejatSsAwNvbG2FhYSq33Hbu3IlJkyZBoVDAyckJc+bMwenTp3H69Gl89913MDMzQ79+/Yrc4Tg/w4cPV3ZYznmv2LlzJ5o2bQoACA4Oxnfffad23szMTHh5eWHMmDHK/V1ISAh27dqFKVOmwN7eHsnJyejbt2++HfQjIyPRrVs3yOVyfP/99zh58iSCg4OxYMECODs7AwCmTZtmNO9HQ4YMgbe3NywtLeHu7o4mTZrgyy+/xOPHj6UuLY8dO3Zgzpw58Pf3x8qVKxEcHIxjx44V6Arx58+fR79+/ZCWlgYrKytMnToVx48fx7lz5/Dbb7/B3d0do0ePRmhoqNblfPLJJ9i9ezcAoFatWli1ahXOnz+PwMBAjBs3Dvfu3UOfPn20LkMf77W6CggIUP587NixQi/HmC1ZsgTt27dH7969ERgYmGdaTEwMqlSpIlFlpiNTkYndd3dLXUapY2VvDX9/CwBA2F1rpD+PyzNdCIGMpFTcXrYNWz5eg8OX3RBrVwUykYVqXsno93VjdJzZGU5lHaUon0ijco2qonrZRADAmTOpSI16LnFFJQfzI+2YH73C/Ij5EfMj5ke6Yn7E/EgXzI+YH1Fe06ZNw+TJkxEWFgZra2ts374dDx8+RKtWrdCrVy+pyzNJjh42AID4GNM9xyEiMgbMjrRjdvQKsyNmR8yOmB3pitkRsyNdMDtidkRkaE452VF0isSVEBGZNmZH2jE7eoXZEbMjZkfMjnTF7IjZkS6YHTE70qtCtXEqxQYPHqzTzdgZY2dwU3Mq4rrw/6O58FvtJ2r/r7U4//Cu1CUZtQNhT0Slz/cJn8/3icozfxd+q/1E5Zm/i0qf7xOVPt8nDoQ9kbpEKiVKcmdwhUIh7l+NEVvmBItFIwPFolGBYtHIQBF1P0Hq0gpt8+bNyu6TOR2qC+P1Lr6//PKLypjIyEjh4OAgAAgPDw8hk8nEzp07VcZdvnxZ2bE2p4v463LWY8ju0UWR06UUgHB3dxd37txRGbNo0SLlGA8PD+Hr6yuioqJUxn322WfKcRcvXlSZvnz5cgFAWFhYiAMHDqitJzY2VtSqVUsAEM2bN1eZHh0dLeLi4jQ+nrS0NPH2228rO5pmZmaqjMndqdfCwkJtl9znz58LT09PAUDUrl1b4/qk9OTJE2FraysAiDJlyoiwsDCNYx88eJDn3+np6cLb21sAEPb29uLSpUsq80RERAgvLy9l5+Lo6GiVMblfS++++65IS0tTGfPdd98px6jrfpx7+xoxYoTa+ocOHZpnXfrqbLxnzx7lMrdu3apxXJ8+fQQA4ejoqLLP1/c2KZfLxcGDBwv9mAwtJSVFWFhYCCBv5291nj9/rnJffp2Rc6SlpSm3UScnJ3H9+nWVMWFhYcLR0VH53BmqMzgAsXbtWpUxqampws/PTwAQbm5uIiMjQ2VMeHi4SE9P17iehw8finLlygkAon///mrH5HQGz3neHj16pDLmxIkTQiaTaX0/Kg6vP2/qbtbW1mLZsmWS1Zgjd03t2rUTqampGsfm1xm8YcOGyvcUdVdBePTokShfvrzaruM5Ll68qPwdNm3aVCQnJ6uM2bp1a5661R1b6OO9VlcZGRnK/cGoUaMKtQxjPp7+9ddfha2trRg7dqzo37+/sLS0zHO1jKdPnwq5XC5hhcWroOdOUUlR4lrMNfFbyG/Cb7Wf8FvtJ1ZfXS2uxVwT12Kuiagk1WNJ0q/0lHSxYthusWhkoDgxcYmIGDhIJF2+IsJDn4o//++gWDz8YPa54shAsXjEP+LAzL3iRSSzQTJ+qQnJ4n/DdolFIwPFoQkrimWdzI9MC/Mjw2B+xPyI+RHzo4JgfvQK8yNVzI+YHxWEMR9LG4K9vb3yOMvZ2Vl5Jd7Q0NB894nGwBg/e3TrXKRYNDJQ7JgfInUpRFSCMTsyLcyODIPZEbMjZkfMjgqC2dErzI5UMTtidlQQxnwsTaqMMTtKTc5QfnYmLUV1H0xEpA/MjkwLsyPDYHbE7IjZEbOjgmB29AqzI1XMjpgdFZSux9Oq7QJJq1WrVul0o5KvmU9NrOq4GvIsVyjMYzD04GCcun9L6rKMUpZCYOb+M5BZP4bc+j4s3YIAAGbWD/677zFm7j+DLIWQtE4ifRNCICMty+C39NRM3AuNxtY5F7B34WVEP0j8r4Ds/2WmG3b9Qhjutfvo0SPlz2XKlNHLMhs3boxPPvlE5f6yZcuie/fuAIDo6Gj07t0b3bp1UxlXu3ZttGjRAgBw4sQJvdQkpW+//RZVq1ZVuX/o0KGwtrYGkP18/Pbbb/Dw8FAZN3r0aOXPrz8fQgj88MMPAIAJEyagU6dOamtwcXHBvHnzAACnTp3Cv//+m2e6u7u7sgOuOpaWlsr579+/n28X1vHjx6N169Yq97u6umLIkCEAgLCwMMTHx2tdjhQWLlyI5ORkAMDy5cvh5+encWyFChXy/Hvnzp3Kbspffvkl6tatqzKPj4+P8rlMTk7WelxrbW2NVatWwdLSUmXahAkTlPere50sWbIEAODp6Ymff/5Z7fJ//fVXtdtcUXXq1Alubm4AgPXr16sd8/LlS+zZswcA8MEHHyhfCzn0vU0OHjwYHTp00PERFL/Y2FhkZGQAAFq2bKl1rKura6HXs3v3buU2+tVXXym79efm5+eHL774otDr0FWPHj3Qv39/lfutrKwwbtw4AMDz58+V3dJzq1SpEiwsLDQuu3z58vjss88AAHv27Mn3fXThwoUoV66cyv0tWrRA48aNAUj/flSlShVMnjwZ27dvR3BwMIKDg7Fp0yb06tULMpkMqampGDVqFJYvXy5pnTnkcjn+97//wcrKqlDznz9/Xtlde+TIkWpfF+XKlcNPP/2kdTnLly9X/v5XrFgBGxsblTE9e/ZUHp+oo6/3Wl2Zm5srX+f37t0r1DKM2e+//44VK1Zg0aJFWLt2LY4ePYqff/4ZM2bMkLo0k7D19lb02dcHy8NevdbnX5iPPvv6oM++Pth6e6uE1ZUOFtYWqNPQFgBw/UVZ3L+TjK2L/sX+pdeQkGIOITcHRBaqeiaj78wAdJrVGU5lHSWumih/Vg42aP6uFwDgdkpFPDpwRuKK9Ke4siOp8yNDZkcA86PiwPzoFeZHzI9yMD/Ki/nRK8yP1GN+xPyI1LOzs1NeYdXLywt3795VTouJiZGqLJPm6JH9OomPTpG4EiKioist2RE/e8TsiNlR8WJ2VHTMjgqO2dErzI7UY3bE7IiouFjZmMPaLnsfmxDD/IiITBuzI/1gdmR4zI5eYXbE7CgHs6O8mB29wuxIPWZHzI4MwdygSycq4RqUq4b1765B/7+GIss8GqMOD8UvrZahXTV/qUszKsHhsYgzOwa7ykfy3G/ttVv5c1x0OwSHt0LTqm7FXR6RwWSmK7D8k2PFvt7Xj3t3zL9o0PWN+LUVLKzMDLLs6Oho5c8uLi56WeaHH36ocVqdOnV0Hnf8+HGT/yOfTCZD79691U6zsbGBr68vwsLC4OLigo4dO6odV7lyZTg4OCAxMVHl+bh+/bryA+E9e/bUWkvug/0zZ87A19dX49i0tDQ8e/YML1++hEKhAIA8J3yXL19GgwYNNM7fr18/jdNy5hNCIDw8XG2oI6V9+/YByD45fP/99ws07+HDhwFk/96HDh2qcVyvXr0wduxYxMfH4/Dhw8oT69e9/fbbGoNkBwcH+Pr64tq1ayrbRWRkpPIkv3fv3rC1tVW7DHt7e/Tu3RuLFy/O97EVhIWFBXr16oVly5bhwIEDePHihUr4tHPnTqSkZP8BVdv2ksOQ26QxcHNzg6WlJdLT07F27Vq8++67MDfX/6lk7m100KBBGscNGTIEU6dONegfTHTZTwDZJ+y1a9fWuqyEhAQ8f/4cycnJyppztvuEhASEh4ejSpUqaud1dnbGe++9p7WWs2fPSvp+1L17dwwaNAgymSzP/Y0aNUKfPn2wb98+9OjRAxkZGZg4cSLef/99lC1bVqJqszVv3hyVKlUq9Pw52yoA5R861OnevTucnZ3x4sULrcupV68eatWqpXE5AwcOxM6dO9VOM9R7rTaurq549uwZnj59Wqj5jVl4eDiaNWum/HezZs1w5MgRtG/fHhkZGfi///u/Qi978eLFmDdvHp4+fYo6depg4cKFCAgIUDv22rVrmDFjBkJCQnD//n38/PPPated3zJTU1Px6aefYtOmTUhLS0PHjh2xZMkSeHp6FvpxaNOrei9Ypvth+fF7eIGLsPI4CgCwfNEDo5u2Q9fqqn+IIP3KePwYbzQug0sX7iPD0glh/qNUxrwz3A9VGnpJUB1R0bzRPQDXj21FZKobjm/+F33a1IeZdeH++GRMpMqOgOLNjwyZHQHMjwyN+ZEq5kfMjwDmR69jfpQX86O8mB8xPyLNmjRpgpMnT6JmzZp499138emnnyIsLAw7duxAkyZNpC7PJDn912gp6UUaMtOzYG5puHMRIiJDKy3ZEcDPHpkyZkeqmB0xOwKYHb2O2VFezI7yYnbE7IiouDl62CA1KQPx0SlwL+8gdTlERIXG7Eg/mB0ZFrMjVcyOmB0BzI5ex+woL2ZHeTE7YnZkKHKDLp2oFPArWwlb3l8L8ywvwDwB/3d8BP66ZdiTQ1MihMCefw/B3OGK8j5F5quOdxmJ1ZEUPhYZLxojKjFVihKJyIjFxsYqf9ZXYFW9enWN03KftOoyLjExUS81ScXd3V1rF9+cx1mtWjWVExF1415/PnK6pgJA06ZNIZPJNN7s7e2VY9UdACclJWHu3LmoU6cO7Ozs4OPjg1q1asHf3x/+/v6oV6+ecmx+V/h94403NE7L/XwY2+83IyMDV69eBZDdEVjb70SdnHkrV66steO2paWl8vnMmUcdbc8j8Oq5fP15DAsLU/7cqFEjrcvQ1ICiqHLCiLS0NGzbtk1l+oYNGwAA3t7eaNOmjdpl6HObzC/wkJqVlRX69OkDANi2bRuqVauGKVOm4K+//tJ4Il4YOdtG5cqV4e7urnGch4dHkcIGXRR1P3H//n2MHz8elSpVgpOTE6pUqQI/Pz/l9jFixAjlWG3bh6+vL+Ryzaftml5nxcnJyUnr/qhz586YMWMGgOwrDvzxxx/FVZpGRX3N5WyrlpaWef7Y9ToLC4s8+4LcUlNTcefOHQDQGmgDQMOGDTVO0+d7ra5yjsmSkpIKvQxj5e7ujocPH+a5z8/PD0eOHMGqVaswZcqUQi138+bNmDRpEmbOnImLFy+iTp066NixI6KiotSOT05ORpUqVfD9999rDHh1WebEiROxd+9ebN26FceOHcOTJ0/Qo0ePQj0GXYTcy8TsHYmIivFA5stXVy9JtT2C2TtjEHIv02DrpmzBPcdi548XkGFmp3GMQxl7jdOIjF27T9vALCsNcdblceFH1eN4Kr2YHxkW8yNVzI+YHwHMj17H/Cgv5kd5MT9ifkSaLViwQHkFyK+//hrt2rXD5s2bUalSJaN4LZgiazsLWFpnf9kiIYafQSEiImZHhsbsSBWzI2ZHALOj1zE7yovZUV7MjpgdERW3nEbd8dEpEldCRETGgNmRYTE7UsXsiNkRwOzodcyO8mJ2lBezI2ZHhqL/dm5EpVB193LY1X0deuwcjHSzh/j81Ggkp/+Cnv5NpS5NUkfCg/H1yR8Rq7gFM2tAZNkgLaYNspJ9YFd5KYSQwcLhNkSGB9KedUYZB2upSybSK3NLOUb82sqg63h0Kw7n94Yj+mEiZDLVruAA0GNyfbhXMNzVFswtDde30dr61X4hJSUFDg5FfxyauhADyHNSoMu4nA7ApkrbYwRePU5dx2VlZeW5X1PzgPwkJyfn+XdERATatm2L8PBwnebP6eisia7bwOuPR2qxsbHKrsJeXl6Fmh+Axm7eueU0dcgdGr+usNtF7mXmV4unp6fW6YXVvHlz+Pj44P79+1i/fj2GDRumnBYVFaXs1vvhhx+qDQv0vU3qK5A3pEWLFuHFixfYu3cv7t+/j3nz5mHevHmQy+WoX78+evfujREjRsDJyanQ6yjINurp6anz818YRdlPHDhwAD179lTZl2mibfvQ9XVm7O9HI0aMwIwZMyCEwLFjx/DFF19IWk9RX3M526qrqyvMzLRfHUXTfix32Kvtjwj5TdfXe21B5GyzFhYWhV6GsWrRogV27NiBt956K8/9b775JgIDAzX+ESM/CxYswPDhw5Wd5JctW4b9+/dj5cqVmDp1qsr4Ro0aKf+oo266LsuMj4/HH3/8gQ0bNqBt27YAgFWrVqFmzZo4e/YsmjRpUqjHokmWQuDrvdfx+umIIsMecssXsPQ4hK/3OuHtN8vCTF6wP7qR7u41H4fEl+yrTyWXUwV31K1jhpCrQOh9R9QIuwNn/2pSl1UkxZEdAdLnR4bMjgDmR4bG/EgV86NszI+YH72O+dErzI8KjvmRKuZHpUPuq0ba2dlh2bJlRVre4sWLMW/ePDx9+hR16tTBwoULdfpw8KZNm/DRRx+ha9eu2LVrV5FqkJpMJoOjhw1iHr5EfEwKXL01N6QmIjJ2pSU7AvjZI1PG7EgVs6NszI6YHb2O2dErzI4KjtmRKmZHVBjMjrLlNFpik24iMnXMjvSD2ZFhMTtSxewoG7MjZkevY3b0CrOjgmN2pIrZUf7YaIlIT3xcymBPz7Xotn0IUs3CMev8BKRmzkf/eoY/YTU2V57exudBP+BRWjAAQCjMoXjRAsnRrQCFDeTWjwEAadHtYV3mECxdT8HWzAkBld+TsmwivZPJZLCw0n4QU1SVa7ujkr8bHl6Pxbk99xB1XzW4Mrc0M3gdhpL7AC02NlYvgRUVn9wncnv37tW5k+/rJ6sDBgxAeHg4ZDIZhgwZgg8//BA1a9aEh4cHLC0tIZPJoFAolCcNQl1yS0oF7ShuSFLVIpPJ0LdvX8ydOxfHjx/H48ePUa5cOQDAli1bkJmZCeBVB/HX6XubzO+E1xg4Ojpiz549CA4OxpYtWxAUFITQ0FBkZWXhwoULuHDhAubPn49du3ahadOiNRs1pm20oGJiYtC3b18kJyfD3t4ekydPRseOHVG1alU4OTnB0tISAHDkyBG0a9cOQOnYZ5UpUwZubm6IiYnB48ePpS5Hb685Y9hW9fVeWxA5gV3uK6qUFFOnTkVISIjaabVq1cKRI0ewffv2Ai0zPT0dISEhmDZtmvI+uVyO9u3b48yZM4WqU5dlhoSEICMjA+3bt1eOeeONN1CxYkWcOXNGbaOltLQ0pKWlKf+dkJCgc03B4bGIjH/14SOR6YC06HbISnOHbfnNsHA9hWcRdRAcXhdNq7oV6PGS7lp/XB+nN15FTFQmILIAmfEfYxAVVKNR7fDv2J1IsHBF0K9H0XVFVaN4Ty6s4siOAOZHZNyYHxknY9q3Mj/KxvwoL2PaRguK+ZF6zI8Mh/mR8RFCGGTb2Lx5MyZNmoRly5ahcePG+OWXX9CxY0fcunVL6+8zIiICkydPVmk+bsqc3LMbLSVEa/9AMRGRsWN2pB/MjkwbsyPjZAznOjmYHWVjdpSXMW2jBcXsSD1mR4bD7Kj0YHb0iqN7dkONhOjCf+mTiMgYMDvSD2ZHpo3ZkXEyhnOdHMyOsjE7ysuYttGCYnakHrMjwynJ2REbLRHpUTlHN/zVey26bBmKJLPb+D50ElIy52J4ow5Sl1YsHsZHYvLhebieeBiQCQghg3NWc8xs8QmyMpwwet1FAK++cJkZ3wipCitYl92HTKe/sOF6fQzw6yPxoyAyPTKZDBVruaHCm655givIAJj4MXDuwCouLg4+Pj4SVkMF5eb26kv0zs7O8PPzK/Aybt68iZMnTwIApk+fju+++07tOG0drEsKV1dXyOVyKBQKREZGFmp+AHj27Fm+Y58+fZpnHn3K3ZE3v1p0qbWw+vXrh7lz50KhUGDjxo2YPHkyAGDDhg0AsptR1K9fX2W+0r5NBgQEKK9glJiYiKCgIKxevRo7duxAVFQUPvjgA9y9exc2NjYFXnbOtqHL792Q20ZRbNu2TdnxeefOnXkanORWUrcPbYwh3NGXnG31+fPnyMrK0hqAadpWc4c90dHRWtenbbo+3msLKi4uDgBQsWJFg6+ruNWuXRu1a9fWON3Pzy/PczxmzBh88803cHd31zhPTEwMsrKyVLrEe3p64ubNm4WqU5dlPn36FJaWlirBoqenp/J9/nVz587F119/XaiaohLzXuFNZDoiPeZtAEBG/C1YOIXC2ms7IhPeAcBGS4ZSoaYruvR2xcXhM3CvchckOvqw4RKVOGbmZmj7cV3s+iMCj82r4uYf+1BzWBepyzIJzI/IWDE/0i/mR/rF/KhwmB9px/xIM+ZHeTE/Krlq1aqFGTNmoEePHsoPOarz77//YsGCBfDx8cHUqVPzXe6CBQswfPhwDBkyBACwbNky7N+/HytXrtQ4f1ZWFvr164evv/4aJ06cyHNFQ1Pm6JH9HhMfw0ZLRES6YnZExorZkX4xO9IvZkeFw+xIO2ZHmjE7yovZERUUs6NXnHKyIzbpJiLSGbMjMlbMjvSL2ZF+MTsqHGZH2jE70ozZUV7MjvInN+jSSwlHR0fcu3dP6jLISHjYOeHvD9fAUdSCTJ6OX69+jt/O7JW6LIOKS4nHyH3f4t0d7+H6y0OATMA6vTam1/4fTgxdgrdrvIFOfl5Y2r8+yjpZK79wKTId4ZrVDrIX2W/kP16YjYPh/0j8aIhMV05w1XNqQ3QZXwdlKjrA1tESNg4WUpdWaP7+/sqfb9++LWElVBj16tVT/nzq1KlCLePatWvKn/v00dyM78KFC4VavimxsLBQnoicOHGiwN2Ec+YNDw/XevKTkZGBS5cu5ZlHn3K/rs+fP691bH7Ti6JWrVqoU6cOgFchVXh4OM6cOQNAc1dwbpOvODg4oEuXLti+fTsmTJgAAIiMjFQGejl0DSpyto3w8HA8f/5c47jo6GhEREQUrmgDy9k+XF1dNYZVQOnYPnKLjo5GTEwMAMDb21viaoouZ1tNT0/H5cuXNY7LzMxEaGio2mnW1taoWrUqACAkJETr+rRtL/p4ry2IZ8+eISEhAUD2frS0W7dunfL5KAmmTZuG+Ph45e3hw4c6z1vGwVrjtLRnnSEybWFm/RSh8bv1USppYeHujjJm0WiR/hda134Bp0zN76lEpqpcQDVU90wEAJw5lYLUKG7nBcH8iIwN8yP9Yn6kX8yPio75kSrmR+oxP1LF/KjkWrhwIebPn4+yZcuiT58+mDdvHtavX4/t27fjf//7HyZNmoSAgADUrVsXjo6OGD16dL7LTE9PR0hISJ79ilwuR/v27ZXvW+p88803KFOmDD7++GOdak9LS0NCQkKemzHK+bJcAr8sR0RUYMyOyNgwO9IvZkf6xeyo6JgdqWJ2pB6zI1XMjqggmB3l5ehuCwBIjE1DVpZC4mqIiEwLsyMyNsyO9IvZkX4xOyo6ZkeqmB2px+xIFbOj/LHRkh4U9GCBSj5nG3v8/dEquKAOZPJMLL/1FX44vk3qsvQuLTMN0wMXodWmDjj9fAsgz4BZemUMqTwPZz9eh771A/IcoHTy88LJz9ti4/Am+PXDutg4vAlOT22H9R/MhCK+MSATmHL8c5yLPCfhoyIyfbmDq4Gzm8HeRfOXno1dw4YNYW2dXb8hT1zJMOrXr4/y5csDAJYvX47U1NQCLyMzM1P5c1JSksZxy5YtK3iBJqhLly4Ask/od+8uWKOCnJNnIQRWrVqlcdy2bdsQHx+fZx598vb2Rs2aNQEAW7duRUqK+g+5JyUlYcuWLXpff245odSlS5dw48YNZXAFAH379lU7D7dJ9dq1a6f8OSeYyJGzH09LS9O6jNzb6J9//qlx3OrVq432HCxn+0hNTYVCof4P8MnJyVi7dm1xliW55cuXK39nrVq1kriaosu9b1yzZo3GcTt37lR20VYn53Vz6dKlPGH467S9HvTxXlsQuY/HGjdubNB1mQJd9kXu7u4wMzNT6RL/7NkzlC1btlDr1WWZZcuWRXp6usqV5LSt18rKCo6Ojnluugqo7AovJ2uo+xOFyLJHatR7AIC/Hv2JBwkPdF4uFZxF2bKodiQQlbduQa0xPdB3RW+8N7oWyviY/gcaiHJrObkTrLJeIsXKHSfn7JK6HJPE/IiMBfMj/WN+pF/Mj/SH+VE25kfqMT9Sj/lRydSuXTtcuHABe/bsQZkyZbB+/XqMGzcO/fr1w6xZs/Dvv/9i4MCBePToEX744Qc4OTnlu8yYmBhkZWXB09Mzz/2enp7Kq8G+7uTJk/jjjz+wYsUKnWufO3cunJyclLcKFSroPG9xcvyv0VI8Gy0RERUasyMyFsyO9I/ZkX4xO9IfZkfZmB2px+xIPWZHpCtmR3nZOVnCzEIOoRB4GWvYbZ6IqKRidkTGgtmR/jE70i9mR/rD7CgbsyP1mB2px+xIOzZaIjIQBysbHPzoD5SRN4JMloW1977F10fWS12WXmQpsrDgzEY0WdsBex/9DiFPBtI90aXsdJwdvAOTWnaCmVx9B0gzuQxNq7qha91yaFrVDWZyGfzLO2N+26+RmVgLCmRizKHxuP78ejE/KqKSRyaTwczCtN/qLS0tlQdDwcHBEldTPCIiIiCTySCTydC6dWupyykSuVyO6dOnAwDu3buHgQMHaj1hTUhIwKJFi/Lc5+vrq/x59erVaudbunRpgcMbQxk8eLDy9xcUFKT35Y8bNw52dnYAgJEjR+Lq1asaxz569CjPv7t166bsyDt79myEhYWpzPPw4UNMnjwZAGBra4shQ4boq/Q8cq6+/PTpU3z66adqx0ycOBFRUVEGWX+Ojz76SNkUcv369di4cSMAoGnTpqhSpYraeYx1m2zdurVy29N31+x79+7h2LFjWsf8888/yp8rV66cZ5qXlxcAICoqComJiRqX0a1bN+XYb7/9Frdu3VIZc/36dcyePVvn2otbzvaRnJysNnDNysrCsGHD8OTJk+IuTa1KlSopt5vCiIiIUF5JQJN9+/bhm2++AQDY2Nho3K/MmjVLWYum15axCAgIQP369QFkv95f74YPZHfJz9mfajJixAjlcz98+HC1Af727duxc+dOjcvQx3ttQeQcj1lbW6Nly5aFXk5pYmlpiQYNGiAwMFB5n0KhQGBgIJo2bWqwZTZo0AAWFhZ5xty6dQsPHjwo9Hq1MZPLMLPLmwCgttlSZnx9+DrUQ1pWGr45843R/uGhpJBbWir3L3K5HJXqeJaIDzQQ5WblaINmnbI/BHo7uQIeHzwrcUWmi/mRaWJ+xPxIG+ZH+sX8SDfMj3TH/EgV8yPNmB+VbC1atMDChQsRGhqKuLg4pKam4tGjR9i7dy/GjRsHFxcXg607MTERAwYMwIoVK+Du7q7zfNOmTUN8fLzy9vDhQ4PVWBRO7tmNlhKep0ChYA5FRFQUzI5ME7MjZkfaMDvSL2ZHumF2pDtmR6qYHWnG7IgMpaRnRzK5DI7ubNRNRKQPzI5ME7MjZkfaMDvSL2ZHumF2pDtmR6qYHWnG7Eg7c4MuvZTo378/HB0dpS6DjJCNpRX++uh3dN08Ho8zT2Hrgx+QfDAVP3T8WOrSCkUIgQ1h/+DXi78gRfYIkAMi0xEt3PphbochcLG1KfSy3/Erh7vRM7H4xlTA7h4+/nskNnVZBx9HHz0+AiIyRV27dsWxY8cQHByMxMREODg4SF0SFcCoUaNw6NAh7Ny5E1u3bsXFixcxcuRIBAQEwMnJCQkJCbh58yaCgoKwZ88eWFtbY9y4ccr569WrBz8/P1y9ehW///474uLiMGDAAHh5eeHRo0dYt24dtm3bhubNm+PUqVMSPtLiUbZsWSxduhQDBw5EVFQUAgICMHz4cLzzzjsoW7YsXr58iatXr2LPnj24desW7t69q5zX0tISy5cvR5cuXZCQkIDmzZvjs88+Q7t27WBmZobTp0/j+++/V4ZE8+fPL9AfSAti9OjRWLVqFS5duoSlS5ciPDwco0aNQoUKFfDw4UMsWbIE//zzDxo2bIgLFy4YpAYAKF++PFq1aoWgoCAsXrwYL168APCqY7g6pXGbfPDgAdq0aYM333wT3bt3R8OGDVGuXDkA2SHn5s2bleFM3bp1VboFN2vWDEB2E5BRo0Zh/PjxebatatWqAcjeRhcuXIiePXsiLi4OTZo0weeff47WrVtDCIGgoCD88MMPynnu3Llj8MdeUL1798b06dORlpaGIUOGIDQ0FG+//TacnJxw7do1LFy4ECEhISVm+4iIiECbNm3QtGlTdOnSBXXq1EGZMmUAZIcn27Ztw7Zt25QNVebPn6/cdkzdkiVL0KJFC2RkZODtt9/GxIkT8e6778LKygrnzp3DnDlzEBMTgzp16uDy5ctql9GgQQMMHz4cy5cvx5kzZ9CoUSN89tln8PPzQ0JCAnbs2IGlS5ciICBAGRSpCxeL+l5bEDlNezp27Agbm8Kf/5U2kyZNwqBBg9CwYUMEBATgl19+QVJSkjLAHThwIMqVK4e5c+cCANLT03H9+nXlz48fP0ZoaCjs7e2V+8z8lunk5ISPP/4YkyZNgqurKxwdHTF+/Hg0bdoUTZo0Mcjj7OTnhaX96+PrvdcRGf96l3oZ2nmMxcPkcTj39Bx23dmF7r7dDVIHqZf9gYbC/YGCyFjV7BGAG8e34WmaG45tvIU+rerBzNpK6rJIIsyPTBvzI/1ifqRfzI90w/xId8yPmB8xPyJDcHd3h5mZGZ49e5bn/mfPnqFs2bIq4+/evYuIiAjlFWkBKK92aW5ujlu3bqFq1aoq81lZWcHKyvjPu+xdrCCXy6DIFEh6kQYHVzaeJiIq7ZgdmTZmR/rF7Ei/mB3phtmR7pgdMTtidkSGwOxIlZOHDeIik5DARktERARmR6aO2ZF+MTvSL2ZHumF2pDtmR8yOmB3pkaBSKT4+XgAQ8fHxUpdSKmRkZorOGyYIv9V+wm+1nxi/b5HUJRXYoTvnRYs1vZSPodYfDUXvTd+JB7Ev9LYOhUIh/m/zaVFzaUfht9pPtN38tniW9ExvyycSouj7v5SUFHH9+nWRkpKi58pIk5iYGGFlZSUAiDVr1hRqGUePHhUABABx9OhRjeNWrVqlHBceHq5x3MyZM5Xj1MmZNnPmzALXev36deX8PXr0KPD8uhg0aJAAIHx8fLSOa9WqlQAgWrVqpXWcj4+PACAGDRqkdnp6eroYPXq0kMlkysem6Va5cmWV+S9duiRcXFw0zuPv7y+ePHmi9XnP73eWQ9dtRZPevXsr579y5UqB59fV6tWrhY2NjdbnUtPvd/Xq1crXlLqbmZmZmDNnjsZ167p957f9PH78WNSoUUNjHR06dBAHDx4s0u9DFytWrMizXnNzcxEVFaV1nuLcJnUVEBAgAAgLCwvx/PlzvSwzR+7XhbbbG2+8Ie7du6cyf1ZWlmjSpInG+V43b948jfsLW1tbsW/fPp33TwWh63tAeHi4ctyqVatUpq9cuVLI5XKNj7dPnz7i8OHDWrdtXR9fUbejMmXKCADC1dW1UPPrum3Y2tqK33//XeuypkyZohy/Z8+eQtWTn4K8P+uyPWzYsEFYWlqqfczm5uZi+fLl+b7npqWlic6dO2t9X7xz547y399//73a5RT1vVYX4eHhyuVv3bq1UMsQomQdT9vb24u7d+/qNHbhwoWiYsWKwtLSUgQEBIizZ88qp7Vq1SrPcVTu/Uzu2+v7BG3LFCL7uR4zZoxwcXERtra2onv37iIyMlLnx1fYc6fMLIU4fSdG7Lr0SJy+EyN+P3ZH+Hy+T9T86oBYcG6Z8FvtJ5ptaCaik6MLtFwiInXiIqLE0mF/iUUjA8XZb9fpbbnMj0wP8yP9Y36kGfMj5kfMj1QxP8qL+dErzI+YHxVUaTqWjo6OFj/88IPo1q2baNKkiWjSpIno1q2b+OGHH/J9n1EnICBAjBs3TvnvrKwsUa5cOTF37lyVsSkpKSIsLCzPrWvXrqJt27YiLCxMpKWl6bROY/7s0dovT4tFIwPFw5uxUpdCRCUQsyPTw+xI/5gdacbsiNkRsyNVzI7yYnb0CrMjZkcFxWPpwmN2lNeJzbfFopGB4uS2f6UuhYhKIGZHpofZkf4xO9KM2RGzI2ZHqpgd5cXs6BVmR8yOCkPX42k5iMjgzM3MsLvPz6hu8w4A4GjMMozYvUDiqnRzKfJfdNowDBNPDsELcQNCYYby8newodNubO7zBSq4OOltXTKZDD/0aIw3ZBOhSHdDVEokhh0cgfi0eL2tg4hMj5ubG3r06AEA2LBhg8TVGN6ZM2eUP0+cOFHCSvTHwsICS5YsweXLlzF+/Hj4+/vDyckJZmZmcHJyQt26dfHxxx9j27ZtuHHjhsr8devWRWhoKEaNGgUfHx9YWFjA1dUVAQEBmD9/PoKDg+Hl5SXBI1N19uxZAEC7du3g7+9vsPUMGjQId+/exRdffIEGDRrA2dkZZmZmcHFxQZMmTTB9+nT8/fffGue9efMmPvnkE9SsWRN2dnawsbFB1apVMXz4cFy6dAnTpk0zWO05vL29cenSJXz33Xfw8/ODjY0NnJ2d0aRJEyxZsgQHDhyApaWlwevo2bNnnivodOjQAR4eHlrnMbZtMjU1FaGhoQCAgQMHwtXVVa/Lf+uttxAUFIRp06ahTZs2qFatGhwcHGBhYQFPT0906NABy5YtQ2hoKCpXrqwyv1wuxz///IMvv/wSderUgb29vdruxjkmT56MkydPokePHihTpgysrKzg4+ODoUOH4sKFC3jvvff0+vj0bciQIThx4gS6desGDw8PWFhYwMvLC506dcLmzZuxadMmmJmZSV0m7t27p7wSQGHfbxo0aIB169Zh7NixaNy4MSpWrAhbW1tYWlrC09MTbdu2xezZsxEeHo4RI0ZoXVbO+1/16tWN/nec46OPPsKlS5cwYMAAeHt7w9LSEuXKlUPv3r1x8uRJDB8+PN9lWFpaYs+ePVi1ahVatGgBJycn2NraombNmpg+fTpCQkLg5uamHO/kpP78q6jvtbrYuHEjhBDw9vZG165dC7WM0mzcuHG4f/8+0tLScO7cuTxXUQgKCsLq1auV/65UqRKEECq3oKAgnZcJANbW1li8eDFiY2ORlJSEHTt2qL0Knb6ZyWVoWtUNXeuWQ9OqbhjWogoCKrsiOT0Lpy/WwhuubyAhPQE/BP9g8FqIqORz9vFA3drZf+YIDXfEi6vGd/UYKh7Mj0wf8yP9Y36kP8yP8sf8qGCYHzE/Yn5E58+fR/Xq1fHbb7/ByckJLVu2RMuWLeHk5ISFCxfijTfeKPCVUydNmoQVK1ZgzZo1uHHjBkaPHo2kpCQMGTIEQPb+P+f929raGn5+fnluzs7OcHBwgJ+fX7G8vxqak0f2lQ0TYlIkroSIiIwBsyPTx+xI/5gd6Q+zo/wxOyoYZkfMjpgdkSEwO8rL0cMaAJAQzeyIiIiYHZUEzI70j9mR/jA7yh+zo4JhdsTsiNmRfsiEEMLgayGjk5CQACcnJ8THx8PR0VHqckoNhUKBATtn4srLXQCAevYfYU2PaVrfsKXy/+zdeVxU9f7H8feZGWAGZIZ9cUlQKyNzT7PSNDVpMc0yTcvyttpPrbx12zVbri1a3sq0PctKs9vmrbTC1BbTktRcsjK3FGRRGbYBZvn9oVKUmiJwYHw9H495CGfOOfM+Wggfz/c9m3dn6bbPpmh98acyDL8CAUMxgW6a2H2cerU6sVZfe3dxufrP+EC7XY/LElKodvHt9fw5z8lhc9Tq6+LYcLRf/zwejzZt2qTU1FTZ7fZaSIgDWbZsmU477TRZrVZt3LhRzZs3NztSrbnqqqs0c+ZM9erVSwsXLjQ7Do7A5s2bK39YX7x4sXr06GFyIhwrFi1apF69eslms2nDhg1q0aKF2ZHQALzyyisaOXKkoqKitGXLFlN/LvR4PIqKilJZWZlmzpypESNGmJalPvryyy/VvXt3SdJnn32m3r1713kGv9+vk046ST/99JMmTZqkO+64o9rnCqbvp0eNGqUHHnhAcXFxZkepFTU5O9q2q0TpU5eouNyna/uE6K0dt8kf8Gta72nq0ZTvmQAcHZ/Xpzf+7z25jWg18W3UgOeuOep5K/Ojhon5ERoC5kcwC/MjVAfzo4YjmOZHx8r30qeddpratWunGTNm/OXnl0AgoBtuuEGrV6+ucqP74Xj66af12GOPKTs7W+3bt9eTTz5ZWc7ds2dPpaSkVCn8/qOrrrpKe/bs0XvvvXfYr1ef7z1a/OYGrVm8XR3Tm6vbwJZmxwEQZJgdNUzMjtAQMDuCWZgdoTqYHTUczI6wH7Oj323+IU8fTlut2CaNNPTeLmbHARBkmB01TMyO0BAwO4JZmB2hOpgdNRzBNDuSDv/7aUu1XwHAEbNYLJo16H51ibpMkvR90ZsaOneC/H6/ycl+l19aoGs+eEj937tAP5YskGH45fC20YQOL2jJyGdrvWRJkqIjQvXKFemy7LxOAZ9dq3JX6tZFt6rCX1Hrrw2gfuratasGDRokn8+nSZMmmR2nVi1evFiSNH78eJOT4Ejt/7M766yzGFahTu3/b2/48OEMq3DY9v93c9NNN5l+E8OyZctUVlamli1bavjw4aZmqY/efPNNSXvbvzt16mRKhjlz5uinn35SXFycRo8ebUqG+mj69OlBW7JU05rFhOueC9IkSTMX+XRB8yGSpAe+eUDFFcVmRgMQBKw2q3qNbCsF/NpubamfXv7Q7EgwCfMjNATMj2AW5keoDuZHDQfzo4Zn1apVuuWWWw5YEmsYhm655ZbKdwQ9EqNHj9aWLVtUVlamZcuWVS6Uk/be/HqwhXLS3pscj2ShXH3nit/7Rl7u3FKTkwAA6gtmR2gImB3BLMyOUB3MjhoOZkfYj9nR7/bPjgryShUIBExOAwCoD5gdoSFgdgSzMDtCdTA7ajiO1dkRRUv1xLRp05SSkiK73a6uXbtq+fLlB933+eefV/fu3RUdHa3o6Gj16dPnkPujfjEMQy8OuEtnxY2UJK0rfVeD5twhn8/csiVPRbn+9ck09XozXct2z5Ys5bJVNNd1xz+mZf94Q4Pb1W1Le6uERpox5AKVbR+pgN+mJduXaMJXE+QP1J9SKgB169///rdsNptefvll/fbbb2bHqRW//fabNm/erO7du6tnz55mx8ERWrJkiSSGjah7S5YskdVq1d133212FDQgS5YskdPp1E033WR2lMqvn3fddZesVqvJaepWXl6e9uzZc9DnFyxYoGeffVaSdOGFFyoqKqpugv1BIBDQQw89JEmaOHGiGjVqVOcZ6kKvXr109tlnH/Hj1VdfNTt6gzH01GbqeWK8yr1+rVzdVY0jGiu7OFtPff+U2dEABIGmpx2vVgmFkqSvvyiRJyff5EQwC/Mj1HfMj2AW5keoDuZH9QPzo+CUlJR0yPt8li9frsTExDpMFHyccfsWy1G0BAD4A2ZHqO+YHcEszI5QHcyO6gdmR0D1OGMdkiF5y3wqLeQN4QEAezE7Qn3H7AhmYXaE6mB2VD8wOzo4I0D18lHzeDwqLy+vsu1ImtXmzJmjESNGaMaMGerataumTp2quXPnasOGDUpISPjL/sOHD9cZZ5yh008/XXa7XY888ojeffddrV27Vk2aNDms13S73XK5XCooKDC9Be5Yduv8Z7Rg53RJUjPb2Xp/6OMKqeMv0D6/T098PVezfnpWPmueJMmoiNfA5tfqnl6XKtRm7l8Ybyzbqns/nStH01dlGH6NSBuhWzvfesB3dgQOx9F+/fN4PNq0aZNSU1Nlt9trISEO5bXXXtPGjRt1zjnn6PTTTzc7DgAAwFFZtGiRBgwYoMGDB6tPnz5q2bKlLBaLtmzZog8++ECzZs2Sz+eTw+HQypUrdcIJJ9R5xh07dui5555TaGiobr/99qMeKtbX76dnzpxZrePat2+vdu3a1XCa+qE2Zkc73R6d88QSFZRW6JIzi7Ug/wEZMjTrvFlqG9+2Rl4DwLHL4y7VrH9+qjJrI7V2bFLvJ66u8nwgEJDfG5A15O/ff4L5UcPG/AgAAASTY21+dKx8Lz1t2jT985//1PXXX6/evXtXlirt3LlTGRkZev755zV58mTdeOONJic9tPp871H+9iLNfmC5wsJtuuZx3tEXQM1idtSwMTsCAADBhNkR6rP6PDuSpJl3faWiXWUadFsnJbd0mR0HQBBhdtSwMTsCAADB5FibHUmH//00RUvVVFJSon/961966623lJ//13fH9vl8h32url276tRTT9XTTz8tSfL7/WrWrJnGjBmjO+6442+P9/l8io6O1tNPP60RI0Yc1mvW94HVseTejJf07rapMoyAEi1naN7QJ+UICa2T135t5ad68vup8li27t3gjVSPhOF6uO/ViqxHP4g/8L91mvnD23I0nitJurnjzbr6lKv/5ijgwBhYAUDDlpOTo5ycnCM+LjQ01JQf9FB31qxZU63jmjZtakrbMiDtHVj16tXrkPs4nU7NnTtX55xzTh2lql18P91w1Nbs6INVOzT2ze9lsxjqe9ZCfZm9QK2iWumtC95SiDWkxl4HwLFp3dvL9PlnxTL8Xp13mlvG4v8p/p//VJ61sZZ98KsKd3k0+M5TFRlz6L+DmB8BQMPG/AgHw/wIDdGxNj86lr6XnjNnjp544gmtWLGi8h4jq9WqTp06ady4cbr00ktNTvj36vO9RxVlPj1302JJ0tVTussewdwJQM1hdgQADRuzIxwMsyM0RMyOUJ/V59mRJL33RKa2b9ijPiPTdGLXJLPjAAgizI4AoGFjdoSDYXaEhuhYmx1Jh//9tK0OMwWV2267TZ9//rmmT5+uK664QtOmTdP27dv17LPP6uGHHz7s85SXl2vFihW68847K7dZLBb16dNHS5cuPaxzlJSUqKKiQjExMQfdp6ysTGVlZZWfu93uw86I2vVA73/IsdiuNzY9op3+r3TuGzfow8ueUURo7f0gvODn7/TA15NVoLWSRQr4wtQ2cqCm9BujZGf9a2K/67yTtCnvXH2xs0T2xA81NXOqou3RGnT8ILOjAQCAOvbMM89o4sSJR3xc8+bNtXnz5poPhHrjlFNOqdZxL7/8sq666qqaDQMcps6dO+uVV17R/PnztWrVKuXm5mrPnj1yOp1q1aqV0tPTNXr0aMXHx5sdFagx/dsma8GabH34Q5Z+WtdLUcnL9cueX/Ty2pd1XdvrzI4HoIE76eIuWr/kbWWXx+rLjD1q/qtbXz2/SbsrciVDUkDyFFX8bdESAKBhY36Eg2F+hIaI+VHwGjJkiIYMGaKKigrl5eVJkuLi4hQSQiFQTQgJsyrcGaoSd7kKckspWgIAAEAlZkc4GGZHaIiYHQHV54xzaPuGPSrILTU7CgAAAOoRZkc4GGZHaIiYHR0cRUvVNG/ePL366qvq2bOnRo4cqe7du6tVq1Zq3ry5Xn/9dQ0fPvywzpOXlyefz6fExMQq2xMTE/Xjjz8e1jluv/12NW7cWH369DnoPpMmTarWX+yoG3edNUyOkFC9+NODyje+Vb83rtVHQ5+T0+6o0ddZsf0X3fn5o8ry7S3xCgSsSgnpo0fTxyktsXGNvlZNsloMPXlZB10yvVS/5hUrLG6RJi6dKFeYS72P6212PAAAAAColkaNGunKK6/UlVdeaXaUY97WrVurdVxUVFS9fMe1+swwDD0wsI2WbdqljTvL1Pe44fqm7Gk9u+pZndP8HKW4UsyOCKAB8+7YodMvaKJ35xaqILKFVrcbLZX7K0uWAAAAgIaG+VHwCwkJUXJystkxgpIr3qESd7nceaVKTGGGBwAAAAAIPsyOgOpzxe9dr+WmaAkAAAAAEKSYHR2cxewADdWuXbvUokULSZLT6dSuXbskSWeeeaaWLFlSZzkefvhhzZ49W++++67s9oO/C/edd96pgoKCyse2bdvqLCMOzy2nX6LRaQ8q4LepwFipfm9epfziwho596bdO3XxW//SlZ9eUlmyFKfTNOOsOfrf8Mn1umRpv0ZhNr1wZWdFll6o8j2d5Q/49a/F/9K32d+aHQ0AANSh++67T4FA4IgftIIHv+r8dxEIBGgFByBJSklJUWpqqlJSUg77kZqaqqlTp5odvUGKiQjVIxfvfUeHz75ropOjT1W5v1wTl06UP+A3OR2Ahmz5Jf+nT1/5UQFryO8bDf4ZBACONcyPcDDMjwA0FBs3btTZZ59tdowGz7lvsVwBi+UAAADwB8yOcDDMjgDg2OKMY3YEAACAv2J2hINhdgQEF1YYVFOLFi20adMmSVLr1q311ltvSZLmzZunqKiowz5PXFycrFardu7cWWX7zp07lZSUdMhjJ0+erIcffliffPKJ2rZte8h9w8LC5HQ6qzxQ/9zQ5QLd2u5RBfwhKrKs07lzrlJW4Z5qny+/uFD/eO/fuvC98/VT6ccyDJ8ifGma2OkFfX7l8zoz9cSaC18HmkaH64URnRXIvVgVhWkq95drzMIxWp+/3uxoAAAAAIAGzO/3y+fzye/3H/bD5/Np/PjxZkdvsHqflKhLOzdVIGBo60/nym6167ud3+ndn981OxqABuzXM0ar0JlidgwAAAAAOCpFRUVavHix2TEaPNe+oiU3i+UAAAAAAADwJ/tnRwV5zI4AAAAAADjW2MwO0FCNHDlSq1at0llnnaU77rhD/fv319NPP62Kigo9/vjjh32e0NBQderUSRkZGRo4cKCkvYv7MjIyNHr06IMe9+ijj+qhhx7SggUL1Llz56O9HNQjV3XsK7stVA+t+KdKrT+p/1tX6p1BL+m46NjDPkdJRZnuzXhJn+x4TbIWShYpxHucrmszWtd3SZdhGLV4BbWrw3HRmjK4o8bM9spo9pKKIzbphs9u0GvnvqbjnMeZHQ8AAAAAABymey9I01e/5Gt7ntS16cVa53tdU76boh5Neyg+PN7seAAaoJ5Xd9TXb65RXo5XCvglg/eaAAAAAFD/PPnkk4d8fvv27XWUJLg54/YtlqNoCQAAAAAAAH+yv2ip1F2uco9XoXaWWAIAAAAAcKxgClBNt9xyS+XHffr00Y8//qgVK1aoVatWatu27RGda9y4cbryyivVuXNndenSRVOnTlVxcbFGjhwpSRoxYoSaNGmiSZMmSZIeeeQRjR8/Xm+88YZSUlKUnZ0tSWrUqJEaNWpUQ1cIMw1te5bCQ57W3UvHqsz2qwa+c4XmDnxZLWMTD3mc3+/Xo1/O1eyfn5XPlitZJYs3Vhe3uFZ39Rgqm9VaR1dQu/q3a6xfc0/WEwuvVETz57RLO3Tdp9fptXNfYyEmAAAAAOCoXHnllbr66qvVo0cPs6MEvUh7iB4b3FbDnl+mZSvTlNb5BG0r/kmTlk/S4z0Pv8gcAPZrdlKM+l8ao8xrx+vX1P4qdDaXAj7JCI65KAAAAIDgcPPNNys5OVmhoaEHfL68vLyOEwWn/Yvl3HkULQEAAAAAAKCqsPAQhUXYVFbslTvPo7imrMcDAAAAAOBYwds5V9Orr76qsrKyys+bN2+uQYMGqXXr1nr11VeP6FxDhgzR5MmTNX78eLVv314rV67U/PnzlZi4t1Rn69atysrKqtx/+vTpKi8v1yWXXKLk5OTKx+TJk2vm4lAvXHjSaZrSfYbki1CFbZsufu8Krd+5XT5/QEs35uv9ldu1dGO+fP6AJOnlFZ+pyysD9PqmB/eWLPkaqVfcdfrq8vka32t40JQs7Te2dytdeEoLlWwdKVXEanvRdt3w2Q1yl7vNjgYAAAAAaMAKCgrUp08fHX/88fr3v/+t7du3mx0pqJ3eMk4jz0iRZFXOrxfKalj16ZZP9fnWz82OBqCBComLU4I1V2eWf6SebffI5c03OxIAAAAAVNG8eXM98cQT2rRp0wEfH374odkRg4Izbm/RUtGeMnkrfCanAQAAAAAAQH3jiqOoGwAAAACAY5HN7AAN1ciRI5Wenq6EhIQq2wsLCzVy5EiNGDHiiM43evRojR49+oDPLVq0qMrnmzdvPqJzo+E65/iOetr2gsZ8fr18tiwNmXeFQvNuVH5RhUKilqliT1dFR5bLGvuRPCHrJKsU8Ieqg3OgJvcbq8RGLrMvodYYhqFHL2mr33aX6Pst/1Bk6rP6afdPGpMxRs/2fVZ2m93siAAAAACABui9995Tbm6uXnvtNc2cOVMTJkxQnz59dPXVV2vAgAEKCQkxO2LQuT29tRb/lKtfc6WTG6drq+9DPbjsQZ2adKoahfJucQCOTEhSklotzJAREiLDMHSS36+tP+Tq24+2qmh3mRyRfB0HAAAAYK5OnTppxYoVuvTSSw/4vGEYCgQCdZwq+DgiQxQSZlVFmU+F+R5FJ0WYHQkAAAAAAAD1iDPeoZwthSrIpWgJAAAAAIBjicXsAA1VIBCQYRh/2f7bb7/J5QrechvUvbNS2+j5vi9J3mgFQnJVGvuULPbfFBafobCk/6o8cYo8IesUCFjUIvQc/feCeXrt4nuDumRpP3uIVc9e0VmNI5qqaMtIWQIOZeZk6rbFt8nr95odD0GOG1sBAACAI9dQvo+Oj4/XuHHjtGrVKi1btkytWrXSFVdcocaNG+uWW27Rzz//bHbEoGIPserxS9vLajG0dm1XxYQmK6ckR//J/I/Z0QA0UJbQ0Mr5vcViUUq7RF1yR2eNeOh0NYquu4L2hvL3HgAAAFBfHCvfQ99///0aPHjwQZ9PS0vTpk2b6jBRcDIMQ854hySxWA5AvXSs/L0HAAAA1BS+h0ZNc8XtnR25mR0BqIf4ew8AAAA4cof7fTRFS0eoQ4cO6tixowzDUO/evdWxY8fKR7t27dS9e3f16dPH7JgIMp2bnKCw3NHyl8fIErpL9uS3JEkhkRtkGAFVuNvKnn2H3hkyWSfGNzY5bd2KjwzTS1edqnA1U9GWEbIoRIt+W6T7vr6PgQJqhdVqlSR5vZR5AQAAAEdq//fR+7+vru+ysrL06aef6tNPP5XVatV5552nH374QWlpaXriiSfMjhdU2jeL0o09W0qBUO3ZdqEkac6GOVqZs9LcYACChmEYsobUzT+JWCx7X8fn89XJ6wEAAADBoqHNjqorLS1NnTt3PujzISEhat68eR0mCl4uipYA1EPcewQAAABUz/5/f93/77HA0aos6c5jdgSg/mB2BAAAAFTf4d57ZKuLMMFk4MCBkqSVK1eqX79+atSoUeVzoaGhSklJ0cUXX2xSOgSr5Zt2Kb/IJ0vFAIUlvStr6B5Jkq8sTuV5Z8tfnqh87979urWMNTesCU5MitRTl3XQ1TO9Ktp2mSKazdL7G99XjD1G4zqPMzsegozNZlNYWJgKCgoUGRlpdhwAAACgQSkoKFBYWJhstvo7kqqoqNAHH3ygl19+WZ988onatm2rm2++WcOGDZPT6ZQkvfvuu/rHP/6hW265xeS0wWXM2ccrY32O1mWlKjXxDOXpK9339X16q/9bCrWGmh0PAA5bSEiIQkJCVFRUVOXfEAAAAAAcWkOYHaFhccXtXSznpmgJQD3CvUcAAABA9RQWFlb+WyxQEyjpBlAfMTsCAAAAqu9w7z3izqQjNGHCBElSSkqKhgwZIrvdbnIiHAtyCj0KiVqmsPiMKtutYXlyNHlLklSW21s5hT3MiFcv9GqdoHsvSNPEeVJp1iDZk9/Wy2tfVrQ9WiPbjDQ7HoKIYRiKiorSzp07tXv3bkVHR5sdCQAAAGgQdu/ercLCQiUmJsowDLPjHFRycrL8fr8uu+wyLV++XO3bt//LPr169VJUVFSdZwt2oTaLHh/SThc+9ZU2/XS2Ek9ao40FG/Ximhc1qt0os+MBwGEzDEORkZHas2ePXC6XHA6H2ZEAAACAeq+hzI5qUocOHQ54rYZhyG63q1WrVrrqqqvUq1cvE9IFB+f+xXJ5LJYDUH9w7xEAAABw5EpLS+V2uxUVFXXMzI5Q+/YXLRXle+T3+WWxWkxOBADMjgAAAIDqOpJ7jyhaqqYrr7xSe/bs0axZs7Rx40bddtttiomJUWZmphITE9WkSROzIyKIJETaVbGnq7xFaZIkq3277MnvyJM1SD7P3v/WAt5IJUQe28VfV52eoo25RZr1jRQSUipr3Id6fMXjigqL0kXHX2R2PASR6OholZeXKzs7W263W40aNZLdbpfFYuEfbgAAAIB9AoGA/H6/PB6PioqKVFJSoujo6Hr/j75PPPGEBg8efMhy7aioKG3atKkOUx07Wic5dUvfE/TI/B9VvOMCGYmv6/nVz6tf835qEdXC7HgAcNji4uJUWlqqrVu3yul0KjIyUlarldkRAAAAsE9DnR3VpPT0dE2fPl2nnHKKunTpIkn69ttvtXr1al111VVat26d+vTpo3feeUcDBgwwOW3D5Irbu1jOnUvREoD6hXuPAAAAgL8XCATk8/lUWFgot9utsLAwxcXFmR0LQSTCFSarzSKf16/CXWWVxUsAYDZmRwAAAMDfO5p7jyhaqqbVq1erT58+crlc2rx5s6699lrFxMTonXfe0datW/Xqq6+aHRFBpEtqjJIiEpRd4FTgD9t9nibye5rIkJTksqtLaoxZEesFwzA0of/J2pJfoi9+7q6YsFJVRC7UxKUTFRUWpV7H8S6PqBmGYSgpKUkOh0Nut1t5eXny+/1mxwIAAADqJYvFovDwcDVu3Fgul8vsOH/riiuuMDvCMe+6Hi302fqdWrGljZLj2qhIazRx6US9nP6yLAbvHAegYbBarWrWrJny8vJUWFioPXv2mB0JAAAAqJca2uyoJuXl5emf//yn7r333irbH3zwQW3ZskWffPKJJkyYoAceeICipWpy7lsc587zKOAPyLCwAAVA/cC9RwAAAMDhCwkJUVRUlOLi4mS1Ws2OgyBiWAw54+zanV0id14pRUsA6g1mRwAAAMDhq869RxQtVdMtt9yiq666So8++qgiIyMrt5933nkaNmyYickQjKwWQxP6p2nUrEz9+Zav/Z9P6J8mKzeEKcRq0dPDOmrQM19p4299ldyqVEUhS3Xbkts0o88MdU7qbHZEBBGXyyWXyyW/3y+v18vQCgAAAPgTi8Uim80mi4VyHBw+q8XQlMHtdO5/vlD2r+cr+oRflJmTqbd/eluXnnip2fEA4LBZrVYlJiYqISFBFRUVzI4AAACAPznWZ0dvvfWWVqxY8ZftQ4cOVadOnfT888/rsssu0+OPP25CuuAQGRMmi8WQz+tXcUGZGkXbzY4EAFVw7xEAAABwaBaLRSEhITIM1sqgdjjjHdqdXaKC3FI1O8nsNABQFbMjAAAA4NCqe+8RRUvV9N133+m55577y/YmTZooOzvbhEQIdultkjX98o6aOG+dsosjVZbbWwFvpJJcdk3on6b0NslmR6w3XI4QvXTVqRo47Stl/XKBmqd5tMv3vcYsHKNX0l/RiTEnmh0RQcZisSg0NNTsGAAAAAAQNFLiInTXea117/trVZpzjmzxH+iJFU/orKZnKTEi0ex4AHBEDMNgdgQAAADgL+x2u77++mu1atWqyvavv/5advveQiC/31/5MY6cxWpRo1i73LmlKsgtpWgJQL3FvUcAAAAAYA5XnEOS5M4tNTkJABwcsyMAAACgZlG0VE1hYWFyu91/2f7TTz8pPj7ehEQ4FqS3SVbftCQt37RLOYU9lBBpV5fUGFkttPP/WfPYCD17RWcNf+EbbVk/SC1P8SinYr2u//R6vXbea2oW2czsiAAAAAAA4BAuP625Plm3U1/8fJriYlarSJs1afkkTe011exoAAAAAAAAR23MmDG64YYbtGLFCp166qmSpG+//VYvvPCC7rrrLknSggUL1L59exNTNnyueEdl0VKTE6LNjgMAAAAAAIB6xBm/t2ipII+iJQAAAAAAjhUWswM0VBdeeKHuv/9+VVRUSNr7jtRbt27V7bffrosvvtjkdAhmVouhbi1jNaB9E3VrGUvJ0iF0SY3RpEFtpUCINq65VIn2VOV78nX9p9crrzTP7HgAAAAAAOAQDMPQo5e0VaQ9VLu2DJBFVmVszVDGlgyzowEAAAAAABy1e+65R88//7yWL1+usWPHauzYsVq+fLmef/553X333ZKkG264QfPmzTM5acPmitu7WM6dy2I5AAAAAAAAVOXaX7TE7AgAAAAAgGMGRUvVNGXKFBUVFSkhIUGlpaU666yz1KpVK0VGRuqhhx4yOx6AfS7p1FQ39mwp+R3auna44u2Nta1wm2749AYVlheaHQ8AAAAAUI85nU79+uuvZsc4piW7HJp44cnylyWrPL+HJOmhZQ/JXe42ORkAAAAAAMDRGz58uJYuXapdu3Zp165dWrp0qYYNG1b5vMPhkN1uNzFhw+fcV7RUkMdiOQAAAAAAAFS1v2jJnVuqQCBgchoAAAAAAFAXbGYHaKhcLpc+/fRTffXVV1q1apWKiorUsWNH9enTx+xoAP7k1nNO1K+5xZq/Nlu7f71KUakztGH3Bo1ZOEbP9n1WYdYwsyMCAAAAAOohbp6pHy7q0EQL1mZrwbqzFRW1VrmlOZq6YqrGdxtvdjQAAAAAAICjtmLFCq1fv16SdPLJJ6tDhw4mJwouf1wsBwAAAAAAAPxRZKxdMqSKMp88RRVyRIaaHQkAAAAAANQyipaO0hlnnKEzzjjD7BgADsFiMfT4kHba/mypftguOXdep4j4p7Vi5wrdtvg2Pd7zcdksfDkEAAAAAKA+MgxD/77oFH23ebf2/DZA4c2f19yf5ur8FuerU2Ins+MBAAAAAABUS05OjoYOHapFixYpKipKkrRnzx716tVLs2fPVnx8vLkBg4RzX9FSQR5FSwAAAAAAAKjKFmJVo6gwFe0uU0FuKUVLAAAAAAAcAyxmB2iICgsLtWLFChUVFUmSMjMzNWLECA0ePFivv/66yekAHEh4qE0vXNlZSU67tmRFKbl0lEItofp82+e6f+n9CgQCZkcEAAAAANQzl19+uZxOp9kxICm2UZj+PegU+UpaqmJPZ0nSxKUTVe4rNzkZAAAAAABA9YwZM0aFhYVau3atdu3apV27dmnNmjVyu90aO3as2fGChjPOLkkqK/aqrKTC5DQAAAAAAACob5xx+4q6cynqBgAAAADgWEDR0hFasmSJmjRpolNPPVXNmzfXJ598op49e+rbb7/V+vXrNWLECD3//PNmxwRwAIlOu164srMcIVZ9/3OsOthHy2JY9O4v72pq5lSz4wEAAAAA6pnp06crLi7O7BjYp9/JSRrUsYk8O8+T4YvUpoJNev4H5nAAAAAAAKBhmj9/vp555hmddNJJldvS0tI0bdo0ffzxxyYmCy6hdpsczlBJLJYDAAAAAADAX7ni9xYtufOYHQEAAAAAcCygaOkI3XPPPRo8eLC2bdumm2++WUOGDNHo0aO1fv16rVmzRhMnTtS0adPMjgngINo0cWnq0PYyDOmzFQnqGz9akvTSmpc0c+1Mk9MBAAAAAIBDmdD/ZCVHxqgkq78k6YUfXtAvu38xORUAAAAAAMCR8/v9CgkJ+cv2kJAQ+f1+ExIFL1fc3sVyFC0BAAAAAADgz5zxzI4AAAAAADiWULR0hFavXq3bbrtNTZo00e233y63260hQ4ZUPj906FBt3LjRxIQA/k6/k5N0e3prSdI7SxrrwmbXSJImfzdZH2z8wMxoAAAAAADgEFyOED16SVt5C0+Rt7C1vH6v7lt6n/wBFh8CAAAAAICG5eyzz9ZNN92kHTt2VG7bvn27brnlFvXu3dvEZMHHGW+XJLnzWCwHAAAAAACAqlz7ipbcFC0BAAAAAHBMoGjpCLndbsXExEiSQkNDFR4ersjIyMrnIyMjVVJSYlY8AIfp+h4tNLhTU/kD0vuLT1T/5kMlSeO/Gq/F2xabnA4AAAAAABxM9+PjdcVpKfJkD5T8YVqVu0pzNswxOxYAAAAAAMARefrpp+V2u5WSkqKWLVuqZcuWSk1Nldvt1lNPPWV2vKDiitu7WK6AxXIAAAAAAAD4k/1FS8yOAAAAAAA4NlC0dIQMw5BhGAf9HEDDYBiGHrroFHVJjVFRmU+Ll3XVOcedL1/Ap38u/qcyd2aaHREAAAAAABzEnee1VnNXY3ly+kmS/pP5H2UXZ5ucCgAAAAAA4PA1a9ZMmZmZ+vDDD3XzzTfr5ptv1kcffaTMzEw1bdrU7HhBZf9iOXcei+UAAAAAAABQlXNfSXeJu1wV5T6T0wAAAAAAgNpmMztAQxMIBNS7d2/ZbHt/60pKStS/f3+FhoZKkrxer5nxAByBUJtFz17eSQOf+Upb8ku06cfzdWYrt77c8YVGZ4zWy+kv68SYE82OCQAAAACoQ2eddZauvvpqDR48WA6Hw+w4OIjwUJumXNpOg2cUyedcqeLwrXpo2UN6steTlKIDAAAAAIAGwzAM9e3bV3379jU7SlBzxodLkgpyKVoCAAAAAABAVfaIEIWF21RW4pU7t1SxTRqZHQkAAAAAANQiipaO0IQJE6p8PmDAgL/sc/HFF9dVHABHKToiVC9eeaoGPfOVMre4dWH0leoQX6Tvc7/XqM9G6dVzX1XTSN4pEgAAAACOFR06dNCtt96qMWPG6NJLL9XVV1+t00477ajOOW3aND322GPKzs5Wu3bt9NRTT6lLly4H3X/u3Lm69957tXnzZh1//PF65JFHdN5551U+f7AioUcffVS33XabJCklJUVbtmyp8vykSZN0xx13HNW11Cedmsfouh7H67lvBiki9Skt2rZIn275VOeknGN2NAAAAAAAgAN68sknD3vfsWPH1mKSY4srfm+hetHuMvkq/LKGWExOBAAAAAAAgPrEGedQ7tZCFVC0BAAAAABA0KNo6Qj9uWjp73z11Vfq3LmzwsLCaikRgKPVKqGRpl/eSSNeWq4PVuZpTJ9bVBT9gH7e/bOu//R6zTx3puIccWbHBAAAAADUgalTp2ry5Mn64IMPNHPmTPXo0UOtWrXSP/7xD11xxRVKTEw8ovPNmTNH48aN04wZM9S1a1dNnTpV/fr104YNG5SQkPCX/b/++mtddtllmjRpki644AK98cYbGjhwoDIzM9WmTRtJUlZWVpVjPv74Y1199dV/Kf++//77de2111Z+HhkZeUTZG4Jb+h6vRRty9Gv+WQqLW6hJyyepa3JXucJcZkcDAAAAAAD4iyeeeOKw9jMMg6KlGuSIDJEtzCpvmU/u/FJFJ0WYHQkAAAAAAAD1iCt+b9GSO6/U7CgAAAAAAKCW8fZctezcc8/V9u3bzY4B4G+c0SpODwzYu2D1qc92aHCT+9WkURNtLdyqGz+7UUXlRSYnBAAAAADUFZvNpkGDBun999/Xb7/9pmHDhunee+9Vs2bNNHDgQC1cuPCwz/X444/r2muv1ciRI5WWlqYZM2YoPDxcL7300gH3/89//qP09HTddtttOumkk/TAAw+oY8eOevrppyv3SUpKqvJ4//331atXL7Vo0aLKuSIjI6vsFxERfAvIwmxWTbm0nQK7z5avLF55pXl6YsXhLVgEAAAAAACoa5s2bTrg47XXXtP69esrP//111+P+NzTpk1TSkqK7Ha7unbtquXLlx9033feeUedO3dWVFSUIiIi1L59e7322mtHc2n1mmEYcsU5JEkFuSyWAwAAAAAAxx5mR4fmjGd2BAAAAADAsYKipVoWCATMjgDgMA3repyuPjNVknTfu9t0S5vHFGOP0fpd6zX287Eq85WZnBAAAAAAUJeWL1+uCRMmaMqUKUpISNCdd96puLg4XXDBBbr11lv/9vjy8nKtWLFCffr0qdxmsVjUp08fLV269IDHLF26tMr+ktSvX7+D7r9z5059+OGHuvrqq//y3MMPP6zY2Fh16NBBjz32mLxe799mbohObuzSTWenqSxrkCTpvz//V99mf2tyKgAAAAAAgMN33nnnaceOHdU+fs6cORo3bpwmTJigzMxMtWvXTv369VNOTs4B94+JidHdd9+tpUuXavXq1Ro5cqRGjhypBQsWVDtDfeeMs0uS3HkslgMAAAAAAMcWZkd/z7WvaMlN0RIAAAAAAEGPoiUA+IO7zjtJZ7dOUJnXr3ve3qn7u05VREiEvs3+VrcvuV0+v8/siAAAAACAWpSTk6MpU6aoTZs26t69u3Jzc/Xmm29q8+bNmjhxol544QV98sknmjFjxt+eKy8vTz6fT4mJiVW2JyYmKjs7+4DHZGdnH9H+M2fOVGRkpAYNGlRl+9ixYzV79mx9/vnnuv766/Xvf/9b//rXvw6ataysTG63u8qjIbnhrJY6Ja6Dynd3kSRNXDqRwmQAAAAAANBgHO0buT3++OO69tprNXLkSKWlpWnGjBkKDw/XSy+9dMD9e/bsqYsuukgnnXSSWrZsqZtuuklt27bVl19+eVQ56rP9i+UKWCwHAAAAAACOMcyO/p4rbt/siJJuAAAAAACCHkVLAPAHVouhJy/roNZJkcotLNPD7xfp0TOfUIglRBlbM/TANw8oEAgotyRXz6x8RrkluWZHPib5/AF9vP4njZ3/sD5e/5N8/qO76RQAAAAA9mvatKleeOEFXXnllfrtt9/09ttvKz09XYZhVO7Ttm1bnXrqqSam/N1LL72k4cOHy263V9k+btw49ezZU23bttUNN9ygKVOm6KmnnlJZ2YHLhyZNmiSXy1X5aNasWV3ErzE2q0VTLm0n7Tpf/opIbXFv0bOrnjU7FgAAAAAAQK0rLy/XihUr1KdPn8ptFotFffr00dKlS//2+EAgoIyMDG3YsEE9evQ46H4Nvah7f9GSO89jchIAAAAAAIC6w+zo8Dj3zY4K8z3ysz4FAAAAAICgRtESAPxJozCbXriys+IahWl9lluvfh6ih7s/Ioth0X9//q+e+v4p5Zbmavqq6cotpWiprs1fk6UzH1mo/5uzSJ/vfF3/N2eRznxkoeavyTI7GgAAAIAgkJGRofXr1+u2225TfHz8AfdxOp168MEHD1patF9cXJysVqt27txZZfvOnTuVlJR0wGOSkpIOe/8vvvhCGzZs0DXXXHPIHJLUtWtXeb1ebd68+YDP33nnnSooKKh8bNu27W/PWd+0jG+k28/poLKdF0qSXlrzkn7a/ZPJqQAAAAAAAP7es88+q8TExGodm5eXJ5/P95fjExMTlZ2dfdDjCgoK1KhRI4WGhur888/XU089pb59+x50/4Ze1L1/sVxBbqnJSQAAAAAAAOoOs6PDExEVJovNkN8XUNEuiroBAAAAAAhmFC3VMsMwzI4AoBqaRofr+RGdFGqz6LP1O/Xduqa697R7JUnP//C8Pvz1Q5MTHpvmr8nSqFmZyiqoOrjOLvBo1KxMypYAAAAAHLXu3bsf1n7nnnuutm/ffsh9QkND1alTJ2VkZFRu8/v9ysjIULdu3Q54TLdu3arsL0mffvrpAfd/8cUX1alTJ7Vr1+5v865cuVIWi0UJCQkHfD4sLExOp7PKoyG66vQUdY4/SxWFafIFfJrw1QT5/D6zYwEAAAAAABzSsGHDFBERUaevGRkZqZUrV+rbb7/VQw89pHHjxmnRokUH3b+hF3W79hUtufNKFfAHTE4DAAAAAABQvx1rsyOLxZAzdl9Rdx5F3QAAAAAABDOb2QGCXSDAjTlAQ9XhuGhNGdxOY978Xs8t+VV3u1pp6IlDNXvDbL267lVJ0rTvp6lVdCtFh0UrxZmi42OOV6w9Vnab3eT0waHCX6H80nzll+ZrZ3GO7l74mUKTsmVYS2SE5kuSrPbt8kkyJE34sEx90y6S1ULJHQAAAIDadbgzn3HjxunKK69U586d1aVLF02dOlXFxcUaOXKkJGnEiBFq0qSJJk2aJEm66aabdNZZZ2nKlCk6//zzNXv2bH333Xd67rnnqpzX7XZr7ty5mjJlyl9ec+nSpVq2bJl69eqlyMhILV26VLfccosuv/xyRUdHH+WV128Wi6HJg9sp/amLFQjfqDX5azR7w2wNP2m42dEAAAAAAABqRVxcnKxWq3bu3Fll+86dO5WUlHTQ4ywWi1q1aiVJat++vdavX69JkyapZ8+eB9w/LCxMYWFhNZa7rjWKscuwGPJV+FVcUK5G0Q33WgAAAAAAAA4Xs6PD54p3aM/OErlzS6XWZqcBAAAAAAC1haKlajr77LP1zjvvKCoqqsp2t9utgQMHauHChZKkwsJCE9IBqCn92zXWr7nFeuKznzTlm5kKifusyvNLti/Rku1L/nJcZEik4sLjFOeIU5w9rvLjeEe8Yh2xlR+7wlyyGJa6upx6IRAIqMRbotySXOWV5imvNE+5pb9/nFOSq6yiHOWX5qnIW1D1YJcU+qfz2ZPfqfx4d25vLd90lrq1jK39CwEAAACAwzBkyBDl5uZq/Pjxys7OVvv27TV//nwlJiZKkrZu3SqL5fefC08//XS98cYbuueee3TXXXfp+OOP13vvvac2bdpUOe/s2bMVCAR02WWX/eU1w8LCNHv2bN13330qKytTamqqbrnlFo0bN652L7aeaBodrvHndtPdGefKnvyenljxH53d7GwlN0o2OxoAAAAAAECNCw0NVadOnZSRkaGBAwdKkvx+vzIyMjR69OjDPo/f71dZWVktpTSf1WpRZEyY3HkeufNKKFoCAAAAAADHBGZHh88Z75AkFeSWmpwEAAAAAADUJoqWqmnRokUqLy//y3aPx6MvvvjChEQAasvY3q20MbdI89Z2kaX0ZNlDDBWHLlVozDJ5i1so1GpRQpRXsni0y7NL5f5yFVYUqrCgUJsKNh3y3DbDphhHjOId8XtLmf7w+GMpU5wjTnabvcauKbckV3N/mqvBJwxWfHh8jZzT5/dpd9nu38uT/lSklF+ar9zSXOWW5Mrj8xz2eQMBiwLeRgp4IxXwORTwhyrgi5BhVCgkaqU8WYPk8zTZu683UjmFh39uAAAAAKgLo0ePPuiNSYsWLfrLtsGDB2vw4MGHPOd1112n66677oDPdezYUd98880R5wwmgzs31fy1F2hpyfdS+Bbdv/QBPdNnmgzDMDsaAAAAAABAjRs3bpyuvPJKde7cWV26dNHUqVNVXFyskSNHSpJGjBihJk2aaNKkSZKkSZMmqXPnzmrZsqXKysr00Ucf6bXXXtP06dPNvIxa54xzyJ3nUUFuqRofH212HAAAAAAAgDrB7OjwuOL2Fi25KVoCAAAAACCoUbR0hFavXl358bp165SdnV35uc/n0/z589WkSRMzogGoJYZh6NFL2uqH7Xu0Ka9EJZIs9i4KjVmmspzz5fE0kVvS9Ms7qt/JSSqsKNxbMFRStWRo/8d5pXnKL83X7rLd8ga8yinJUU5Jzt/miAyJVKwjVvHh8YqzxykuPO4v5UxxjjhFhUXJYlgOeh6fP6CMn3/R9FXTFWN00OBT4mS1HHyhqcfrqVKYtL9EKd+TX6VMaZdnl3wB32H/vgZ8oQp4nfL7Gingde4rU3LK741UqFxKjIhXU2eiUqLidVxMI5WUe/XEZz9XHm+xb1dI1Er5PE3k9/z+dTchsuYKqQAAAAAADZNhGHr44nY65+lL5XU8ri93fKEFmxcoPTXd7GgAAAAAAAA1bsiQIcrNzdX48eOVnZ2t9u3ba/78+UpMTJQkbd26VRbL7/cRFBcX68Ybb9Rvv/0mh8Oh1q1ba9asWRoyZIhZl1AnXPEO/fbjbrnzeAMnAAAAAABw7GB2dHic8XuLlgryKFoCAAAAACCYGYFAIGB2iIbEYrHIMPYWkhzot87hcOipp57SP/7xj7qOdkTcbrdcLpcKCgrkdDrNjgPUez5/QN0mZSinsEzS3pKfiNSnVLxpjPyeJjIkJbns+vL2sw9ZWvRHFb4K5XvyK4uK/ljKlFuSqzxPXuXH5f7yw85qM2yKccQozhGneEd8lRKmbblWzV1WoHzPboU3e1Wl24Yp2uHSwM6RahzrrSxSqixTKs1XYUXh4f9GBQwFfBHyeyMV2Pf448f7Pw+RS02jotQ0OlzNoh17f41xVH4eExFa+bV2P58/oDMfWajsAo8CR/FnwNc/AAAAADXB6XRq5cqVatGihdlRakWw/Oz04eos3fLJIwqLz5AzJFofXTxPrjCX2bEA1HPB8jUQAAAAAGpTQ/zZKfOTLVr6zkYdf2qizrn6ZLPjAGigGuLXPwAAAACoaw3xZ6ddO4r15v3LFGq36ponevxlTQsAHI6G+PUPAAAAONbYzA7Q0GzatEmBQEAtWrTQ8uXLFR8fX/lcaGioEhISZLVaTUwIoDYs37SrsmRJkgLeSJXl9lbAG7n3c0lZBR5d8NQXSnTa5Qixyl75sFR+7tj3uf0PzztCktQopLHiIqxqH2WVI9Qqu82y71erDEMqrCjcW4BUUrWQaf/H+8uR9pTtkTfgVU5JjnJKcg58MfFS+L4PHc3ekEfS7M2SNh/8+i0KkS3gkt8bqbKyCPnKGyng21+c5FTA20gBr1MBb4Qkq0KshhpHOdQ02qFm0eF7f40Jr/w8rlGYLIdZSLWf1WJoQv80jZqVKeNPfwb7zzShf9phF10BAAAAwNGgu7xhOL9tsj5eM0wLi36QWzl6ZPlj+nf3B82OBQAAAAAAABO44h2SpILcUpOTAAAAAAAAoL5xxtklSeUenzzFFXI0CjU5EQAAAAAAqA0ULR2h5s2bS5L8fr/JSQDUpZxCT5XPA16nyvP6/mW/9VmFWp9VWKOvHWqz/F68FGKV3dZI9lCX7LYTKsuYUkKtah1qUWh4QAFrkQKWAnmNApUHClQWKFCpf4+WZy+TQnIP+jr+siQ18p2swhKHyssaKeDdX6QUKfntkn4vMLIYUrLLoWYxDjWNDv9LmVKi014rhUfpbZI1/fKOmjhvnbIKVPlnkOyya0L/NKW3Sa7x1wQAAABwbDn77LP1zjvvKCoqqsp2t9utgQMHauHChZKkwsKa/dkPtefBge3Ve9oQlSc8pXm/vq8Brfqra3JXs2MBAAAAAACgju0vWnJTtAQAAAAAAIA/sYVaFREVpuI9ZSrILaVoCQAAAACAIEXR0lFat26dtm7dqvLy8irbL7zwQpMSAagNCZH2w9pv7Nmt1CwmXJ4KnzwVfpVW+OSp8O371a+yyo9/3+b50+elFT6Ve38vcyv3+lXu9cvt8R5haue+RzNJkmFrK8O2dyGw1b5d9uR35MkaJJ+niSQp4I1Usde5d19DSnLa1TRhf5HS3l+bxjjULDpcSS67QqyWI8xTM9LbJKtvWpKWb9qlnEKPEiLt6pIaUyvFTgAAAACOPYsWLfrLnEeSPB6PvvjiCxMS4WhFhYdq8oUDdcPH3yo0+hvduWS8Prr4fdlth/ezPgAAAAAAAIKDM25v0ZKnuEJlpV6FObh1DgAAAAAAAL9zxTtUvKdM7txSJaW6zI4DAAAAAABqAXeLVNOvv/6qiy66SD/88IMMw1AgEJAkGcbeog+fz2dmPAA1rEtqjJJddmUXeBQ4wPOGpCSXXTf1OaFGCn/8/oA83j+VNZX7VOb1qbTc/4diJp88Xr885X8ta/pjqdO23SX6JUcK7CtS2s/naSL/vqIlSbqxZ0td2rmZkqPsCrNZj/o6aovVYqhby1izYwAAAAAIIqtXr678eN26dcrOzq783Ofzaf78+WrSpMmBDkUD0OvEBPVfc40+3r1OudqhJzOf0b+6jDM7FgAAAAAAAOpQqN0mR2SISgsr5M4tVfxxkWZHAgAAAAAAQD3ijHdox897VJBbanYUAAAAAABQSyhaqqabbrpJqampysjIUGpqqpYvX678/Hz985//1OTJk82OB6CGWS2GJvRP06hZmTKkKmVL+2uVJvRPq5GSJUmyWAyFh9oUHlojp9PSjfm67Plv/na/7sfHKyUuomZeFAAAAAAakPbt28swDBmGobPPPvsvzzscDj311FMmJENNue+CTvpixmCVRL2oWetn6sJW56l1TGuzYwEAAAAAAKAOOeMcKi2sUAFFSwAAAAAAAPgTV5xDkuSmaAkAAAAAgKBlMTtAQ7V06VLdf//9iouLk8VikcVi0ZlnnqlJkyZp7NixZscDUAvS2yRr+uUdleSyV9me5LJr+uUdld4m2aRkf69LaoySXfbKUqiAN1Jlub0V8O69adCQlOyyq0tqjGkZAQAAAMBMmzZt0saNGxUIBLR8+XJt2rSp8rF9+3a53W794x//MDsmjkKjMJue7H+FvO42CsivcQvvls/vMzsWAAAAAAAA6pArft9iuTwWywEAAAAAAKAqZ/ze9UIFzI4AAAAAAAhaNrMDNFQ+n0+RkXsLSuLi4rRjxw6deOKJat68uTZs2GByOgC1Jb1NsvqmJWn5pl3KKfQoIXJvOZHVYvz9wSayWgxN6J+mUbMyZUgKeJ0qz+srSZXlSxP6p9X76wAAAACA2tK8eXNJkt/vNzkJalPXFrEa1Hy03s+7WduKf9ILq17V9R1Gmh0LAAAAAAAAdcS5r2ipIJfFcgAAAAAAAKjKFRcuSXIzOwIAAAAAIGhRtFRNbdq00apVq5SamqquXbvq0UcfVWhoqJ577jm1aNHC7HgAapHVYqhby1izYxyx9DbJmn55R02ct05ZBZ7K7Ukuuyb0T1N6m2QT0wEAAABA/bJu3Tpt3bpV5eXlVbZfeOGFJiVCTbn33NP0+XMDVdhotp5Z/bQuOP4cNWnUxOxYAAAAAAAAqAMuipYAAAAAAABwEPtnR8UF5fKW+2QLtZqcCAAAAAAA1DSKlqrpnnvuUXFxsSTp/vvv1wUXXKDu3bsrNjZWc+bMMTkdABxYeptk9U1L0vJNu5RT6FFCpF1dUmNktRhmRwMAAACAeuHXX3/VRRddpB9++EGGYSgQCEiSDGPvz00+n8/MeKgB9hCrnrlwlIb9b5kUvkljPrlb/73o5co/YwAAAAAAAAQvV9zexXJuipYAAAAAAADwJ2ERNoU6bCov9aogr1SxjRuZHQkAAAAAANQwi9kBGqp+/fpp0KBBkqRWrVrpxx9/VF5ennJycnT22WebnA4ADs5qMdStZawGtG+ibi1jKVkCAAAAgD+46aablJqaqpycHIWHh2vt2rVasmSJOnfurEWLFpkdDzWkfbMYDW5+swJ+q34uXKE3171ndiTs4/MHtHRjvt5fuV1LN+bL5w+YHQkAAAAAAAQRZ/zeoqWi3R75vH6T0wAAAAAAAKA+MQxDrniKugEAAAAACGY2swMEk5iYGLMjAAAAAAAA4CgsXbpUCxcuVFxcnCwWiywWi84880xNmjRJY8eO1ffff292RNSQe/r11MIXztMe+zw99u2jSm9xlmIczPfMNH9NlibOW6fs4hyFRC1TxZ6uSopI0IT+aUpvk2x2PAAAAAAAEATCnaGyhVrkLferMN+jqMRwsyMBAAAAAACgHnHGOZS7tVAFFC0BAAAAABCULGYHaKiKi4t177336vTTT1erVq3UokWLKg8AAAAAAAA0PD6fT5GRkZKkuLg47dixQ5LUvHlzbdiwwcxoqGEhVouevfBW+csS5TWKNHrB/WZHOqbNX5OlUbMylVXgkWErVFh8hgxbobILPBo1K1Pz12SZHREAAAAAAAQBwzDkjHNIkgryWCwHAAAAAACAqlzxdkmSO89jchIAAAAAAFAbbGYHaKiuueYaLV68WFdccYWSk5NlGIbZkQAAAAAAAHCU2rRpo1WrVik1NVVdu3bVo48+qtDQUD333HOUawehtOQYDUn5p97acbt+KMjQ+xs+14ATe5kd65jj8wc0cd46BQ7wXECSIWnivHXqm5Ykq4U5LAAAAAAAODqueId27SiWO5eiJQAAAAAAAFRVWdLN7AgAAAAAgKBE0VI1ffzxx/rwww91xhlnmB0FAAAAAAAANeSee+5RcXGxJOn+++/XBRdcoO7duys2NlZz5swxOR1qw9190vXZyx9rt+1zTfz6frl0vApKDSVE2tUlNYZinzqwfNMuZRfnyGIvlCTZnCsrf/Xu2ye7OFLLN+1St5ax5oQEAAAAAABBwxnPYjkAAAAAAAAcmGvf7Midx+wIAAAAAIBgRNFSNUVHRysmJsbsGAAAAAAAAKhB/fr1q/y4VatW+vHHH7Vr1y5FR0fLMCjcCUZWi6HnLrhXl8zLVEVInq7/6D4FfI1UsaerkiISNKF/mtLbJJsdM6jlFHoUErVMYfEZVbaHxX6hsNgvJEllub2VU9jDjHgAAAAAACDIuOIoWgIAAAAAAMCBOf9QtOT3B2ThTdoAAAAAAAgqFrMDNFQPPPCAxo8fr5KSErOjAAAAAAAAoBbFxMRQshTkNud6VZo9QJIUEr238MewFSq7wKNRszI1f02WyQmDW0KkXRV7uqh8d5cDPu8taa4K9ylKiLTXcTIAAAAAABCMXH9YLAcAAAAAAAD8UaNouyxWQ35fQEW7PWbHAQAAAAAANcxmdoCGpEOHDlUW1f3yyy9KTExUSkqKQkJCquybmZlZ1/EAAAAAAABwlIqLi/Xwww8rIyNDOTk58vv9VZ7/9ddfTUqG2uLzBzRx3jr5itJU4W6rEOfq/c8oIMmQNHHeOvVNS5KVd6irFW2bRig88TNZnN9Kksp3d1RodKY8uWcrLHaJbOFbFH7cK8qrOFlSrLlhAQAAAABAg+eM21e0lFuqQCBAyToAAAAAAAAqWSyGnHEO7dlZInduqZyxDrMjAQAAAACAGkTR0hEYOHCg2REAAAAAAABQi6655hotXrxYV1xxhZKTk1lkdQxYvmmXsotzZLEXqmJ3Z9karZNh8Sos+V2VZV8oBUKVXRyp5Zt2qVtLSn5qWk7xHl009wZZnGsVCBgqyx4gn6eZQqMz5Ss6WSWFbeRo+rosofm685sb9NW26zWpzw38vwkAAAAAAKotMtYuw5C8FX6VuMsV4QozOxIAAAAAAADqkf1FSwW5pWra2uw0AAAAAACgJlG0dAQmTJhgdgQAAAAAAADUoo8//lgffvihzjjjDLOjoI7kFHoUErVMYfEZVbbb7FmypTwrSSrL7a2cwh5mxAtqa3O2asT/rle59TcF/CHqGTVOK7KSle3NUVlubwW8kUqKSNCNbWfo2XUPq8CyQh/ueEYr38zUGxdNUYzDafYlAAAAAACABshqs6hRjF2F+R4V5JZStAQAAAAAAIAqXHF2SZI7z2NyEgAAAAAAUNMoWgIAAAAAAAD2iY6OVkxMjNkxUIcSIu2q2NNV3qI0SZLVvl325Hfk99plsXkU8IXKVxarhEi7yUmDS8bGlbpl8RgFrHskX6Qmdpmii9t0k88f0PJNu5RT2EMJkXZ1SY2R1WLoss4v6foPpmpZwUxtr/hGfWYP0n/Oflzdm7c1+1IAAAAAAEAD5Ip3qDDfI3duqRq3ijI7DgAAAAAAAOoRZ7xDklSQW2pyEgAAAAAAUNMoWjoC999/f7WO69mzp3r04B3vAQAAAAAA6rsHHnhA48eP18yZMxUeHm52HNSBLqkxSopIUHaBU4E/bPdsH6aw+AxZw7fI0WSuZqyyqUvK7bJaLaZlDRavrPhEU1bfLVk9snoTNaPvdJ123PGSJKvFULeWsX85xma16MWLxumlbzvoidX3qsK2UzcuvEqXH3+Lbj/zirq+BAAAAAAA0MA54x3Sj7tZLAcAAAAAAIC/cO0rWnLnMTsCAAAAACDYULR0BDZt2lSt49q3b1+zQQAAAAAAAFBjOnToIMMwKj//5ZdflJiYqJSUFIWEhFTZNzMzs67joZZZLYYm9E/TqFmZMv6wPeCPUOmWaxWaNE+h0cuUWfiGzp71k+YMmqqkSJdpeRu6+xbO1NtbH5dh8cvhO15vDXpWKdHxh338P07tpS5N39I/PrpFpbZ1mrXxUS3LWqHXBkxSRKijFpMDAAAAAIBg4orbO0egaAkAAAAAAAB/5oz/fXYUCASq3FsGAAAAAAAaNoqWjsDLL79sdgQAAAAAAADUsIEDB5odASZLb5Os6Zd31MR565RdHKmy3N4KeCOV5GqkCX0e0OKseZq3/RntMr5T+luXalqfJ3VG8xPNjt2g+P1+XfvBw1pe8KYMQ4ozuur9YU/JaT/ycqQ2yY21eMQsXfHff+tHz3/1c0mGer5xsV489ym1TWxZC+kBAAAAAECwce4rWnLnUbQEAAAAAACAqvaXdJeXelVW7JW9UcjfHAEAAAAAABoKipYAAAAAAABwTJswYYLZEVAPpLdJVt+0JC3ftEs5hT2UEGlXl9QYWS2G0ttcp45rWuuB5XfIZ9uhGzKu0A0n3af/63ae2bEbhNKKMl0891Ztq1gkSWptH6A3L5kom9Va7XM6QkL09tAJemxJR838+SF5bNs0/KOhGtP2bl3XaWDNBAcAAAAAAEHLFb93sVxBLkVLAAAAAAAAqMoWalWEK1TFBeUqyC2laAkAAAAAgCBiMTsAAAAAAAAAANQHVouhbi1jNaB9E3VrGSurxah8bnCbHpp9wRzZ/SmStVTTN9yha957TD6f37zADUBO0R71ef1KbatYpEDAUO/4UZo75MGjKln6o9t69NezvV+XraKFZPHoqTX36qr371G5r7xGzg8AAAAAAILT/qIlT1GFyku9JqcBAAAAAABAfePcNz9y51HUDQAAAABAMLGZHaAhSU1NlWEYf7/jn9x8880aO3ZsLSQCAAAAAADA0br//vurdVzPnj3Vo0ePGk6D+iwtoZk+H/6Whvz3Nm0tX6xlBa+qz6yfNPeSxxUXEWl2vHpn7c6tuuLD61Vh/U0Bf4iuPmG8bjljYI2/zhkpLbVw2Ju67O0J2h6YrxV73lev19dpVv+nlBrdpMZfDwAAAAAANHyhDpvsjULkKapQQV6p4psx2wEAAAAAAMDvXHEOZf1SoIJcipYAAAAAAAgmFC0dgVdeeaVax6WkpNRoDgAAAAAAANScTZs2Veu49u3b12wQNAiNQh3639Cn9K9PpuvjrGeVZ3yjvrMv1bN9n1KX41qZHa/e+OyXlRq3ZIwC1j2SL1ITu0zRxW261drrRYeH6+MrHtVdCzpq3o7H5bb+rAHvXaLxXR7QJSf3qbXXBQAAAAAADZcr3iFPUYXcuRQtAQAAAAAAoCpnvEOSVJBH0RIAAAAAAMGEoqUjcNZZZ5kdAQAAAAAAADXs5ZdfNjsCGhjDMPRYvxvVYdVJmrTiLnltv+nqzy7XmDYTdV2XfmbHM91LKz7RE6vvlqweWb2Jevac6era7Phaf13DMDQp/TKduf4U3fnlrQqEbtd9347TF9uG6/FzbpXVYq31DAAAAAAAoOFwxjm0c5NbBbkslgMAAAAAAEBVrn1FS25mRwAAAAAABBWL2QEAAAAAAAAAoCEa1q6X3jjvTYX5jpOsxXpy3b90wwdT5ff7zY5mmgkLZ+rxH26TLB45fMfr/UFv1knJ0h+df1IbfTz4LUX7esgwAlq4c5bOefMKZRfl1mkOAAAAAABQv+1fLFeQx2I5AAAAAAAAVOXcPzuiaAkAAAAAgKBC0RIAAAAAAAAAVNMpSSnKGPaWmtjOkGH49dXuF9V31o3aVVJkdrQ65ff79Y/3/q13tk2WYfgVb3TVZ8NeV/PoeFPyNIlyauGVT+kM5xgF/CHK8f6g9LkX6bNfvzElDwAAAAAAqH+ccXsXy7lZLAcAAAAAAIA/2V/SXbynTN5yn8lpAAAAAABATaFoCQAAAAAAAMe01NRUtWjR4ogfTz75pNnRUU+47BH6eNh09U64VoGARTmBr9TnzSHK3L7J7Gh1orSiTBfMHqtvC96UJJ3kGKBPhj8rp91hai6b1aIZF12nO9rOkMoT5LMU6JYl12vComkKBAKmZgMAAAAAAObbv1jOnUfREgAAAAAAAKqyR4Qo1G6VJLnzPCanAQAAAAAANcVmdgAAAAAAAADATK+88kq1jktJSanRHGjYDMPQ1HPHaub3J2ny9/eqwrZVVy4YpnFtH9TIzr3Njldrdhbt0UVv36BCY60CAUN9E2/QE+feaHasKi7v1EWnNp2jER/8SyWh3+qdLTO04q1MzRrwuKLsLrPjAQAAAAAAk+wvWircVSafzy+rlfcsBAAAAAAAwF6GYcgZ71DetiK580oV0zjC7EgAAAAAAKAGcHcIAAAAAAAAjmlnnXVWtR7Nmzc/rPNPmzZNKSkpstvt6tq1q5YvX37I/efOnavWrVvLbrfrlFNO0UcffVTl+auuukqGYVR5pKenV9ln165dGj58uJxOp6KionT11VerqKjoyH5jUC1XduirmemzFOprKlmLNGXNOI3539Py+/1mR6txa3du1blvXba3ZMkfomtOeKDelSztd2JinBZd+ZxOCRupgN+qLZ7l6j37Ii37bbXZ0QAAAAAAgEnCXaGyhVgU8AdUmO8xOw4AAAAAAADqGVfc3qLugtxSk5MAAAAAAICaQtESAAAAAAAAUEvmzJmjcePGacKECcrMzFS7du3Ur18/5eTkHHD/r7/+Wpdddpmuvvpqff/99xo4cKAGDhyoNWvWVNkvPT1dWVlZlY8333yzyvPDhw/X2rVr9emnn+p///uflixZouuuu67WrhNVdWzcSp9dNldJ1tNkGH4tyn9W574+Vm5P8Nx09cnPK3XZh8NVYf1N8kXqgS7P6ObTB5gd65AcoTa9MXScrm01RYGKaJUbubrmsys1ddmrCgQCZscDAAAAAOCoHEnZ9/PPP6/u3bsrOjpa0dHR6tOnz9+WgwcjwzDkjN+7WM7NYjkAAAAAABDEmB1Vz/7ZUUEesyMAAAAAAIIFRUsAAAAAAABALXn88cd17bXXauTIkUpLS9OMGTMUHh6ul1566YD7/+c//1F6erpuu+02nXTSSXrggQfUsWNHPf3001X2CwsLU1JSUuUjOjq68rn169dr/vz5euGFF9S1a1edeeaZeuqppzR79mzt2LGjVq8Xv4t2NNKCYc+qR9xIBQKGdvgXq9frQ7Q6a6vZ0Y7ai98t0D+/vFYB6x5ZvYl66ZxXddHJp5kd67Dd1L23Xur7hkLK2kiGVy/++Jgue+8mFZcXmx0NAAAAAIBqOdKy70WLFumyyy7T559/rqVLl6pZs2Y655xztH379jpObj5n3L7FchQtAQAAAACAIMXsqPpclHQDAAAAABB0KFoCAAAAAAAAakF5eblWrFihPn36VG6zWCzq06ePli5desBjli5dWmV/SerXr99f9l+0aJESEhJ04oknatSoUcrPz69yjqioKHXu3LlyW58+fWSxWLRs2bIDvm5ZWZncbneVB46exWLRtPPH6eY2j0h+h8ptmzT846Ga9f0Ss6NV2/iMV/TEmn9JFo/Cfcfrg4vf1KlNW5kd64h1ad5UC694RcdpsAIBi9a6P1fv2RdrXd7PZkcDAAAAAOCIHWnZ9+uvv64bb7xR7du3V+vWrfXCCy/I7/crIyOjjpObz7W/aCmPxXIAAAAAACA4MTuqPmc8Jd0AAAAAAAQbipYAAAAAAACAWpCXlyefz6fExMQq2xMTE5WdnX3AY7Kzs/92//T0dL366qvKyMjQI488osWLF+vcc8+Vz+erPEdCQkKVc9hsNsXExBz0dSdNmiSXy1X5aNas2RFfLw7ums7n6sW+sxTiayxZC/XwqrH658fPKhAImB3tsPn9fl317kN697cpMgy/Eiyn6dNhr+u4qHizo1VblCNM/xtxry5OfkB+b6SKA9s19H9D9cqqd82OBgAAAADAYatO2feflZSUqKKiQjExMQfdJ1iLuvcvlnOzWA4AAAAAAAQhZkdHZ39Jtzu/VH5/w7nPBwAAAAAAHBxFSwAAAAAAAEADMnToUF144YU65ZRTNHDgQP3vf//Tt99+q0WLFlX7nHfeeacKCgoqH9u2bau5wJAkdWl6gj4d8rbiLZ1lGD59kvO0zn/jFhV6PGZH+1slFWU6/82xWuGeLUlKCx+gBcNmyGl3mJzs6BmGoYn9LtQTZ8yUxdNKAaNcU1aO13Uf3qVyX7nZ8QAAAAAA+FvVKfv+s9tvv12NGzeusuDuz4K1qNu1v2gpj6IlAAAAAAAQfJgdHZ1GMXZZLIb83oCK95SZHQcAAAAAANQAipbqiWnTpiklJUV2u11du3bV8uXLD7rv2rVrdfHFFyslJUWGYWjq1Kl1FxQAAAAAAACHJS4uTlarVTt37qyyfefOnUpKSjrgMUlJSUe0vyS1aNFCcXFx+uWXXyrPkZOTU2Ufr9erXbt2HfQ8YWFhcjqdVR6oebERkfps+IvqFj1cgYChbd4M9Xp9qNburL/FVtmFu9Vn1pX6zbtYgYChcxJu1JzBD8pmtZodrUad0/p4zR86S7He8yRJS/Pmqc+bg7WloP7+2QAAAAAAUBMefvhhzZ49W++++67sdvtB9wvWou79RUsFeR4FAgGT0wAAAAAAANQvx/rsyGIxFBm797rduRR1AwAAAAAQDChaqgfmzJmjcePGacKECcrMzFS7du3Ur1+/vyyI26+kpEQtWrTQww8/fMhFdgAAAAAAADBPaGioOnXqpIyMjMptfr9fGRkZ6tat2wGP6datW5X9JenTTz896P6S9Ntvvyk/P1/JycmV59izZ49WrFhRuc/ChQvl9/vVtWvXo7kk1ACLxaLnLrxD/3fSQ5LfrjLbRg3932Was/ors6P9xZrsrTrvrctUaFmrgD9E153wgKacO8rsWLUm2RWhz66apJ6uOxXwhmu371dd+O4lem/Dp2ZHAwAAAADgoKpT9r3f5MmT9fDDD+uTTz5R27ZtD7lvsBZ1R8baZRiSt8ynEne52XEAAAAAAABqFLOjo/d7UTdFSwAAAAAABAOKluqBxx9/XNdee61GjhyptLQ0zZgxQ+Hh4XrppZcOuP+pp56qxx57TEOHDlVYWFgdpwUAAAAAAMDhGjdunJ5//nnNnDlT69ev16hRo1RcXKyRI0dKkkaMGKE777yzcv+bbrpJ8+fP15QpU/Tjjz/qvvvu03fffafRo0dLkoqKinTbbbfpm2++0ebNm5WRkaEBAwaoVatW6tevnyTppJNOUnp6uq699lotX75cX331lUaPHq2hQ4eqcePGdf+bgAMa1bW/nuv9qmy+RMlWoAdWjNbtC140O1alBT9/r2EfDVeFbbvka6QHuz6jsacPMDtWrbNZLXpq4DDd0+F5yXOc/EaJ7v1mnG77bJK8fq/Z8QAAAAAA+IvqlH1L0qOPPqoHHnhA8+fPV+fOnesiar1ktVnUKNouSXLnslgOAAAAAAAEF2ZHR8+5v2iJ2REAAAAAAEGBoiWTlZeXa8WKFerTp0/lNovFoj59+mjp0qUmJgMAAAAAAMDRGjJkiCZPnqzx48erffv2WrlypebPn6/ExERJ0tatW5WVlVW5/+mnn6433nhDzz33nNq1a6e3335b7733ntq0aSNJslqtWr16tS688EKdcMIJuvrqq9WpUyd98cUXVQq5X3/9dbVu3Vq9e/fWeeedpzPPPFPPPfdc3V48/la3407SgiFvK9boIMPi1UfZU9X/jVtVXO4xNdcL3y7QrV9ep4B1j6zeRL10zmsamHaaqZnq2tCObfXuoNfVqKynJGn+9jd03luXa2dRjrnBAAAAAAA4gCMt+37kkUd077336qWXXlJKSoqys7OVnZ2toqIisy7BVJWL5fJYLAcAAAAAAIIPs6Oj49o3O6KkGwAAAACA4GAzO8CxLi8vTz6fr3Jx3X6JiYn68ccfa+x1ysrKVFZWVvm52+2usXMDAAAAAADg4EaPHq3Ro0cf8LlFixb9ZdvgwYM1ePDgA+7vcDi0YMGCv33NmJgYvfHGG0eUE+ZIiIhSxuUv69oPHta3BbO1uWKBes36VbP6T9MJ8cl1nueez17Re789IcPiV7j/eL198XNqFhVX5znqg1bxUfp85FRd+/aL+r70WWWVrdW5b1+kKT0nq1fKwd/VEQAAAACAujZkyBDl5uZq/Pjxys7OVvv27f9S9m2x/P5+fNOnT1d5ebkuueSSKueZMGGC7rvvvrqMXi+44uzavkEqYLEcAAAAAAAIQsyOjo4zbl9JN7MjAAAAAACCAkVLx4hJkyZp4sSJZscAAAAAAAAA8CdWi1UvDbxbTy5N0/M/PqRS68+65IMhuu+0RzXo5NPqJIPf79fI9yYps3C2DENKsJymd4f+R86w8Dp5/frKHmLVa5ddp2e+PEXT1o1XRVi2xi66XkNaXae7zrhRFsPy9ycBAAAAAKAOHEnZ9+bNm2s/UAPijN+7WM6dx2I5AAAAAAAQnJgdVZ+L2REAAAAAAEGFVSAmi4uLk9Vq1c6dO6ts37lzp5KSkmrsde68804VFBRUPrZt21Zj5wYAAAAAAABw9MZ2u0hP93xFVl+8ArbdGr98lO797NVaf93i8jKd98ZYZRbOliSdHDFAC4bNOOZLlv7oxjO76dX0WQot7SoZAc3Z+KwG/fdq7S7dbXY0AAAAAABwlFzxe2cg7lwWywEAAAAAAKAqZ9zeoqWyEq88xRUmpwEAAAAAAEeLoiWThYaGqlOnTsrIyKjc5vf7lZGRoW7dutXY64SFhcnpdFZ5AAAAAAAAAKhfzkpto48H/1dRaivD4tV72x/TRbNvV2lFea28XlbhbvV5/Upt9y1WIGCoX+KNmn3Jg7JZrbXyeg1Zp+MStXDEdKVqpAJ+mzYWf6dz5l6k77JWmh0NAAAAAAAcBVf83sVyBRQtAQAAAAAA4E9CwqwKd4ZKktx5zI8AAAAAAGjoKFqqB8aNG6fnn39eM2fO1Pr16zVq1CgVFxdr5MiRkqQRI0bozjvvrNy/vLxcK1eu1MqVK1VeXq7t27dr5cqV+uWXX8y6BAAAAAAAAAA1JDkyWguHz1SHyEskSb+UfaSerw3XxvydNfo6P2Rv0flvXaYiy1oF/CG6vvUDmpw+qkZfI9i4wkP03hW36NImj8pfHitPIF8jF1ylp797RYFAwOx4AAAAAACgGpz7ipZKCytU7vGanAYAAAAAAAD1DUXdAAAAAAAED4qW6oEhQ4Zo8uTJGj9+vNq3b6+VK1dq/vz5SkxMlCRt3bpVWVlZlfvv2LFDHTp0UIcOHZSVlaXJkyerQ4cOuuaaa8y6BAAAAAAAAAA1KMRm06uDJujKluMV8IeqxPqjLnrvUs1b/12NnH/+hu81/MPLVWHbLvka6aHTpmvMaQNq5NzBzmIxNP6cvnqyxyuylLSVDJ+eXTtFV8wbo+KKYvn8AX28/ieNnf+wPl7/k3x+CpgAAAAAAKjPwhw22SNCJEnuPBbLAQAAAAAAoConRUsAAAAAAAQNm9kBsNfo0aM1evToAz63aNGiKp+npKTw7ugAAAAAAADAMeDWMwerQ/LxGrf4Fvltebrzm+uUmXWrJpw9rNrnfO7bBXpyzT0ybB5ZvYl6od8MdW7aqgZTHxt6n5iiBUkvaPhbk7Uz5G2t2r1YPd8YKGPnlcorKVFE6uv63zcxSgzbpgn905TeJtnsyAAAAAAA4CCccXZ5iitUkFuquKaRZscBAAAAAABAPeLaV7TkpmgJAAAAAIAGz2J2AAAAAAAAAADAwfVu2V4fXjxXzsDJMiwVenvbJF0y5x6VVVQc8bnu/vQVPbn2XzIsHoX7j9e8i2dTsnQUklwOzf/H3erjmih/hUseZask/nFZG62v3Ce7wKNRszI1f02WiUkBAAAAAMCh/L5YzmNyEgAAAAAAANQ3zri9s6MCipYAAAAAAGjwKFoCAAAAAAAAgHquqStOiy6fpTYRAyRJGzzvq+esK7Rld95hHe/3+zXivw/qgx1TZBh+JVpO02fDXlezqLjajH1MCLFaNGXAAFlzrpW35DgZlgrZ4z+TJNmcmTLsW2Wxb9eED5fK5w+YnBYAAAAAAByIc1/RUkEei+UAAAAAAABQVWVJN7MjAAAAAAAaPIqWAAAAAAAAAKABCLHZ9OYlD2p46p0K+ENUZFmr/u8M1vyfvj/kccXlZTr3jTH6vmiOJKlNxEAtGD5DkWGOuoh9TFi+aZc8od/LFr61yvaw2K8UkfqMwlOfUkH4W1r08xaTEgIAAAAAgEOpXCyXW2JyEgAAAAAAANQ3zri9s6OiPWXyVvhMTgMAAAAAAI6GzewAAAAAAAAAAIDDd0ePYeqQfKL+9cU4+W15uvWra/R91u2686xL5fMHtHzTLuUUepQQaVfTWEOXvjtKRZZ1CgQMnZc8So/2G2X2JQSdnEKPKvZ0lbcoTZJka7RGYfGfy++1y2LzSJJCnGt189IBarmmvQYcf47ObdlbSRFJZsYGAAAAAAD77C9aKsgtNTkJAAAAAAAA6htHZIhCwqyqKPOpMN+j6KQIsyMBAAAAAIBqomgJAAAAAAAAABqYfsd3Uuu4uRr6/v+pyPKj3tj8gBZvXqnd23sppyRPIVHL5C1Mk6Px27LYsxTwh+iGtPs0uuuFZkcPSgmRdgW8TgW8TkmSV1JY/Ocq3Xa1JMkWuU62yLWyhuVoY1GmHv8+U49//7CSwlqpX2ofDTyhn1pGtZRhGCZeBQAAAAAAxy5nXLgkqXBXmXw+v6xWi8mJAAAAAAAAUF8YhiFnvEP5vxWpILeUoiUAAAAAABow7ggBAAAAAAAAgAaoeXSCFl3+hlqHny9J2q55cjufkxGSp7D4DDmavSyLPUt+byMNaTqJkqVa1CU1Rskuu/5ak2SR39NMFbn9FJ5zhy6MnarIkoHyljRXIGAou+wXzfxxhi764CKd+UY/3b14klZkr5DP7zPhKgAAAAAAOHZFuEJlDbEo4A+oaJfH7DgAAAAAAACoZ1zxDklSQW6pyUkAAAAAAMDRsJkdAAAAAAAAAABQPWG2EM2+eJI6POGUP2aubJE/ymLPkiRZQorkK4tX6baR+ijHprt6B2S1/LUKCEfPajE0oX+aRs3KlCEp4I1UWW5vBbyRleVLDw5so/Q2yZJ6a1Nesd7/4Uf97+cMba/4VtbwX+T2ZumDzW/og81vKMxwqktidw0+KV3dGp8mu81u4tUBAAAAABD8DIshZ6xdu7NLVJBbKld8uNmRAAAAAAAAUI+44vYWLbkpWgIAAAAAoEGjaAkAAAAAAAAAGrDlm3apcHeqrGWDFJbwkSwhBZIkX1msPFkDZVhLlV2co+Wbdqlby1iT0wav9DbJmn55R02ct05ZBVJ5Xl9JUrLLrgn90/aVLO2VGhehm3t10s29Oim3sEzz123WO+sXakPhN7JErFOZ1a0vsj/UF9kfyqownRzdRRe37qfezXvKFeYy6xIBAAAAAAhqrniHdmeXyJ3nMTsKAAAAAAAA6hln/N6ipYI8ipYAAAAAAGjIKFoCAAAAAAAAgAYsp9CjkKhlCovPqLLdGpaviJTnJUllub2VU9jDjHjHlPQ2yeqblqTlm3Ypp9CjhEi7uqTGyGoxDnpMfGSYruh6oq7oeqKKy67Vop+y9NYPS5SZ/4X8jjVSSIFW7/5Cq5d+oQlLLUqNOEUXHn+Ozm/ZV8mNkg96XgAAAAAAcGQqF8vlslgOAAAAAAAAVbni9s6O3MyOAAAAAABo0ChaAgAAAAAAAIAGLCHSroo9XeUtSpMkWe3bZU9+R56sQfJ5mkiSAt5IJUTazYx5zLBaDHVrGVutYyPCbDr/lGY6/5ThqvBdpuWb8vXW6mX6cscilYasktWerU3Fq/Sflav0n5WPKSG0pc5JPVsDT+inE6JPkGEcvNAJAAAAAAAcmiuexXIAAAAAAAA4sP0l3e48jwL+gIxDvOkWAAAAAACovyhaAgAAAAAAAIAGrEtqjJIiEpRd4FTgD9t9nibye5rIkJTksqtLaoxZEVENIVaLzmgVrzNaXaBA4Hyt3eHWf1ev0qdbFirfnylr+GbllG/UrA0bNWvD82pkTVCPJr10yUn91CGhg2wWxv8AAAAAABwJZ9zexXIFFC0BAAAAAADgTyJjwmSxGPJ5/SouKFOjaN7wDAAAAACAhoiVFgAAAAAAAADQgFkthib0T9OoWZn683vl7f98Qv80WXknvQbLMAy1aeJSmyY9NEE9tG1Xid774Sf97+fPtNWzXNaIn1WkHH20dY4+2jpHoUakOsWfocEnpevMpqfLYXOYfQkAAAAAANR7rvh9RUt5pQoEAjIMZikAAAAAAADYy2K1qFGsXe7cUhXkllK0BAAAAABAA0XREgAAAAAAAAA0cOltkjX98o6aOG+dsosjVZbbWwFvpJJcdk3on6b0NslmR0QNahYTrjFntdeYs9prV3G55q/bqnfWLdR699cywter3FaopTnztTRnviwK1UlRnXXxif3UN+VsRdmjzI4PAAAAAEC95Ix1SIbkLfOptLBC4c5QsyMBAAAAAACgHnHFOyqLlpqcEG12HAAAAAAAUA0ULQEAAAAAAABAEEhvk6y+aUlavmmXcgp7KCHSri6pMbJaDLOjoRbFRIRq2KmtNOzUViotv1qLf96pt35YrBW5X8hr/0EK3aO1e77W2mVf6/5l9+m48Dbq36qvLmjznBeFAABcV0lEQVTVV00jmx7wnD5/QJ9s+Fkfb3lH5zYfpHNOPJ7/jgAAAAAAQc8aYlGjqDAV7S6TO6+UoiUAAAAAAABU4YpzaJskd26p2VEAAAAAAEA1UbQEAAAAAAAAAEHCajHUrWWs2TFgEkeoVeknN1b6yZfJ5x+q7zbv0lurl2nJ9kUqtq2U1Z6lrSU/aNrqHzRt9eOKC01R3+a9ddGJ/dQ6prUMw9D8NVmaOG+ddpZtVETq6/rfNzFKDNumCf3TlN4m2exLBAAAAACgVrniHSraXaaC3FIltXCZHQdBKrckV3N/mqvBJwxWfHi82XEAAAAAAMBhcsY7JEkFeRQtoXYxPwIAAACA2kPREgAAAAAAAAAAQcZqMdS1Ray6tjhPgcC5+mlnkf67arUWbM5Qjm+FrOGblVe+WW/+/KLe/PlFRVji1DLiNC1bkyxvSYos9t/PlV3g0ahZmZp+eUfKlgAAAAAAQc0Z79D2n/aoIJfFcqg9uaW5mr5quno268lCOQAAAAAAGhBX3N6iJTezI9Qy5kcAAAAAUHsoWgIAAAAAAAAAIIgZhqETkyJ1V9IZuktnaPueUs374Wd98FOGNpcukyXiJxUrT6sL/ydHcyngtctXvvcmrdDoL+X1NJZ84Ro/P1tnHj9UjcIiTL4iAAAAAABqhyuexXIAAAAAAAA4MOe+2VFBHrMj1C6vz2t2BAAAAAAIWhQtAQAAAAAAAABwDGkS5dAN3dvqhu5tVVBSoU/Wb9PLmQu02f+urPYsGTaPbLZtkqSQqO8Vou8lSaWSus2eKqvCZLe41MgWJVdYjGLs0UoIj1Nyo3g1ccarcWS8Yu2xinXEyhXmksWw1On1+fwBLd+0SzmFHiVE2tUlNUZWi1GnGQAAAAAADZMzbt9iOYqWUMNyS3KVW5qrQCCgKd9NkSR98MsHlc/HO+IVHx5vVjwAAAAAAHAYnHF2SVJZsVdlJRUKCw8xORGCyf750ZLflui51c9Jktblr6t8nvkRAAAAANQMipYAAAAAAAAAADhGucJDNLhTC4VaL9TNb0fJsBXIEpYlW+Q6hUT+KJ8nSVJAhrVEhrVUhsUrn8pU7M9RcXmOdpZLKjzECwQsCjUi5bC61CgkWlGh0YpzxCo+PFZNIhPU1BWvJpHxinPEKcYRozBr2FFdz/w1WZo4b52yi3MUErVMFXu6KikiQRP6pym9TfJRnRsAAAAAEPxc8fuKlvIoWkLNmvvTXE1fNb3Kttd/fF2v//i6JGlUu1G6sf2NZkQDAAAAAACHKdRuk8MZqlJ3uQpyS5XQnKIl1JwDzY8mLp1Y+THzIwAAAACoGRQtAQAAAAAAAABwjEuItCvgdSrgdcrvaSZ/WROFRP4oT9Zg+T1N9u0V0D+6N1FoaLF2FucptzRfuz275C7frWLfHpX5C+S3FMmwFcmwFsliK5EMv8pVoHJfgQp8W7XdI8l98ByWgENhFqfCrS5FhkQrOixGcY5YJUbEqXFknI5zJaqZK0Gxjlg5Q50yDKPy2PlrsjRqVqYCkiz2QoXFZ8hblKbsAqdGzcrU9Ms7UrYEAAAAADgkZ9zeoqVSd7nKPV6F2rm9DjVj8AmD5bA59PiKx6tsj3fE66EzH1KrqFYmJQMAAAAAAEfCFef4Q9GS0+w4CCJnND5Dr617TUUVRYq1xyrfky9Dhv516r/UMbGj4h3xZkcEAAAAgKDAnSAAAAAAAAAAABzjuqTGKNllV3aBR4EDPG9ISnI5dPe57WW1GAfYY6+Scq/yi8q1q7hcOYXF2laQp6yiXO0szlNeab72lO2Su2KPSnx7VO53y28prCxmMiw++Y1SlQZKVerdqXyvtLlU0p6DvFjAKpsiZbe4FG51aefuEIUmRMjvjZAsFfuClymwL//EeevUNy3pkPkBAAAAAMc2e0SIwsJtKivxqjDfo9gmjcyOhCCRV5qn6aumS5LSU9I1f/N8JYUnKbskW9NXTdcL57xgckIAAAAAAHA4XPEOZf9aIHdeqdlREEQKyws1/uvxKqooUlpsmu7ocodGfDxCAQX09Mqn9dq5ryk+nKIlAAAAAKgJFC0BAAAAAAAAAHCMs1oMTeifplGzMmVICngjVZbbWwFvpPbXEk3on/a3JUXhoTaFx9jULCZcUpSkJofc31PhU35xufILy/Sbe5e2FeQouyhPO4vzlO/JV0H5LhVW7FGpr0DlAbcClcVMHsnwyas9KgrsUZFXMiKl0D+d3xbxs7yBMElSdnGklm/apW4tY6vxOwQAAAAAOFa44h3K2VKogtxSipZQI3JKcjR64WiVekt1RuMzNCJthOZvnq/bu9yu8V+N1/c53+u+r+/TQ2c+JMOgIBoAAAAAgPrMGWeXJLlzKVpCzfD6vbpt8W36teBXJTgS9GSvJ5XvyZckpcWmaV3+Oo1ZOEavn/e6Yh3c8wIAAAAAR4uiJQAAAAAAAAAAoPQ2yZp+eUdNnLdOWQVSeV5fSVKyy64J/dOU3ia5xl/THmJVkyiHmkQ51FZRkloccn9PhU+7S8qV7S7S1j25+s2do6yiXP2Q/Zt+KloiW6NfquwfFv+5wuI/lySV5fZWTmGPGr8GAAAAAEBwcf6haAk4WqXeUo1dOFY5JTlq4Wqhx856TB6vR6PajVK7+Haa0nOKRn02SvN+nacWUS10zSnXmB0ZAAAAAAAcgiveIUkqyGN2hJox+bvJ+mrHV7Jb7Xqy95NKjEiUxbBoVLtR6pfST2MXjtXWwq26ZdEteuGcFxRq/fPbkAEAAAAAjgRFSwAAAAAAAAAAQNLesqW+aUlavmmXcgo9Soi0q0tqjKwWw+xokvYWMyW7HEp2OdShWbykNEnS0o35GvZykgxboSTJat8ue/I78mQNks/TRJIU8EYqIdJuVnQAAAAAQAPhitu7WM5N0RKOkj/g171f3au1+WsVFRalp89+WpGhkYoMjdSN7W+UJMWHx+vOLnfqwWUP6j+Z/1GqM1W9m/c2OTkAAAAAADgYZ3y4JFHSjRrx1oa39Pr61yVJ/+7+b50ce7KkvTOj/fOjp3s/reEfDtf3Od/rvq/v00NnPiTDqB/38QAAAABAQ2QxOwAAAAAAAAAAAKg/rBZD3VrGakD7JurWMrbelCwdSpfUGCVFJCjgaSK/p0lluZJv3+cBTxMlRSSoS2qMyUkBAAAAAPWdM35v0VJBHovlcHSmr5quBZsXyGax6YmeT6iZs9kB9xvSeoiGtR4mSbrzyzu1Pn99XcYEAAAAAABHwLVvdlS0u0y+Cr/JadCQLd2xVP9e9m9J0pgOY9S3ed8D7pfqStWUnlNkNaya9+s8vbjmxbqMCQAAAABBh6IlAAAAAAAAAADQoFkthib0T5Mk/bkWav/nE/qnNYjSKAAAAACAuVxx+4qWcilaQvV99OtHmrFqhiRp/Gnj1Tmp8yH3v+3U23RG4zNU6i3V6IWjlVuSWxcxAQAAAADAEXJEhsgWZpUCkjuf+RGqZ1PBJv1z8T/lC/h0QYsLdO0p1x5y/26Nu+nOLndKkv6T+R99tuWzuogJAAAAAEGJoiUAAAAAAAAAANDgpbdJ1vTLOyrJZVfAG6my3N4KeCOV5LJr+uUdld4m2eyIAAAAAIAGwBm/t2ipKN8jv89vcho0RKtzV+ver+6VJI08eaQuOv6ivz3GZrHpsbMeUwtXC+WU5GjswrHyeD21HRUAAAAAABwhwzAo6sZRKSgr0JiFY1RYXqh28e103+n3yTD+/o3DhrQeomGth0mS7vryLq3PX1/bUQEAAAAgKFG0BAAAAAAAANSiadOmKSUlRXa7XV27dtXy5csPuf/cuXPVunVr2e12nXLKKfroo48qn6uoqNDtt9+uU045RREREWrcuLFGjBihHTt2VDlHSkqKDMOo8nj44Ydr5foAoD5Jb5OsL28/W2+MPEeP9blNb4w8R1/efjYlSwAAAACC3pHMoNauXauLL764coY0derUugvaADSKCpPVZpHfH1DR7jKz46CBySrK0tiFY1XuL1fPZj11U8ebDvvYyNBIPX3204oKi9Ka/DW656t75A9Q9gUAAAAAOHrMjmqWa19RtzuPoiUcmQp/hcYtGqct7i1KjkjW1F5TFWYNO+zjbzv1Np3R+AyVeks1euFo5ZTk1GJaAAAAAAhOFC0BAAAAAAAAtWTOnDkaN26cJkyYoMzMTLVr1079+vVTTs6Bb3D4+uuvddlll+nqq6/W999/r4EDB2rgwIFas2aNJKmkpESZmZm69957lZmZqXfeeUcbNmzQhRde+Jdz3X///crKyqp8jBkzplavFQDqC6vFULeWsRrQvom6tYyV1fL37/oHAAAAAA3Zkc6gSkpK1KJFCz388MNKSkqq47T1n2Ex9P/t3Xd4VHXe/vH7zEw6mYQE0jBg0FCVLlUlAgoK7ipY4Oc+KNbHle6isAsIKihtqS6sPmJnbbti2RWXpQhiFimCIIiANIFAKCmkZ+b8/ggJhg4mOXMm79d1zRVz5syZ+8uZ5Nq5d84n7lrBkqTMdC6Ww8XLLcrVoKWDdDT/qBrUbKBJN0yS0+G8pGMkuhM1PWW6XA6Xvtj9heZtnFdJaQEAAAAA1QXdUcUr7Y6y0vMtTgI7MU1TE1dP1Ddp3yjUFao5XeeoVkitSzqGy+HSlM5TVD+ivg7nHtbgpYOVV0yHCQAAAACXgkFLAAAAAAAAQCX585//rEceeUQDBgxQkyZNNG/ePIWGhmr+/Pln3X/mzJnq0aOHRowYocaNG+u5555Tq1atNGfOHElSRESEFi9erHvuuUcNGzZU+/btNWfOHK1bt0579+4td6zw8HDFxcWV3cLCwip9vQAAAAAAAKh6l9pBXXfddZoyZYr69u2roKCL/2vp1Ym7dogkBi3h4nlNr0auHKltx7cpOjhac7rMUWhA6GUdq01cG41tP1aSNHfjXH2+6/OKjAoAAAAAqGbojipeRGl3dITuCBfv7a1v68MfP5QhQ5NvnKwGNRtc1nHCA8M1p8scRQZF6vuj32vMqjHymt4KTgsAAAAA/otBSwAAAAAAAEAlKCws1Lp169StW7eybQ6HQ926dVNqaupZH5Oamlpuf0nq3r37OfeXpMzMTBmGocjIyHLbX3zxRUVHR6tly5aaMmWKiouLz3mMgoICZWVllbsBAAAAAADA911OB4ULi6hVcrFcFoOWcJFmrJ+hZfuWKdARqJldZiq+RvyvOt6dyXdqQNMBkqTRX43Wd+nfVURMAAAAAEA1Q3dUORjSjUu14ucVmrp2qiTpyTZPqnNi5191vER3oqanTJfL4dIXu7/Q3I1zKyImAAAAAFQLDFoCAAAAAAAAKsGRI0fk8XgUGxtbbntsbKzS0tLO+pi0tLRL2j8/P19PP/20+vXrJ7fbXbZ98ODBevfdd7Vs2TI99thjmjhxop566qlzZn3hhRcUERFRdktMTLzYZQIAAAAAAMBCl9NBXY7qNqjbfXLQUuYRLpbDhS3csVCvbX5NkvRsp2fVvHbzCjnukFZDlJKYokJvoQYvHay0nIr7mQYAAAAAVA90R5Uj4uSgpawjeTK9psVp4Ou2H9+up1Y8Ja/pVe/k3urfpH+FHLdNXBuNbT9WkjRv4zz966d/VchxAQAAAMDfMWgJAAAAAAAAsKGioiLdc889Mk1Tc+eW/4tUw4cPV0pKipo1a6b//d//1bRp0zR79mwVFBSc9VijRo1SZmZm2W3fvn1VsQQAAAAAAADYRHUb1P3Li+WA81l3aJ3Gp46XJD3W7DH1rN+zwo7tdDj14g0vqkHNBjqaf1QDlwxUblFuhR0fAAAAAICKUt26oxpRwTIchjxFXuVkFlodBz7saN5RDVo6SDlFOWoT20aj242WYRgVdvw7k+/UgKYDJEljVo3Rd+nfVdixAQAAAMBfMWgJAAAAAAAAqAS1atWS0+nUoUOHym0/dOiQ4uLizvqYuLi4i9q/dMjSnj17tHjxYrnd7vNmadeunYqLi7V79+6z3h8UFCS3213uBgAAAAAAAN93OR3U5ahug7rdJwctZabnyTRNi9PAV+3L3qehy4aq2Fusm+vdrN+3+H2FP0dYQJhmd5mtqOAobTu+TSNXjpTX9Fb48wAAAAAA/BPdUeVwOh0KjwqSJGUdYSgyzq7QU6hhy4dp/4n9SgxP1PSU6QpwBlT48wxpNUQpiSkq9BZq8NLBOnjiYIU/BwAAAAD4EwYtAQAAAAAAAJUgMDBQrVu31pIlS8q2eb1eLVmyRB06dDjrYzp06FBuf0lavHhxuf1Lhyxt375d//nPfxQdHX3BLBs2bJDD4VBMTMxlrgYAAAAAAAC+6HI6qMtR3QZ1u2sFS4ZUlO9R/okiq+PAB2UXZmvQkkHKKMhQ0+immnD9BDmMyvk4ZkKNBM3qMkuBjkAt27dMM9fPrJTnAQAAAAD4H7qjyuOudWpQN3A60zQ1PnW8vj38rcIDwjWn6xxFBkdWynM5HU5NumGSGtRsoKP5RzVo6SDlFjEADAAAAADOhUFLAAAAAAAAQCUZPny4XnnlFb3xxhvaunWrHn/8ceXk5GjAgAGSpP79+2vUqFFl+w8ZMkSLFi3StGnT9MMPP2jcuHFau3atBg4cKKlkyNJdd92ltWvX6p133pHH41FaWprS0tJUWFgoSUpNTdWMGTO0ceNG/fTTT3rnnXc0bNgw/e53v1PNmjWr/h8BAAAAAAAAlepSO6jCwkJt2LBBGzZsUGFhofbv368NGzZox44dVi3B57gCnKoRGSSJi+VwpmJvsUasGKGdmTsVExKjWV1mKcQVUqnP2bx2cz3b6VlJ0vzN87Vwx8JKfT4AAAAAgP+gO6ocEbVLuoCsI/kWJ4EvenXzq/pk5ydyGk5NTZmq+hH1K/X5QgNCNafLHEUFR2nb8W0auXKkvKa3Up8TAAAAAOzKZXUAAAAAAAAAwF/de++9Sk9P19ixY5WWlqYWLVpo0aJFio2NlSTt3btXDsepWegdO3bUggULNHr0aP3xj39UcnKyFi5cqGuuuUaStH//fn3yySeSpBYtWpR7rmXLliklJUVBQUF69913NW7cOBUUFCgpKUnDhg3T8OHDq2bRAAAAAAAAqFKX2kEdOHBALVu2LPt+6tSpmjp1qjp37qzly5dXdXyf5a4VohPHC5SZnqe4+hFWx4EPmbp2qlbtX6VgZ7BmdZ2lmNCYKnnenvV76qfMn/Tydy9rfOp4JYYnqnVs6yp5bgAAAACAfdEdVQ73yUFLDOnG6ZbsWaKZ62dKkka2HamOCR2r5Hnja8RrVpdZenDRg1q2b5lmrJ+h4a35zCAAAAAAnM4wTdO0OgSqXlZWliIiIpSZmSm32211HACoMvz+AwAAAIAL470TgOqM34EAAAAAcGHV4b3T0je3auvXB9X29iRd1zPJ6jjwEe9ve1/P/fc5SdL0lOnqVq9blT6/1/TqD1/+QYv3LFZkUKQW9FygxPDEKs1Q3VWH338AAAAA8GtVh/dOO789rEV/3ayYK926e2Qbq+PAR2w9ulX3L7pfecV56tuwr/7U/k9VnuGfP/1TI1eOlCQ91+k53XH1HVWeoTqrDr//AAAAALtzXHgXAAAAAAAAAAAAAAAAAACqD3etEElSZnqexUngK/578L+auHqiJGlwy8FVPmRJkhyGQxOun6Am0U2UUZChQUsGKbswu8pzAAAAAABQ3UXULumOsuiOcFJ6broGLR2kvOI8dUzoqKfbPm1Jjp71e+qxZo9Jksanjte6Q+ssyQEAAAAAvopBSwAAAAAAAAAAAAAAAAAA/ELZxXJHuFgO0q7MXRq+fLg8pke96vfSw9c+bFmWEFeIZt00SzEhMdqZuVMjVoxQsbfYsjwAAAAAAFRHpUO683OKVJDH+/LqLr84X4OXDtah3ENKikjSlM5T5HK4LMvz+xa/1831blaxt1hDlw3Vvux9lmUBAAAAAF/DoCUAAAAAAAAAAAAAAAAAAH7BfXLQUmY6g5aqu8yCTA1aOkjZhdlqUbuFxnUcJ8MwLM0UGxarWV1nKdgZrFX7V2na2mmW5gEAAAAAoLoJDHYpJDxAkpRFf1Stmaap0atGa/PRzYoIitBLXV6SO9BtaSaH4dCE6yeoaXRTZRRkaOCSgcouzLY0EwAAAAD4CgYtAQAAAAAAAAAAAAAAAADwCxEnBy3lZhaqqNBjcRpYpchbpCeXP6k9WXsUHxavGTfNUJAzyOpYkqSm0U018YaJkqS3t76t97e9b3EiAAAAAACqF3ctBnVDmrtxrr7Y/YVcDpemp0xXojvR6kiSpBBXiGZ1maWY0Bj9lPmTRnw5QsXeYqtjAQAAAIDlGLQEAAAAAAAAAAAAAAAAAMAvBIcFKCjUJUnK4mK5ask0TU1cPVGr01Yr1BWqOV3nKDok2upY5dxc72YNajlIkjRx9UT99+B/LU4EAAAAAED1UTqoO+sI3VF19fmuzzV341xJ0tj2Y3Vd3HUWJyovJjRGs7vMVrAzWKsOrNLUtVOtjgQAAAAAlmPQEgAAAAAAAAAAAAAAAAAAp3HXKrlYLpNBS9XSO1vf0Yc/fihDhibfOFkNajawOtJZPXLtI+pVv5c8pkfDlw/X7szdVkcCAAAAAKBacNemO6rOvkv/TqO/Gi1JeqDpA7oz+U6LE51dk+gmeuGGFySV9F3vb3vf4kQAAAAAYC0GLQEAAAAAAAAAAAAAAAAAcJrSQUtZR7hYrrpZ+fNKTVk7RZL0ZJsn1Tmxs8WJzs0wDI3rOE7NazdXdmG2Bi4dqMyCTKtjAQAAAADg9yIYtFRtpeWkafDSwSr0FqrzFZ01tNVQqyOdV7d63TS45WBJ0sTVE5V6INXiRAAAAABgHQYtAQAAAAAAAAAAAAAAAABwmtKL5bK4WK5a2X58u0asGCGv6VXv5N7q36S/1ZEuKMgZpBk3zVB8WLz2ZO3Rk8ufVJG3yOpYAAAAAAD4tYhadEfVUW5RrgYuGaij+UfVoGYDTbpxkpwOp9WxLujhax9Wr/q95DE9evLLJ7Urc5fVkQAAAADAEgxaAgAAAAAAAAAAAAAAAADgNKWDljKPcLFcdXEs/5gGLR2knKIctYlto9HtRsswDKtjXZRaIbU0p+schbpCtTpttSaunijTNK2OBQAAAACA33Kf7I5OHM+Xp9hrcRpUBa/p1ciVI7Xt+DZFBUdpdpfZCgsIszrWRTEMQ+M6jlOL2i2UXZitQUsHKbMg0+pYAAAAAFDlGLQEAAAAAAAAAAAAAAAAAMBpSi+Wy0xn0FJ1UOgp1NBlQ7X/xH4lhidqesp0BTgDrI51SRrUbKDJN06WIUMf/vih3tn6jtWRAAAAAADwW6HuQLkCHTJNKftovtVxUAVmrp+pZfuWKdARqJk3zVRCjQSrI12SIGeQZtw0QwlhCdqTtUfDlw9XkbfI6lgAAAAAUKUYtAQAAAAAAAAAAAAAAAAAwGkiTg5ayj6aL6/XtDgNKpNpmhqfOl7fHv5W4QHhmtN1jiKDI62OdVk6J3bWk22elCRNWTtFK39eaXEiAAAAAAD8k2EYctc6Oaj7CIO6/d3CHQs1f/N8SdL4TuPVIqaFtYEuU3RItGZ3na1QV6i+SftGE/47QaZJ9wkAAACg+mDQEgAAAAAAAAAAAAAAAAAApwmLDJLDZcjrMXXiWL7VcVCJ5m+er092fiKn4dTUlKmqH1Hf6ki/Sv8m/dU7ube8plcjVozQjuM7rI4EAAAAAIBfKh3UnZXOoCV/tv7Qeo1PHS9JerTZo+pVv5fFiX6dBjUbaPKNk2XI0N+3/11vb33b6kgAAAAAUGUYtAQAAAAAAAAAAAAAAAAAwGkcDkPu6JKL5TKPcLGcv1qyd4lmrp8pSRrZdqQ6JnS0ONGvZxiGRrcbrTaxbZRTlKOBSwfqWP4xq2MBAAAAAOB33CcHLWUyaMlv7cvep6HLhqrYW6yb692sJ1o8YXWkCtE5sbOebPOkJGnq2qla8fMKixMBAAAAQNVg0BIAAAAAAAAAAAAAAAAAAGfhrlVysVwWF8v5pa1Ht2rUylEyZapvw77q26iv1ZEqTIAzQNNTpisxPFH7T+zX0GVDVegptDoWAAAAAAB+JaIWg5b8WXZhtgYtGaTjBcfVJLqJJlw/QQ7Dfy7J7d+kv/ok95HX9OqpFU9p+/HtVkcCAAAAgErnP+/qAAAAAAAAAAAAAAAAAACoQBG1Tw5aOsLFcv4mPTddg5YOUl5xnjomdNTTbZ+2OlKFiwyO1JyucxQeEK5vD3+r8anjZZqm1bEAAAAAAPAbdEf+q9hbrBErRmhn5k7FhMRo1k2zFOIKsTpWhTIMQ39q9ye1iW2jnKIcDVo6SEfzjlodCwAAAAAqFYOWAAAAAAAAAAAAAAAAAAA4i9KL5TLTuVjOn+QX52vIsiE6lHtISRFJmtJ5ilwOl9WxKkX9iPqa2nmqnIZTn+z8RPM3z7c6EgAAAAAAfsNdOmgpPY/hxn5m2tppWrV/lYKdwZrVdZZiw2KtjlQpApwBmp4yXXXD62r/if0atnyYCj2FVscCAAAAgErDoCUAAAAAAAAAAAAAAAAAAM7CzaAlv2OapsasGqNNRzYpIihCc7rMkTvQbXWsStWxTkc93fZpSdLM9TO1ZO8SixMBAAAAAOAfwqOCZRhScZFXuVkMp/EX7297X29vfVuSNOH6CWoa3dTiRJUrMjhSs7vOVnhAuL49/K3Gp45ncBgAAAAAv8WgJQAAAAAAAAAAAAAAAABApcvbtFl77n9AeZs2Wx3lokXUKhm0lJWex8VFfmLexnlatHuRXIZL01Omq667rtWRqkS/Rv3Ut2FfmTI1auUobT261epIAAAAAADYntPlUI2oYEkM6vYXqw+u1sTVEyVJg1oO0i1X3mJxoqpRP6K+pqZMldNw6pOdn+jVza9aHQkAAAAAKgWDlgAAAAAAAAAAAAAAAAAAlS7z44+Vu3q1Mj/5xOooF81dq+RCucJ8j/JziixOg19r0a5F+svGv0iSxnQYo+virrM4UdV6uu3T6hDfQXnFeRq0dJDSc9OtjgQAAAAAgO1F1D41qBv2tjtzt4YtHyaP6VHP+j31yLWPWB2pSnVM6KiRbUdKkmaun6kle5ZYnAgAAAAAKh6DlgAAAAAAAAAAAAAAAAAAlaJo/37lbf5eed9/r8yPPpIkZf3zn8r7/nvlbf5eRfv3W5zw/FyBToVFBEqSMrlYztY2pW/S6FWjJUn3N7lfvZN7W5yo6rkcLk1NmaqkiCQdyj2kIcuGKL843+pYAAAAAADYmvvkoCW6I3vLLMjUwKUDlV2Yrea1m2t8x/EyDMPqWFWub6O+6teonyRp1FejtPXoVosTAQAAAEDFYtASAAAAAAAAAAAAAAAAAKBS7OjaTbvvuku7+9wlb06OJMlz7Jh297lLu++6Szu6drM44YWVXiyXdYSL5ewqLSdNg5cNVoGnQJ2v6KxhrYdZHcky7kC35nSZo4igCG06skljVo2RaZpWxwIAAAAAwLYiajFoye6KvEV6cvmT2pO1R/Fh8Zpx0wwFOYOsjmWZp657Sh0TOiqvOE+Dlg5Sem661ZEAAAAAoMIwaAkAAAAAAAAAAAAAAAAAUCkSpkyWnM5z3u+IjNThadOUv+3HKkx1aSJKBy1xsZwt5RblatDSQTqSd0TJNZM16cZJcjrO/ZqsDuq662p6ynS5DJcW7V6keRvnWR0JAAAAAADbimBIt62ZpqkXVr+g1WmrFeoK1ewus1UrpJbVsSzlcrg0pfMUJUUk6VDuIQ1eOlj5xflWxwIAAACACsGgJQAAAAAAAAAAAAAAAABApYi4/XZd+f57Z73PCA6WNyNDR1/5P+367W/1029+qyMvv6KiAweqOOX5lV4sl8mgJdvxml6NWjlKPxz7QVHBUZrTZY7CAsKsjuUTrou7TmM6jJEk/WXjX7Ro1yKLEwEAAAAAYE/uWnRHdvbO1nf0wY8fyJChSTdOUsOohlZH8gnuQLde6vKSIoIitPnoZo1eNVpe02t1LAAAAAD41Ri0BAAAAAAAAAAAAAAAAACofIZR7mvd1+arzowZqtGtq4yAABX8+KPS//xn7ejSVbt/9zsdf/c9eTIyrMt7kptBS7Y1a/0sLd23VAGOAM28aaYSaiRYHcmn9E7urfub3C9JGr1qtDalb7I4EQAAAAAA9lM6pDv/RJEK84otToNLsfLnlZqydook6ck2TyolMcXaQD4m0Z2o6SnT5XK49MXuLzRv4zyrIwEAAADAr8agJQAAAAAAAAAAAAAAAABApXFFR8tZq5aCmzZV3LhxCm7aVM5atRQQHy93j+5KnDNHyV+tVNyz4xXatq1kGMpbu05p48bpxxtu1L7fP6Gsf/1L3jxrBh1F1AqVJGUxaMlWPt7xsV7d/Kok6dlOz6pFTAtrA/moYa2HqfMVnVXgKdDgZYOVlpNmdSQAAAAAAGwlMMSl4BoBkqTMI/RHdrHj+A6NWDFCXtOr3sm91b9Jf6sj+aTr4q7T2PZjJUlzN87V57s+tzgRAAAAAPw6LqsDAAAAAAAAAAAAAAAAAAD8V0BcnK5eukRGQIAMw1DkvffILCqSIzCwbB9nRIRq3nOPat5zj4oOHlTWv/6lzE8/U8EPP+jE0qU6sXSpHKGhCr/5Zrlvv11h7dvJcFXNx98iaodIknIyC1Vc6JEr0Fklz4vLt/7Qeo1LHSdJeuTaR9Srfi9rA/kwp8OpSTdO0v98/j/afny7Bi0dpDd6vKHQgFCrowEAAAAAYBsRtUOUf6JIWel5qp0YbnUcXMCx/GMauHSgcopy1Ca2jUa3Gy3DMKyO5bPuTL5TP2X+pNe/f12jvxqtOjXqqFntZlbHAgAAAIDL4rA6AAAAAAAAAAAAAAAAAADAvzkCA8suVjIMo9yQpdMFxMcr+qGHVH/hR6r/6SeKfuwxBdSpI29urjI//lj7Hn5Y21NuUtqEicr77juZplmp2YPCXAoMLhmulHkkr1KfC7/ez9k/a+iyoSr2FuvmejdrYMuBVkfyeWEBYZrTZY6igqP0w7EfNGrlKHlNr9WxAAAAAACwDXetkkHdmel0R76u0FOoYcuGaf+J/UoMT9T0lOkKcAZYHcvnDW01VJ2v6KxCb6EGLx2stJw0qyMBAAAAwGVh0BIAAAAAAAAAAAAAAAAAwCcFJScrZthQXfWfxaq34B1F9usrZ2SkPEeO6Phbb2n3PfdqZ48eSp81WwW7dlVKBsMw5K5dcrFc1pH8SnkOVIwThSc0aOkgHS84rsZRjfV8p+flMPiY5MVIqJGgmTfNVIAjQEv3LdWs9bOsjgQAAAAAgG1EnOyOGNLt20zT1PjU8Vp/eL3CA8I1p+scRQZHWh3LFpwOpybdOEkNajbQ0fyjGrhkoHKLcq2OBQAAAACXjE8QAAAAAAAAAAAAAAAAAAAqlcdrKnXnUX28Yb9Sdx6Vx2te0uMNw1Boq1aKf+YZJa9coSvmzZW7Z08ZwcEq2rNXR/7yF/10623addfdOvbGGypOT6/Q/KUXy2Wlc7Gcryr2FmvEihHakbFDMSExmt1ltkIDQq2OVc6v/TmobC1iWujZTs9Kkl7d/Ko+3vGxxYkAAAAAALAHuiN7mL95vj7Z+YmchlNTU6aqfkR9qyPZSlhAmGZ3ma2o4ChtO75NI1eOlNf0Wh0LAAAAAC6Jy+oAAAAAAAAAAAAAAAAAAAD/tWjzQY3/dIsOZuaXbYuPCNYztzdRj2viL/l4RkCAwlNSFJ6SIm9OjrKXLFHmZ58pZ9XXyt+8WfmbN+vQpMkKa99e7l69FH7LzXLWqPGr1lB6sVwmF8v5rGlrp+mr/V8p2BmsWV1mKTYs1upI5VT0z0Fl6VW/l37K+EmvbHpF41LHKTE8Ua1iW1kdCwAAAAAAn+auRXfk65bsXaKZ62dKkp5u+7Q6JnS0OJE9JdRI0MybZuqhLx7Ssn3LNHP9TA1rPczqWAAAAABw0RxWBwAAAAAAAAAAAAAAAAAA+KdFmw/q8bfXlxsuI0lpmfl6/O31WrT54K86viMsTBG/+Y3qvvyykld8qdjRoxXSvLnk9Srn66918I9/1PZO1+vnocOUvWSJzMLCy3oeLpbzbR/8+IHe3vq2JGnC9RPUtFZTixOVV9k/BxVtYMuBurnezSr2FmvosqH6Ofvnsvs8XlOpO4/q4w37lbrzqDxe08KkAAAAAAD4htIh3SeO5cvj8VqcBqfbenSrRq0cJVOm+jbsq36N+lkdydZaxLTQ+E7jJUnzN8/Xwh0LrQ0EAAAAAJfAZXUAAAAAAAAAAAAAAAAAAID/8XhNjf90i842hsWUZEga/+kW3dwkTk6H8aufzxUdrajf3aeo392nwr17lfXPfyrz089U+NNPyl60SNmLFskRESH3LbfIfXsvhbZpI8NxcX+rsPRiuawjDFqyksdr6ptdx3Q4O18x4cFqmxSltYe+0cT/TpQkDWwxULdceYvFKcvzeE2NO8/PgSQ988n3SmkYo+AAZ1VGOyeH4dDznZ7Xz9k/a+uxrRq0dJDeuvUtffVjtsZ/uqXcwKj4iGA9c3sT9bgm3sLEF+9sr6GK+P0DAAAAAKjeQiMC5QpwqLjIq+yj+YqMCbU6Ek5Kz03XoKWDlFecp44JHfV026etjuQXetXvpV2Zu/Tydy9rfOp4JYYnqnVsa6tjAQAAAMAFMWgJAAAAAAAAAAAAAAAAAFDhvtl1TPfmvC2P06HZnt5n3D/Q+Q85c7zqMzdIjePdinUHK84drNiIkq9x7mBFhgbIMC59CEpg3bqq9fjjiv7f/1X+li3K+vQzZf3znypOT1fGBx8o44MP5IqPV0TP2+Tu1UtBDRue93nctU4NWvJ6TTkYzFK1lr2g7em56r8zpdyQn9ioLDlip6hYxbot6TY92uzRSo9SWOxVRm6hjucW6Xhu4Wn/XaTjOSXfl2wvVHp2gR4sfvecPweDnP+QM9erRmMKFOhyKCzQqdBAl8KCnAoLciks0KXQQKdqBLkUGuQ8+f2p+0MDS7aFBZVsCw10le0bGuCUy3lxw8ROFxoQqtldZqvfP/tpR8YOPfHeb3XtD/V00NOn3H5pmfna8rfRurpZrK6+d+JlPVeVOMdrKD4iWG9etVzJtUOlm0ZZlw8AAAAAYGuGYchdO0THDuQoKz2PQUs+Ir84X0OWDdGh3ENKikjSlM5T5HJwSW1FeaLFE9qVuUuL9yzW0GVDtaDnAiWGJ1odCwAAAADOi3eFPuKll17SlClTlJaWpubNm2v27Nlq27btOff/4IMPNGbMGO3evVvJycmaNGmSbrvttipMDAAAAAAAgItR0b2PaZp65pln9MorrygjI0OdOnXS3LlzlZycXLbPsWPHNGjQIH366adyOBzq06ePZs6cqRo1alTqWgEAAAAAAGANX/3s0eHsfHlMh54M+FCSyg2ZGeT8h54M+FDTiu7Shn2Z2rAv86zHCHI5ygYwxbiDSgYwRQSXbIs4tT3I5Tzr4w3DUEjTpgpp2lQxI/6g3DVrlPnpp8r+4t8qPnhQR//vVR39v1cVlHy13L1uV0SvngqoU6f8QZa9oBpyyuG8Tl6PqY9W7VFCQrjaJkXJsWKKvMVeObuNrJh/tMqw7AXJ4ZTnhhH6ZtcxHc7OV0x4sH3yS9qenqvkLbN0V9EBzdbJ15EjV66af1aWWaSGqqVnOz17SUO5TNNUdkGxMnJKhiSVDUrK/eWgpFMDk47nlPx3TqHnkvN7nOf+ORju+lB/LrpHUskQp8Jir47nFl3yc5xLkMtRbkjTL4czhQadHOAU6CoZ8BTkUo2gXwx6CnRpyLUv6Nm1T2i997CaxO7QoENGuTUMdP5Dw1wf6uVt/09JXlNOHx1CdtbXkKS7TyzQ1d9/qG2Nh6ihhfkAAAAAoDL5anf0Sx6veUZv4avvMc/FXatk0NLKbw+qfrBKuhdD8habcgZc3iDkqna282CnNfwyf+0aQfrHz5O0KX2TagZGaU6XOXIHuq2OeEF2OgcOw6EJ10/Q/hP7teXoFg1aMkiv93hTW/cX2SL/udjpHAAAAAC4dAxa8gHvvfeehg8frnnz5qldu3aaMWOGunfvrm3btikmJuaM/b/++mv169dPL7zwgnr16qUFCxbojjvu0Pr163XNNddUTsiTH7ZR56fOvO/LyZLX49t/zcnu+SX7r8Hu+SX7r8Hu+SX/WAMAAACAaqUyep/Jkydr1qxZeuONN5SUlKQxY8aoe/fu2rJli4KDgyVJ9913nw4ePKjFixerqKhIAwYM0KOPPqoFCxZUzkLt/n7N7vkl+6/B7vkl1uAL7J4fAAAAAC6TL3/2KCY8WENODmR5MuBD5ToL9ZY7Wv+TdVRPOj7RtKK7NNvTW4/ckKSwIJcOZeUrLTNfaVkFOpSVr2M5hSoo9mrvsVztPZZ73ueKCgs8OZAp6NQgJnewYiOCFRteMpSpZmiAwtq3V1j79vKOHasTy79U1mef6cTy5SrYvkPp06crffp0hbRqpYjbeym8Rw+5ataUHE45lk2QV29KClfuC6P1TL2W6h2VpejMBGW7rtTdrfIVHhVcof9+FcbhlJZN0KsrdurDgw300NZ/6JlGvW2T3+M11X9niu4qOqAnAz5UUOZx1f4+TYtuLFJa7pW6ZU9PheVfoZ9vypMnuFDHc84xKOm0bRm5RSr2mpeVyWFIESEBqhkaqMjQ0q+BqhkaoJphv9wWoH3HcvX030se92TAh4o4fkJh3+XoxLVh6h6ZpjlHXpHHG625DzRU84bRyikoVk6hR7kFxTpRUKzcQo9yCouVW+A5+X3J/TkFxcop8JT7Prfg1H+Xrq2g2KuC4kIdzbn8c+AK76OQKxbo7Qi3xhZ9rj/sOq7a3x9SepNY/cZ9VHOOvKI8b7R+O2m5giODFOhylNycDgW4HApylnwfcPJr6X2//HrmfYYCnc6T9xkKdDkU5HIo0OlUgMso97ggl+O8Q7bO/hoqn79gRbTiuuUpolbI5f9DAQAAAIAP8uXuSJK07AVtT89V/50pCt+3oaS3aNxb2Ykt9OZVy5VcO9T3/7/+k2v4fFeKGstQ/icf6ZlVoapRu4XuzMtWUWGw7n4mxWe7F0lnPw+NettnDWfJ/3y7JJnxBeqz90nFF8eoZo8zX+8+5RdrqLF7ux78/jONbdpL4bHJPn0OQlwhmnXTLP2/j27XzsydSnnjIcVsvE4Pbf3YXq8hyf4/BwAAAAAuCoOWfMCf//xnPfLIIxowYIAkad68efrnP/+p+fPna+TIM/9S2MyZM9WjRw+NGDFCkvTcc89p8eLFmjNnjubNm1c5IU9+2EZS+YtUvpxcsv2mP1XO81YUu+eX7L8Gu+eX7L8Gu+eX/GMNAAAAAKqViu59TNPUjBkzNHr0aP32t7+VJL355puKjY3VwoUL1bdvX23dulWLFi3SmjVr1KZNG0nS7Nmzddttt2nq1KlKSEio+IXa/f2a3fNL9l+D3fNLrMEX2D0/AAAAAFwmX/7sUdukKMVHBGtOZsmwpT5hH+v92vHqU3hQ+/Jrqb1jq64PnKS2x2rLcDhL3tuFOKQwp5TglEcO5Xuk3GJDuUWmcotN5RSZOlEo5RSayi70KqvQqyKvIU+BQ950hzyHHfLIqTw5tEMO/SiHPCdvhsOpGiGBqhEcpPDQILlDguW+sZHcKY0V/sMuOdd9r6Ktu5S3fr3y1q9X2vPPq0aba3T4mmu1Pb+z6jq3a6+nldzGlbq7oJYKj7bUYZlSsaH83d8rvMA3P463ytFaPxV306N6V3X2N1JEfp0z8//wX4XHeiWvV/IWS6anZGhx2Vfvad+f/Hq2bb/Y1/R45PEWy1NcLE9xkTwej7yeYnk8xfJ6PPJ6T371FMv0euT1emR6PTI9xZK3ZFt+YZGm5ebJ6fTqZ2+0bvp5nY7nt1arA7fLcaieJK8kh/bP668aAfsVICnm5O28Tp4uh2HI6TDkchhyORxyOkv/++R2p+PUfzsccjkNOQ1D5eb6FEvKOnk7jWlKTUIyVeTx6oA3Sj33fa2dnuu0t+BmfXq8vhzyKkyGWv/3acVsOnTpJ9iQFHTyVvqckkzTlNcreUxTXtOUx2vKa0per1myzXva9rL/PrWt7PtCUx8dc+ofUR5NiI7SrFUb5MhvoYK82/Sp59Qansqarhp5+y99DRdgSio4eTv3P0PJOTGMknNqSDIMQw5D8prSS8UeySkd8EaVvYZK80umQmRo7Y9H1LVWYoXnBwAAAAAr+XJ3JEnb03OVvGWW7io6oOJ9uWp28Ji6hK9VYM0tSt7yobY3GazkCn/WilW6hqu9NSRdp0BnvHoV1JDzsKEs1ZDkUP6JIp8eznL6eaiTH6teBXVss4az5b/1aFc5Mkq6o2Ifzy+VX0PRPocSPYHqVRgtlw3OQWxYrEa42mlM0VLlB/+gm9MP2e41JNn/5wAAAADAxfHNT3ZUI4WFhVq3bp1GjTo1WdvhcKhbt25KTU0962NSU1M1fPjwctu6d++uhQsXVl7Q0otSlk2QPIXS9cOkr6ZLK6ZIN46QOjwhFf6KP3lV2To8UZLbrvkl+6/B7vkl+6/B7vmls6/h6znS8oklF8r98gI6AAAAALBYZfQ+u3btUlpamrp161Z2f0REhNq1a6fU1FT17dtXqampioyMLBuyJEndunWTw+HQ6tWrdeedd1bgKk+iO7Ke3ddg9/wSa/AFdEcAAAAAqiFf/+yR02Homdub6PG312uOp7eaO/8pSdrvcumqoAzFK0OStGvvxR2vdJZMVOmG0gEzl8KUlHfydrrWUmBjhzy7g+TdFSzzWIBOrP5Ooau/UzOnV5tapkg1pJ8Tu5QMEyoLIW17c6z2Oyt+wExFCMt36JoiaZlu1WF3T+2Or3Nm/ven+Gx+SQrNd8gskrarrXaH91RuXB05ytbgkCTF5BSppqOwwp+7+OTt14jKd8hT5NBBo502RfZUTp1fnoOS/Md2HpPpuIxBS7+S8+TtQh455FBMQIR2BzTSjhqdldf8zDU48jxyFHoqK+pFMSWdLYHj5Gtom9qVvYZK8ztO/hwcy6n41w8AAAAAWMnXuyOP19Swjc302+M99Hvnx9q6N06SdPOe7xScdFQzPZ208tsQPd18hRzGBQ5mEa8pvfhtiG7M6qRkc5d26zplRdSX87T3zGvXr1PoHt9chGlKr6+ppZY5vXWNUaj9NXtpY51426zhXPlP745+/uFn5R7zzQE5HtPUC/9toE4596qzI0ff1bpNG+vGy2WTNXhMU+9/01Z3FWVof2iYokKu18bmCbZ5DUnn+zkobZpK1uDxmtaFBAAAAFAhDNM0+V/2Fjpw4IDq1Kmjr7/+Wh06dCjb/tRTT+nLL7/U6tWrz3hMYGCg3njjDfXr169s21/+8heNHz9ehw6d/YMWBQUFKig49fecsrKylJiYqMzMTLnd7osPvPT5kotqAMCXXMKFcllZWYqIiLj0338AAAAAcIkqo/f5+uuv1alTJx04cEDx8fFl+9xzzz0yDEPvvfeeJk6cqDfeeEPbtm0rd+yYmBiNHz9ejz/++BnPS3cEwK9d4pAl+iMAAAAAdmKHzx6l56br481blbb0r/o4doPyHY5LXaZl6hwxdf33Xt20tYF2Jv1G2e4rrY4EoBI16p+srh0Tz7sP3REAAAAAO/H17ih151FF9rz+cpbmU47VbEh3BFQTF+qP6I4AAAAA3+eyOgCqxgsvvKDx48f/+gNdP4yL5QD4FmfgJV0oBwAAAAA4E90RAL9FdwQAAAAAFeLX9Ecf/PiB5m6dK8VLpX/1+5cCHYEKdvnOX2E3TclrmjJN6WiMqb/XMhUSdI+CzbjzPs5RnCdD3vPuYxWPM0Qyzj/gypfzSxe3Bmdxngz55t+dLHYG2zq/dHFr8OXX0cW8hpomRFRRGgAAAADwL5fbHR3Oztf8lGs1eMUmuXzz7eRF+fHqu5UbFn/efQIKMuUwPVWU6NIVBkbIdDjPu48vr8Hu+SX7r8Hu+aWLW8OxnMIqSgMAAACgsjBoyWK1atWS0+k8Y6L3oUOHFBd39g/nxMXFXdL+kjRq1CgNHz687PvSyeCX7Os5JV+dgZKnULpxRMkFdHbx1fSSi/3sml+y/xrsnl+y/xrsnl86cw1fTuaCOQAAAAA+pzJ6n9Kvhw4dUnx8fLl9WrRoUbbP4cOHyx2juLhYx44dO+fz0h2d5I/vme22Brvnl1iDL6A7AgAAAFCN2OGzR3cfPayU/QelNg9p65VtNS51nMZ1GKfGu7+R1r6q2u0GqnbXcRd1LCuk7jyqkd8v113ZaXKYcZLpkYwzL7Zp8GCz8/4lc6uk7jyqkX9drruyC2yZv9TiuS/q4KZoZXuvOuca+oy9UbXrhluQ7sL2vTdXXy936oh5tS3zS9LmBTO0/quw856Du3x4DRfzGnI6DAuSAQAAAEDl8fXuKCY8WP+pdad2d7tWs/694Mzjdr1Tu8Ov1Ky7b1SrupEXPJ4V1u/N0AcL1uj6nExFKOKc7znr9b1KnVrFWJDwwtbvzdCLC9bo+pwatlyD3fNLJ9fw1ve6Pi9IEUao7dbgN+fgItYQFRZoQToAAAAAFYlBSxYLDAxU69attWTJEt1xxx2SJK/XqyVLlmjgwIFnfUyHDh20ZMkSDR06tGzb4sWL1aFDh3M+T1BQkIKCgn5d2C8nS8snSjf9qeSilC8nS8sm2Ocvgn85ueTiGrvml+y/Brvnl+y/Brvnl869Bsk+awAAAABQLVRG75OUlKS4uDgtWbKkbLBSVlaWVq9erccff7zsGBkZGVq3bp1at24tSVq6dKm8Xq/atWt31uelO5J/v2e2yxrsnl9iDb6A7ggAAABANWOHzx7VdgSpdqenSt6XHd0iSWoc3VhNGvSRgqIlr+/+BXNJapsUpfvC/63f5f1d69feqJ+SeinbfeUZF9o0TYiwLuR52D1/qZsbmdqWv1Hp739+zjX4ssSYDN3e4bjWz12kn5JuV7a7nq3yS9I18Xmq3/6A1s/93JZrsPtrCAAAAAAuh693R22TohQXFqN7jy2UJJmSjF987WXu1KsRXdWpZUOfHY7bKTpWx/+9X7VzX1bjDUXnfM/ZvOGVqlHbbV3Q87D7GuyeX/rFGvbacw1+dQ4usAZf71EBAAAAXBiDlnzA8OHDdf/996tNmzZq27atZsyYoZycHA0YMECS1L9/f9WpU0cvvPCCJGnIkCHq3Lmzpk2bpp49e+rdd9/V2rVr9fLLL1deyNKLUUovTpFOfbXDRSp2zy/Zfw12zy/Zfw12zy/5xxoAAAAAVCsV3fsYhqGhQ4fq+eefV3JyspKSkjRmzBglJCSUfRiqcePG6tGjhx555BHNmzdPRUVFGjhwoPr27auEhITKWajd36/ZPb9k/zXYPb/EGnyB3fMDAAAAwGXy+c8e3TTq3PfZ4H2a02GoS4NovX6sh5rn/ij37je1rXW06mXeoaLQOiq99M9XL/aze/4yN41S/cZpMv5+t4IzP9BH0aFKPtFbOUHxVie7ODeNUkBammJevlsJhf9SXrN++nZdoTIDYqxOdvF+sYaauX/XguggNczpo+zAOKuTXRy7v4YAAAAA4DL5cnfkdBh686rluvL4v7U5KFF7w6K0vG26Ur6prbo5x3R/jX+r81UN5HR0rfDnrijl1pCbeJbuxSvJ4dPdi93XYPf80plrCP/pXW26qoeSnTEqCk2Qr6/BH8+BHdcAAAAA4OIwaMkH3HvvvUpPT9fYsWOVlpamFi1aaNGiRYqNjZUk7d27Vw6Ho2z/jh07asGCBRo9erT++Mc/Kjk5WQsXLtQ111xTeSG9nvIXp5Qq/d7H/7Kc7fNL9l+D3fNL9l+D3fNL/rEGAAAAANVKZfQ+Tz31lHJycvToo48qIyND119/vRYtWqTg4OCyfd555x0NHDhQXbt2lcPhUJ8+fTRr1qzKW6jd36/ZPb9k/zXYPb/EGnyB3fMDAAAAwGWyxWePTqodUluPN39ctUNqV/pzVaSr752oHU0PamT0Rv2cd0wBNb9R0TGn2jiK1N0RLme+VyHhAVbHPCe75y8VEBenq5cu0ZGiDNXZ/qFuvbqb8nZKa/61VyeOF/j8GkrzGwEBMgxDjb1e7d2Ubpv80pnnoPvVXW15Duz6GgIAAACAy+Hr3VFy7VBtbzNQg92dynqLhWFtdUVIlOY3WKXk2qGV8rwV6WxrKO1eflOQp+KiYJ9/z2n3Ndg9v1R+DfuyiyXDkLymrgu0xxr87RzYdQ0AAAAALswwTdO0OgSqXlZWliIiIpSZmSm32211HACoMvz+AwAAAIAL470TgOqM34EAAAAAcGHV9b2Tx2vqm13HdDg7XzHhwWqbFCWHIXmLTTkDHBc+gMXsnv9cTNO09Rrsnl+y/xouJX91/f0HAAAAAJfict47na23cDqMSk5asfyhe7H7GuyeX7L/GuyeX/p1a6A7AgAAAHyfy+oAAAAAAAAAAAAAAAAAAAD4OqfDUIeros/cHmCPi/7snv9cDMOw9Rrsnl+y/xrsnh8AAAAA/MG5egs78Yfuxe5rsHt+yf5rsHt+yT/WAAAAAODc7DECFgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4DIwaAkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgtBi0BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC/xaAlAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgtxi0BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/BaDlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN9i0BIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBbDFoCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB+i0FLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAbzFoCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+C2X1QFgDdM0JUlZWVkWJwGAqlX6e6/09yAAAAAA4Ex0RwCqM/ojAAAAALgw+iMA1RXdEQAAAABcGN0RgOqK7ggAAADwfQxaqqays7MlSYmJiRYnAQBrZGdnKyIiwuoYAAAAAOCT6I4AgP4IAAAAAM6H/ghAdUd3BAAAAADnRncEoLqjOwIAAAB8l2EyGrVa8nq9OnDggMLDw2UYxiU9NisrS4mJidq3b5/cbnclJaw8ds8v2X8Nds8v2X8Nds8vXf4aTNNUdna2EhIS5HA4KjEhAAAAANgX3ZF980v2X4Pd80uswRf8mvz0RwAAAABwYZfbH9n9/aZk/zXYPb9k/zXYPb9k/zXQHQEAAABA5aI7Yg1Wsnt+yf5rsHt+ievWAAAAAH/msjoArOFwOHTFFVf8qmO43W7bvtGV7J9fsv8a7J5fsv8a7J5furw1MBEcAAAAAM6P7sj++SX7r8Hu+SXW4AsuNz/9EQAAAACc36/tj+z+flOy/xrsnl+y/xrsnl+y/xrojgAAAACgctAdsQZfYPf8kv3XYPf8EtetAQAAAP6IkagAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBvMWgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4LQYt4ZIFBQXpmWeeUVBQkNVRLovd80v2X4Pd80v2X4Pd80v+sQYAAAAA8Ed2f79m9/yS/ddg9/wSa/AFds8PAAAAAP7KH96v2X0Nds8v2X8Nds8v2X8Nds8PAAAAAP7KH96vsQbr2T2/ZP812D2/5B9rAAAAAHB2hmmaptUhAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKoPD6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACVhUFLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAbzFoCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+C0GLeGCXnzxRRmGoaFDh5Zty8/P1xNPPKHo6GjVqFFDffr00aFDh6wLeZpx48bJMIxyt0aNGpXd7+v5S+3fv1+/+93vFB0drZCQEF177bVau3Zt2f2maWrs2LGKj49XSEiIunXrpu3bt1uYuLwrr7zyjPNgGIaeeOIJSb5/Hjwej8aMGaOkpCSFhIToqquu0nPPPSfTNMv28fVzkJ2draFDh6pevXoKCQlRx44dtWbNmrL7fS3/ihUrdPvttyshIUGGYWjhwoXl7r+YvMeOHdN9990nt9utyMhIPfTQQzpx4kQVrgIAAAAAqh/6I2vQHVnLH7ojif6I/ggAAAAAKh/dkTXojqznD/0R3RHdEQAAAABUNroj69i5P6I78g10R3RHAAAAgB0xaAnntWbNGv31r39Vs2bNym0fNmyYPv30U33wwQf68ssvdeDAAfXu3duilGfXtGlTHTx4sOz21Vdfld1nh/zHjx9Xp06dFBAQoM8//1xbtmzRtGnTVLNmzbJ9Jk+erFmzZmnevHlavXq1wsLC1L17d+Xn51uY/JQ1a9aUOweLFy+WJN19992SfP88TJo0SXPnztWcOXO0detWTZo0SZMnT9bs2bPL9vH1c/Dwww9r8eLFeuutt7Rp0ybdcsst6tatm/bv3y/J9/Ln5OSoefPmeumll856/8Xkve+++/T9999r8eLF+uyzz7RixQo9+uijVbUEAAAAAKh26I+sQXdkPX/ojiT6I/ojAAAAAKhcdEfWoDvyDf7QH9Ed0R0BAAAAQGWiO7KO3fsjuiPrz4FEd0R3BAAAANiUCZxDdna2mZycbC5evNjs3LmzOWTIENM0TTMjI8MMCAgwP/jgg7J9t27dakoyU1NTLUpb3jPPPGM2b978rPfZIb9pmubTTz9tXn/99ee83+v1mnFxceaUKVPKtmVkZJhBQUHm3/72t6qIeMmGDBliXnXVVabX67XFeejZs6f54IMPltvWu3dv87777jNN0/fPQW5urul0Os3PPvus3PZWrVqZf/rTn3w+vyTzo48+Kvv+YvJu2bLFlGSuWbOmbJ/PP//cNAzD3L9/f5VlBwAAAIDqgv7IOnRH1rN7d2Sa9Eel6I8AAAAAoHLQHVmH7sg32L0/ojsqQXcEAAAAAJWD7sha/tYf0R1VPbqjEnRHAAAAgP04qnasE+zkiSeeUM+ePdWtW7dy29etW6eioqJy2xs1aqS6desqNTW1qmOe0/bt25WQkKD69evrvvvu0969eyXZJ/8nn3yiNm3a6O6771ZMTIxatmypV155pez+Xbt2KS0trdw6IiIi1K5dO59aR6nCwkK9/fbbevDBB2UYhi3OQ8eOHbVkyRL9+OOPkqSNGzfqq6++0q233irJ989BcXGxPB6PgoODy20PCQnRV1995fP5T3cxeVNTUxUZGak2bdqU7dOtWzc5HA6tXr26yjMDAAAAgL+jP7IO3ZH17N4dSfRHpeiPAAAAAKBy0B1Zh+7IN9i9P6I7KkF3BAAAAACVg+7IWv7UH9EdWYPuqATdEQAAAGA/LqsDwDe9++67Wr9+vdasWXPGfWlpaQoMDFRkZGS57bGxsUpLS6uihOfXrl07vf7662rYsKEOHjyo8ePH64YbbtDmzZttkV+SfvrpJ82dO1fDhw/XH//4R61Zs0aDBw9WYGCg7r///rKssbGx5R7na+sotXDhQmVkZOiBBx6QZI/X0ciRI5WVlaVGjRrJ6XTK4/FowoQJuu+++yTJ589BeHi4OnTooOeee06NGzdWbGys/va3vyk1NVVXX321z+c/3cXkTUtLU0xMTLn7XS6XoqKifHJNAAAAAGBn9EfWojuynt27I4n+qBT9EQAAAABUPLoja9Ed+Qa790d0RyXojgAAAACg4tEdWc+f+iO6I2vQHZWgOwIAAADsh0FLOMO+ffs0ZMgQLV68+IyJwnZROrlZkpo1a6Z27dqpXr16ev/99xUSEmJhsovn9XrVpk0bTZw4UZLUsmVLbd68WfPmzdP9999vcbpL9+qrr+rWW29VQkKC1VEu2vvvv6933nlHCxYsUNOmTbVhwwYNHTpUCQkJtjkHb731lh588EHVqVNHTqdTrVq1Ur9+/bRu3TqrowEAAAAAbIz+yHp0R9bzh+5Ioj8CAAAAAFQ8uiPr0R35Bn/oj+iOAAAAAAAVje7IN/hTf0R3ZB26IwAAAAB25LA6AHzPunXrdPjwYbVq1Uoul0sul0tffvmlZs2aJZfLpdjYWBUWFiojI6Pc4w4dOqS4uDhrQl9AZGSkGjRooB07diguLs4W+ePj49WkSZNy2xo3bqy9e/dKUlnWQ4cOldvH19YhSXv27NF//vMfPfzww2Xb7HAeRowYoZEjR6pv37669tpr9T//8z8aNmyYXnjhBUn2OAdXXXWVvvzyS504cUL79u3TN998o6KiItWvX98W+X/pYvLGxcXp8OHD5e4vLi7WsWPHfHJNAAAAAGBX9EfWozuynj90RxL9kUR/BAAAAAAVje7IenRHvsEf+iO6I7ojAAAAAKhodEe+wV/6I7oja9Ed0R0BAAAAdsSgJZyha9eu2rRpkzZs2FB2a9Omje67776y/w4ICNCSJUvKHrNt2zbt3btXHTp0sDD5uZ04cUI7d+5UfHy8WrdubYv8nTp10rZt28pt+/HHH1WvXj1JUlJSkuLi4sqtIysrS6tXr/apdUjSa6+9ppiYGPXs2bNsmx3OQ25urhyO8r8mnU6nvF6vJHudg7CwMMXHx+v48eP64osv9Nvf/tZW+aWL+/fu0KGDMjIyyk0+X7p0qbxer9q1a1flmQEAAADAX9EfWY/uyHr+1B1J9Ef0RwAAAABQceiOrEd35Bv8qT+iO6I7AgAAAICKQnfkG/ylP6I78g10R3RHAAAAgJ24rA4A3xMeHq5rrrmm3LawsDBFR0eXbX/ooYc0fPhwRUVFye12a9CgQerQoYPat29vReQz/OEPf9Dtt9+uevXq6cCBA3rmmWfkdDrVr18/RURE+Hx+SRo2bJg6duyoiRMn6p577tE333yjl19+WS+//LIkyTAMDR06VM8//7ySk5OVlJSkMWPGKCEhQXfccYe14X/B6/Xqtdde0/333y+X69SvHDuch9tvv10TJkxQ3bp11bRpU3377bf685//rAcffFCSPc7BF198IdM01bBhQ+3YsUMjRoxQo0aNNGDAAJ/Mf+LECe3YsaPs+127dmnDhg2KiopS3bp1L5i3cePG6tGjhx555BHNmzdPRUVFGjhwoPr27auEhARL1gQAAAAA/oj+yHp0R9bzh+5Ioj+iPwIAAACAikd3ZD26I9/gD/0R3RHdEQAAAABUNLoj3+AP/RHdkfXojuiOAAAAAFsygYvQuXNnc8iQIWXf5+Xlmb///e/NmjVrmqGhoeadd95pHjx40LqAp7n33nvN+Ph4MzAw0KxTp4557733mjt27Ci739fzl/r000/Na665xgwKCjIbNWpkvvzyy+Xu93q95pgxY8zY2FgzKCjI7Nq1q7lt2zaL0p7dF198YUo6ay5fPw9ZWVnmkCFDzLp165rBwcFm/fr1zT/96U9mQUFB2T6+fg7ee+89s379+mZgYKAZFxdnPvHEE2ZGRkbZ/b6Wf9myZaakM27333//Rec9evSo2a9fP7NGjRqm2+02BwwYYGZnZ1uwGgAAAACoXuiPqh7dkbX8oTsyTfoj+iMAAAAAqBp0R1WP7sh6/tAf0R3RHQEAAABAVaA7sobd+yO6I+vRHdEdAQAAAHZkmKZpVt1YJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgKrjsDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZWHQEgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8FsMWgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH6LQUsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBvMWgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4LQYtAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv8WgJQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4LcYtAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwWg5aAauKBBx7QHXfcYXWMi2a3vAAAAAAAAHZmty7GbnkBAAAAAADszG5djN3yAgAAAAAA2Jnduhi75QUAAAAAVCzDNE3T6hAAKl9mZqZM01RkZGSlHH/cuHFauHChNmzYUCHHq+y8F8MwDH300UeUZwAAAAAAwO/RHV06uiMAAAAAAFBd0B1dOrojAAAAAABQXdAdXTq6IwAAAACwjsvqAACqRkREhNURJElFRUUKCAi44H6+khcAAAAAAKA68JUuhu4IAAAAAADA9/hKF0N3BAAAAAAA4Ht8pYuhOwIAAAAAXAyH1QEAVJwPP/xQ1157rUJCQhQdHa1u3bopJydHkvTAAw+UTbnevXu3DMM445aSklJ2rK+++ko33HCDQkJClJiYqMGDB5cd63Svv/66xo8fr40bN5Yd6/XXX5dUMmF77ty5+s1vfqOwsDBNmDBBHo9HDz30kJKSkhQSEqKGDRtq5syZ5Y75y7ySlJKSosGDB+upp55SVFSU4uLiNG7cuPP+eyxfvlxt27ZVWFiYIiMj1alTJ+3Zs6fs/o8//litWrVScHCw6tevr/Hjx6u4uFiSdOWVV0qS7rzzThmGUfY9AAAAAACAXdEdlUd3BAAAAAAAcArdUXl0RwAAAAAAAKfQHZVHdwQAAAAA9uWyOgCAinHw4EH169dPkydP1p133qns7GytXLlSpmmesW9iYqIOHjxY9n1aWpq6deumG2+8UZK0c+dO9ejRQ88//7zmz5+v9PR0DRw4UAMHDtRrr712xvHuvfdebd68WYsWLdJ//vMfSeWne48bN04vvviiZsyYIZfLJa/XqyuuuEIffPCBoqOj9fXXX+vRRx9VfHy87rnnnnOu8Y033tDw4cO1evVqpaam6oEHHlCnTp108803n7FvcXGx7rjjDj3yyCP629/+psLCQn3zzTcyDEOStHLlSvXv31+zZs3SDTfcoJ07d+rRRx+VJD3zzDNas2aNYmJi9Nprr6lHjx5yOp0XcxoAAAAAAAB8Et1ReXRHAAAAAAAAp9AdlUd3BAAAAAAAcArdUXl0RwAAAABgb4Z5tne0AGxn/fr1at26tXbv3q169eqdcf8DDzygjIwMLVy4sNz2/Px8paSkqHbt2vr444/lcDj08MMPy+l06q9//WvZfl999ZU6d+6snJwcBQcHn3H8cePGaeHChdqwYUO57YZhaOjQoZo+ffp58w8cOFBpaWn68MMPz5o3JSVFHo9HK1euLHtM27Zt1aVLF7344otnHO/YsWOKjo7W8uXL1blz5zPu79atm7p27apRo0aVbXv77bf11FNP6cCBA2XZP/roo3JTygEAAAAAAOyI7qg8uiMAAAAAAIBT6I7KozsCAAAAAAA4he6oPLojAAAAALA3l9UBAFSM5s2bq2vXrrr22mvVvXt33XLLLbrrrrtUs2bN8z7uwQcfVHZ2thYvXiyHwyFJ2rhxo7777ju98847ZfuZpimv16tdu3apcePGl5StTZs2Z2x76aWXNH/+fO3du1d5eXkqLCxUixYtznucZs2alfs+Pj5ehw8fPuu+UVFReuCBB9S9e3fdfPPN6tatm+655x7Fx8eXrXHVqlWaMGFC2WM8Ho/y8/OVm5ur0NDQS1ojAAAAAACAL6M7Ko/uCAAAAAAA4BS6o/LojgAAAAAAAE6hOyqP7ggAAAAA7M1hdQAAFcPpdGrx4sX6/PPP1aRJE82ePVsNGzbUrl27zvmY559/Xl988YU++eQThYeHl20/ceKEHnvsMW3YsKHstnHjRm3fvl1XXXXVJWcLCwsr9/27776rP/zhD3rooYf073//Wxs2bNCAAQNUWFh43uMEBASU+94wDHm93nPu/9prryk1NVUdO3bUe++9pwYNGui///1v2RrHjx9fbo2bNm3S9u3bzzr9HAAAAAAAwM7ojs5EdwQAAAAAAFCC7uhMdEcAAAAAAAAl6I7ORHcEAAAAAPblsjoAgIpjGIY6deqkTp06aezYsapXr54++ugjDR8+/Ix9//73v+vZZ5/V559/fkYR1apVK23ZskVXX331RT93YGCgPB7PRe27atUqdezYUb///e/Ltu3cufOin+tStGzZUi1bttSoUaPUoUMHLViwQO3bt1erVq20bdu2864xICDgotcEAAAAAADg6+iOzkR3BAAAAAAAUILu6Ex0RwAAAAAAACXojs5EdwQAAAAA9sSgJcBPrF69WkuWLNEtt9yimJgYrV69Wunp6WrcuPEZ+27evFn9+/fX008/raZNmyotLU1SSfEUFRWlp59+Wu3bt9fAgQP18MMPKywsTFu2bNHixYs1Z86csz7/lVdeqV27dmnDhg264oorFB4erqCgoLPum5ycrDfffFNffPGFkpKS9NZbb2nNmjVKSkqqsH+PXbt26eWXX9ZvfvMbJSQkaNu2bdq+fbv69+8vSRo7dqx69eqlunXr6q677pLD4dDGjRu1efNmPf/882VrWrJkiTp16qSgoCDVrFmzwvIBAAAAAABUJbqj8uiOAAAAAAAATqE7Ko/uCAAAAAAA4BS6o/LojgAAAADA3hxWBwBQMdxut1asWKHbbrtNDRo00OjRozVt2jTdeuutZ+y7du1a5ebm6vnnn1d8fHzZrXfv3pKkZs2a6csvv9SPP/6oG264QS1bttTYsWOVkJBwzufv06ePevTooZtuukm1a9fW3/72t3Pu+9hjj6l3796699571a5dOx09erTcpPCKEBoaqh9++EF9+vRRgwYN9Oijj+qJJ57QY489Jknq3r27PvvsM/373//Wddddp/bt22v69OmqV69e2TGmTZumxYsXKzExUS1btqzQfAAAAAAAAFWJ7qg8uiMAAAAAAIBT6I7KozsCAAAAAAA4he6oPLojAAAAALA3wzRN0+oQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlcFhdQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDKwqAlAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgtxi0BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/BaDlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN9i0BIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBbDFoCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB+i0FLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAbzFoCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+C0GLQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL/FoCUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOC3GLQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8FoOWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3/r/qBcXw21fE1kAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DJHHiKFqIUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FhKy2v5qIb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "840TDfGaqIei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SijOuiZYgmon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TG_Fsg4Mgmrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZRfmkoYlgmuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2vbxlxxNgmyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zJgEeongm1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkEtCuWEgm3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjbzANmcg_cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JsQXdlOg_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4FH2Zo7g_j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxm1VFuIg_q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3cxU4-RZg_uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktlqpLJ9g_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doiemfrVg_zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bzoCpqTg_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwoz_Lp2g_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-Kc_0IPg_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMqppMFSgm5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSeaLOr-qLYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azRmYEueqLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4l2vYHzqLd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7X3AQIZqLgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iv34YkpnqLju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCRKDvv-qLmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJ6b5Zd_vZ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7swocNpvZ_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cxt5tWj1vaCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kCvPWMOtvaE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9kxssOuRMv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWcLfNW2RM1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S5O3hTLTvaIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE8VHJ90vaMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZnN2xpSvaOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze5Q9M4Tycsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzWhOlCoycwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZMXiJW-ycz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uAINCofcyc20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uORnN_wO05n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQ441A0hO09K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iF_8aBrWO1Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHLiMt5wO1Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gB_XEEFvaQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFwxXhyWefs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Kw8bLBTefv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXN7C2Jfefzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeFvCalref4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "An113TsYef7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kF5dEO1zef-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zuC2em6egA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MM7Zk7OWegDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVL97vbaegFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA3cOcmeegJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FpYA6ClegNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3MxLnLIqLol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DgSOhmwgm7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSdrq6HmqIhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4nfPNbTqIjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4xXWwHeeMR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oonp7YBzeMUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnVLZhvbeMXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9Yk_s6leMZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5asNezNqImF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwGCYcYWqIrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6dLlbTgqIt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lu0iNCNHc_0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "031VAAc5c_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quVErgChc_-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVqmuefndAEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7M3O9KqdAL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LN_xYsFMdAQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wo4YT1OODeeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl-gtIlyDeh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnKMsLPgDemY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKCZUoDYDesF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1vpjYZ9dAVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1Fx16kedAX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(2, 5, size=(2, 2, 2))\n",
        "print(X)\n",
        "\n",
        "XX = np.concatenate(X)\n",
        "print(XX)\n",
        "\n",
        "\n",
        "Y = np.random.randint(2, 5, size=(1, 3, 2))\n",
        "print(Y)\n",
        "\n",
        "YY = np.concatenate(Y)\n",
        "print(YY)\n",
        "\n",
        "\n",
        "Z = np.random.randint(2, 5, size=(5, 2))\n",
        "print(Z)\n",
        "\n",
        "ZZ = np.concatenate(Z)\n",
        "print(ZZ)\n",
        "\n",
        "print(\"other\")\n",
        "s = np.random.randint(2, 4, 5)\n",
        "print(s)\n",
        "z = np.tile(s, reps=3)  # np.array([s] * 2)\n",
        "print(z)\n",
        "\n",
        "\n",
        "print(\"other mult\")\n",
        "s = np.random.randint(2, 8, size=(3, 2))\n",
        "print(s)\n",
        "z = np.tile(s, reps=(3, 1))  # np.array([s] * 2)\n",
        "print(z)\n"
      ],
      "metadata": {
        "id": "J-KLwpDqTkGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBkG1_lacBfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBILRQvDuI4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dPT52NAbKyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2ShK9JYb6c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fk7A_5N_c1gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgcEt2LBhEBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FiP-uNujLRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uENE-JShLaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JeqAEblFooY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXByx8OrjqZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TCzI5siopUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4pGls4IpDT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWpiTpQ5lVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ASCmfdEnvjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jq6GembmmAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nb6YB8DbvKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9pv_OW7pJtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgNt4tVYQk7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlebwxRZ1_QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1dmiXA-FcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDRrQMKGU3Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnNTv-mXVIB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBlyABpt0-qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQgiJb-V-hIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCuJj9HPb2cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VM2QQJkmcsdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## random forest imputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_estimator = RandomForestRegressor(n_estimators=4, max_depth=10, bootstrap=True, max_samples=0.5, n_jobs=2, random_state=0)\n",
        "\n",
        "X_rf = single_imputation(X_nan, rf_estimator)\n",
        "print(X_rf.shape)\n",
        "sd_rf = np.std(X_rf, axis=0)\n",
        "S_inv_rf = np.diag(1 / sd_rf)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std rf\\n \", sd_rf)\n",
        "fig, ax = plt.subplots(num='advtrain_linf_rf')\n",
        "linfadvtrain_rf = AdversarialTraining(X_rf, y, S_inv_rf, p=np.inf)\n",
        "estimator_rf = lambda X, y, a:  linfadvtrain_rf(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_rf  = get_path(X_rf, y, estimator_rf, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_rf, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "uSgnV3aVXL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## iterative imputer Bayesian Ridge\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "br_estimator = BayesianRidge()\n",
        "\n",
        "X_br = single_imputation(X_nan, br_estimator)\n",
        "sd_br = np.std(X_br, axis=0)\n",
        "S_inv_br = np.diag(1 / sd_br)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std  br\\n \", sd_br)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_br')\n",
        "linfadvtrain_br = AdversarialTraining(X_br, y, S_inv_br, p=np.inf)\n",
        "estimator_br = lambda X, y, a:  linfadvtrain_br(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_br  = get_path(X_br, y, estimator_br, 1e4)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_br, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "pgNaP74gWAga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## mean imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_mean = imp_mean.fit_transform(X_nan)\n",
        "sd_mean = np.std(X_mean, axis=0)\n",
        "print(sd_mean)\n",
        "S_inv_mean = np.diag(1 / sd_mean)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_mean')\n",
        "linfadvtrain_mean = AdversarialTraining(X_mean, y, S_inv_mean, p=np.inf)\n",
        "estimator_mean = lambda X, y, a:  linfadvtrain_mean(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_mean  = get_path(X_mean, y, estimator_mean, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_mean, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "u0kpCJCkFbcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# imputation elliptic\n",
        "\n",
        "mu = np.nanmean(X_nan, axis=0)\n",
        "print(\"means \", mu)\n",
        "delta = np.mean(masks) # parameter missingness\n",
        "print(\"delta \", delta)\n",
        "X_0 = np.nan_to_num(X_nan)\n",
        "print(\"nbr obs\", X_0.shape[0])\n",
        "S_ellp =  X_0.T @ X_0 / X_0.shape[0]\n",
        "S_ellp = (1/delta - 1/(delta**2)) * np.diag(np.diag(S_ellp)) + 1/(delta**2) * S_ellp\n",
        "print(\"eig cov \", np.linalg.eigvalsh(S_ellp))\n",
        "X_ellp = imputation_elliptic(mu, S_ellp, X_nan, masks)\n",
        "#S_inv_ellp = np.linalg.inv(S_ellp)  # other variance\n",
        "sd_inv_ellp = np.std(X_ellp, axis=0)\n",
        "print(\"sd ellp\", sd_inv_ellp)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_ellp')\n",
        "linfadvtrain_ellp = AdversarialTraining(X_ellp, y, S_ellp, p=np.inf)\n",
        "estimator_ellp = lambda X, y, a:  linfadvtrain_ellp(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_ellp  = get_path(X_ellp, y, estimator_ellp, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_ellp, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "2RYR4_BJhXjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mlM-FR-OfL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgxEbR071wT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7pwDiPU0D_ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdM7Mk_mjf0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYa8pmuMk4jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMwgzXI1_rEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Example data\n",
        "x_test_rect = np.random.rand(10)\n",
        "y_test_rect = np.random.rand(10)\n",
        "\n",
        "# Plot the points\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x_test_rect, y_test_rect)\n",
        "\n",
        "width = 0.1\n",
        "height = 0.1\n",
        "\n",
        "#add_rectangles(x_test_rect, y_test_rect, width, height, ax)\n",
        "\n",
        "# Add the rectangle to the plot\n"
      ],
      "metadata": {
        "id": "-9qaVcwZUB6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WZeO2EOWHwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for some tests\n",
        "\n",
        "def test_clear_dataset(n, d):\n",
        "  print(\"test clear dataset\")\n",
        "  X = np.random.randint(1, 3, size=(n, d))\n",
        "  y = np.random.randint(1, 3, size=n)\n",
        "  masks = np.random.binomial(1, 0.3, size=(n, d))\n",
        "  print(\"X \\n\", X)\n",
        "  print(\"y\\n\", y)\n",
        "  print(\"masks \\n\", masks)\n",
        "  masks[:, 0] = np.ones(n)\n",
        "  masks[0, :] = np.ones(d)\n",
        "  X_res, y_res, masks_res = clear_dataset(X, y, masks)\n",
        "  print(\"X_res \\n\", X_res)\n",
        "  print(\"y\\n\", y_res)\n",
        "  print(\"masks \\n\", masks_res)\n",
        "  print(\"test clear dataset ended successfully\")\n",
        "\n",
        "def test_generate_X():\n",
        "    print(\"test generate_X started\")\n",
        "    fig, ax = plt.subplots(3, 1, figsize=(10, 8), num='advtrain_linf')\n",
        "    gen = generate_X('circles', 2)\n",
        "    data = gen(1000)\n",
        "    print(data.shape)\n",
        "    ax[0].scatter(data[:, 0], data[:, 1])\n",
        "    print(\"test generate passed syccessfully\")\n",
        "\n",
        "def test_preparation_dataset(n, d):\n",
        "      print(\"\\ntest preparation dataset started\")\n",
        "      X_train = np.random.rand(n, d)\n",
        "      print(\"X_train \\n\", X_train)\n",
        "      mask = np.random.binomial(1, 0.5, (n, d))\n",
        "      print(\"mask, 0 seen, 1 missing \\n \", mask)\n",
        "      X_masked = X_train * (1 - mask)\n",
        "      print(\"X_masked \\n\", X_masked)\n",
        "      X_nan_train = X_train.copy()\n",
        "      X_nan_train[mask == 1] = np.nan\n",
        "      print(\"X_nan_train \\n\", X_nan_train)\n",
        "      X_br_train = single_imputation(X_nan_train, BayesianRidge())\n",
        "      print(\"X_br_train\\n \", X_br_train)\n",
        "\n",
        "      print(\"what happens if we run single_imputation of full dataset\")\n",
        "      X_br_full = single_imputation(X_train, BayesianRidge())\n",
        "      print(\"X_br_full\\n \", X_br_full)\n",
        "      np.testing.assert_allclose(X_train, X_br_full)  # shuold be untouched\n",
        "      print(\"test preparation dataset ended successfully\")\n",
        "\n",
        "def test_listwise_delection(n, d):\n",
        "    print(\"\\n test list_wise delection started\")\n",
        "    X = np.random.rand(n, d)\n",
        "    print(\"data\\n\", X)\n",
        "    mask = np.random.binomial(1, 0.2, (n, d))\n",
        "    print(\"mask \\n\", mask)\n",
        "    X_ld = listwise_delection(X, mask)\n",
        "    print(\"after calling function, X_ld \\n\", X_ld)\n",
        "\n",
        "    print(\"edge cases, all missing\")\n",
        "    mask_1 = np.ones_like(X)  # all missing\n",
        "    X1 = listwise_delection(X, mask_1)\n",
        "    print(\"X1 \\n\", X1)  # should be empty\n",
        "    mask_0 = np.zeros_like(X)  # all seen\n",
        "    X0 = listwise_delection(X, mask_0)\n",
        "    print(\"X0 \\n\", X0)\n",
        "    np.testing.assert_allclose(X0, X)  # should be the original dataset\n",
        "\n",
        "    print(\"one dimnsional array\")\n",
        "    y = np.random.rand(n)\n",
        "    print(\"y before \", y)\n",
        "    y_ld = listwise_delection(y, mask)\n",
        "    print(\"y after ld \", y_ld)\n",
        "    print(\"test listwise_delection passed\")\n",
        "\n",
        "\n",
        "test_generate_X()\n",
        "test_preparation_dataset(3, 4)\n",
        "test_listwise_delection(3, 4)\n",
        "test_clear_dataset(6, 3)\n",
        "\n",
        "xxx = np.random.randint(2, 5, size=(3, 3)) * 1.0\n",
        "mmm = np.random.binomial(1, 0.5, size=(3, 3))\n",
        "print(xxx)\n",
        "print(mmm)\n",
        "print(mmm == 1)\n",
        "print(xxx[mmm == 1])\n",
        "xxx[mmm == 1] = np.nan\n",
        "print(xxx)\n",
        "mask_from_xxx = np.isnan(xxx).astype(int)\n",
        "print(\"mask from xxx \\n\", mask_from_xxx)\n"
      ],
      "metadata": {
        "id": "SDHMAeapZVgK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test best predictor\n",
        "\n",
        "def test_best_predictor(n, d, nb_coeff):\n",
        "  X_test = np.random.randint(1, 9, size=(n, d))\n",
        "  beta_gt_test = np.random.randint(1, 7, size=d)\n",
        "  y_test = X_test @ beta_gt_test\n",
        "  #print(\"X_test \\n\", X_test, \"\\n beta_gt\", beta_gt_test, \"\\n y_test = X_test @ beta_gt_test \", y_test)\n",
        "  coeff_test = np.random.randint(1, 5, size=(d, nb_coeff))\n",
        "  rdm_idx = np.random.randint(1, d+1, size=1)\n",
        "  print(rdm_idx)\n",
        "  #print(\"coeff test partial \", coeff_test[:, -1])\n",
        "  rng = np.arange(nb_coeff)\n",
        "  #print(rng != rdm_idx)\n",
        "  coeff_test[:, rng != rdm_idx] = coeff_test[:, rng != rdm_idx] + 1000  # increase artificially the value of the other coefficient, to induce the minimum index to be rdm_idx\n",
        "  #print(\"coeff_test \\n\", coeff_test)\n",
        "  best_coeff, best_score = best_predictor(X_test, coeff_test, y_test)\n",
        "  print(\"best coeff \", best_coeff)\n",
        "  print(\"best score \", best_score)\n",
        "  np.testing.assert_allclose(best_coeff, coeff_test[:,rdm_idx].squeeze())\n",
        "  print(\"test best predictor passed\")\n",
        "\n",
        "test_best_predictor(100, 5, 20)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJk1Yaj1ReIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test train_and_plot\n",
        "\n",
        "X_diab, y_diab = datasets.load_diabetes(return_X_y=True)\n",
        "n, d = X_diab.shape\n",
        "print(\"n:  \", n, \", d: \", d)\n",
        "# Standardize data\n",
        "X_diab -= X_diab.mean(axis=0)\n",
        "X_diab /= X_diab.std(axis=0)\n",
        "\n",
        "## original lasso\n",
        "fig_l, ax_l = plt.subplots(num='lasso')\n",
        "alphas_lasso, coefs_lasso, _ = get_lasso_path(X_diab, y_diab)\n",
        "plot_coefs_l1norm(coefs_lasso, ax_l)\n",
        "\n",
        "## Antonio's algo, 1 matrix\n",
        "S_diab_eye = np.eye(X_diab.shape[1])\n",
        "fig, ax_1 = plt.subplots(1, 1, num='advtrain_linf_diab')\n",
        "fig, ax_2 = plt.subplots(1, 1, num='advtrain_linf_diab_2')\n",
        "train_and_plot(X_diab, y_diab, S_diab_eye, [ax_1, ax_2])\n",
        "\n",
        "## Antonio's algo, multiple diagonal matrix\n",
        "#S_diab = np.eye(X_diab.shape[1])\n",
        "#S_diab = np.random.randint(1, 3, size=(n, d))\n",
        "#print(S_diab)\n",
        "#fig, ax_5 = plt.subplots(1, 1, num='advtrain_linf_diab_5')\n",
        "#fig, ax_6 = plt.subplots(1, 1, num='advtrain_linf_diab_6')\n",
        "#train_and_plot(X_diab, y_diab, S_diab, [ax_5, ax_6])\n",
        "\n",
        "\n",
        "## Antonio's algo, multiple matrices (same matrix stacked multiple time)\n",
        "S_diab_stacked = np.array([S_diab_eye] * X_diab.shape[0])\n",
        "S_diab_stacked = np.concatenate(S_diab_stacked)\n",
        "fig, ax_3 = plt.subplots(1, 1, num='advtrain_linf_diab_3')\n",
        "fig, ax_4 = plt.subplots(1, 1, num='advtrain_linf_diab_4')\n",
        "train_and_plot(X_diab, y_diab, S_diab_stacked, [ax_3, ax_4])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KjpHk0mYdiFh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test imputations\n",
        "\n",
        "np.random.seed(45)\n",
        "\n",
        "\n",
        "def test_imputations(n, d):\n",
        "  X = np.random.randint(2, 5, size=(n, d)) * 1.0\n",
        "  y = X @ np.random.randint(1, 3, size=d)\n",
        "  m = np.random.binomial(1, 0.4, size=(n, d))  # 1 missing, 0 seen\n",
        "  print(\"m original\\n\", m)\n",
        "  X, y, m = clear_dataset(X, y, m)\n",
        "  print(m)\n",
        "  X_nan = X.copy()\n",
        "  X_nan[m == 1] = np.nan\n",
        "\n",
        "  #mask_from_xxx = np.isnan(xxx).astype(int)\n",
        "  print(\"X\\n \", X)\n",
        "  print(\"masks \\n\", m)\n",
        "  print(\"X_nan\\n \", X_nan)\n",
        "  methods = ['BR_si', 'mi', 'l_d']\n",
        "  nbr_mi = [1, 3]\n",
        "  #for method in methods:\n",
        "  #  dict_info = {'imp_method': method, 'mi_nbr':nbr_mi}\n",
        "  #dict_info = {'imp_method':methods, 'mi_nbr':nbr_mi}\n",
        "  for method in methods:\n",
        "    print(\"---------- method: \", method)\n",
        "    if method == 'mi':\n",
        "      for x in nbr_mi:\n",
        "        print(\"-------------------- nbr mi: \", x)\n",
        "        dict_info = {'imp_method':method, 'mi_nbr':x}\n",
        "        #print(\"XNANNANAN \", X_nan)\n",
        "        X_res, y_res, mask_res = imputations(dict_info, X_nan, y)\n",
        "        print(X_res, y_res, \"\\n\", mask_res)\n",
        "    else:\n",
        "      dict_info = {'imp_method': method}\n",
        "      X_res, y_res, mask_res = imputations(dict_info, X_nan, y)\n",
        "      print(X_res, y_res, \"\\n\", mask_res)\n",
        "    print(\"test imputations ended successfully\")\n",
        "\n",
        "test_imputations(6, 3)\n"
      ],
      "metadata": {
        "id": "z5crxb1usyn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = np.array([1, 2])\n",
        "x.append(y)\n",
        "x.append(y)\n",
        "x.append(y)\n",
        "xx = np.stack(x)\n",
        "print(x)\n",
        "print(xx)\n",
        "print(type(xx))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sizes = [100, 1000, 10000, 100000]\n",
        "values = [0.8, 0.85, 0.9, 0.92]\n",
        "positions = range(len(sizes))\n",
        "\n",
        "plt.plot(positions, values, marker='o', label='Model Accuracy')  # Add label here\n",
        "plt.xticks(positions, sizes)\n",
        "\n",
        "plt.xlabel(\"Dataset Size (equispaced)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Performance vs Dataset Size (equispaced x-axis)\")\n",
        "#plt.legend()  # Show legend\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GU2RjW63SNaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dictio = {'a':1, 'b':2, 'c':3}\n",
        "vv = dictio.values()\n",
        "#print(vv)\n",
        "#print(vv[1])\n",
        "\n",
        "x1 = np.array([1, 2, 3])\n",
        "x2 = np.array([3, 2 ,1])\n",
        "v = np.maximum(x1, x2)\n",
        "print(v)\n"
      ],
      "metadata": {
        "id": "UE1NuR4D2h8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "648zfFp8ERD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n, d = 2, 3, 2\n",
        "x_int = np.random.randint(1, 9, (m, n, d))\n",
        "print(x_int)\n",
        "s = np.std(x_int, axis=0)\n",
        "print(s)\n",
        "\n",
        "# manual\n",
        "print(\"manual computation\")\n",
        "x = np.zeros((m, d))\n",
        "for i in range(n):\n",
        "  print(\"i -----> \", i)\n",
        "  x = x_int[:, i, :]\n",
        "  print(\"x\\n\", x)\n",
        "  ss = np.std(x, axis=0)\n",
        "  print(ss)\n",
        "\n",
        "\n",
        "print(\"little exp on squeeze\")\n",
        "sss = np.random.rand(1, 3, 3)\n",
        "print(sss)\n",
        "print(sss.squeeze())\n",
        "print(sss.squeeze())\n",
        "\n"
      ],
      "metadata": {
        "id": "vpBvPibeERnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(34.99)\n",
        "\n",
        "xxxx = np.random.randint(2, 4, (5, 2))\n",
        "print(xxxx)\n",
        "xxxx[0:2, :] = 1\n",
        "print(xxxx)\n",
        "\n",
        "print(\"yyyy\\n\")\n",
        "yy = []\n",
        "yy.append([1, 2, 3])\n",
        "yy.append([4, 5, 6])\n",
        "print(yy)\n",
        "print(np.stack( yy ).T)\n",
        "print(\"\\n\\n\")\n",
        "yyy = np.random.randint(1, 10, size=(3 , 3))\n",
        "print(yyy)\n",
        "yyy_a = np.array([yyy] * 2)\n",
        "print(yyy_a.shape)\n",
        "print(np.concatenate([yyy] * 2))\n",
        "#print(np.tile(yyy_a, (2, 1, 1) ))\n",
        "\n",
        "zzz = np.zeros((2, 2))\n",
        "\n",
        "np.sum(np.zeros((2, 2)) == zzz)"
      ],
      "metadata": {
        "id": "et578OpzERsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def multiple_imputation1(nbr_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 1000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res shape\", res.shape)\n",
        "       #if nbr_mi == 1:\n",
        "        #res = res[0, :, :]\n",
        "        #print(\"fin res shape\", res.shape)\n",
        "    return res\n",
        "\n",
        "\n",
        "Xx = np.random.randint(1, 3, (4, 4)) * 1.0\n",
        "mm = np.random.binomial(1, 0.25, (4, 4))\n",
        "print(Xx)\n",
        "print(mm)\n",
        "Xx[mm == 1] = np.nan\n",
        "print(Xx)\n",
        "\n",
        "ice = IterativeImputer(random_state=18, max_iter=50, sample_posterior=True)\n",
        "ice.fit(Xx)\n",
        "XxX = np.random.randint(1, 3, (2, 4)) * 1.0\n",
        "mmM = np.random.binomial(1, 0.5, (2, 4))\n",
        "print(XxX)\n",
        "print(mmM)\n",
        "XxX[mmM == 1] = np.nan\n",
        "print(XxX)\n",
        "\n",
        "print(ice.transform(XxX))\n",
        "print(ice.transform(XxX))\n",
        "\n",
        "print(\"new\")\n",
        "\n",
        "ls = [[[]],[[]]]\n",
        "print(ls)\n",
        "ls[0][0]\n",
        "\n"
      ],
      "metadata": {
        "id": "_U_r_qaJ9pw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "XX = np.random.randint(1, 7, (2, 3, 3))\n",
        "print(XX)\n",
        "XXX = np.tile(XX, (2, 1, 1))\n",
        "print(XXX)\n",
        "\n",
        "print(np.zeros(2))\n",
        "\n",
        "y_o = np.array([1, 2])\n",
        "y_oo = np.tile(y_o, 3)\n",
        "print(y_oo)\n"
      ],
      "metadata": {
        "id": "PXfceAK8es4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def generate_masks_binomial_general(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "\n",
        "\n",
        "#mm = np.random.binomial(1, [[0.2, 0.2, 0.2], [0.8, 0.8, 0.8]], (2, 3, 3))\n",
        "#print(mm)\n",
        "cc = np.array([np.random.binomial(1, x, (4, 4)) for x in [0.2, 0.2, 0.2]])\n",
        "print(cc)\n",
        "s_cc = np.cumsum(cc, axis=0)\n",
        "print(s_cc)\n",
        "s_cc[s_cc>1] = 1\n",
        "print(s_cc)\n",
        "\n",
        "s_v = np.random.randint(1, 4, (3, 4))\n",
        "print(s_v)\n",
        "s_vv = s_v[:, None, :] * np.eye(4)\n",
        "print(s_vv)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "auugsvFPZ88A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import ridge_regression\n",
        "\n",
        "X = np.random.randn(100, 4) #rng.randn(100, 4)\n",
        "\n",
        "y = 2.0 * X[:, 0] - 1.0 * X[:, 1] + 0.1 * np.random.randn(100)\n",
        "np.random.seed(4)\n",
        "alphas = [0.00001, 0.001, 0.1, 1]\n",
        "estim = lambda XX, yy, rad: ridge_regression(XX, yy, alpha=rad, return_intercept=False, random_state=0)\n",
        "for a in alphas:\n",
        "  #coef, intercept = estim(X, y, a)\n",
        "  coef = estim(X, y, a)\n",
        "  print(\"coef : \", coef)\n",
        "  #print(\"intercpt \", intercept)\n",
        "  coef, intercept = ridge_regression(X, y, alpha=a, return_intercept=True, random_state=0)\n",
        "  #print(\"coef : \", coef)\n",
        "  #print(\"intercpt \", intercept)\n",
        "\n",
        "\n",
        "lg = np.random.logistic(loc=0.0, scale=1.0, size=(4, 3))\n",
        "print(\"log res \", lg)\n",
        "\n"
      ],
      "metadata": {
        "id": "t3KaZyJKwnRz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}