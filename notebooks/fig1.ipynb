{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea987/advtrain-linreg/blob/main/notebooks/fig1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install miceforest"
      ],
      "metadata": {
        "id": "6Sgo-CifolM3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install gcimpute"
      ],
      "metadata": {
        "id": "5dNp2M8GkRLB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ahPyLc7tfNVL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQ9K3f57kWSG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_NXEAOWmC8d"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ggDSA-ktpXgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c98f61-6afb-40d1-e8fd-94b81ac2ade4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CLARABEL', 'CVXOPT', 'GLPK', 'GLPK_MI', 'HIGHS', 'OSQP', 'SCIPY', 'SCS']\n",
            "coef :  [ 2.00859818e+00 -9.93414896e-01  2.26469644e-03  1.80957127e-03]\n",
            "intercpt  -0.005990821168185856\n",
            "coef :  [ 2.00859818e+00 -9.93414896e-01  2.26469644e-03  1.80957127e-03]\n",
            "intercpt  -0.005990821168185856\n",
            "coef :  [ 2.00857724e+00 -9.93402772e-01  2.27018282e-03  1.80985449e-03]\n",
            "intercpt  -0.005990333886965181\n",
            "coef :  [ 2.00857724e+00 -9.93402772e-01  2.27018282e-03  1.80985449e-03]\n",
            "intercpt  -0.005990333886965181\n",
            "coef :  [ 2.00648574e+00 -9.92192070e-01  2.81773059e-03  1.83799362e-03]\n",
            "intercpt  -0.005941677516374973\n",
            "coef :  [ 2.00648574e+00 -9.92192070e-01  2.81773059e-03  1.83799362e-03]\n",
            "intercpt  -0.005941677516374973\n",
            "coef :  [ 1.98767643 -0.98133262  0.00769714  0.00207904]\n",
            "intercpt  -0.005505159788923517\n",
            "coef :  [ 1.98767643 -0.98133262  0.00769714  0.00207904]\n",
            "intercpt  -0.005505159788923517\n",
            "end block\n"
          ]
        }
      ],
      "source": [
        "from re import VERBOSE\n",
        "from itertools import cycle\n",
        "import miceforest as mf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from sklearn.linear_model import lasso_path\n",
        "from sklearn import datasets\n",
        "from sklearn import linear_model\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import ridge_regression\n",
        "import tqdm\n",
        "import cvxpy as cp\n",
        "print(cp.installed_solvers())\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "import traceback\n",
        "\n",
        "\n",
        "def compute_q(p):\n",
        "    if p != np.inf and p > 1:\n",
        "        q = p / (p - 1)\n",
        "    elif p == 1:\n",
        "        q = np.inf\n",
        "    else:\n",
        "        q = 1\n",
        "    return q\n",
        "\n",
        "\n",
        "class AdversarialTraining:\n",
        "    def __init__(self, X, y, S_dict, p):  # S is the matrix such that ||S^(-1) @ Dx||\\leq delta. As a consequence, S appears in the unconstrained problem\n",
        "        # S: (d, d) matrix, or S = np.concatenate(tS), with tS = [S1,..,S_m], so S is (d * n, d)\n",
        "        n, d = X.shape\n",
        "        q = compute_q(p)\n",
        "\n",
        "        #print(\"who is X\", X)\n",
        "        #print(\"who is y\", y)\n",
        "        #print(\"who is S\", S)\n",
        "        #print(\"who is q in AdversarialTraining: \", q)\n",
        "        #Formulate problem\n",
        "        param = cp.Variable(d)\n",
        "        #print(\"shape param \", param.shape)\n",
        "        #print(\"dim \", n)\n",
        "        print(\"X \", n,\" \", d)\n",
        "        print(\"y shape\", y.shape)\n",
        "        #print(\"S_dict \", S_dict)\n",
        "        #print(\"S in adv training\", S)\n",
        "        print(\"nm \", d*n)\n",
        "        S_dts = S_dict['S_dts']\n",
        "        S_mis = S_dict['S_mis']\n",
        "        adv_radius_times_scale_dts = cp.Parameter(name='adv_radius_times_dts', nonneg=True)\n",
        "        adv_radius_times_scale_mis = cp.Parameter(name='adv_radius_times_mis', nonneg=True)\n",
        "        #scale_dts = cp.Parameter(name='scale_dts', nonneg=True)\n",
        "        #scale_mis = cp.Parameter(name='scale_mis', nonneg=True)\n",
        "        print(\"S_mis in Adbvt training \", S_mis)\n",
        "        #if np.sum(S_mis * S_mis) == 0:\n",
        "        if np.all(S_dict['S_mis'] == 0):\n",
        "          print(\"no missing part\")\n",
        "          S = S_dts * adv_radius_times_scale_dts\n",
        "        else:  # S_mis.shape == (n, d, d):\n",
        "          S_dts_tiled = np.concatenate([S_dts] * n)\n",
        "          S_mis_conc = np.concatenate(S_mis)\n",
        "          #np.concatenate([yyy] * 2)\n",
        "          S = S_dts_tiled * adv_radius_times_scale_dts + S_mis_conc * adv_radius_times_scale_mis\n",
        "          print(\"S type \", type(S))\n",
        "          #S = np.concatenate(S)\n",
        "          print(\"S is a tensor, concatenated\")\n",
        "          print(\"final S after conc \\n\", S)\n",
        "\n",
        "        if S.shape == (d, d):\n",
        "          print(\"one matrix in input, S.shape = (n, n)\")\n",
        "          partial = S @ param  # should be (m * n,)\n",
        "          param_norm = cp.pnorm(partial, p=q)\n",
        "        elif S.shape == (d * n, d):  # should be a stack of matrices\n",
        "          print(\"multiple matrices in input, S conc\")\n",
        "          partial = S @ param  # should be (m * n,)\n",
        "          partial = cp.reshape(partial, (n, d), order='C')\n",
        "          param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        else:\n",
        "          print(\"--------> ERROR: NO MATRIX S FOUND IN ADVERSARIAL TRAINING\")\n",
        "        #elif S.shape == (m , n):  # stack of diagonal matrices\n",
        "        #  print(\"multiple matrices in input, S_i diag\")\n",
        "          #S_cvx = cp.Constant(S)\n",
        "        #  partial = cp.multiply(cp.Parameter(S), param)\n",
        "        #  param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        abs_error = cp.abs(X @ param - y)\n",
        "        adv_loss = 1 / n * cp.sum((abs_error + param_norm) ** 2)\n",
        "        prob = cp.Problem(cp.Minimize(adv_loss))\n",
        "        self.prob = prob\n",
        "        self.adv_radius_times_scale_dts = adv_radius_times_scale_dts\n",
        "        self.adv_radius_times_scale_mis = adv_radius_times_scale_mis\n",
        "        #self.scale_dts = scale_dts\n",
        "        #self.scale_mis = scale_mis\n",
        "        self.param = param\n",
        "        self.warm_start = False\n",
        "\n",
        "\n",
        "    def __call__(self, dict_hyper_p, **kwargs):\n",
        "        try:\n",
        "            #print(\"dic thyper p \", dict_hyper_p)\n",
        "            self.adv_radius_times_scale_dts.value = dict_hyper_p['adv_radius_times_dts']\n",
        "            self.adv_radius_times_scale_mis.value = dict_hyper_p['adv_radius_times_mis']\n",
        "            #self.scale_dts.value = dict_hyper_p['scale_dts\n",
        "            #self.scale_mis.value = dict_hyper_p['scale_mis']\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "\n",
        "'''\n",
        "    def __call__(self, adv_radius, **kwargs):\n",
        "        try:\n",
        "            self.adv_radius.value = adv_radius\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "'''\n",
        "\n",
        "\n",
        "def get_lasso_path(X, y, eps_lasso=1e-5):\n",
        "    alphas, coefs, _ = lasso_path(X, y, eps=eps_lasso)\n",
        "    coefs= np.concatenate([np.zeros([X.shape[1], 1]), coefs], axis=1)\n",
        "    alphas = np.concatenate([1e2 * np.ones([1]), alphas], axis=0)\n",
        "    return alphas, coefs, []\n",
        "\n",
        "# dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4 'eps_adv_rad_times_delta_dts': 1e-4}}\n",
        "def get_path(X, y, estimator, S_dict): #eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "    _, m = X.shape\n",
        "\n",
        "    if S_dict['algo_superv_learn'] == 'adv':\n",
        "      #n_a_dts = S_dict['n_a_dts']\n",
        "      #a_d_dts_max = S_dict['adv_rad_times_delta_dts_max']\n",
        "      #a_d_dts_min = a_d_dts_max * S_dict['eps_adv_rad_times_delta_dts']\n",
        "\n",
        "      if np.all(S_dict['S_dts'] == 0):\n",
        "        n_a_dts, a_d_dts_max, a_d_dts_min = 1, 0, 0\n",
        "      else:\n",
        "        n_a_dts = S_dict['n_a_dts']\n",
        "        a_d_dts_max = S_dict['adv_rad_times_delta_dts_max']\n",
        "        a_d_dts_min = a_d_dts_max * S_dict['eps_adv_rad_times_delta_dts']\n",
        "\n",
        "      if np.all(S_dict['S_mis'] == 0):\n",
        "        n_a_mis, a_d_mis_max, a_d_mis_min = 1, 0, 0\n",
        "      else:\n",
        "        n_a_mis = S_dict['n_a_mis']\n",
        "        a_d_mis_max = S_dict['adv_rad_times_delta_mis_max']\n",
        "        a_d_mis_min = a_d_mis_max * S_dict['eps_adv_rad_times_delta_mis']\n",
        "\n",
        "\n",
        "      if a_d_dts_max < 0 or a_d_mis_max < 0 or n_a_dts < 1 or n_a_mis <1:\n",
        "        print(\"WARNING: some bad values for the grid of cross validation, the number of grid point should be strictly potive, the radius strictly positive\")\n",
        "      alphas_dts = np.logspace(np.log10(a_d_dts_min), np.log10(a_d_dts_max), n_a_dts) if a_d_dts_max > 0 else np.zeros(1)\n",
        "      alphas_mis = np.logspace(np.log10(a_d_mis_min), np.log10(a_d_mis_max), n_a_mis) if a_d_mis_max > 0 else np.zeros(1)\n",
        "      #alphas_dts = np.logspace(np.log10(a_d_dts_min), np.log10(a_d_dts_max), n_a_dts)\n",
        "      #alphas_mis = np.logspace(np.log10(a_d_mis_min), np.log10(a_d_mis_max), n_a_mis)\n",
        "      print(\"dts deltas \", alphas_dts)\n",
        "      print(\"mis deltas \", alphas_mis)\n",
        "      #hyper_p = {'scale_dts': dts_deltas, 'scale_mis': mis_deltas}\n",
        "      hyper_p_ret_ = []\n",
        "      coefs_ = []\n",
        "      for a_mis_value in tqdm.tqdm(alphas_mis):\n",
        "        for a_dts_value in tqdm.tqdm(alphas_dts):\n",
        "            #tuple_key = (scale_dts_value, scale_mis_value)\n",
        "            #coefs_ = []\n",
        "            #for a in tqdm.tqdm(alphas):\n",
        "              #dict_hyper_p_values = {'adv_radius': a, 'scale_dts': scale_dts_value, 'scale_mis': scale_mis_value}\n",
        "              dict_hyper_p_values = {'adv_radius_times_dts': a_dts_value, 'adv_radius_times_mis': a_mis_value}\n",
        "              #print(\"dict hyper in get path \", dict_hyper_p_values)\n",
        "              coefs = estimator(X, y, dict_hyper_p_values)\n",
        "              #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "              coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "              hyper_p_ret_.append([a_dts_value, a_mis_value])\n",
        "            #res[tuple_key] = np.stack((coefs_)).T\n",
        "    elif S_dict['algo_superv_learn'] == 'ridge':\n",
        "      n_a_rid = S_dict['n_a_rid']\n",
        "      a_rid_max = S_dict['alpha_ridge_reg_max']\n",
        "      a_rid_min = a_rid_max * S_dict['eps_alpha_ridge_reg']\n",
        "      alphas_rid = np.logspace(np.log10(a_rid_min), np.log10(a_rid_max), n_a_rid) if a_rid_max > 0 else np.zeros(1)\n",
        "      print(\"rid alphas \", alphas_rid)\n",
        "      hyper_p_ret_ = []\n",
        "      coefs_ = []\n",
        "      print(\"S_dts_inv in get path, ridge regression \\n\", S_dict['S_dts'])\n",
        "      S_dts_inv = np.linalg.inv(S_dict['S_dts'])  # (d, d)\n",
        "      print(\"S_dts_inv in get path, ridge regression \\n\", S_dts_inv)\n",
        "      for a_rid in tqdm.tqdm(alphas_rid):\n",
        "            #dict_hyper_p_values = {'adv_radius_times_dts': a_dts_value, 'adv_radius_times_mis': a_mis_value}\n",
        "            #print(\"dict hyper in get path \", dict_hyper_p_values)\n",
        "            coefs = estimator(X @ S_dts_inv, y, a_rid)\n",
        "            coefs = S_dts_inv @ coefs\n",
        "            print(\"alpha  \", a_rid, \"coef_ridge: \", coefs)\n",
        "            coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "            hyper_p_ret_.append([a_rid, 0])  #([a_dts_value, a_mis_value])\n",
        "\n",
        "\n",
        "    '''\n",
        "    for scale_dts_value in tqdm.tqdm(dts_deltas):\n",
        "        for scale_mis_value in tqdm.tqdm(mis_deltas):\n",
        "          #tuple_key = (scale_dts_value, scale_mis_value)\n",
        "          #coefs_ = []\n",
        "          for a in tqdm.tqdm(alphas):\n",
        "              #dict_hyper_p_values = {'adv_radius': a, 'scale_dts': scale_dts_value, 'scale_mis': scale_mis_value}\n",
        "              dict_hyper_p_values = {'adv_radius_times_scale_dts': a * scale_dts_value, 'adv_radius_times_scale_mis': a * scale_mis_value}\n",
        "              coefs = estimator(X, y, dict_hyper_p_values)\n",
        "              #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "              coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "              hyper_p_ret_.append([a, scale_dts_value, scale_mis_value])\n",
        "          #res[tuple_key] = np.stack((coefs_)).T\n",
        "    '''\n",
        "    return np.stack((hyper_p_ret_)).T, np.stack((coefs_)).T\n",
        "\n",
        "#dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg': 1,\n",
        "#                             'eps_adv_rad_times_delta_dts': 1e-4, 'eps_adv_rad_times_delta_mis': 1e-4, 'eps_alpha_ridge_reg': 1e-4,\n",
        "#                             'n_a_dts': 25, 'n_a_mis':4, 'n_a_rid': 25}}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "def get_path(X, y, estimator, amax, eps=1e-5, n_alphas=200):\n",
        "    _, m = X.shape\n",
        "    amin = eps * amax\n",
        "    alphas = np.logspace(np.log10(amin), np.log10(amax), n_alphas)\n",
        "    coefs_ = []\n",
        "    for a in tqdm.tqdm(alphas):\n",
        "        coefs = estimator(X, y, a)\n",
        "        #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "        coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "    return alphas, np.stack((coefs_)).T\n",
        "'''\n",
        "\n",
        "\n",
        "def plot_coefs(alphas, coefs, ax):\n",
        "    #print(\"you are printing coefs in function of 1/alphas\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).sum(axis=0)\n",
        "    ax.set_xlabel(\"1/alphas\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.semilogx(1/alphas, coef_l, c=c)\n",
        "        #ax.semilogx(1/alphas, l1norm, c=c)\n",
        "        #ax.plot(1/alphas, coef_l, c=c)\n",
        "\n",
        "\n",
        "def plot_coefs_l1norm(coefs, ax):\n",
        "    #print(\"you are printing coeff in function of l1 norm\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).mean(axis=0)\n",
        "    l1norm = np.abs(coefs).sum(axis=0)\n",
        "    #print(\"coef \", coefs)\n",
        "    #print(\"l1norm \", l1norm)\n",
        "    ax.set_xlabel(\"l1norm\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "\n",
        "\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.plot(l1norm, coef_l, c=c)\n",
        "\n",
        "\n",
        "def train_and_plot(X, y, S_dict, list_ax):\n",
        "\n",
        "    if S_dict['algo_superv_learn'] == 'adv':\n",
        "      linfadvtrain = AdversarialTraining(X, y, S_dict, p=np.inf)\n",
        "      estimator = lambda X, y, dic_h:  linfadvtrain(dict_hyper_p=dic_h)\n",
        "      hyper_p, coefs_advtrain_linf  = get_path(X, y, estimator, S_dict)\n",
        "    elif S_dict['algo_superv_learn'] == 'ridge':\n",
        "      estimator = lambda XX, yy, rad: ridge_regression(XX, yy, alpha=rad, return_intercept=False)#, random_state=0)\n",
        "      hyper_p, coefs_advtrain_linf  = get_path(X, y, estimator, S_dict)\n",
        "      #estimator = lambda X, y, a: linear_model.Ridge(alpha=a).fit(X, y).coef_\n",
        "    #print(\"hyper_p used\\n \", hyper_p)\n",
        "    if len(list_ax) > 0:\n",
        "      plot_coefs_l1norm(coefs_advtrain_linf, list_ax[0])\n",
        "      plot_coefs(alphas_adv, coefs_advtrain_linf, list_ax[1])\n",
        "    return hyper_p, coefs_advtrain_linf\n",
        "\n",
        "\n",
        "X = np.random.randn(100, 4) #rng.randn(100, 4)\n",
        "\n",
        "y = 2.0 * X[:, 0] - 1.0 * X[:, 1] + 0.1 * np.random.randn(100)\n",
        "\n",
        "alphas = [0.00001, 0.001, 0.1, 1]\n",
        "estim = lambda XX, yy, rad: ridge_regression(XX, yy, alpha=rad, return_intercept=True, random_state=0)\n",
        "for a in alphas:\n",
        "  coef, intercept = estim(X, y, a)\n",
        "  print(\"coef : \", coef)\n",
        "  print(\"intercpt \", intercept)\n",
        "  coef, intercept = ridge_regression(X, y, alpha=a, return_intercept=True, random_state=0)\n",
        "  print(\"coef : \", coef)\n",
        "  print(\"intercpt \", intercept)\n",
        "\n",
        "\n",
        "'''\n",
        "def add_rectangles_old(x, y, box_width, box_height, ax):\n",
        "  r_c = (np.random.binomial(1, 1, size=x.size) == 1)  # 1 taken, 0 not taken\n",
        "  #print(r_c)\n",
        "\n",
        "  for xi, yi in zip(x[r_c], y[r_c]):\n",
        "      rect = patches.Rectangle(\n",
        "        (xi-box_width/2, yi-box_height/2),\n",
        "        box_width, box_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "      )\n",
        "      ax.add_patch(rect)\n",
        "'''\n",
        "\n",
        "def add_rectangles(x, y, S, ax):\n",
        "  r_c = (np.random.binomial(1, 1, size=x.size) == 1)  # 1 taken, 0 not taken\n",
        "  #print(r_c)\n",
        "  d = S.shape[-1]\n",
        "  #S = S * 100\n",
        "  if S.ndim == 2 or S.shape == (1, d, d):\n",
        "    S = S.squeeze()\n",
        "    print(\"------------------------> who is S in add_rectangles\\n\", S)\n",
        "    box_width = S[0, 0]\n",
        "    box_height = S[1, 1]\n",
        "    for xi, yi in zip(x[r_c], y[r_c]):\n",
        "        rect = patches.Rectangle(\n",
        "          (xi-box_width/2, yi-box_height/2),\n",
        "          box_width, box_height,\n",
        "          linewidth=1, edgecolor='r', facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "  else:  # S is something like (n, d, d)\n",
        "    #print(\"---------------> who is S in add_rectangles (mult imp)\\n\", S)\n",
        "    box_width = S[:, 0, 0]\n",
        "    box_height = S[:, 1, 1]\n",
        "    #print(\"bw\\n \", box_width)\n",
        "    #print(\"bh\\n \", box_height)\n",
        "    #print(\"------------------------------> boxes printed\")\n",
        "    for xi, yi, bw, bh in zip(x[r_c], y[r_c], box_width[r_c], box_height[r_c]):\n",
        "        #print(\"bw, bh \", bw, \",   \", bh)\n",
        "        rect = patches.Rectangle(\n",
        "          (xi-bw/2, yi-bh/2),\n",
        "          bw, bh, linewidth=1, edgecolor='r', facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "\n",
        "\n",
        "print(\"end block\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yy = np.random.randint(low=1, high=10, size=(3, 2))\n",
        "print(yy)\n",
        "\n",
        "yyy = np.array([yy] * 3)\n",
        "print(yyy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ3P4s7I9DTz",
        "outputId": "d0b4cfd6-4ad4-466a-da7a-83504d61c87f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5 8]\n",
            " [6 8]\n",
            " [1 8]]\n",
            "[[[5 8]\n",
            "  [6 8]\n",
            "  [1 8]]\n",
            "\n",
            " [[5 8]\n",
            "  [6 8]\n",
            "  [1 8]]\n",
            "\n",
            " [[5 8]\n",
            "  [6 8]\n",
            "  [1 8]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation's block\n",
        "\n",
        "def clear_dataset(X, y, masks):\n",
        "  # remove observations full NaN\n",
        "  # X is an (n, d) matrix, y is a (n,) vector,\n",
        "  # masks is an (n, d) binary matrix associated to X. 1 missing, 0 seen\n",
        "  M = np.sum(1 - masks, axis=1) > 0\n",
        "  print(\"X shape in clear data \", X.shape)\n",
        "  print(\"y shape in clear data \", y.shape)\n",
        "  print(\"M shape in clear data \", M.shape)\n",
        "  M_col = np.sum(1 - masks, axis=0) > 0  # True if in the column there is at least one seen component\n",
        "  if np.sum(M_col) < masks.shape[1]:\n",
        "    print(\"Careful, there is one column full of nan\")\n",
        "  return X[M, :][:, M_col], y[M], masks[M, :][:, M_col]\n",
        "\n",
        "\n",
        "def single_imputation(X_nan, impute_estimator):\n",
        "    ice = IterativeImputer(estimator=impute_estimator)\n",
        "    return ice.fit_transform(X_nan)\n",
        "\n",
        "\n",
        "def multiple_imputation(info_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    print(\"info mi\", info_mi)\n",
        "    nbr_mi = info_mi['mi_nbr']\n",
        "    nbr_feature = info_mi['nbr_feature']\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 100000)\n",
        "       print(\"nbr features \", nbr_feature)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True, n_nearest_features=nbr_feature)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res shape\", res.shape)\n",
        "       #if nbr_mi == 1:\n",
        "        #res = res[0, :, :]\n",
        "        #print(\"fin res shape\", res.shape)\n",
        "    return res\n",
        "\n",
        "def miceforest_imputation(info_mf, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    nbr_mi = info_mf['mi_nbr']\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    if np.isnan(X_nan).sum() == 0:  # no missing component\n",
        "      print(\"CAREFUL::: no missing component, so no multiple imputation\")\n",
        "      res = [X_nan] * nbr_mi\n",
        "    else:\n",
        "      x = pd.DataFrame(X_nan)\n",
        "      x.columns = x.columns.astype(str)\n",
        "      # Create kernel.\n",
        "      kernel = mf.ImputationKernel(\n",
        "      x,\n",
        "      num_datasets=nbr_mi,\n",
        "      #random_state=1,\n",
        "      mean_match_candidates=info_mf['nbr_candidates_mm']\n",
        "      )\n",
        "      # Run the MICE algorithm for 2 iterations on each of the datasets\n",
        "      %time kernel.mice(2)\n",
        "      for i in range(nbr_mi):\n",
        "        res[i, :, :] = kernel.complete_data(dataset=i)\n",
        "    return res\n",
        "\n",
        "\n",
        "'''\n",
        "x = pd.DataFrame(x)\n",
        "x.columns = x.columns.astype(str)\n",
        "m = np.random.binomial(1, 0.3, size=(n, d))\n",
        "mm = (m==1)\n",
        "x[mm] = np.nan\n",
        "print(mm)\n",
        "print(x)\n",
        "\n",
        "\n",
        "# Create kernel.\n",
        "kernel = mf.ImputationKernel(\n",
        "  x,\n",
        "  num_datasets=4,\n",
        "  random_state=1,\n",
        "  mean_match_candidates=0\n",
        ")\n",
        "\n",
        "# Run the MICE algorithm for 2 iterations on each of the datasets\n",
        "\n",
        "%time kernel.mice(3)\n",
        "\n",
        "\n",
        "cd1 = kernel.complete_data(dataset=1)\n",
        "cd2 = kernel.complete_data(dataset=2)\n",
        "print(\"cd1\\n\", cd1, \"\\ncd2\\n\", cd2)\n",
        "\n",
        "# Printing the kernel will show you some high level information.\n",
        "print(kernel)\n",
        "\n",
        "print()\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def imputation_elliptic(mu, sigma, x, masks):\n",
        "  # mu, mean elliptical distribution (,d)\n",
        "  # sigma, cov matrix elliptical distribution (d, d)\n",
        "  # x: dataset (n, d)\n",
        "  # masks: mask data, 0 seen, 1 missing\n",
        "  n, d = x.shape\n",
        "  print(n, d)\n",
        "  x_imp = x.copy()\n",
        "  #print(\"x_imp clean\", x_imp)\n",
        "  for i in range(n):\n",
        "    if not (masks[i, :] == 0).all():  # if we have at least one missing component\n",
        "      #print(\"nbr : \", i)\n",
        "      x_c = x[i, :]\n",
        "      m_bool = (masks[i, :] == 0)  # True seen, False missing\n",
        "      sigma_aa_inv = np.linalg.inv(sigma[m_bool, :][:, m_bool])\n",
        "      sigma_ma = sigma[~m_bool, :][:, m_bool]\n",
        "      mu_cond = mu[~m_bool] + sigma_ma @ sigma_aa_inv @ (x_c[m_bool] - mu[m_bool])\n",
        "      x_imp[i, ~m_bool] = mu_cond\n",
        "  return x_imp\n",
        "\n",
        "\n",
        "def listwise_delection(X, masks):\n",
        "  # masks: 1 missing, 0 seen\n",
        "    M = np.sum(masks, axis=1) == 0  # zeros components are the one with full entries\n",
        "    ret = X[M, :] if X.ndim == 2 else X[M]\n",
        "    return ret\n"
      ],
      "metadata": {
        "id": "qyWskXpdOW9e"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ElCvHxBiO_2t"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZA7J67yAuQM8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(42)\n",
        "\n",
        "#p_miss_2d = [0.2, 0.4, 0.4]\n",
        "#beta_2d = np.array([0.5, 2])  # ground truth\n",
        "\n",
        "from sklearn.datasets import make_moons, make_circles\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import train_test_split\n",
        "'''\n",
        "def generate_masks_2d(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "'''\n",
        "\n",
        "def generate_masks(dictio_data):#nbr_of_sample, dim, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    dim = len(dictio_data['beta_gt'][0])\n",
        "    nbr_of_sample = dictio_data['n_train'][-1]  # last one should be the biggest one\n",
        "    p_missing = dictio_data['p_miss'][0]\n",
        "    print(\"p_missing in generate mask \", p_missing)\n",
        "    if dim == 2:\n",
        "      if len(p_missing) < 3:\n",
        "        print(\"WARNING: p_missing should be a list with a length of 3 if the dimension is 2\")\n",
        "      masks = np.zeros((nbr_of_sample, 2))\n",
        "      v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "      masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "      masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "      masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    else:\n",
        "      # in this branch, p_missing = [p1,.., pl],\n",
        "      masks = np.array([np.random.binomial(1, 1-pr, (nbr_of_sample, dim)) for pr in p_missing])\n",
        "      masks = np.cumsum(masks, axis=0)  # each round\n",
        "      masks[masks>1] = 1\n",
        "    return masks\n",
        "\n",
        "def best_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  r = hat_y - y  # residual\n",
        "  score = np.mean(r * r, axis=1)\n",
        "  print(\"scores:  \", score)\n",
        "  i_min = np.argmin(score)\n",
        "  return coeff[:, i_min], score[i_min]\n",
        "\n",
        "def best_idx_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  r = hat_y - y  # residual\n",
        "  #score = np.mean(r * r, axis=1)\n",
        "  score = np.mean(r * r, axis=1)\n",
        "  #print(\"score in best idx\", score)\n",
        "  i_min = np.argmin(score)\n",
        "  #### find the minimum value with a threshold, so we get bigger uncertainty set that are visible\n",
        "  min = np.min(score)\n",
        "  max = np.max(score)\n",
        "  score[ score < min + -1 ] = max\n",
        "  ####\n",
        "  #print(\"score after \", score)\n",
        "  i_min = np.argmin(score)\n",
        "  return i_min, score[i_min]\n",
        "\n",
        "\n",
        "\n",
        "def generate_X(data, dim):\n",
        "    if data == 'Gaussian':\n",
        "      def generator(n):\n",
        "        return np.random.randn(n, dim)\n",
        "    elif data == 'Uniform':\n",
        "      def generator(n):\n",
        "        return np.random.rand(n, dim)\n",
        "    elif data == 'moons':\n",
        "      def generator(n):\n",
        "        return make_moons(n, noise=0.1)[0]\n",
        "    elif data == 'circles':\n",
        "      def generator(n):\n",
        "        return make_circles(n, noise=0.1, factor=0.4)[0]\n",
        "    return generator\n"
      ],
      "metadata": {
        "id": "AN61ok0A_Mbv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jB0J9uh-dJBp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwSkM31ztfUZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment 2d with dataset generated externally\n",
        "\n",
        "def imputations(info, dict_obs_for_imp):  # X_nan, y):\n",
        "  # info contains the method and possible extra information\n",
        "  # X_nan is the dataset with nan in place of the missing components\n",
        "  # y is return as it is, unless the method require to change it, like in\n",
        "  # listwise deletion\n",
        "    #print(info)\n",
        "    X_nan = dict_obs_for_imp['X_nan']\n",
        "    y = dict_obs_for_imp['y_train']\n",
        "    mask_from_X_nan = np.isnan(X_nan).astype(int)\n",
        "    if info['imp_method'] == 'BR_si':  # Baeysian_Ridge_single_imputation\n",
        "        X = single_imputation(X_nan, BayesianRidge())\n",
        "    elif info['imp_method'] in  ['mi', 'mi_pure']:\n",
        "        print(\"info in imputations \", info)\n",
        "        X = multiple_imputation(info, X_nan)  # size (info['mi_nbr], n, d)\n",
        "    elif info['imp_method'] == 'mf_imp':\n",
        "        X = miceforest_imputation(info, X_nan)\n",
        "    elif info['imp_method'] == 'l_d':  # listwise_deletion\n",
        "        #mask_from_X_nan = np.isnan(X_nan).astype(int)\n",
        "        X = listwise_delection(X_nan, mask_from_X_nan)\n",
        "        y = listwise_delection(y, mask_from_X_nan)\n",
        "        if len(X) == 0:  # no elements left, add an artificial element\n",
        "            X = np.zeros((1, X_nan.shape[-1]))\n",
        "            y = np.zeros(1)\n",
        "        mask_from_X_nan = np.zeros_like(X)\n",
        "    elif info['imp_method'] == 'oracle':\n",
        "        X = dict_obs_for_imp['X_train_masked'][0]\n",
        "        mask_from_X_nan = np.zeros_like(X)\n",
        "    else:\n",
        "      print(\"-------------------> ERROR: WRONG KEYWORD (in imputations)\")\n",
        "    return X, y, mask_from_X_nan\n",
        "\n",
        "\n",
        "def cov_strategy(info, dict_observations):\n",
        "    # uncertainty coming from considering the imputed values as true values (within uncertanty)\n",
        "    X_imputed = dict_observations['X_imputed']\n",
        "    X_nan = dict_observations['X_nan']\n",
        "    masks = dict_observations['masks_after_imputation']\n",
        "    print(np.sum(masks, axis=-1))\n",
        "    if info['cov_strategy'] == 'sd':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      #print(\"sd in cov strategy \", sd)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(sd)\n",
        "    elif info['cov_strategy'] == 'inv_sd':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(1 / sd)\n",
        "    elif info['cov_strategy'] == 'zero':\n",
        "      #sd = np.std(X_imputed, axis=0)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.zeros((X_imputed.shape[-1], X_imputed.shape[-1]))\n",
        "    elif info['cov_strategy'] == 'eye':\n",
        "      S = np.eye(X_imputed.shape[-1])\n",
        "    elif info['cov_strategy'] == 'threshold':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      sd[sd < info['threshold']] = info['threshold']\n",
        "      #S = np.diag(sd) The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(sd)\n",
        "    elif info['cov_strategy'] == 'std_nan':\n",
        "      if info['imp_method'] in ['oracle']:\n",
        "        print(\"DON'T USE std_nan with oracle and ld because you do not have any nan. Use sd\")\n",
        "      else:\n",
        "        std_columnwise = np.nanstd(X_nan, axis=0)\n",
        "        S = np.diag(std_columnwise)\n",
        "    elif info['imp_method'] in ['mi_pure', 'mi', 'mf_imp']:\n",
        "      if info['cov_strategy'] == 'std_mi':   # std (standard_dev) of the imputed dataset, then the mean\n",
        "        std_vectors = np.std(X_imputed, axis=-2)  # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        #s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        S = std_vectors[:, None, :] * np.eye(std_vectors.shape[-1])  # should be (m, d, d), with each diagonal the diagonals of std_vectors\n",
        "        #S = s_within\n",
        "        #S = np.diag(s_within)\n",
        "        print(\"final S.shape in cov strategy std_mi \", S.shape)\n",
        "      elif info['cov_strategy'] == 'RR':\n",
        "        #if info['mi_nbr'] == 1:\n",
        "        #  X_imputed = np.array([X_imputed])\n",
        "        # X shape = (m, n, d)\n",
        "        std_vectors = np.std(X_imputed, axis=-2)  # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        print(\"s_within \", s_within)\n",
        "        print(\"cov computed\")\n",
        "        #print(s_mean)\n",
        "        s_between = np.std(std_vectors, axis=0) # between imputation variance  # shape: d. That's already scaled because we are computing the std\n",
        "        print(\"s_between \", s_between)\n",
        "        S = np.diag(s_within + s_between * (1 + 1 / info['mi_nbr']))\n",
        "        print(\"final S in cov strategy RR \", S)\n",
        "        #mu = np.mean(X_imputed, axis=0)\n",
        "        #sigma = np.cov(X_imputed, rowvar=False)\n",
        "      elif info['cov_strategy'] == 'RR_scaled (to check)':\n",
        "        print(\"Rub Rule right scaled\")\n",
        "        #if info['mi_nbr'] == 1:\n",
        "        #  X_imputed = np.array([X_imputed])\n",
        "        # X shape = (m, n, d)\n",
        "        std_vectors = np.std(X_imputed, axis=-2) # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        print(\"s_within \", s_within)\n",
        "        print(\"cov computed\")\n",
        "        #print(s_mean)\n",
        "        s_between = np.std(std_vectors, axis=0) # between imputation variance  # shape: d\n",
        "        #s_between = np.sqrt(s_between)\n",
        "        print(\"s_between \", s_between)\n",
        "        S = np.diag(s_within + s_between * (1 + 1 / info['mi_nbr']))\n",
        "        #S = np.sqrt(S)\n",
        "        print(\"final S in cov strategy RR \", S)\n",
        "      #elif info['cov_strategy'] == 'cond_var':\n",
        "        # we have imputed [X1,..,X_m]\n",
        "        #s = np.std(X_imputed, axis=0)\n",
        "        #print(\"s\\n \", s)\n",
        "        #eye = np.array([np.eye(X_imputed.shape[-1])] * X_imputed.shape[-2])\n",
        "        #S = eye * s[:, None, :]\n",
        "        #S = np.concatenate(S, axis=0)\n",
        "        #print(\"S in cond variance \", S)\n",
        "    elif info['cov_strategy'] == 'lounici':\n",
        "      mu = np.nanmean(X_nan, axis=0)\n",
        "      print(\"means \", mu)\n",
        "      delta = 1 - np.mean(masks) # parameter missingness\n",
        "      print(\"delta \", delta)\n",
        "      X_0 = np.nan_to_num(X_nan - mu)  # check if this is correct\n",
        "      print(\"nbr obs\", X_0.shape[0])\n",
        "      S =  X_0.T @ X_0 / X_0.shape[0]\n",
        "      S = (1/delta - 1/(delta**2)) * np.diag(np.diag(S)) + 1/(delta**2) * S\n",
        "    else:\n",
        "      raise ValueError(\"-------------> ERROR: NO COVARIANCE METHOD HAS BEEN CHOSEN\")\n",
        "      #print(\"-------------> ERROR: NO COVARIANCE METHOD HAS BEEN CHOSEN\")\n",
        "      #S = np.diag(S)\n",
        "      #mu = np.mean(X_imputed, axis=0)\n",
        "      #sigma = np.cov(X_imputed, rowvar=False)\n",
        "    return S\n",
        "\n",
        "\n",
        "def cov_strategy_missing(info, dict_observations):\n",
        "    # uncertainty coming from sampling multiple values to get multiple datasets. It is zero for single imputation\n",
        "    X_imputed = dict_observations['X_imputed']\n",
        "    if info['imp_method'] in ['mi', 'mi_pure'] and 'cov_strategy_between' in info.keys():\n",
        "      m, n, d = X_imputed.shape\n",
        "      if info['cov_strategy_between'] == 'cond_var':\n",
        "        # we have imputed [X1,..,X_m], so shape (m, n, d)\n",
        "        s = np.std(X_imputed, axis=0)\n",
        "        s[s<1e-14] = 0  # set to zero values that are basically zero\n",
        "        #print(\"var \", s)\n",
        "        eye = np.array([np.eye(X_imputed.shape[-1])] * X_imputed.shape[-2])\n",
        "        S_mis = eye * s[:, None, :]\n",
        "        if info['post_imp'] == 'conc':\n",
        "          S_mis = np.tile(S_mis, (m, 1, 1))\n",
        "      elif info['cov_strategy_between'] == 'zero':\n",
        "        d = dict_observations['X_test'].shape[-1]\n",
        "        S_mis = np.zeros((d, d))\n",
        "    else:  # not using a mi method, so uncertainty on missing part should be zero\n",
        "      print(\"shape oject in cov strategy missing \", dict_observations['X_test'].shape[-1])\n",
        "      print(\"shape oject in cov strategy missing \", dict_observations['X_test'].shape)\n",
        "      d = dict_observations['X_test'].shape[-1]\n",
        "      S_mis = np.zeros((d, d))\n",
        "    return S_mis\n",
        "\n",
        "\n",
        "def post_imputation(info_imp, dict_dataset):\n",
        "  # X_imptued should be a matrix (n, d) or tensor (m, d, n) (in multiple imputations methods)\n",
        "    X_imputed = dict_dataset['X_imputed']\n",
        "    y_train = dict_dataset['y_from_X_imputed']\n",
        "    #print(\"info imp in post_imp\", info_imp)\n",
        "    print(\"shape X_imputed in post_imputation \", X_imputed.shape)\n",
        "    mask_train = dict_dataset['masks_after_imputation']\n",
        "    if 'post_imp' not in info_imp.keys():\n",
        "      X_train = X_imputed\n",
        "    elif info_imp['post_imp'] == 'mean':\n",
        "      #print(\"entered in pst_iputation, in mi_mean\")\n",
        "      X_train = np.mean(X_imputed, axis=0)\n",
        "    elif info_imp['post_imp'] == 'conc':\n",
        "      print(\"shape X_imputed \", X_imputed.shape)\n",
        "      X_train = np.concatenate(X_imputed)\n",
        "      y_train = np.tile(y_train, X_imputed.shape[0])\n",
        "    else:\n",
        "      X_train = X_imputed\n",
        "    return X_train, y_train, mask_train\n",
        "\n",
        "\n",
        "def generate_dataset(data, n_tot, dim, beta_gt, perc_test, p_miss, err):\n",
        "    print(data)\n",
        "    if data['data'] == 'Gaussian':\n",
        "      X_complete = np.random.randn(n_tot, dim)\n",
        "    elif data['data'] == 'Normal':\n",
        "      #print(\"you are here\")\n",
        "      if len(beta_gt) != len(data['mean']) or len(beta_gt) != data['cov'].shape[0]:\n",
        "        print(\"ERROR: DIMENSION MISSMATCH\")\n",
        "      X_complete = np.random.multivariate_normal(mean=data['mean'], cov=data['cov'], size=n_tot)\n",
        "    elif data['data'] == 'LogNormal':\n",
        "      if len(beta_gt) != len(data['mean']) or len(beta_gt) != data['cov'].shape[0]:\n",
        "        print(\"ERROR: DIMENSION MISSMATCH\")\n",
        "      X_complete = np.random.lognormal(mean=data['mean'], sigma=data['cov'], size=n_tot)\n",
        "    elif data['data'] == 'Uniform':\n",
        "      X_complete = np.random.rand(n_tot, dim) -0.5\n",
        "    elif data['data'] == 'Logistic':\n",
        "      X_complete = np.random.logistic(loc=0.0, scale=1.0, size=(n_tot, dim))\n",
        "    elif data['data'] == 'moons':\n",
        "      X_complete = make_moons(n_tot, noise=0.1)[0]\n",
        "    elif data['data'] == 'circles':\n",
        "      X_complete = make_circles(n_tot, noise=0.1, factor=0.4)[0]\n",
        "\n",
        "    if err['type'] == 'Gaussian_on_y':\n",
        "      #print(\"---> you have entered in GAUSSIAN ERROR \", \"scaling : \", err['scaling'])\n",
        "      error = np.random.randn(n_tot) * err['scaling']\n",
        "    elif err['type'] == 'Uniform_on_y':\n",
        "      error = (np.random.rand(n_tot)-0.5) * err['scaling']\n",
        "    elif err['type'] == 'Gaussian_on_X':\n",
        "      error = (np.random.randn(n_tot, dim) @ beta_gt) * err['scaling']  # error is of the form DX@beta_gt + error\n",
        "    elif err['type'] == 'Uniform_on_X':\n",
        "      error = ((np.random.rand(n_tot, dim)-0.5) @ beta_gt) * err['scaling']\n",
        "    #elif err['type'] == 'Gaussian':\n",
        "    #  error = np.random.randn(n_tot) * err['scaling']\n",
        "\n",
        "    print(X_complete.shape)\n",
        "\n",
        "    y_complete = X_complete @ beta_gt + error  #np.random.randn(n_tot) * err  # (np.random.rand(n_tot) - 0.5) * err\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_complete, y_complete, test_size=perc_test)\n",
        "    n_train = X_train.shape[0]\n",
        "    # masks_train = generate_masks_2d(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    # masks_train = generate_masks_binomial(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    #X_train, y_train, masks_train = clear_dataset(X_train, y_train, masks_train)\n",
        "    # M = np.sum(masks, axis=1)  # M[i] > 0 iff i has missing component\n",
        "    # dict_obs = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test, 'masks_train': masks_train}\n",
        "    dict_obs = {'X_train_masked': (X_train, []), 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}#, 'masks_train': masks_train}\n",
        "    return dict_obs\n",
        "\n",
        "\n",
        "def experiment_2d_ext_dataset(dict_obs, dict_imp, ax):\n",
        "    # dict_obs contains info on the observations, i.e. train, test, masks\n",
        "    # dict_imp contains info on the imputation an covariance methods used,\n",
        "    # dict_imp = {'imp_method': , 'cov_strategy': , .... }\n",
        "    # ax contains info for the plots\n",
        "\n",
        "    X_test = dict_obs['X_test']\n",
        "    y_test = dict_obs['y_test']\n",
        "    mask = dict_obs['X_train_masked'][1]\n",
        "\n",
        "    M = np.sum(mask, axis=1)  # M[i] > 0 iff i has missing component\n",
        "\n",
        "    X_nan_train = dict_obs['X_train_masked'][0].copy()\n",
        "    oracle_sd = np.std(X_nan_train, axis=0)\n",
        "    print(\"-------> ORACLE SD, std of the original dataset (with no missing)\", oracle_sd)\n",
        "    X_nan_train[mask == 1] = np.nan\n",
        "    #print(\"dict imp -----> \", dict_imp)\n",
        "    dict_obs = dict_obs | {'X_nan': X_nan_train} #, 'y_from_X_imputed': y_from_X_imputed, 'masks_after_imputation': mask_from_X_imputed}\n",
        "    if len(dict_obs['imp_ds'][dict_imp['imp_method']]) == 0:  # no previous imputation has been done\n",
        "      #results = imputations(dict_imp, X_nan_train, dict_obs['y_train'])\n",
        "      print(\"NO PREVIOUS IMPUTATION HAS BEEN DONE\")\n",
        "      results = imputations(dict_imp, dict_obs)\n",
        "      X_imputed, y_from_X_imputed, mask_from_X_imputed = results  # imputations(dict_imp, X_nan_train, dict_obs['y_train'])\n",
        "      print(\"X_imputed in experiment_2d_external_dataset \", np.sum(X_imputed, axis=(-1,-2)))\n",
        "      dict_obs['imp_ds'][dict_imp['imp_method']].append(results)\n",
        "      print(\"crush test-------------------------------------------------> \", np.sum(X_imputed))\n",
        "    else:\n",
        "      print(\"A PREVIOUS IMPUTATION HAS BEEN DONE\")\n",
        "      X_imputed, y_from_X_imputed, mask_from_X_imputed = dict_obs['imp_ds'][dict_imp['imp_method']][0]\n",
        "      print(\"crush test-------------------------------------------------> \", np.sum(X_imputed))\n",
        "    #print(\"X_imputed \", X_imputed)\n",
        "    n_imputed, n_test = X_imputed.shape[-2], X_test.shape[-2]\n",
        "    #print(\"X_train\\n \", X_train)\n",
        "    M = np.sum(mask_from_X_imputed, axis=1)  # M[i] > 0 iff i has missing component\n",
        "\n",
        "    dict_obs = dict_obs | {'X_imputed': X_imputed, 'y_from_X_imputed': y_from_X_imputed, 'masks_after_imputation': mask_from_X_imputed}\n",
        "    #  print(dict_obs)\n",
        "    S_dataset = cov_strategy(dict_imp, dict_obs) #* dict_imp['multip_dataset']\n",
        "    print(\"S dataset \\n\", S_dataset)\n",
        "    #  dict_obs = dict_obs | {'cov_within': S_within}\n",
        "    S_missing = cov_strategy_missing(dict_imp, dict_obs)  #* dict_imp['multip_missing']\n",
        "    print(\"S missing shape\\n \", S_missing.shape)\n",
        "    print(\"S missing\\n \", S_missing)\n",
        "    if 'post_imp' in dict_obs.keys():\n",
        "      if dict_obs['post_imp'] == 'conc':\n",
        "        print(S_missing)\n",
        "    #  dict_obs = dict_obs | {'cov_between': S_between}\n",
        "    S_dict = {'S_dts': S_dataset, 'S_mis': S_missing} | dict_obs['info_algo'] | {'algo_superv_learn': dict_imp['algo_superv_learn']}  # , 'multipliers_dts': dict_imp['multip_dataset'], 'multipliers_mis': dict_imp['multip_missing']}\n",
        "    # dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4 'eps_adv_rad_times_delta_dts': 1e-4}}\n",
        "\n",
        "    #if True:  # check what to do of this part later\n",
        "      #S = S_dataset * dict_imp['multip_dataset'] + S_missing * dict_imp['multip_missing']\n",
        "      #if S.ndim == 2:\n",
        "      #  print(\"final S \\n\", S)\n",
        "\n",
        "\n",
        "    #print(\"matrices S \\n\", S)\n",
        "    #print(\"---....---....----....--> diag matrix: \", np.diag(S))\n",
        "\n",
        "    #if dict_imp['imp_method'] == 'mi':  # prepare the training set in case of multiple imputation\n",
        "    #  X_train = np.concatenate(X_train)  # X_train, if the method is mi, should be (mi_nbr, n, dim)\n",
        "    #  y_train = np.tile(y_train, reps=dict_imp['mi_nbr'])\n",
        "    #  mask_train = np.tile(mask_train, reps=(dict_imp['mi_nbr'], 1))\n",
        "    #  M = np.sum(mask_train, axis=1)\n",
        "    #print(\"final matrices (exp 2d ext run)\\n \", S)\n",
        "    X_train, y_train, mask_train = post_imputation(dict_imp, dict_obs)\n",
        "    n_train = X_train.shape[-2]\n",
        "    print(\"y_train length \", y_train.shape[0])\n",
        "    print(\"-------> size test: \", n_test, \" , size train: \", n_train, \"nbr_full_seen (train): \", np.sum(M == 0), \" nbr_at_least_one_miss : \", np.sum(M > 0))\n",
        "\n",
        "#    plt.tight_layout()\n",
        "    #S_between = S.copy()\n",
        "    if dict_imp['imp_method'] == 'mi' and dict_imp['cov_strategy'] == 'std_mi':  # run a standard multiple imputation procedure\n",
        "      best_coeff = np.zeros(X_train.shape[-1])\n",
        "      best_alpha = 0\n",
        "      min_score = 0\n",
        "      temporary_dictionary = copy.deepcopy(S_dict)\n",
        "      for i in range(dict_imp['mi_nbr']):\n",
        "        print(\"i  mi .-------------> \", i)\n",
        "        #dict_obs_i = {'X_imputed': X_train[i, :, :], 'X_nan': X_nan_train, 'masks': mask_train}\n",
        "        #dict_imp_new = {'imp_method': dict_imp['imp_method'], 'cov_strategy': dict_imp['cov_strategy_within']}\n",
        "        #S_within = cov_strategy(dict_imp_new, dict_obs_i)  # within the dataset\n",
        "        #print(\"S_within \", S_within)\n",
        "        #S = S_within[None, :, :] + S_between\n",
        "        #S = np.concatenate(S, axis=0)\n",
        "        #print(S)\n",
        "        #alphas_used, coeff_results = train_and_plot(X_train[i, :, :], y_train, S, [ax[1], ax[2]])\n",
        "        temporary_dictionary['S_dts'] = S_dict['S_dts'][i, :, :]\n",
        "        print(\"temporary dict \", temporary_dictionary)\n",
        "        hyper_p_used, coeff_results = train_and_plot(X_train[i, :, :], y_train, temporary_dictionary, [])\n",
        "        idx_best, min_score_partial = best_idx_predictor(X_test, coeff_results, y_test)\n",
        "        print(\"weee \", idx_best)\n",
        "        print(coeff_results.shape)\n",
        "        print(hyper_p_used.shape)\n",
        "        best_coeff_partial, _ = coeff_results[:, idx_best], hyper_p_used[:, idx_best]\n",
        "        print(\"best coeff partial \", best_coeff_partial)\n",
        "        best_coeff += best_coeff_partial\n",
        "        min_score += min_score_partial\n",
        "        #best_alpha += best_alpha_partial\n",
        "        if len(ax) > 0:\n",
        "          ax[0].scatter(X_train[i, M == 0, 0], X_train[i, M == 0, 1])\n",
        "          ax[0].scatter(X_train[i, M == 1, 0], X_train[i, M == 1, 1])\n",
        "          ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', n_s: ' + str(np.sum(M == 0)) + \" n_m: \" + str(np.sum(M > 0)))  # n_s = nbr seen, n_m = nbr missing\n",
        "          add_rectangles(X_train[i, :, 0], X_train[i, :, 1], S[0, 0] * best_alpha_partial, S[1, 1] * best_alpha_partial, ax[0])\n",
        "      best_coeff /= dict_imp['mi_nbr']\n",
        "      min_score /=  dict_imp['mi_nbr']\n",
        "      best_hyper_p = 0  # not important right now\n",
        "      best_alpha_delta_dts = 1  # not important right now\n",
        "      #best_alpha /= dict_imp['mi_nbr']\n",
        "    else:\n",
        "      #alphas_used, coeff_results = train_and_plot(X_train, y_train, S_dict, [ax[1], ax[2]])\n",
        "      hyper_p_used, coeff_results = train_and_plot(X_train, y_train, S_dict, [])\n",
        "      idx_best, min_score = best_idx_predictor(X_test, coeff_results, y_test)\n",
        "      #best_coeff, best_alpha = coeff_results[:, idx_best], alphas_used[idx_best]\n",
        "      #print(\"-----------------> shape hyper_p used \", hyper_p_used.shape)\n",
        "      best_coeff, best_hyper_p = coeff_results[:, idx_best], hyper_p_used[:, idx_best]\n",
        "      #print(\"hyper_p_used \", hyper_p_used.T)\n",
        "      #input()\n",
        "      #print(X_br_train[M == 0, 0])\n",
        "      best_alpha_delta_dts, best_alpha_delta_mis = best_hyper_p[0], best_hyper_p[1]\n",
        "#     print(\"best alpha ----> \", best_alpha_dts)\n",
        "      if len(ax) > 0:\n",
        "        ax[0].scatter(X_train[M == 0, 0], X_train[M == 0, 1])\n",
        "        ax[0].scatter(X_train[M == 1, 0], X_train[M == 1, 1])\n",
        "        #ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', n_s: ' + str(np.sum(M == 0)) + \" n_m: \" + str(np.sum(M > 0)))  # n_s = nbr seen, n_m = nbr missing\n",
        "        # 'multip_betw': 1, 'multip_with':1\n",
        "        ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', dts:'+str(dict_imp['multip_dataset']) + ', mis:' + str(dict_imp['multip_missing']) )  # n_s = nbr seen, n_m = nbr missing\n",
        "        S_plot = S_dict['S_dts'] * best_alpha_delta_dts + S_dict['S_mis'] * best_alpha_delta_mis\n",
        "        #print(\"S_plot \", S_plot)\n",
        "        add_rectangles(X_train[:, 0], X_train[:, 1], S_plot, ax[0])\n",
        "        ax[0].set_aspect('equal')  # equal proportion of the axis\n",
        "    #print(\"X_train \", X_train)\n",
        "    #print(\"y_train \", y_train)\n",
        "    #print(\"mask_train \", mask_train)\n",
        "    #print(\"M \", M)\n",
        "\n",
        "\n",
        "    print(\"X_test shape, \", X_test.shape, \",   y_test shape \", y_test.shape)\n",
        "    #print(\"X_test shape, \", X_test.shape)\n",
        "    print(\"---------------------------------> best idx \", idx_best, \" best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]: \", best_hyper_p, \", min score \", min_score)\n",
        "    print(\"---------------------------------> best coeff \", best_coeff)\n",
        "    #input()\n",
        "    #print(\"best 1/alpha \", 1 / best_alpha)\n",
        "    #print(\"min score \", min_score)\n",
        "\n",
        "    #\n",
        "    #add_rectangles(X_train[:, 0], X_train[:, 1], S[0, 0] * best_alpha, S[1, 1] * best_alpha, ax[0])\n",
        "\n",
        "\n",
        "    # obsere that one day you shoul add the return of alpha_delta_mis also\n",
        "    return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n",
        "\n"
      ],
      "metadata": {
        "id": "OhNXUBahJgBL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiments(dictio, methods_strategy):  # ---------------------> new\n",
        "  # dictio: dictionary of lists that contains the parameters of generate_dataset.\n",
        "  # Each list should have the same length\n",
        "  # methods_strategy = list of dictionary, each one of the form\n",
        "  # {'imp_method': .., 'cov_strategy':.., extra info}\n",
        "\n",
        "    l = len(dictio['data'])  # how many trials shall we do\n",
        "    m = len(methods_strategy)\n",
        "    nbr_iter = len(methods_strategy)\n",
        "    coeff_fin = np.zeros((nbr_iter, 2, l))\n",
        "    scores_fin = np.zeros((nbr_iter, l))\n",
        "\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(3 * l , 9 *l), num='advtrain_linf_')\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(6 * l , 9 *l), num='advtrain_linf_')\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(6 * l / 2, 9 *l / 2), num='advtrain_linf_')\n",
        "    print(dictio['plots'])\n",
        "    print(dictio['plots'][0])\n",
        "    nbr_ima = len(dictio['plots'][0])\n",
        "    if nbr_ima == 1:\n",
        "      #nbr_ima = 1\n",
        "      fig, ax = plt.subplots(nbr_ima * nbr_iter, l, figsize=(3 * l, 8/3 * m), squeeze=False)#, num='advtrain_linf_')\n",
        "    elif nbr_ima == 3:  # == 3, one day should be more general\n",
        "      #nbr_ima = 3\n",
        "      fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(3 * l, 8 * m), squeeze=False)#, num='advtrain_linf_')\n",
        "\n",
        "    res = {}\n",
        "    for info_imp_cov_dict in methods_strategy:\n",
        "      key_list = []\n",
        "      for value in info_imp_cov_dict.values():\n",
        "        print(value)\n",
        "        key_list.append(value)\n",
        "      key_tuple = tuple(key_list)\n",
        "      res[key_tuple] = {'best_coeff':[], 'l2_dist_best_coeff_gt':[], 'best_score':[], 'best_hyper_p':[], 'best_alpha_dts':[], 'best_alpha_mis':[]}\n",
        "      #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])] = {'best_coeff':[], 'l2_dist_best_coeff_gt':[], 'best_score':[], 'best_alpha':[]}\n",
        "\n",
        "    if dictio['generation'] == 'fixed':  # use this if you want to fix the generated data, and not change at every iteartion\n",
        "      dictio_obser_fixed  = generate_dataset(data=dictio['data'][0],\n",
        "                                    n_tot=dictio['n_tot'][-1],  # last one should be the biggest\n",
        "                                    dim=dictio['dim'][0],\n",
        "                                    beta_gt=dictio['beta_gt'][0],\n",
        "                                    perc_test=dictio['perc_test'][-1],\n",
        "                                    p_miss=dictio['p_miss'][0],\n",
        "                                    err=dictio['err'][0]\n",
        "                                             )  # return {'X_train_masked':(X_train, mask_train) , 'X_test':.., 'y_train':, 'y_test'}\n",
        "      #mask_no_both_seen = generate_masks_2d(dictio['n_train'][0], [0, 0.5, 0.5]) # generate a mask where there are no entries both seen. The idea then will be to consider percentage of this mask seen\n",
        "      full_masks = generate_masks(dictio)\n",
        "    dictio_obser_fixed_copy = copy.deepcopy(dictio_obser_fixed)\n",
        "\n",
        "    for i in range(l):\n",
        "      print(\"---------------------------------------------------------------------------------------------------------------------------> iteration \", i)\n",
        "      #  dict_obs = {'X_train_masked': (X_train, masks_train), 'X_test': ....., 'y_train': ....., 'y_test': ....}\n",
        "      dict_obser_partial = generate_dataset(data=dictio['data'][i],\n",
        "                                    n_tot=dictio['n_tot'][i],\n",
        "                                    dim=dictio['dim'][i],\n",
        "                                    beta_gt=dictio['beta_gt'][i],\n",
        "                                    perc_test=dictio['perc_test'][i],\n",
        "                                    p_miss=dictio['p_miss'][i],\n",
        "                                    err=dictio['err'][i])\n",
        "      if dictio['generation'] == 'fixed':\n",
        "        dict_obser = dictio_obser_fixed\n",
        "        if len(dictio['beta_gt'][0]) == 2:\n",
        "          #mask_partial = dict_obser_partial['X_train_masked'][1]\n",
        "          p_i = dictio['p_miss'][i][0]  # probability of seen both component at round i\n",
        "          n_train = full_masks.shape[0]\n",
        "          mask_partial = full_masks.copy()\n",
        "          mask_partial[0:int(n_train * p_i), :] = 0\n",
        "          tuple_partial = (dictio_obser_fixed['X_train_masked'][0], mask_partial)\n",
        "          dict_obser['X_train_masked'] = tuple_partial\n",
        "        else:\n",
        "          #print(\"size in run experiment\", dictio_obser_fixed_copy['X_train_masked'][0].shape, \"wee \", dictio_obser_fixed['y_train'].shape)\n",
        "          ## we use the next line of code with dictio_obser_fixed_copy because we need to test the mask with the original dataset, otherwise we get size error (the dataset change if an observation get fully hidden)\n",
        "          n_train = dictio['n_train']\n",
        "          print(\"n_tot_fll \", n_train, \",  \", n_train[i])\n",
        "          #print(dictio_obser_fixed_copy['X_train_masked'][0][0:n_train[i], :].shape)\n",
        "          #print(dictio_obser_fixed_copy['X_train_masked'][0].shape)\n",
        "          X_train_cleaned, y_train_cleaned, masks_train_cleaned = clear_dataset(dictio_obser_fixed_copy['X_train_masked'][0][0:n_train[i], :], dictio_obser_fixed_copy['y_train'][0:n_train[i]], full_masks[i][0:n_train[i], :])\n",
        "          print(\"shapes X_train cleaned, mask train cleaned, y train cleaned\")\n",
        "          print(X_train_cleaned.shape)\n",
        "          print(masks_train_cleaned.shape)\n",
        "          print(y_train_cleaned.shape)\n",
        "          #tuple_partial = (dictio_obser_fixed['X_train_masked'][0], full_masks[i])\n",
        "          print(\"full masks in run experiment \", full_masks[i])\n",
        "          dict_obser['X_train_masked'] = (X_train_cleaned, masks_train_cleaned)\n",
        "          dict_obser['y_train'] = y_train_cleaned\n",
        "      else:\n",
        "        dict_obser = dict_obser_partial\n",
        "\n",
        "      #print(\"dict obser \", dict_obser)\n",
        "      print(\"info algo in run experiments \", dictio['info_algo'])\n",
        "      dict_obser = dict_obser | {'imp_ds':{'BR_si':[], 'l_d':[], 'oracle':[], 'mi':[], 'mf_imp':[]}} | {'info_algo': dictio['info_algo']}  # add an entry for imputed dataset, and info for algorithm\n",
        "      print(\"ciaoooooo dict obser in run experiments \\n \", dict_obser)\n",
        "      for idx, info_imp_cov_dict in enumerate(methods_strategy):\n",
        "        print(\"----------------------------------------------> new method tested: \", info_imp_cov_dict)\n",
        "        if nbr_ima > 0:\n",
        "          coeff_round, score_round, hyper_p_round = experiment_2d_ext_dataset(dict_obser, info_imp_cov_dict, ax[(idx * nbr_ima):((idx+1) * nbr_ima), i])\n",
        "        else:  # == 0\n",
        "          coeff_round, score_round, hyper_p_round = experiment_2d_ext_dataset(dict_obser, info_imp_cov_dict, [])\n",
        "        r = coeff_round - dictio['beta_gt'][i]\n",
        "        l2_dist = np.linalg.norm(r)\n",
        "        key_list = []\n",
        "        for value in info_imp_cov_dict.values():\n",
        "          print(value)\n",
        "          key_list.append(value)\n",
        "        key_tuple = tuple(key_list)\n",
        "        res[key_tuple]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "        res[key_tuple]['best_coeff'].append(coeff_round)\n",
        "        res[key_tuple]['best_score'].append(score_round)\n",
        "        res[key_tuple]['best_hyper_p'].append(hyper_p_round)  # both hyperparameters\n",
        "        res[key_tuple]['best_alpha_dts'].append(hyper_p_round[0])  # one of the hyperparameter\n",
        "        res[key_tuple]['best_alpha_mis'].append(hyper_p_round[1])  # the other hyperparameter\n",
        "\n",
        "        #res[key_tuple]['best_alpha'].append(alpha_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_coeff'].append(coeff_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_score'].append(score_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_alpha'].append(alpha_round)\n",
        "    plt.tight_layout()\n",
        "    return res\n",
        "\n",
        "\n",
        "def plot_res(x_axis_info, res, extra_info):\n",
        "  x_axis = x_axis_info['vector']\n",
        "  print(\"x_axis for print in plot_res----> \", x_axis)\n",
        "  l = len(x_axis)\n",
        "  lb = extra_info['what_to_plot']\n",
        "  nbr_plot = len(lb)\n",
        "  fig_res, ax_res = plt.subplots(1, nbr_plot,\n",
        "                                 figsize=(45 * (nbr_plot / 3 ), 7.5))  # , num='advtrain_linf_res')\n",
        "  positions = range(l)\n",
        "\n",
        "  for key, values in res.items():\n",
        "    print(\"key in plot_res\", key, \": values\\n\", values)\n",
        "    #print(\"values \", values)\n",
        "  #print(\"res\\n \", res)\n",
        "\n",
        "  ch = ['o', 'x', '+', '*', '<', '>', 'p', 'D', 'd', 'v']\n",
        "  # lb = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha']\n",
        "  for i in range(nbr_plot):\n",
        "    for idx, (key, dictio) in enumerate(res.items()):\n",
        "      #print(dictio)\n",
        "      print(\"lb[i] in plot_res \", lb[i], \"  \", dictio[lb[i]])\n",
        "      print(\"key: \", key)\n",
        "      ax_res[i].plot(positions, dictio[lb[i]], marker=ch[idx], label=str(key), color=key[-1])  # the marker is linked to the key (= method), different key correspond to different marker\n",
        "      #ax_res[1].plot(positions, dictio[lb[idx]], marker=ch[idx], label=str(key))\n",
        "      #ax_res[2].plot(positions, -np.log(dictio['best_alpha']), marker=ch[idx], label=str(key))\n",
        "      #ax_res[0].xticks(positions, n_tot)  # Set custom labels for the x-axis\n",
        "    ax_res[i].set_xticks(positions)         # Set the tick positions\n",
        "    ax_res[i].set_xticklabels(x_axis)        # Set the labels at those positions\n",
        "    ax_res[i].set_xlabel(x_axis_info['name'])\n",
        "    #ax_res[i].legend(loc='upper center', bbox_to_anchor=(1, 1))\n",
        "    ax_res[i].legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0., fontsize=20,)\n",
        "  ax_res[0].set_ylabel(\"||hat_Beta - Beta^*||_2\", fontweight='bold', fontsize=16)\n",
        "  ax_res[1].set_ylabel(\"||hat_y - y||_2^2 / n_test\", fontweight='bold', fontsize=16)\n",
        "  dict_err = extra_info['err'][0]\n",
        "  #size_train = extra_info['n_tot'][0]\n",
        "  #ax_res[0].set_title(\"\")\n",
        "  n_test = extra_info['n_test'][0]\n",
        "  #ax_res[1].set_title(\"err: \" + dict_err['type'] + \", scale: \" + str(dict_err['scaling'])  + \", n_test: \" + str(n_test))\n",
        "  #ax_res[0].set_title('n_test: ' + str(n_test) + extra_info['title_infer_error'])\n",
        "  #ax_res[1].set_title('n_test: ' + str(n_test) + extra_info['title_test_error'])\n",
        "  ax_res[0].set_title(extra_info['title_infer_error'], fontweight='bold', fontsize = 24)\n",
        "  ax_res[1].set_title(extra_info['title_test_error'], fontweight='bold', fontsize = 24)\n",
        "  ax_res[2].set_title(extra_info['title_dts_radius'], fontweight='bold', fontsize = 24)\n",
        "  ax_res[3].set_title(extra_info['title_mis_radius'], fontweight='bold', fontsize = 24)\n",
        "  ax_res[2].set_ylabel(\"-log10(alpha)\", fontsize=16, fontweight='bold')\n",
        "  ax_res[3].set_ylabel(\"-log10(alpha)\", fontsize=16, fontweight='bold')\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n",
        "def make_dictionary_data(nbr_experiments, n_train, n_test, data, beta_gt, p_miss, err_vector, plots):\n",
        "  # make a dictionary where each element is a list of nbr_experiments element made by the other element of the function\n",
        "  if isinstance(n_train, int):  # in case n_train is just a number\n",
        "    n_train = [n_train] * nbr_experiments\n",
        "  else:  # should be a list of integer\n",
        "    print(\"change nbr_experiments to match the size of n_train\")\n",
        "    nbr_experiments = len(n_train)\n",
        "  if isinstance(n_test, int):  # in case n_test is just a number\n",
        "    n_test = [n_test] * nbr_experiments\n",
        "  n_tot = [x + y for x, y in zip(n_train, n_test)]\n",
        "  perc_test = [x / (x+y) for x, y in zip(n_test, n_train)]\n",
        "  dim = beta_gt.size\n",
        "\n",
        "  list_errors = []\n",
        "  for i in range(nbr_experiments):\n",
        "    err_dic_app = {'type': err_vector[0], 'scaling': err_vector[1][i]}\n",
        "    list_errors.append(err_dic_app)\n",
        "\n",
        "  dictio = {'data':[data] * nbr_experiments,\n",
        "        'n_tot': n_tot,\n",
        "        'n_train': n_train,\n",
        "        'n_test': n_test,\n",
        "        'dim': [dim] * nbr_experiments,\n",
        "        'beta_gt': [beta_gt] * nbr_experiments,\n",
        "        'perc_test': perc_test,\n",
        "        #'p_miss': [p_miss] * nbr_experiments,\n",
        "        'err': list_errors,\n",
        "        'plots': [plots] * nbr_experiments\n",
        "        }\n",
        "  dictio['p_miss'] = p_miss\n",
        "\n",
        "  return dictio\n",
        "\n",
        "def make_probabilities(list_prob):\n",
        "  l = []\n",
        "  for x in list_prob:\n",
        "    l.append([x, 0.5 - x/2, 0.5 - x/2])\n",
        "  return l\n",
        "\n",
        "def make_info_axis(vector, name):\n",
        "  if name == 'train':\n",
        "    dictio = {'name': 'size train set', 'vector': vector}\n",
        "  elif name == 'p_seen':\n",
        "    dictio = {'name': 'probability seen full entries', 'vector': vector}\n",
        "  elif name == 'error':\n",
        "    dictio = {'name': 'error', 'vector': vector}\n",
        "  else:\n",
        "    print(\"wrong info_axis\")\n",
        "  return dictio\n",
        "\n",
        "def make_dictionary_method(list_meth):\n",
        "  # make a dictionary where each element is a list of nbr_experiments element made by the other element of the function\n",
        "  list_dictio=[]\n",
        "  list_key = ['imp_method', 'cov_strategy', 'mi_nbr']\n",
        "  for meth in list_meth:\n",
        "    dictio_imp = {}\n",
        "    for i in range(len(meth)):\n",
        "      dictio_imp[list_key[i]] = meth[i] #= {list_key[i]: meth[i]}\n",
        "      #print(dictio_imp)\n",
        "    list_dictio.append(dictio_imp)\n",
        "  return list_dictio\n",
        "\n",
        "\n",
        "def run_multiple_experiments(nbr_exp, rdm_seed, dictio, info_x_axis):\n",
        "  #rdm_seed = 4654321\n",
        "  np.random.seed(rdm_seed)\n",
        "  res = run_experiments(dicc, list_methods_strategy)\n",
        "  plot_res(info_x_axis, res, dicc)\n",
        "  '''\n",
        "  if nbr_exp > 1:\n",
        "    for k in res:\n",
        "      for h in res[k]:\n",
        "        res[k][h] = [res[k][h]]\n",
        "    for i in range(nbr_exp-1):\n",
        "      print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "      #np.random.seed(rdm_seed * (i+2))\n",
        "      res_partial = run_experiments(dictio, list_methods_strategy)\n",
        "      plot_res(info_x_axis, res_partial, dictio)\n",
        "      print(res)\n",
        "      for k in res:\n",
        "        res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "        res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "        res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "        #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "        #res.append(res['l2_dist_best_coeff_gt'])\n",
        "  '''\n",
        "  for k in res:\n",
        "    for h in res[k]:\n",
        "      res[k][h] = [res[k][h]]\n",
        "  for i in range(nbr_exp-1):\n",
        "      print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "      #np.random.seed(rdm_seed * (i+2))\n",
        "      res_partial = run_experiments(dictio, list_methods_strategy)\n",
        "      print(\"res partial \\n\")\n",
        "      for k, value in res_partial.items():\n",
        "        print(\"key: \", k, \" value: \", value)\n",
        "      plot_res(info_x_axis, res_partial, dictio)\n",
        "      print(\"res in run multipl experiments\\n\")\n",
        "#      for k, value in res.items():\n",
        "#        print(\"key: \", k, \" value: \", value)\n",
        "      for k in res:\n",
        "        res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "        res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "        res[k]['best_hyper_p'].append(res_partial[k]['best_hyper_p'])\n",
        "        res[k]['best_alpha_dts'].append(res_partial[k]['best_alpha_dts'])\n",
        "        res[k]['best_alpha_mis'].append(res_partial[k]['best_alpha_mis'])\n",
        "\n",
        "        #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "        #res.append(res['l2_dist_best_coeff_gt'])\n",
        "\n",
        "  print(\"final step, let's take the mean of the results\")\n",
        "  #print(\"res, after all the experimetns \", res)\n",
        "  for k in res:\n",
        "    print(\"key in res \", k)\n",
        "    print(np.array(res[k]['l2_dist_best_coeff_gt']))\n",
        "    print(\"mean l2_dist              \", np.mean(np.array(res[k]['l2_dist_best_coeff_gt']), axis=0))\n",
        "    print(\"mean_l2_dist diff method: \", np.mean(res[k]['l2_dist_best_coeff_gt'], axis=0))\n",
        "  #mean_res = {k: np.mean(v, axis=0) for k, v in res.items()}\n",
        "  mean_res = {k: {v: np.mean(w, axis=0) for v, w in res[k].items()} for k in res}\n",
        "  print(\"final dictionary, dictionary of the means:\")\n",
        "  for k, v in mean_res.items():\n",
        "    print(\"k:   \", k)\n",
        "    for s, t in v.items():\n",
        "      print(s, \": \", t)\n",
        "  return mean_res\n",
        "  #print(np.mean(res, axis=0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_2LB5UnMpgCC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#info_axis = 'train'\n",
        "#n_train = [400, 800, 1200, 1600, 2000]\n",
        "#p_seen = make_probabilities([0.8, 0.8, 0.8, 0.8, 0.8])\n",
        "#main_vec = n_train if info_axis == 'train' else p_seen\n",
        "#info_x_axis = make_info_axis(main_vec, info_axis)\n",
        "\n",
        "# def get_path(X, y, estimator, amax, dts_max, mis_max, S_dict, eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "gen = 'fixed'\n",
        "info_axis = 'train'  # train or p_seen\n",
        "#p_seen_both = [1, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.40, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.02]\n",
        "#p_seen_both = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
        "#p_seen_both = [1, 0.9, 0.8/0.9, 0.7/0.8, 0.6/0.7, 0.5/0.6]\n",
        "#p_seen_both = [1, 0.9, 0.8/0.9, 0.7/0.8, 0.6/0.7, 0.5/0.6, 0.4/0.5, 0.3/0.4]\n",
        "n_train = [100, 200, 300]  # check how dataset are generated, there should be some problems with 'fixed'\n",
        "lenght_vec = len(n_train)\n",
        "p_seen_both = [0.3, 1, 1, 1, 1, 1]\n",
        "#p_seen_both = [1, 0.9, 0.8]\n",
        "length_vec = len(p_seen_both)\n",
        "#n_train = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
        "error_vec =  [0] * length_vec\n",
        "#p_seen = make_probabilities(p_seen_both)\n",
        "p_seen = [p_seen_both] * length_vec\n",
        "if info_axis == 'train':\n",
        "  main_vec = n_train\n",
        "  fix_vec = 'prob_seen:' + str(p_seen_both[0])\n",
        "elif info_axis == 'p_seen':\n",
        "  main_vec = np.cumprod(p_seen_both)  # p_seen_both\n",
        "  fix_vec = 'n_train:' + str(n_train[0])\n",
        "elif info_axis == 'error':\n",
        "  main_vec = error_vec\n",
        "#main_vec = n_train if info_axis == 'train' else p_seen_both\n",
        "info_x_axis = make_info_axis(main_vec, info_axis)\n",
        "number_test = 20000\n",
        "#cov_var = 0.6\n",
        "#beta_gt = np.array([-0.5, 2, 1, 3, -2, -3, 4, 0.5, 7, -9, -1, -2, -3, 4, 5, 6, 7, 8])\n",
        "#beta_gt = np.array([2, 4, -0.5, 2, 1, 3, -2, -3, 4, 0.5, 7, -9, -1, -2, -3, 4])\n",
        "beta_gt = np.random.randn(10)\n",
        "print(beta_gt)\n",
        "dim = len(beta_gt)\n",
        "#nbr_feature = int(dim/2)\n",
        "nbr_feature = int(np.sqrt(dim))\n",
        "mean = np.array([0] * dim)\n",
        "matr = np.random.randn(dim, dim) * 1\n",
        "cov = matr.T @ matr + np.eye(dim) * 0.5\n",
        "# np.array([[1, cov_var], [cov_var, 1]])\n",
        "data_type = 'Gaussian'\n",
        "\n",
        "dicc = make_dictionary_data(\n",
        "    nbr_experiments= len(main_vec), n_train = n_train, n_test=number_test,\n",
        "    data = {'data': data_type, 'mean': mean, 'cov': cov},\n",
        "    beta_gt = beta_gt,\n",
        "    p_miss = p_seen,\n",
        "    err_vector = ['Gaussian_on_X', error_vec],\n",
        "    plots = [] #['points', 'l1_vs_coef', '1/alpha_vs_coef']\n",
        ")\n",
        "#dicc = dicc | {'generation':gen}\n",
        "dicc['what_to_plot'] = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts']\n",
        "dicc = dicc | {'generation': gen, 'title_infer_error':' inference_error', 'title_test_error':'  test_error'}\n",
        "dicc = dicc | {'title_dts_radius': 'dts_radius', 'title_mis_radius': 'mis_radius'}\n",
        "dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100,\n",
        "                             'eps_adv_rad_times_delta_dts': 1e-7, 'eps_adv_rad_times_delta_mis': 1e-5, 'eps_alpha_ridge_reg': 1e-7,\n",
        "                             'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
        "dicc['what_to_plot'] = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts', 'best_alpha_mis']\n",
        "\n",
        "for key, value in dicc.items():\n",
        "  print(key, \": \" , value)\n",
        "\n",
        "# (imp method, cov strategy, mi_nbr)\n",
        "#list_imp_cov_methods = [('BR_si', 'sd'), ('l_d', 'sd'), ('mi', 'sd', 1)]\n",
        "\n",
        "#list_methods_strategy = make_dictionary_method(list_imp_cov_methods)\n",
        "mi_nbr = 5\n",
        "nbr_cand = 50\n",
        "# def get_path(X, y, estimator, amax, dts_max, mis_max, S_dict, eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "\n",
        "list_methods_strategy = [#{'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'},  #, 'multip_dataset': 3, 'multip_missing':0},\n",
        "\n",
        "                         #{'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge', 'color': 'k'},  #, 'multip_dataset': 3, 'multip_missing':0},\n",
        "                        #{'imp_method': 'l_d', 'cov_strategy': 'std_nan', 'multip_dataset': 3, 'multip_missing':3},\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'zero', 'algo_superv_learn': 'adv'},\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'zero', 'algo_superv_learn': 'ridge'},  #, 'multip_dataset': 3, 'multip_missing': 0}\n",
        "\n",
        "                        # {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'},\n",
        "\n",
        "                         #{'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'ridge', 'color': 'purple'},\n",
        "                        #{'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'ridge'},#, 'multip_dataset': 3, 'multip_missing':0},\n",
        "                        #{'imp_method': 'l_d', 'cov_strategy': 'std_nan', 'multip_dataset': 3, 'multip_missing':3},\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn':'ridge'},#, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'nbr_feature': dim, 'algo_superv_learn':'adv', 'color':'g'},  #, 'multip_dataset': 3, 'multip_missing': 3},\n",
        "                        {'imp_method': 'mf_imp', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'nbr_candidates_mm': nbr_cand, 'algo_superv_learn':'adv', 'color':'r'},  #, 'multip_dataset': 3, 'multip_missing': 3},\n",
        "                        {'imp_method': 'mf_imp', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'nbr_candidates_mm': 0, 'algo_superv_learn':'adv', 'color':'purple'},  #, 'multip_dataset': 3, 'multip_missing': 3},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'algo_superv_learn':'adv', 'color': 'g'}, #, 'multip_dataset': 3, 'multip_missing': 3},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'zero', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'algo_superv_learn':'adv', 'color': 'r'}\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'algo_superv_learn':'adv'}\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'sd', 'multip_dataset': 0, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 1},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 3},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'std_mi', 'mi_nbr': mi_nbr},\n",
        "                        #{'imp_method': 'mi_pure', 'cov_strategy': 'cond_var', 'cov_strategy_within': 'sd', 'mi_nbr': 5},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 1},\n",
        "                        #{'imp_method': 'mi_mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'eye', 'mi_nbr': 5},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'multip_betw': 0, 'multip_with': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.2},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.4},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.6},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 0, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 0, 'multip_missing': 1},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'conc', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr}#, 'multip_dataset': 3, 'multip_missing': 3}\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 5},\n",
        "                        ]\n",
        "print(list_methods_strategy)\n",
        "for el in list_methods_strategy:\n",
        "  for key, value in el.items():\n",
        "    print(key,\": \" , value)\n",
        "\n",
        "print(\"----> Starting experiments\")\n",
        "\n",
        "'''\n",
        "nbr_exp = 2\n",
        "#res[key_tuple]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "#res[key_tuple]['best_coeff'].append(coeff_round)\n",
        "#res[key_tuple]['best_score'].append(score_round)\n",
        "#res[key_tuple]['best_alpha'].append(alpha_round)\n",
        "res_l2 = []\n",
        "\n",
        "rdm_seed = 4654321\n",
        "np.random.seed(rdm_seed)\n",
        "res = run_experiments(dicc, list_methods_strategy)\n",
        "plot_res(info_x_axis, res, dicc)\n",
        "if nbr_exp > 1:\n",
        "  for k in res:\n",
        "    for h in res[k]:\n",
        "      res[k][h] = [res[k][h]]\n",
        "  for i in range(nbr_exp-1):\n",
        "    print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "    #np.random.seed(rdm_seed * (i+2))\n",
        "    res_partial = run_experiments(dicc, list_methods_strategy)\n",
        "    plot_res(info_x_axis, res_partial, dicc)\n",
        "    print(res)\n",
        "    for k in res:\n",
        "      res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "      res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "      res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "      #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "    #res.append(res['l2_dist_best_coeff_gt'])\n",
        "\n",
        "print(\"final \")\n",
        "print(res)\n",
        "for k in res:\n",
        "  print(k)\n",
        "  print(np.array(res[k]['l2_dist_best_coeff_gt']))\n",
        "  print(np.mean(np.array(res[k]['l2_dist_best_coeff_gt']), axis=0))\n",
        "  print(np.mean(res[k]['l2_dist_best_coeff_gt'], axis=0))\n",
        "#mean_res = {k: np.mean(v, axis=0) for k, v in res.items()}\n",
        "mean_res = {k: {v: np.mean(w, axis=0) for v, w in res[k].items()} for k in res}\n",
        "for k, v in mean_res.items():\n",
        "  print(\"k:   \", k)\n",
        "  for s, t in v.items():\n",
        "    print(s, \": \", t)\n",
        "#print(np.mean(res, axis=0))\n",
        "'''\n",
        "\n",
        "nbr_exp = 5\n",
        "seed = 67\n",
        "mean_res = run_multiple_experiments(nbr_exp, seed, dicc, info_x_axis)\n",
        "print(\"PLOT OF THE MEANS\")\n",
        "dicc['title_infer_error'] = 'seed: ' + str(seed) + ', nbr_exp: ' + str(nbr_exp) + ', data: '+ data_type + ', dim: ' + str(dim) # ', cov: ' + str(cov_var)\n",
        "dicc['title_test_error'] = 'sigma_err: ' + str(error_vec[0]) + ', ' + fix_vec + ', n_test: ' + str(number_test)\n",
        "#dicc['title_dts_radius'] = 'dts_radius'\n",
        "#dicc['title_mis_radius'] = 'mis_radius'\n",
        "#dicc = dicc | {'title_dts_radius': 'title_dts_radius', 'title_mis_radius': 'title_mis_radius'}\n",
        "#dicc = dicc | {'generation':gen, 'title_infer_error':'mean_infer_error, rep: ' + str(nbr_exp), 'title_mean_error':'mean_test_error'}\n",
        "#dicc['what_to_plot'] = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts', 'best_alpha_mis']\n",
        "plot_res(info_x_axis, mean_res, dicc)\n",
        "\n",
        "## you can see if you manage to take the index i that maximize alpha\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXcjBX8GqIAF",
        "outputId": "89c54344-d730-40ca-9bb5-c57df82962de"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "change nbr_experiments to match the size of n_train\n",
            "data :  [{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}, {'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}]\n",
            "n_tot :  [20100, 20200, 20300]\n",
            "n_train :  [100, 200, 300]\n",
            "n_test :  [20000, 20000, 20000]\n",
            "dim :  [10, 10, 10]\n",
            "beta_gt :  [array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895])]\n",
            "perc_test :  [0.9950248756218906, 0.9900990099009901, 0.9852216748768473]\n",
            "err :  [{'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}]\n",
            "plots :  [[], [], []]\n",
            "p_miss :  [[0.3, 1, 1, 1, 1, 1], [0.3, 1, 1, 1, 1, 1], [0.3, 1, 1, 1, 1, 1], [0.3, 1, 1, 1, 1, 1], [0.3, 1, 1, 1, 1, 1], [0.3, 1, 1, 1, 1, 1]]\n",
            "what_to_plot :  ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha_dts', 'best_alpha_mis']\n",
            "generation :  fixed\n",
            "title_infer_error :   inference_error\n",
            "title_test_error :    test_error\n",
            "title_dts_radius :  dts_radius\n",
            "title_mis_radius :  mis_radius\n",
            "info_algo :  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "[{'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}, {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}, {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}, {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}, {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}]\n",
            "imp_method :  BR_si\n",
            "cov_strategy :  std_nan\n",
            "algo_superv_learn :  adv\n",
            "color :  b\n",
            "imp_method :  oracle\n",
            "cov_strategy :  sd\n",
            "algo_superv_learn :  adv\n",
            "color :  orange\n",
            "imp_method :  mi\n",
            "post_imp :  mean\n",
            "cov_strategy_between :  cond_var\n",
            "cov_strategy :  std_nan\n",
            "mi_nbr :  5\n",
            "nbr_feature :  10\n",
            "algo_superv_learn :  adv\n",
            "color :  g\n",
            "imp_method :  mf_imp\n",
            "post_imp :  mean\n",
            "cov_strategy_between :  cond_var\n",
            "cov_strategy :  std_nan\n",
            "mi_nbr :  5\n",
            "nbr_candidates_mm :  10\n",
            "algo_superv_learn :  adv\n",
            "color :  r\n",
            "imp_method :  mf_imp\n",
            "post_imp :  mean\n",
            "cov_strategy_between :  cond_var\n",
            "cov_strategy :  std_nan\n",
            "mi_nbr :  5\n",
            "nbr_candidates_mm :  0\n",
            "algo_superv_learn :  adv\n",
            "color :  purple\n",
            "----> Starting experiments\n",
            "[[], [], []]\n",
            "[]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20300, 10)\n",
            "p_missing in generate mask  [0.3, 1, 1, 1, 1, 1]\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  0\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20100, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   100\n",
            "X shape in clear data  (100, 10)\n",
            "y shape in clear data  (100,)\n",
            "M shape in clear data  (100,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(99, 10)\n",
            "(99, 10)\n",
            "(99,)\n",
            "full masks in run experiment  [[1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 0 1 1]\n",
            " [1 1 0 ... 1 0 1]\n",
            " ...\n",
            " [0 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [0 0 1 ... 1 0 1]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 1.40871720e+00,  4.71945008e-01,  1.36941475e+00,\n",
            "         8.21446071e-01,  4.30877183e-01, -1.76943323e+00,\n",
            "         5.31546881e-02,  8.06024754e-02,  4.51827451e-01,\n",
            "        -1.77895815e-01],\n",
            "       [-7.36408329e-01,  3.91230481e-01,  1.14434956e+00,\n",
            "        -4.66139583e-01, -2.81947507e-01, -9.05829214e-01,\n",
            "        -1.11331984e+00,  1.46768537e+00,  1.59450424e+00,\n",
            "        -5.38858313e-01],\n",
            "       [ 4.59965441e-01, -3.93880713e-01, -1.05790591e+00,\n",
            "        -7.39693304e-01,  8.42666847e-01,  6.13559396e-01,\n",
            "        -2.59398407e-01, -1.21261360e-01,  1.02077289e+00,\n",
            "         9.22951660e-01],\n",
            "       [-4.42448823e-01,  9.53559164e-01,  4.46945990e-01,\n",
            "        -8.22494178e-02,  2.37873264e+00,  2.40555484e-01,\n",
            "         1.22361095e+00,  3.20183565e-01, -2.11020450e-01,\n",
            "         1.24533399e+00],\n",
            "       [ 2.54724034e-01, -5.29822723e-01,  1.43774819e+00,\n",
            "         1.01678987e+00, -1.70852052e+00,  8.47096138e-01,\n",
            "         1.44898080e+00, -1.82761273e+00,  1.38534286e+00,\n",
            "        -7.66096814e-01],\n",
            "       [-4.82056969e-01,  7.08530660e-01,  3.56585263e-01,\n",
            "         1.37791688e+00, -4.32239696e-01,  2.66436973e-01,\n",
            "         1.14585161e-01, -3.05979392e-01, -5.60963545e-01,\n",
            "         3.63132767e-01],\n",
            "       [ 4.28896237e-01, -1.98402495e+00, -1.00185803e+00,\n",
            "        -1.47647274e+00, -3.95439320e-01,  1.00966897e+00,\n",
            "        -1.58226487e+00,  3.37077924e-02,  5.25863749e-01,\n",
            "         2.01214178e-01],\n",
            "       [ 1.04114497e+00, -1.44069792e+00, -3.48984682e-01,\n",
            "         9.65421300e-01,  1.89327052e-01, -4.57045328e-01,\n",
            "         1.32851785e+00, -6.31395952e-01, -1.66022681e+00,\n",
            "        -1.07339824e-01],\n",
            "       [ 4.39530781e-01,  8.22367806e-01, -6.45826811e-01,\n",
            "         2.25725071e+00,  3.59490681e-01,  5.54527561e-02,\n",
            "         4.01602068e-01, -2.57939168e-01,  1.07134764e+00,\n",
            "         1.71266996e+00],\n",
            "       [ 3.79213593e-01, -1.57352255e+00,  1.61579343e+00,\n",
            "        -1.44075322e+00,  1.15714762e-01, -4.28591060e-01,\n",
            "         1.38481838e+00,  5.98955584e-01, -8.61330018e-01,\n",
            "         2.73068396e-01],\n",
            "       [-1.11349486e+00,  4.28283962e-01, -3.57163698e-01,\n",
            "         1.05111474e+00,  8.64818031e-01,  1.38676337e+00,\n",
            "         7.07184160e-01,  4.76260105e-01, -8.54832097e-01,\n",
            "        -8.94010410e-01],\n",
            "       [ 1.10028628e+00,  4.35076435e-01,  1.80479950e+00,\n",
            "        -3.91360754e-01, -9.67676412e-02,  5.32644554e-01,\n",
            "        -5.95429294e-01, -4.74099534e-01,  2.72376491e+00,\n",
            "        -5.41462152e-01],\n",
            "       [ 1.65926667e+00, -1.12627085e+00,  1.53700299e+00,\n",
            "        -5.12965101e-01, -7.06947757e-03,  1.03701362e+00,\n",
            "        -6.67737661e-01,  1.39931169e+00,  1.22315400e-01,\n",
            "        -5.49626051e-01],\n",
            "       [ 1.24923246e+00,  3.63050552e-01, -1.88564404e+00,\n",
            "        -1.84012203e-01,  9.92290714e-01, -1.09712157e+00,\n",
            "        -2.64730447e+00,  9.69114029e-01,  4.45367533e-01,\n",
            "        -9.76365605e-01],\n",
            "       [ 8.02322656e-01, -3.80053275e-01,  1.35500119e+00,\n",
            "        -1.37806897e+00,  7.96059160e-01, -4.54573331e-01,\n",
            "         3.59495549e-01, -4.99603455e-01, -1.04982626e-01,\n",
            "        -2.66143572e-01],\n",
            "       [ 1.33303534e+00, -6.65858665e-01,  3.10488865e-01,\n",
            "         8.55304909e-01, -7.23741838e-01,  1.33373768e+00,\n",
            "        -5.47542224e-01, -7.39973464e-01, -9.49158610e-01,\n",
            "        -3.59907448e-01],\n",
            "       [ 8.59755730e-01,  5.89857798e-01, -9.88636348e-02,\n",
            "        -4.11923666e-01,  1.31234306e+00,  9.85465680e-02,\n",
            "        -1.33643831e+00,  1.48678563e+00, -1.32383365e+00,\n",
            "        -9.78893581e-01],\n",
            "       [ 1.48306127e-01,  7.28702171e-02,  1.23249569e+00,\n",
            "        -5.00268880e-01, -1.17671320e-01,  2.78758082e-01,\n",
            "         9.84673461e-01, -5.16460450e-01,  6.23078103e-01,\n",
            "         2.44346020e+00],\n",
            "       [ 1.04839754e+00,  2.62903619e-01, -5.30859805e-01,\n",
            "        -1.43221854e+00, -4.36773481e-02, -4.48094406e-02,\n",
            "        -5.54626474e-01,  9.51231402e-01, -6.26457209e-01,\n",
            "        -4.50173231e-01],\n",
            "       [ 5.97757363e-01,  1.33091546e+00,  1.59533294e+00,\n",
            "        -2.18670264e+00, -8.80267771e-01,  7.18786339e-02,\n",
            "         4.04636113e-01,  1.48555819e+00, -1.59230489e-01,\n",
            "        -1.08849184e+00],\n",
            "       [-9.08966888e-01,  8.91926083e-01, -2.75848697e-02,\n",
            "         8.35976535e-01, -1.53666492e+00,  8.38986482e-01,\n",
            "        -4.30628240e-01,  9.84338985e-02, -8.24269718e-01,\n",
            "        -5.32093058e-01],\n",
            "       [ 8.73963359e-01, -4.80683916e-01, -6.51016617e-01,\n",
            "         2.31026404e-01,  4.85079071e-02,  2.78180580e-01,\n",
            "        -1.95377857e-01, -3.47397498e-01, -1.61727719e-01,\n",
            "         5.67373173e-01],\n",
            "       [ 2.26907863e-01,  1.08632566e-01,  3.55505488e-01,\n",
            "        -1.15596436e+00, -5.25211231e-01,  3.42637889e-01,\n",
            "        -8.17478504e-01,  5.37012606e-01,  2.70547565e-01,\n",
            "         6.55241104e-01],\n",
            "       [-1.37734284e+00,  6.44801035e-01, -7.11386298e-01,\n",
            "         2.57286152e-01,  6.62528580e-01,  1.37689750e+00,\n",
            "        -8.83164309e-01, -1.42449067e+00, -4.31205713e-01,\n",
            "         1.62570426e+00],\n",
            "       [ 1.14473897e+00,  1.02848474e+00,  6.11147915e-02,\n",
            "        -1.58391293e-01,  7.83908467e-02, -9.17629464e-01,\n",
            "        -2.94193111e-01,  4.22907566e-01, -5.33605697e-01,\n",
            "        -4.43681331e-02],\n",
            "       [ 3.93106567e-01,  3.92300738e-01,  5.68028965e-01,\n",
            "         5.53312951e-01,  1.21894685e+00, -2.37836383e+00,\n",
            "         1.48663222e+00, -1.25825034e+00,  4.68970472e-01,\n",
            "        -4.21496927e-01],\n",
            "       [ 1.40900585e+00, -1.92223275e+00,  1.39124001e-02,\n",
            "         9.26446682e-02, -8.86797201e-01, -2.33743704e+00,\n",
            "        -1.20159720e+00,  1.39695720e-01, -8.88251809e-01,\n",
            "         3.76074070e-01],\n",
            "       [-7.52962428e-01,  1.08868108e+00, -5.92326271e-01,\n",
            "         3.64815660e-01, -1.51400191e+00, -5.07745388e-01,\n",
            "        -2.91066629e-01,  6.70992825e-01,  1.18270414e+00,\n",
            "        -5.90886054e-01],\n",
            "       [ 3.79308398e-01, -7.81952469e-01, -1.18544760e+00,\n",
            "         4.27980966e-01, -9.65868429e-01,  5.45303896e-01,\n",
            "         1.14847661e+00,  1.85103843e+00,  1.86719173e-01,\n",
            "        -1.03220700e+00],\n",
            "       [ 2.23648977e-01,  5.12404862e-01, -6.53703744e-03,\n",
            "         1.01567743e+00, -6.38936265e-01,  9.30673519e-01,\n",
            "         4.52211037e-01, -3.92644681e-01,  7.78770975e-01,\n",
            "         1.35651129e+00],\n",
            "       [ 1.76683008e+00, -9.86546671e-01, -6.58514304e-01,\n",
            "        -1.47163722e-01,  1.10715844e+00, -6.58183749e-01,\n",
            "         2.86494506e-01, -1.25293274e+00, -3.76070401e-01,\n",
            "        -1.03276445e+00],\n",
            "       [-1.03669074e+00, -1.26521891e+00,  6.44836923e-01,\n",
            "        -1.90690297e+00,  2.23109325e+00,  1.79474951e+00,\n",
            "        -1.55690787e+00, -1.56231124e-01, -5.33019645e-01,\n",
            "         1.24371705e+00],\n",
            "       [ 2.89680242e-01, -1.09827796e-01, -1.65210961e+00,\n",
            "         3.06216226e+00, -1.70315032e+00,  8.40670300e-01,\n",
            "        -9.47752001e-01, -1.14587457e+00,  6.02135366e-01,\n",
            "        -1.22972635e+00],\n",
            "       [ 1.15056667e+00,  7.04947489e-01,  4.27288378e-01,\n",
            "         4.99654891e-01,  1.43054084e+00, -5.48773798e-01,\n",
            "        -1.65151865e+00, -7.08102032e-01,  5.06073708e-01,\n",
            "         3.90592526e-01],\n",
            "       [-1.12048496e+00,  1.09763532e+00, -1.61064579e+00,\n",
            "         1.22287250e+00,  8.63589976e-02,  1.09465785e+00,\n",
            "         1.18506419e+00, -1.74400379e-01, -1.42606467e+00,\n",
            "         4.19391534e-01],\n",
            "       [-9.70912670e-01,  1.41601514e+00,  2.76768006e-01,\n",
            "         4.97113398e-01, -2.29102341e-01,  7.13487433e-01,\n",
            "        -1.28861480e-01,  2.58187791e-01, -8.86828824e-01,\n",
            "        -1.15259609e+00],\n",
            "       [-7.26623290e-01, -3.64725770e-01, -1.00278669e+00,\n",
            "         5.12214467e-01, -1.03615492e+00, -1.59610351e+00,\n",
            "        -5.17621185e-01,  1.02212319e+00, -9.63072743e-01,\n",
            "         3.33761144e-01],\n",
            "       [-1.56686103e-01, -1.21788456e+00,  1.58208036e+00,\n",
            "        -2.28505431e-01, -1.60992908e+00, -8.18460757e-01,\n",
            "        -7.09704521e-01,  1.37204702e+00,  6.36952537e-01,\n",
            "        -1.27510759e+00],\n",
            "       [-6.77747464e-01,  1.35534044e-02, -2.70325425e-01,\n",
            "        -2.26399781e+00, -5.09346736e-01,  7.24801695e-01,\n",
            "         9.77968732e-01, -1.44635374e+00, -1.14576104e+00,\n",
            "        -3.84638096e-01],\n",
            "       [-2.74780301e-01,  6.27911079e-01, -8.59667243e-01,\n",
            "         1.72657480e+00,  9.47146709e-01, -9.65971008e-01,\n",
            "        -1.30341991e-01, -1.55252218e+00, -3.17594137e-01,\n",
            "        -8.05926517e-01],\n",
            "       [-1.24301423e+00, -5.52703376e-01,  1.84704279e+00,\n",
            "         1.01176040e+00,  1.09061950e+00, -7.05105451e-01,\n",
            "        -2.46845624e-01, -5.63953610e-02,  1.40593614e+00,\n",
            "        -2.21441109e-01],\n",
            "       [ 8.17153430e-01,  3.38533641e-01, -5.41331404e-01,\n",
            "        -6.16540705e-01, -1.58073004e-01,  1.08605716e+00,\n",
            "         1.22179541e+00, -7.06444781e-01,  6.40680824e-01,\n",
            "         6.20146282e-01],\n",
            "       [-4.81834490e-01, -3.21352711e-01, -9.48065877e-01,\n",
            "        -5.95647358e-01,  3.89794404e-01,  2.60014612e+00,\n",
            "         1.60292116e-01,  5.65501718e-01,  3.29115515e-01,\n",
            "         6.78641884e-01],\n",
            "       [ 1.98468506e+00, -5.26304642e-01, -1.99072790e+00,\n",
            "        -9.12425445e-02,  6.86463387e-01, -6.96229637e-01,\n",
            "         3.56950608e-01, -2.49769288e-01, -6.68257288e-01,\n",
            "        -1.33215144e-01],\n",
            "       [-7.27994151e-01,  1.19980451e+00, -9.40189556e-01,\n",
            "        -1.01882945e+00, -5.46231379e-01, -5.62064556e-01,\n",
            "         1.51991974e-01, -4.94412750e-01,  5.26115879e-01,\n",
            "        -8.28678242e-01],\n",
            "       [ 9.43953118e-01, -2.36916091e-01,  1.46643660e-01,\n",
            "        -2.27087750e+00, -7.65795630e-03, -1.14425480e+00,\n",
            "         4.17111409e-01, -4.46651828e-01, -1.44895539e-01,\n",
            "         1.32226037e+00],\n",
            "       [ 1.23728920e+00,  2.25406623e-01, -1.71272172e+00,\n",
            "        -7.15603424e-01, -1.43698173e+00, -6.47009215e-01,\n",
            "        -7.10735446e-01, -8.83031517e-01, -2.31357086e-01,\n",
            "         9.12944233e-01],\n",
            "       [ 2.18212035e-01, -5.22357576e-01,  1.45383246e+00,\n",
            "        -7.05811095e-01,  6.07176200e-01,  6.11054585e-01,\n",
            "         4.10861875e-01, -2.86574477e-01,  2.23152806e+00,\n",
            "        -1.61290489e-01],\n",
            "       [-6.97977547e-01,  1.05413026e+00, -6.80190028e-01,\n",
            "        -9.31150473e-01,  1.01108468e+00,  3.87207307e-01,\n",
            "        -1.42527396e+00,  1.43131870e-01,  2.53611643e-01,\n",
            "         1.07634325e+00],\n",
            "       [ 4.40578681e-01, -5.52442809e-01, -1.33310024e+00,\n",
            "        -3.32897489e-01,  9.85146040e-01, -5.60522971e-01,\n",
            "        -6.82308511e-01, -7.57696698e-01, -3.56399272e-01,\n",
            "         5.77793463e-01],\n",
            "       [ 4.59391812e-01,  4.97089048e-02,  8.04589235e-01,\n",
            "        -5.59340782e-01,  6.35782510e-01, -2.27351126e+00,\n",
            "         1.27114392e+00,  1.11988784e+00, -7.86308171e-01,\n",
            "         8.98202524e-01],\n",
            "       [ 1.77694178e+00,  8.34835964e-01, -4.11545285e-02,\n",
            "         3.99897091e-01,  7.13081356e-03,  7.42296408e-01,\n",
            "         5.33917128e-01,  1.51618120e-01,  5.01343073e-01,\n",
            "         1.30008832e+00],\n",
            "       [-5.71265416e-01,  1.19234160e-01, -2.76689037e-01,\n",
            "         6.25312835e-01,  1.28158543e+00,  1.03930906e+00,\n",
            "        -9.67253473e-01, -2.09319194e-01, -1.08390922e+00,\n",
            "        -9.12871255e-01],\n",
            "       [ 1.20776166e+00,  1.26057010e+00, -5.94702278e-02,\n",
            "         1.97851997e-01, -1.01464532e-01,  8.17238258e-01,\n",
            "        -5.84620642e-01,  1.06665815e+00,  1.92515161e-01,\n",
            "         4.55536757e-01],\n",
            "       [-7.84091188e-01,  2.34508213e-01,  6.07970813e-01,\n",
            "        -5.02358669e-01, -1.27630525e+00, -1.45957420e+00,\n",
            "         1.34500935e+00, -1.28150683e-02, -6.58809061e-01,\n",
            "         4.76256952e-02],\n",
            "       [-6.48471752e-01, -7.10073282e-01, -3.66326512e-01,\n",
            "         1.05414494e+00,  1.80394130e+00,  8.75229064e-01,\n",
            "         6.56209050e-02, -1.44001538e+00, -8.98244001e-01,\n",
            "         1.53473808e+00],\n",
            "       [-2.49954880e-01, -8.82110679e-01, -2.89655981e-01,\n",
            "         2.71315524e-02,  8.74420828e-01,  1.82695155e+00,\n",
            "         3.32794900e-01, -7.00956906e-01, -8.89723438e-01,\n",
            "        -9.98328374e-01],\n",
            "       [ 7.04168954e-01,  1.14345298e+00,  7.71944165e-01,\n",
            "         1.08924273e+00, -3.36987039e-01, -5.79796889e-01,\n",
            "         1.95600477e+00, -8.91924700e-02, -2.81169428e-01,\n",
            "        -5.58372406e-01],\n",
            "       [ 1.09669675e-01, -4.99849164e-01,  1.14212501e+00,\n",
            "         6.86931414e-01, -3.52205259e-01, -9.37574041e-01,\n",
            "        -1.44833210e+00, -4.62971093e-01, -9.70675368e-01,\n",
            "        -5.27840581e-01],\n",
            "       [-2.39795005e-01,  2.15439884e-01,  7.21132034e-01,\n",
            "         9.14142893e-01, -4.72435909e-01,  1.73195607e+00,\n",
            "        -9.06222949e-01, -9.71385263e-02, -1.58267736e+00,\n",
            "         1.29411229e+00],\n",
            "       [-3.12756741e-01,  3.32016161e-01,  2.94508509e-01,\n",
            "        -1.64946254e+00,  9.80029989e-01, -8.60469874e-01,\n",
            "        -4.53061333e-02,  3.82984620e-01,  7.17037757e-01,\n",
            "        -5.84833751e-01],\n",
            "       [-1.40154538e+00, -1.00059592e-01,  1.19634569e+00,\n",
            "        -8.90028998e-02,  3.84089921e-01,  4.89083044e-01,\n",
            "         1.13599174e+00, -6.07619039e-01, -4.58736657e-01,\n",
            "        -3.36437330e-01],\n",
            "       [-1.65427359e+00, -3.59706673e-01, -3.50566810e-01,\n",
            "        -2.14275002e-01,  6.12442395e-01,  5.55808285e-01,\n",
            "        -6.72872960e-01, -3.60501584e-01, -1.02631177e+00,\n",
            "         1.07407943e+00],\n",
            "       [-1.89737461e+00,  8.26454358e-01,  2.50870684e-01,\n",
            "         6.32013776e-01, -6.62821702e-02, -7.85158944e-01,\n",
            "         6.09729393e-01, -1.09866143e+00, -2.15259834e+00,\n",
            "        -5.06189500e-01],\n",
            "       [-1.34270483e+00,  6.01995676e-01,  5.90614092e-01,\n",
            "         3.16104335e-01, -1.07805084e+00,  9.36086376e-01,\n",
            "         1.15815969e-01, -5.34812470e-01,  1.05451371e+00,\n",
            "         1.05852152e+00],\n",
            "       [ 7.49176468e-02,  4.17086272e-01, -6.32685352e-02,\n",
            "         2.07090455e+00, -1.19936957e+00, -1.29463991e-01,\n",
            "        -1.14781512e+00,  8.49009788e-01, -3.93553524e-01,\n",
            "         3.71436347e-01],\n",
            "       [-3.73995186e-01, -9.08337217e-01,  2.48641756e-01,\n",
            "         5.04500781e-01,  1.01024489e+00,  1.16474670e+00,\n",
            "        -9.06950862e-01, -7.76024714e-01,  3.49207002e-01,\n",
            "        -5.90253457e-01],\n",
            "       [-8.86343674e-01, -3.07697452e-01, -6.80057074e-02,\n",
            "         3.99382969e-01,  6.05497920e-01,  1.73025459e-01,\n",
            "        -3.00375724e-01,  1.53406922e+00, -7.54100386e-01,\n",
            "         1.56348762e+00],\n",
            "       [-9.32768897e-01,  1.28041712e+00,  8.01309277e-01,\n",
            "         1.15073185e-01, -5.60484998e-02,  2.30596822e-01,\n",
            "         4.50373458e-01,  1.82523408e+00, -4.84247142e-02,\n",
            "         3.33687125e-01],\n",
            "       [ 2.08442858e-01, -5.33367781e-01, -1.45995216e+00,\n",
            "        -9.79076813e-01, -1.16610590e+00, -1.28850189e+00,\n",
            "         6.04584814e-01,  1.31047555e-01,  1.05787762e+00,\n",
            "         1.32861052e+00],\n",
            "       [ 1.55869403e+00,  4.11605074e-01, -2.59176097e-01,\n",
            "        -1.37821036e+00, -8.06097973e-01,  6.45309897e-02,\n",
            "        -8.30902730e-01, -4.29275183e+00,  9.02037438e-02,\n",
            "        -1.27745113e+00],\n",
            "       [-6.33614075e-01, -5.30117475e-01,  1.93638094e+00,\n",
            "        -1.22372343e+00, -1.33531534e+00,  1.88930734e+00,\n",
            "        -2.96963114e-01, -6.29426644e-01, -2.07679641e+00,\n",
            "         6.93834646e-01],\n",
            "       [-1.68700371e+00, -6.41588914e-01, -9.52650170e-01,\n",
            "         6.78530657e-01,  1.50441291e-01,  7.06307849e-01,\n",
            "        -7.13655315e-01, -2.21564298e-01, -6.07689436e-01,\n",
            "         1.55047025e+00],\n",
            "       [ 1.62589004e-01, -2.93435277e-01,  1.31979525e+00,\n",
            "        -1.46932484e+00,  1.29110523e+00,  1.07140243e+00,\n",
            "        -1.89728383e+00, -1.16615313e+00, -1.24998455e+00,\n",
            "        -1.30813627e+00],\n",
            "       [ 1.02236984e+00,  1.05311989e-01, -2.27969565e-01,\n",
            "        -4.72018307e-01, -5.08805745e-01, -6.84516433e-01,\n",
            "        -1.14029223e+00, -2.16655934e-01, -9.24469016e-01,\n",
            "        -1.11444473e+00],\n",
            "       [ 4.11436519e-01,  1.28089322e-01, -1.26815122e+00,\n",
            "         1.79448984e+00, -6.52323902e-01, -6.57379655e-01,\n",
            "         2.68275621e-01,  7.16711618e-01,  1.33647490e-01,\n",
            "         2.03865602e+00],\n",
            "       [-1.10241752e+00, -2.12402015e-01, -1.18223037e-01,\n",
            "        -1.96110412e-01, -9.81151089e-01,  9.36887323e-02,\n",
            "        -2.47859174e+00,  1.10111702e+00, -1.44580129e+00,\n",
            "         5.81604268e-01],\n",
            "       [-1.09317342e-01, -2.32440439e+00, -1.02358988e+00,\n",
            "         7.36302706e-01,  1.34419819e-01,  5.46421543e-01,\n",
            "        -1.68706327e+00, -5.70379423e-01,  6.39427387e-01,\n",
            "        -1.42005412e+00],\n",
            "       [ 1.10780573e-01,  9.82014998e-01, -5.92152686e-01,\n",
            "         6.33309543e-01, -1.08098774e+00,  5.15871365e-01,\n",
            "         2.85224628e-01,  2.63607116e-01,  1.41663052e+00,\n",
            "         1.95612002e-01],\n",
            "       [-1.05777671e+00, -9.91842740e-01,  3.36161747e-02,\n",
            "         4.56509785e-01, -6.60809738e-01,  1.43098463e+00,\n",
            "        -1.27130096e+00,  3.09157981e+00, -4.92473491e-01,\n",
            "         1.41776971e+00],\n",
            "       [-5.57668010e-01, -3.39775380e-01, -5.48721627e-01,\n",
            "         2.24854194e-01, -6.01718545e-03,  1.64542079e+00,\n",
            "         1.58618850e+00,  1.07995861e+00, -2.80745993e-01,\n",
            "        -8.03562622e-01],\n",
            "       [-2.31201962e+00, -2.66145174e+00, -4.42120202e-01,\n",
            "         8.20844190e-01, -3.13938733e-01, -7.11469461e-01,\n",
            "        -5.31413609e-01,  6.18096260e-01, -3.62861795e-01,\n",
            "         6.41594404e-01],\n",
            "       [ 8.96078225e-01,  7.65834158e-01,  2.70742929e+00,\n",
            "         3.13428402e-01,  7.54015544e-01, -9.76268543e-01,\n",
            "         3.01497883e-01, -1.39815763e+00,  1.08033867e-01,\n",
            "        -1.67089547e-01],\n",
            "       [-3.15811882e-02,  1.70984059e+00,  8.47715240e-01,\n",
            "        -1.03082441e+00,  2.88192918e-02, -8.87674250e-01,\n",
            "        -6.59354888e-01, -4.86574288e-01,  3.20009239e+00,\n",
            "        -1.60731711e+00],\n",
            "       [ 2.85770261e-01, -1.41112963e+00,  5.60793368e-01,\n",
            "         9.06361959e-02, -2.60049105e-01,  2.97896237e-01,\n",
            "        -6.85404750e-01,  1.00040716e+00,  2.01917596e-01,\n",
            "        -1.84146909e+00],\n",
            "       [ 3.85971279e-01,  1.20920957e+00,  1.13246318e+00,\n",
            "        -1.13753595e+00, -6.57105831e-01,  2.57649596e-01,\n",
            "         3.54602725e-01, -9.48629833e-01,  4.07976496e-03,\n",
            "         7.68999804e-01],\n",
            "       [-1.67812411e+00, -1.28678678e+00,  1.30009447e+00,\n",
            "         6.96527799e-01, -1.58997774e+00,  8.67352243e-01,\n",
            "        -1.22821414e+00, -1.17368500e-01,  5.01168292e-01,\n",
            "         2.95399386e-01],\n",
            "       [ 4.90140029e-01,  1.36213947e+00,  5.64499879e-01,\n",
            "         1.74843120e+00,  2.91078972e-01, -2.48591238e-01,\n",
            "        -1.21679201e+00, -9.06646429e-02,  9.32953118e-01,\n",
            "         1.28108693e+00],\n",
            "       [ 9.99296837e-01, -3.86181337e-01, -6.60835896e-02,\n",
            "         2.58512142e+00,  5.42348775e-01,  1.42415647e+00,\n",
            "         7.36462683e-01,  3.95686533e-01, -1.69173570e-01,\n",
            "         1.54870776e+00],\n",
            "       [ 1.46399660e-01,  3.83410666e-01,  1.48312045e-01,\n",
            "        -2.09625060e+00, -1.90147378e+00, -3.02136461e-01,\n",
            "         1.05287174e-01,  3.05955142e-01,  8.36627655e-01,\n",
            "        -1.13785762e+00],\n",
            "       [-6.13409889e-03, -6.02331522e-01, -5.75334782e-01,\n",
            "        -9.54128886e-01,  2.36537388e-01, -5.79933340e-01,\n",
            "         6.73506676e-01,  6.74989278e-01, -2.04314969e-01,\n",
            "         8.62961074e-01],\n",
            "       [-5.25914513e-01, -2.07061777e+00,  9.01611212e-01,\n",
            "         6.95231005e-01, -7.10521990e-02,  1.32526113e+00,\n",
            "         5.42079006e-01,  4.65749105e-02,  1.05121012e+00,\n",
            "        -5.42932150e-02],\n",
            "       [ 1.61857140e-01,  4.56492434e-01, -3.78682533e-01,\n",
            "        -1.70396885e+00, -2.81982022e+00,  5.42784573e-01,\n",
            "         1.88493123e-01,  1.19210550e-01,  6.60143847e-01,\n",
            "        -6.55397801e-01],\n",
            "       [ 4.34388971e-01,  7.32662992e-01, -8.13605468e-02,\n",
            "        -1.24494737e+00,  2.10777139e+00, -3.22594381e-01,\n",
            "        -1.33719740e+00, -6.33389212e-01,  9.06536136e-01,\n",
            "         1.06081521e+00],\n",
            "       [ 1.27307869e+00,  8.61153996e-02,  1.85444850e-01,\n",
            "         1.03032260e+00, -8.58388262e-01, -2.20898223e-01,\n",
            "        -3.40073827e-01, -3.00030052e-01,  1.90013556e-01,\n",
            "        -1.58147059e-01],\n",
            "       [ 3.66416294e-01,  2.73383243e-01,  1.03882559e+00,\n",
            "        -1.09507879e+00,  4.41230548e-01,  2.34778142e-01,\n",
            "        -1.65853690e-01, -1.24428735e+00, -1.69040861e-01,\n",
            "         1.40976770e+00],\n",
            "       [ 1.33219749e+00,  9.06488671e-01,  3.70599845e-01,\n",
            "        -1.07336063e+00,  9.72263879e-01,  2.84026553e-01,\n",
            "        -8.79937010e-01,  1.09567359e+00, -1.11888902e-01,\n",
            "        -1.84470667e+00],\n",
            "       [ 4.33958298e-01, -6.14898256e-01,  1.12331528e+00,\n",
            "         1.12133677e+00, -1.59345450e+00,  2.91055788e-01,\n",
            "         1.01475562e-01,  1.43215114e+00, -4.22518733e-01,\n",
            "         3.56584780e-02],\n",
            "       [-9.05800448e-01, -1.11125262e+00, -1.81693395e+00,\n",
            "        -4.24932502e-01, -2.01269885e-02,  1.97243227e+00,\n",
            "        -1.84263213e-02, -2.06932027e+00, -9.04312445e-01,\n",
            "        -1.03344226e+00]]), array([[1, 1, 1, 0, 0, 1, 0, 1, 1, 1],\n",
            "       [0, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 0, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 0, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 1, 0, 1, 0, 1, 0, 0, 0],\n",
            "       [1, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 0, 1, 0, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 0, 0, 1, 0, 1, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 0, 0, 1, 0, 1],\n",
            "       [0, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
            "       [0, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [0, 0, 0, 1, 0, 0, 0, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 1, 0, 0],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
            "       [1, 0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],\n",
            "       [1, 1, 0, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [0, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 0, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 0, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 0, 0, 0, 1, 1],\n",
            "       [1, 0, 1, 0, 0, 1, 0, 1, 1, 0],\n",
            "       [1, 1, 1, 0, 0, 0, 1, 1, 1, 0],\n",
            "       [0, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 0, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 0, 1, 1, 0, 1, 1, 1, 0, 0],\n",
            "       [1, 1, 0, 1, 1, 0, 0, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 0, 1, 1, 1, 0, 1],\n",
            "       [0, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
            "       [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
            "       [0, 1, 0, 0, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 0, 1, 0, 1, 0, 1, 1, 0],\n",
            "       [0, 0, 0, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [0, 0, 1, 1, 1, 0, 0, 1, 1, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 0, 1, 0, 0],\n",
            "       [0, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [0, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
            "       [0, 1, 1, 1, 0, 0, 1, 0, 1, 0],\n",
            "       [0, 0, 1, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 0, 0, 1, 1, 0, 0],\n",
            "       [1, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [0, 0, 1, 1, 1, 0, 1, 1, 1, 0],\n",
            "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 0, 0, 1, 1, 0, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 0, 0, 1, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 0, 1, 1]])), 'X_test': array([[-0.14119944, -0.14622299,  0.04325781, ..., -1.52889821,\n",
            "        -0.13385379,  0.15681423],\n",
            "       [-0.00815081, -0.46876798, -0.16440122, ...,  0.46623542,\n",
            "         0.0483185 , -0.10502403],\n",
            "       [-0.08273124, -1.0186805 ,  1.241534  , ..., -0.29265638,\n",
            "        -2.15610532,  0.5074812 ],\n",
            "       ...,\n",
            "       [ 1.50812198,  1.09638107, -2.24708424, ..., -1.39224186,\n",
            "         0.9818755 , -0.85242999],\n",
            "       [ 0.69743205,  1.68804848, -0.37750316, ...,  0.87036358,\n",
            "        -0.81622109,  0.21803187],\n",
            "       [-0.05217442, -0.73393012, -1.03523011, ..., -0.93347666,\n",
            "         0.54269735, -2.54890062]]), 'y_train': array([ 1.57856925, -4.85201977, -4.31944736, -4.82449359,  8.05982457,\n",
            "        2.61064353, -1.9392001 ,  5.68759882, -1.27354612,  1.06455249,\n",
            "        1.04024534,  0.59886116,  2.97152853, -4.41621479,  0.76294746,\n",
            "        7.95360848, -0.52351239, -1.55791389, -0.41518355,  1.2487652 ,\n",
            "        3.86260915,  1.04010552, -1.73472809, -2.48598303,  0.73267707,\n",
            "       -0.09048095,  1.83995397, -1.54384171,  1.26696743,  1.00068558,\n",
            "        3.29647726, -5.93884341,  7.0048748 , -1.16099472,  1.03655992,\n",
            "        2.39159207, -1.83318631,  1.53399519,  2.00898268,  1.54958943,\n",
            "       -2.98590924,  0.97138291, -2.45801515,  1.0794004 , -1.95393625,\n",
            "       -2.48631023,  0.95637766, -1.76157474, -6.55839129, -2.43994575,\n",
            "       -2.79098028,  1.35044507,  0.96981121,  0.26013951,  0.98964214,\n",
            "       -0.89472437,  3.28624951,  4.94694996,  3.63351364,  3.75803955,\n",
            "       -4.9626079 ,  1.12522734, -3.22136216,  2.63409867, -0.92559134,\n",
            "        2.37579004,  0.57092423, -4.56463022, -2.76083686, -4.42171473,\n",
            "        8.086446  ,  5.92983432, -3.4067377 ,  2.85505366,  3.38121507,\n",
            "       -1.73672013, -1.64297088,  0.97134239, -0.22737064, -4.15465905,\n",
            "        1.21729619, -4.12614029,  4.06427379, -3.64831942,  2.35361123,\n",
            "        1.8286952 ,  1.1660198 , -1.09165402,  2.87614169,  0.54980519,\n",
            "       -3.60516941,  1.10973647,  2.49065916, -6.7290016 ,  4.39463522,\n",
            "       -0.21179038,  0.60923051,  4.47632651,  3.40152972]), 'y_test': array([-2.01481788, -0.38757976,  3.54586038, ...,  6.61672963,\n",
            "       -1.65162069,  2.21406433]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.93489699 0.90138771 0.97345445 1.08339819 0.9736496  0.99234313\n",
            " 0.9355024  1.00694675 0.93679764 0.96835533]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  0.7442135900102151\n",
            "crush test------------------------------------------------->  0.7442135900102151\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8]\n",
            "S dataset \n",
            " [[1.02225852 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.8270546  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.8657955  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.89338074 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8893535  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.85635971\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8467545  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93205791 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.88205986 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96981859]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (99, 10)\n",
            "y_train length  99\n",
            "-------> size test:  20000  , size train:  99 nbr_full_seen (train):  0  nbr_at_least_one_miss :  99\n",
            "X  99   10\n",
            "y shape (99,)\n",
            "nm  990\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 98.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  3.3112424951787602\n",
            "---------------------------------> best coeff  [ 1.69922757 -0.15171203  0.6149815   0.81787162 -0.68437955  0.40187532\n",
            " -0.58880379 -1.13966524 -0.36976909 -1.1061292 ]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.93489699 0.90138771 0.97345445 1.08339819 0.9736496  0.99234313\n",
            " 0.9355024  1.00694675 0.93679764 0.96835533]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  4.197788231298912\n",
            "crush test------------------------------------------------->  4.197788231298912\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.93489699 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.90138771 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.97345445 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.08339819 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9736496  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.99234313\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.9355024  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.00694675 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.93679764 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96835533]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (99, 10)\n",
            "y_train length  99\n",
            "-------> size test:  20000  , size train:  99 nbr_full_seen (train):  99  nbr_at_least_one_miss :  0\n",
            "X  99   10\n",
            "y shape (99,)\n",
            "nm  990\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 77.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  1.8660456390432851e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.93489699 0.90138771 0.97345445 1.08339819 0.9736496  0.99234313\n",
            " 0.9355024  1.00694675 0.93679764 0.96835533]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [-43.18418376  20.05688742 -13.54724165 -22.27432766 -35.60422269]\n",
            "crush test------------------------------------------------->  -94.55308834413529\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8]\n",
            "S dataset \n",
            " [[1.02225852 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.8270546  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.8657955  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.89338074 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8893535  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.85635971\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8467545  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93205791 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.88205986 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96981859]]\n",
            "S missing shape\n",
            "  (99, 10, 10)\n",
            "S missing\n",
            "  [[[0.92500267 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.98052699 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.6625416  ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.52809226 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.9181197  0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.86356531]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.69838339 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.85912312 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.5870671 ]]\n",
            "\n",
            " [[1.31864431 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.61150855 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.91828158 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.77253264]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1.25719565 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.61937361 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.38488502 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.46836758 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.65307543 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.31771264 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.8823559  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.71388835 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.36241921 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.57673422 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.99079641]]]\n",
            "shape X_imputed in post_imputation  (5, 99, 10)\n",
            "y_train length  99\n",
            "-------> size test:  20000  , size train:  99 nbr_full_seen (train):  0  nbr_at_least_one_miss :  99\n",
            "X  99   10\n",
            "y shape (99,)\n",
            "nm  990\n",
            "S_mis in Adbvt training  [[[0.92500267 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.98052699 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.6625416  ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.52809226 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.9181197  0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.86356531]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.69838339 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.85912312 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.5870671 ]]\n",
            "\n",
            " [[1.31864431 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.61150855 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.91828158 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.77253264]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1.25719565 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.61937361 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.38488502 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.46836758 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.65307543 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.31771264 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.8823559  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[0.71388835 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.36241921 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.57673422 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.99079641]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.02 0.00 ... 0.00 0.00]\n",
            " [0.00 0.83 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.88 0.00]\n",
            " [0.00 0.00 ... 0.00 0.97]] @ Promote(adv_radius_times_dts, (990, 10)) + [[0.93 0.00 ... 0.00 0.00]\n",
            " [0.00 0.98 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.58 0.00]\n",
            " [0.00 0.00 ... 0.00 0.99]] @ Promote(adv_radius_times_mis, (990, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 24.97it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 28.44it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 28.74it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 29.45it/s]\n",
            " 33%|███▎      | 1/3 [00:00<00:01,  1.95it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 25.74it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 28.88it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 28.42it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 29.40it/s]\n",
            " 67%|██████▋   | 2/3 [00:01<00:00,  1.95it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 33.32it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 33.28it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 33.15it/s]\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 1.e-05] , min score  4.867713851084003\n",
            "---------------------------------> best coeff  [ 1.67507425 -0.059702   -0.50745558  0.66150071 -0.51964504  0.45891016\n",
            "  0.42969031 -0.16669165 -0.95543941 -0.9384786 ]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.93489699 0.90138771 0.97345445 1.08339819 0.9736496  0.99234313\n",
            " 0.9355024  1.00694675 0.93679764 0.96835533]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 3.91 s, sys: 212 ms, total: 4.13 s\n",
            "Wall time: 2.31 s\n",
            "X_imputed in experiment_2d_external_dataset  [-45.38621394 -35.96048501 -21.81232862   2.31880978 -26.15198002]\n",
            "crush test------------------------------------------------->  -126.99219781290276\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8]\n",
            "S dataset \n",
            " [[1.02225852 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.8270546  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.8657955  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.89338074 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8893535  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.85635971\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8467545  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93205791 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.88205986 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96981859]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 99, 10)\n",
            "y_train length  99\n",
            "-------> size test:  20000  , size train:  99 nbr_full_seen (train):  0  nbr_at_least_one_miss :  99\n",
            "X  99   10\n",
            "y shape (99,)\n",
            "nm  990\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 106.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  6.408676836502915\n",
            "---------------------------------> best coeff  [ 1.21498459 -0.22067683 -0.91467831  0.05923438 -0.79745388  1.25553143\n",
            "  0.09450634 -0.51973298 -0.74744078 -1.5007369 ]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.93489699 0.90138771 0.97345445 1.08339819 0.9736496  0.99234313\n",
            " 0.9355024  1.00694675 0.93679764 0.96835533]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -126.99219781290276\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8]\n",
            "S dataset \n",
            " [[1.02225852 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.8270546  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.8657955  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.89338074 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8893535  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.85635971\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8467545  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93205791 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.88205986 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96981859]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 99, 10)\n",
            "y_train length  99\n",
            "-------> size test:  20000  , size train:  99 nbr_full_seen (train):  0  nbr_at_least_one_miss :  99\n",
            "X  99   10\n",
            "y shape (99,)\n",
            "nm  990\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 86.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  6.408676836502915\n",
            "---------------------------------> best coeff  [ 1.21498459 -0.22067683 -0.91467831  0.05923438 -0.79745388  1.25553143\n",
            "  0.09450634 -0.51973298 -0.74744078 -1.5007369 ]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  1\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20200, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   200\n",
            "X shape in clear data  (200, 10)\n",
            "y shape in clear data  (200,)\n",
            "M shape in clear data  (200,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(197, 10)\n",
            "(197, 10)\n",
            "(197,)\n",
            "full masks in run experiment  [[1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 0 1 1]\n",
            " [1 1 0 ... 1 0 1]\n",
            " ...\n",
            " [0 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [0 0 1 ... 1 0 1]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 1.4087172 ,  0.47194501,  1.36941475, ...,  0.08060248,\n",
            "         0.45182745, -0.17789582],\n",
            "       [-0.73640833,  0.39123048,  1.14434956, ...,  1.46768537,\n",
            "         1.59450424, -0.53885831],\n",
            "       [ 0.45996544, -0.39388071, -1.05790591, ..., -0.12126136,\n",
            "         1.02077289,  0.92295166],\n",
            "       ...,\n",
            "       [-0.01806628,  0.18280176, -0.37555095, ...,  0.11160813,\n",
            "         0.50785467,  0.43063981],\n",
            "       [ 2.17139102, -1.51148532,  0.8580068 , ...,  0.05203784,\n",
            "        -1.51894963,  0.9950457 ],\n",
            "       [ 1.00448679,  2.10182269, -0.66932547, ...,  1.31931507,\n",
            "        -1.0012478 , -0.41320702]]), array([[1, 1, 1, ..., 1, 1, 1],\n",
            "       [0, 1, 0, ..., 0, 1, 1],\n",
            "       [1, 1, 0, ..., 1, 0, 1],\n",
            "       ...,\n",
            "       [1, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 1, 1, ..., 1, 0, 1],\n",
            "       [1, 1, 1, ..., 1, 0, 1]])), 'X_test': array([[-0.14119944, -0.14622299,  0.04325781, ..., -1.52889821,\n",
            "        -0.13385379,  0.15681423],\n",
            "       [-0.00815081, -0.46876798, -0.16440122, ...,  0.46623542,\n",
            "         0.0483185 , -0.10502403],\n",
            "       [-0.08273124, -1.0186805 ,  1.241534  , ..., -0.29265638,\n",
            "        -2.15610532,  0.5074812 ],\n",
            "       ...,\n",
            "       [ 1.50812198,  1.09638107, -2.24708424, ..., -1.39224186,\n",
            "         0.9818755 , -0.85242999],\n",
            "       [ 0.69743205,  1.68804848, -0.37750316, ...,  0.87036358,\n",
            "        -0.81622109,  0.21803187],\n",
            "       [-0.05217442, -0.73393012, -1.03523011, ..., -0.93347666,\n",
            "         0.54269735, -2.54890062]]), 'y_train': array([ 1.57856925, -4.85201977, -4.31944736, -4.82449359,  8.05982457,\n",
            "        2.61064353, -1.9392001 ,  5.68759882, -1.27354612,  1.06455249,\n",
            "        1.04024534,  0.59886116,  2.97152853, -4.41621479,  0.76294746,\n",
            "        7.95360848, -0.52351239, -1.55791389, -0.41518355,  1.2487652 ,\n",
            "        3.86260915,  1.04010552, -1.73472809, -2.48598303,  0.73267707,\n",
            "       -0.09048095,  1.83995397, -1.54384171,  1.26696743,  1.00068558,\n",
            "        3.29647726, -5.93884341,  7.0048748 , -1.16099472,  1.03655992,\n",
            "        2.39159207, -1.83318631,  1.53399519,  2.00898268,  1.54958943,\n",
            "       -2.98590924,  0.97138291, -2.45801515,  1.0794004 , -1.95393625,\n",
            "       -2.48631023,  0.95637766, -1.76157474, -6.55839129, -2.43994575,\n",
            "       -2.79098028,  1.35044507,  0.96981121,  0.26013951,  0.98964214,\n",
            "       -0.89472437,  3.28624951,  4.94694996,  3.63351364,  3.75803955,\n",
            "       -4.9626079 ,  1.12522734, -3.22136216,  2.63409867, -0.92559134,\n",
            "        2.37579004,  0.57092423, -4.56463022, -2.76083686, -4.42171473,\n",
            "        8.086446  ,  5.92983432, -3.4067377 ,  2.85505366,  3.38121507,\n",
            "       -1.73672013, -1.64297088,  0.97134239, -0.22737064, -4.15465905,\n",
            "        1.21729619, -4.12614029,  4.06427379, -3.64831942,  2.35361123,\n",
            "        1.8286952 ,  1.1660198 , -1.09165402,  2.87614169,  0.54980519,\n",
            "       -3.60516941,  1.10973647,  2.49065916, -6.7290016 ,  4.39463522,\n",
            "       -0.21179038,  0.60923051,  4.47632651,  3.40152972,  0.89159723,\n",
            "        2.70587036, -5.30293319, -3.0627484 , -1.9305731 , -0.06535448,\n",
            "        3.30875053,  3.87846029, -2.16731408,  3.57339677, -2.70228885,\n",
            "       -0.7478314 ,  4.06633796,  2.64469073, -3.74008468, -0.85233153,\n",
            "        8.39511982, -4.26629689, -2.04347769,  0.41365783,  1.01542547,\n",
            "        0.77277482,  3.88986604,  1.68469496, -4.04777408, -0.34733005,\n",
            "       -0.31526787,  4.58331119, -0.98117111,  0.91665275,  0.49180386,\n",
            "        1.07451896, -6.00903492, -1.84929065,  0.41252571,  0.18873986,\n",
            "        1.08376574, -0.38432679, -3.84406528,  2.35532087, -1.46713213,\n",
            "       -0.38951127, -1.19131738,  0.37007411, -2.64425093, -0.9996588 ,\n",
            "       -0.74775735,  2.27962614, -4.37076024,  3.7649719 ,  4.7353076 ,\n",
            "        1.16995909, -2.22608466,  2.30128804, -2.03068555,  0.09872895,\n",
            "        6.47905908, -0.71384232, -4.09534495, -0.50339116,  2.04102623,\n",
            "        6.53111984, -2.13075161, -5.43096996, -2.26245993,  2.80205938,\n",
            "        2.20692314,  0.69352754, -6.99889577, -0.40058023,  3.19501823,\n",
            "        3.04150952,  2.80466834, -1.41221323, -1.92890814,  0.87990197,\n",
            "       -2.37906046, -1.71009112,  4.10115169,  0.65520453,  4.33577785,\n",
            "        0.14653067, -3.08119926, -0.48285085,  3.18916902,  2.45269643,\n",
            "       -5.18963862,  3.74781791,  4.97130806,  2.81073065, -3.51487601,\n",
            "       -3.49867317, -0.80074212,  5.84463162, -5.79941011, -2.20992597,\n",
            "        7.03842026,  5.08937639]), 'y_test': array([-2.01481788, -0.38757976,  3.54586038, ...,  6.61672963,\n",
            "       -1.65162069,  2.21406433]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97768037 0.96413496 0.98334319 1.06903874 1.0049965  0.97772765\n",
            " 0.9256416  1.02201829 0.96440606 1.00722568]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  23.686298451825778\n",
            "crush test------------------------------------------------->  23.686298451825778\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8]\n",
            "S dataset \n",
            " [[1.04393492 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.96051249 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.86811804 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.00074693 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9887404  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.90333649\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.88649489 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93014454 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.874762   0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.9127546 ]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 55.39it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 55.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.01 0.  ] , min score  4.866289962873608\n",
            "---------------------------------> best coeff  [ 3.81307090e-01 -1.30281742e-10 -4.57582260e-01  7.23625024e-01\n",
            " -1.05765681e+00  6.00852286e-01 -2.78678692e-01 -8.12113988e-01\n",
            " -1.36745608e+00 -1.93224344e+00]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97768037 0.96413496 0.98334319 1.06903874 1.0049965  0.97772765\n",
            " 0.9256416  1.02201829 0.96440606 1.00722568]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -40.19889261574781\n",
            "crush test------------------------------------------------->  -40.19889261574781\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.97768037 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.96413496 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.98334319 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.06903874 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         1.0049965  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.97772765\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.9256416  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.02201829 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.96440606 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.00722568]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  197  nbr_at_least_one_miss :  0\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 33.84it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 48.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  2.147333860807118e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97768037 0.96413496 0.98334319 1.06903874 1.0049965  0.97772765\n",
            " 0.9256416  1.02201829 0.96440606 1.00722568]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [-15.40549843 -37.16536526 -62.57970633  74.08031796  44.28617562]\n",
            "crush test------------------------------------------------->  3.2159235616331863\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8]\n",
            "S dataset \n",
            " [[1.04393492 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.96051249 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.86811804 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.00074693 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9887404  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.90333649\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.88649489 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93014454 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.874762   0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.9127546 ]]\n",
            "S missing shape\n",
            "  (197, 10, 10)\n",
            "S missing\n",
            "  [[[0.55415479 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.5366477  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.86433963 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.40060442 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.7954559  0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.0255549 ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.74340586 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.82404161 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.81677626]]\n",
            "\n",
            " [[1.18704705 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.83244153 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.88852171 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.7903183 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.65303374 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.65339955 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.48368237 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.97538087]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.78661444 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.47009336 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.33780042 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.12720936]]\n",
            "\n",
            " [[1.24278747 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.27436533 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.29378469 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.87753735 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8148997 ]]]\n",
            "shape X_imputed in post_imputation  (5, 197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[[0.55415479 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.5366477  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.86433963 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.40060442 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.7954559  0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.0255549 ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.74340586 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.82404161 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.81677626]]\n",
            "\n",
            " [[1.18704705 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.83244153 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.88852171 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.7903183 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.65303374 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.65339955 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.48368237 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.97538087]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.78661444 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.47009336 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.33780042 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.12720936]]\n",
            "\n",
            " [[1.24278747 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.27436533 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.29378469 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.87753735 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8148997 ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.04 0.00 ... 0.00 0.00]\n",
            " [0.00 0.96 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.87 0.00]\n",
            " [0.00 0.00 ... 0.00 0.91]] @ Promote(adv_radius_times_dts, (1970, 10)) + [[0.55 0.00 ... 0.00 0.00]\n",
            " [0.00 0.54 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.00 0.00]\n",
            " [0.00 0.00 ... 0.00 0.81]] @ Promote(adv_radius_times_mis, (1970, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:01,  9.23it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01, 11.83it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:00, 12.78it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 13.23it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 12.96it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:00<00:00, 13.30it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:00<00:00, 13.54it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00, 13.06it/s]\n",
            " 33%|███▎      | 1/3 [00:01<00:02,  1.15s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01, 12.92it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 12.51it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 13.26it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 13.35it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 12.96it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:00<00:00, 13.49it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00, 13.24it/s]\n",
            " 67%|██████▋   | 2/3 [00:02<00:01,  1.14s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 14.97it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 14.95it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 14.83it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 14.66it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 14.69it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:00<00:00, 14.67it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00, 14.40it/s]\n",
            "100%|██████████| 3/3 [00:03<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 1.e-05] , min score  4.115311307724778\n",
            "---------------------------------> best coeff  [ 1.07067395 -0.2355901  -0.08642996  0.44376903 -0.6254064   0.54277543\n",
            " -0.07977387 -0.25479589 -0.97749127 -0.85077901]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97768037 0.96413496 0.98334319 1.06903874 1.0049965  0.97772765\n",
            " 0.9256416  1.02201829 0.96440606 1.00722568]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 7.17 s, sys: 301 ms, total: 7.47 s\n",
            "Wall time: 5.08 s\n",
            "X_imputed in experiment_2d_external_dataset  [-34.65802566 -20.55701448 -30.24822062   3.24841651   7.86311265]\n",
            "crush test------------------------------------------------->  -74.35173159447181\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8]\n",
            "S dataset \n",
            " [[1.04393492 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.96051249 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.86811804 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.00074693 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9887404  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.90333649\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.88649489 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93014454 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.874762   0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.9127546 ]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 57.00it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 58.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.3800433856241883\n",
            "---------------------------------> best coeff  [ 1.18618417 -0.5309376  -0.16998548  0.829616   -1.24527355  0.49661977\n",
            "  0.06155747 -0.69094765 -1.18731771 -1.59667863]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97768037 0.96413496 0.98334319 1.06903874 1.0049965  0.97772765\n",
            " 0.9256416  1.02201829 0.96440606 1.00722568]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -74.35173159447181\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8]\n",
            "S dataset \n",
            " [[1.04393492 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.96051249 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.86811804 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.00074693 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9887404  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.90333649\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.88649489 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93014454 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.874762   0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.9127546 ]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 35.37it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 49.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.3800433856241883\n",
            "---------------------------------> best coeff  [ 1.18618417 -0.5309376  -0.16998548  0.829616   -1.24527355  0.49661977\n",
            "  0.06155747 -0.69094765 -1.18731771 -1.59667863]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  2\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20300, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   300\n",
            "X shape in clear data  (300, 10)\n",
            "y shape in clear data  (300,)\n",
            "M shape in clear data  (300,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(295, 10)\n",
            "(295, 10)\n",
            "(295,)\n",
            "full masks in run experiment  [[1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 0 1 1]\n",
            " [1 1 0 ... 1 0 1]\n",
            " ...\n",
            " [0 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [0 0 1 ... 1 0 1]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 1.4087172 ,  0.47194501,  1.36941475, ...,  0.08060248,\n",
            "         0.45182745, -0.17789582],\n",
            "       [-0.73640833,  0.39123048,  1.14434956, ...,  1.46768537,\n",
            "         1.59450424, -0.53885831],\n",
            "       [ 0.45996544, -0.39388071, -1.05790591, ..., -0.12126136,\n",
            "         1.02077289,  0.92295166],\n",
            "       ...,\n",
            "       [ 0.89635222, -0.84843433, -1.19740002, ..., -0.12999146,\n",
            "         0.1842438 , -0.49466545],\n",
            "       [ 0.01501082,  1.46391201,  1.14234348, ...,  1.64104058,\n",
            "        -0.31428037, -0.28179269],\n",
            "       [ 1.09637583,  0.3027997 , -0.92531129, ...,  0.37356975,\n",
            "        -1.16342758,  0.03432248]]), array([[1, 1, 1, ..., 1, 1, 1],\n",
            "       [0, 1, 0, ..., 0, 1, 1],\n",
            "       [1, 1, 0, ..., 1, 0, 1],\n",
            "       ...,\n",
            "       [0, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 0, 0, 1],\n",
            "       [0, 0, 1, ..., 1, 0, 1]])), 'X_test': array([[-0.14119944, -0.14622299,  0.04325781, ..., -1.52889821,\n",
            "        -0.13385379,  0.15681423],\n",
            "       [-0.00815081, -0.46876798, -0.16440122, ...,  0.46623542,\n",
            "         0.0483185 , -0.10502403],\n",
            "       [-0.08273124, -1.0186805 ,  1.241534  , ..., -0.29265638,\n",
            "        -2.15610532,  0.5074812 ],\n",
            "       ...,\n",
            "       [ 1.50812198,  1.09638107, -2.24708424, ..., -1.39224186,\n",
            "         0.9818755 , -0.85242999],\n",
            "       [ 0.69743205,  1.68804848, -0.37750316, ...,  0.87036358,\n",
            "        -0.81622109,  0.21803187],\n",
            "       [-0.05217442, -0.73393012, -1.03523011, ..., -0.93347666,\n",
            "         0.54269735, -2.54890062]]), 'y_train': array([ 1.57856925, -4.85201977, -4.31944736, -4.82449359,  8.05982457,\n",
            "        2.61064353, -1.9392001 ,  5.68759882, -1.27354612,  1.06455249,\n",
            "        1.04024534,  0.59886116,  2.97152853, -4.41621479,  0.76294746,\n",
            "        7.95360848, -0.52351239, -1.55791389, -0.41518355,  1.2487652 ,\n",
            "        3.86260915,  1.04010552, -1.73472809, -2.48598303,  0.73267707,\n",
            "       -0.09048095,  1.83995397, -1.54384171,  1.26696743,  1.00068558,\n",
            "        3.29647726, -5.93884341,  7.0048748 , -1.16099472,  1.03655992,\n",
            "        2.39159207, -1.83318631,  1.53399519,  2.00898268,  1.54958943,\n",
            "       -2.98590924,  0.97138291, -2.45801515,  1.0794004 , -1.95393625,\n",
            "       -2.48631023,  0.95637766, -1.76157474, -6.55839129, -2.43994575,\n",
            "       -2.79098028,  1.35044507,  0.96981121,  0.26013951,  0.98964214,\n",
            "       -0.89472437,  3.28624951,  4.94694996,  3.63351364,  3.75803955,\n",
            "       -4.9626079 ,  1.12522734, -3.22136216,  2.63409867, -0.92559134,\n",
            "        2.37579004,  0.57092423, -4.56463022, -2.76083686, -4.42171473,\n",
            "        8.086446  ,  5.92983432, -3.4067377 ,  2.85505366,  3.38121507,\n",
            "       -1.73672013, -1.64297088,  0.97134239, -0.22737064, -4.15465905,\n",
            "        1.21729619, -4.12614029,  4.06427379, -3.64831942,  2.35361123,\n",
            "        1.8286952 ,  1.1660198 , -1.09165402,  2.87614169,  0.54980519,\n",
            "       -3.60516941,  1.10973647,  2.49065916, -6.7290016 ,  4.39463522,\n",
            "       -0.21179038,  0.60923051,  4.47632651,  3.40152972,  0.89159723,\n",
            "        2.70587036, -5.30293319, -3.0627484 , -1.9305731 , -0.06535448,\n",
            "        3.30875053,  3.87846029, -2.16731408,  3.57339677, -2.70228885,\n",
            "       -0.7478314 ,  4.06633796,  2.64469073, -3.74008468, -0.85233153,\n",
            "        8.39511982, -4.26629689, -2.04347769,  0.41365783,  1.01542547,\n",
            "        0.77277482,  3.88986604,  1.68469496, -4.04777408, -0.34733005,\n",
            "       -0.31526787,  4.58331119, -0.98117111,  0.91665275,  0.49180386,\n",
            "        1.07451896, -6.00903492, -1.84929065,  0.41252571,  0.18873986,\n",
            "        1.08376574, -0.38432679, -3.84406528,  2.35532087, -1.46713213,\n",
            "       -0.38951127, -1.19131738,  0.37007411, -2.64425093, -0.9996588 ,\n",
            "       -0.74775735,  2.27962614, -4.37076024,  3.7649719 ,  4.7353076 ,\n",
            "        1.16995909, -2.22608466,  2.30128804, -2.03068555,  0.09872895,\n",
            "        6.47905908, -0.71384232, -4.09534495, -0.50339116,  2.04102623,\n",
            "        6.53111984, -2.13075161, -5.43096996, -2.26245993,  2.80205938,\n",
            "        2.20692314,  0.69352754, -6.99889577, -0.40058023,  3.19501823,\n",
            "        3.04150952,  2.80466834, -1.41221323, -1.92890814,  0.87990197,\n",
            "       -2.37906046, -1.71009112,  4.10115169,  0.65520453,  4.33577785,\n",
            "        0.14653067, -3.08119926, -0.48285085,  3.18916902,  2.45269643,\n",
            "       -5.18963862,  3.74781791,  4.97130806,  2.81073065, -3.51487601,\n",
            "       -3.49867317, -0.80074212,  5.84463162, -5.79941011, -2.20992597,\n",
            "        7.03842026,  5.08937639, -1.87986901,  3.75303683,  4.65379621,\n",
            "        9.75781096, -4.82889637,  3.29876347, -3.11571057,  5.45932662,\n",
            "        1.53099751,  0.69289239, -1.70146112,  5.03864832, -1.36846355,\n",
            "       -4.68547917, -2.54929077,  2.07056757, -2.50985959,  4.73729346,\n",
            "       -1.51012812,  2.3109111 ,  0.01586957, -5.24734091, -1.89244971,\n",
            "       -4.23310893, -0.32127838, -1.98107392, -2.58018036,  2.434724  ,\n",
            "       -2.9296864 ,  1.97367035,  1.3015143 ,  0.04658355, -4.36788853,\n",
            "        1.69991136, -5.43673421, -1.7549887 ,  1.29037501,  3.24567295,\n",
            "       -0.07967188,  1.88158835, -2.75759344, -3.14153647,  4.94498239,\n",
            "       -1.48452412,  2.10310787,  1.87974275,  1.85875446,  3.08057752,\n",
            "        0.97043792, -0.73947261, -6.61001285, -5.16127857, -0.91569713,\n",
            "       -4.14384839,  0.17146692, -0.77391163, -3.6984157 ,  5.34748339,\n",
            "        0.05885876, -0.20531565, -3.05590162, -2.74022729,  1.53940159,\n",
            "       -0.87826218, -5.10567145, -1.12452918, -0.64378149, -1.90059787,\n",
            "        0.75244661, -3.25328959, -0.28792268, -2.95697074,  4.40590619,\n",
            "        5.83868881,  3.65295367,  1.8101783 ,  7.79174818, -0.27491595,\n",
            "        2.71108496,  3.01062124, -5.01059774, -6.79716394,  3.116863  ,\n",
            "       -0.2743092 ,  2.47001258,  1.01365374, -3.04702599,  2.5750477 ,\n",
            "        4.85294206, -1.17136704, -0.65720552,  3.99067744,  2.15428125,\n",
            "       -1.98292125,  4.71812658,  3.26743651,  1.23856745,  1.14468935]), 'y_test': array([-2.01481788, -0.38757976,  3.54586038, ...,  6.61672963,\n",
            "       -1.65162069,  2.21406433]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96387421 0.97688838 0.99070092 1.07263057 0.98792238 0.96947353\n",
            " 0.95135506 1.00202554 0.99825255 1.00904379]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_imputed in experiment_2d_external_dataset  73.45794471838975\n",
            "crush test------------------------------------------------->  73.45794471838975\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8 7 7 8 8 7 5 9 5 6 7 5 7 8 7 8 6 9 5 7 8 7 5 6 8 8\n",
            " 9 5 6 7 3 7 6 6 7 8 8 8 6 6 8 6 8 3 6 5 8 6 6 9 7 7 7 9 9 8 7 6 9 6 4 6 5\n",
            " 6 8 8 3 8 8 4 7 8 6 9 6 8 7 4 8 5 7 6 9 6 6 6 6 9 9 7 9 7 9 9 7 6 8 7 7]\n",
            "S dataset \n",
            " [[1.02516019 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.94853233 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.88592416 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.11742223 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         1.00403801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.89251948\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.025084   0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.89669956 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94463272 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99519016]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (295, 10)\n",
            "y_train length  295\n",
            "-------> size test:  20000  , size train:  295 nbr_full_seen (train):  0  nbr_at_least_one_miss :  295\n",
            "X  295   10\n",
            "y shape (295,)\n",
            "nm  2950\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 38.39it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 44.93it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 43.25it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  7  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.03162278 0.        ] , min score  9.522774227188862\n",
            "---------------------------------> best coeff  [ 1.75616696e+00 -4.13005730e-11  1.51266248e+00  3.70816240e-12\n",
            " -5.72339835e-03 -1.72865951e-10  4.27876534e-01 -1.19828179e-11\n",
            " -1.05529648e-11 -2.97569455e-12]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96387421 0.97688838 0.99070092 1.07263057 0.98792238 0.96947353\n",
            " 0.95135506 1.00202554 0.99825255 1.00904379]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -27.2373457482309\n",
            "crush test------------------------------------------------->  -27.2373457482309\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.96387421 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.97688838 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.99070092 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.07263057 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.98792238 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.96947353\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.95135506 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.00202554 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99825255 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.00904379]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (295, 10)\n",
            "y_train length  295\n",
            "-------> size test:  20000  , size train:  295 nbr_full_seen (train):  295  nbr_at_least_one_miss :  0\n",
            "X  295   10\n",
            "y shape (295,)\n",
            "nm  2950\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 18.05it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 34.32it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 37.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  3.2553396873108846e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96387421 0.97688838 0.99070092 1.07263057 0.98792238 0.96947353\n",
            " 0.95135506 1.00202554 0.99825255 1.00904379]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [83.14993401  2.2547904  11.93715154 39.51831763 21.54473078]\n",
            "crush test------------------------------------------------->  158.4049243630264\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8 7 7 8 8 7 5 9 5 6 7 5 7 8 7 8 6 9 5 7 8 7 5 6 8 8\n",
            " 9 5 6 7 3 7 6 6 7 8 8 8 6 6 8 6 8 3 6 5 8 6 6 9 7 7 7 9 9 8 7 6 9 6 4 6 5\n",
            " 6 8 8 3 8 8 4 7 8 6 9 6 8 7 4 8 5 7 6 9 6 6 6 6 9 9 7 9 7 9 9 7 6 8 7 7]\n",
            "S dataset \n",
            " [[1.02516019 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.94853233 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.88592416 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.11742223 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         1.00403801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.89251948\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.025084   0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.89669956 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94463272 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99519016]]\n",
            "S missing shape\n",
            "  (295, 10, 10)\n",
            "S missing\n",
            "  [[[1.12762062 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.1226109  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.77107967 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.46301174 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.82624441 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.05661357]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.55617372 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.38543407 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.0485032 ]]\n",
            "\n",
            " [[1.21785359 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.88447407 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.67986209 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.34118205]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.42238337 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.22394384 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.79422379 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.50152503 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.72907063]]\n",
            "\n",
            " [[0.45620252 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.7594675  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.02974942 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.71120552]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.95863038 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.61437294 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.48857317]]]\n",
            "shape X_imputed in post_imputation  (5, 295, 10)\n",
            "y_train length  295\n",
            "-------> size test:  20000  , size train:  295 nbr_full_seen (train):  0  nbr_at_least_one_miss :  295\n",
            "X  295   10\n",
            "y shape (295,)\n",
            "nm  2950\n",
            "S_mis in Adbvt training  [[[1.12762062 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.1226109  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.77107967 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.46301174 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.82624441 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.05661357]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.55617372 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.38543407 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.0485032 ]]\n",
            "\n",
            " [[1.21785359 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.88447407 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.67986209 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.34118205]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.42238337 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.22394384 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.79422379 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.50152503 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.72907063]]\n",
            "\n",
            " [[0.45620252 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.7594675  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.02974942 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.71120552]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.95863038 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.61437294 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.48857317]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.03 0.00 ... 0.00 0.00]\n",
            " [0.00 0.95 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.94 0.00]\n",
            " [0.00 0.00 ... 0.00 1.00]] @ Promote(adv_radius_times_dts, (2950, 10)) + [[1.13 0.00 ... 0.00 0.00]\n",
            " [0.00 1.12 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.00 0.00]\n",
            " [0.00 0.00 ... 0.00 0.49]] @ Promote(adv_radius_times_mis, (2950, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:02,  6.39it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01,  7.18it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01,  7.44it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:01,  7.64it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:01,  7.78it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:01,  7.81it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:01,  7.67it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:01<00:00,  7.53it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:01<00:00,  6.99it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:01<00:00,  7.24it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:01<00:00,  7.57it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:01<00:00,  7.69it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:01<00:00,  7.81it/s]\u001b[A\n",
            " 93%|█████████▎| 14/15 [00:01<00:00,  7.84it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00,  7.51it/s]\n",
            " 33%|███▎      | 1/3 [00:02<00:04,  2.00s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:01,  7.39it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01,  7.73it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01,  7.66it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:01,  7.73it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:01,  7.79it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:01,  7.87it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:01,  7.99it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:01<00:00,  7.32it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:01<00:00,  6.83it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:01<00:00,  7.09it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:01<00:00,  7.45it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:01<00:00,  7.54it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:01<00:00,  7.44it/s]\u001b[A\n",
            " 93%|█████████▎| 14/15 [00:01<00:00,  7.59it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:02<00:00,  7.50it/s]\n",
            " 67%|██████▋   | 2/3 [00:04<00:02,  2.00s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:01,  7.54it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01,  8.00it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01,  8.18it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:01,  8.28it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:01,  8.21it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:01,  8.24it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00,  8.24it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00,  8.24it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:01<00:00,  7.96it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:01<00:00,  8.07it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:01<00:00,  8.11it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:01<00:00,  8.12it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:01<00:00,  7.96it/s]\u001b[A\n",
            " 93%|█████████▎| 14/15 [00:01<00:00,  7.96it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00,  8.05it/s]\n",
            "100%|██████████| 3/3 [00:05<00:00,  1.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 1.e-05] , min score  2.1224722485450545\n",
            "---------------------------------> best coeff  [ 1.06416756 -0.20108676  0.42245039  0.87639484 -0.90391486  0.4377993\n",
            "  0.09808296 -0.54206689 -0.75872357 -1.02934911]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96387421 0.97688838 0.99070092 1.07263057 0.98792238 0.96947353\n",
            " 0.95135506 1.00202554 0.99825255 1.00904379]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 8.16 s, sys: 405 ms, total: 8.57 s\n",
            "Wall time: 6.72 s\n",
            "X_imputed in experiment_2d_external_dataset  [95.53639396 -4.54650482 85.63068814 -9.79077836 49.35014265]\n",
            "crush test------------------------------------------------->  216.17994155863332\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8 7 7 8 8 7 5 9 5 6 7 5 7 8 7 8 6 9 5 7 8 7 5 6 8 8\n",
            " 9 5 6 7 3 7 6 6 7 8 8 8 6 6 8 6 8 3 6 5 8 6 6 9 7 7 7 9 9 8 7 6 9 6 4 6 5\n",
            " 6 8 8 3 8 8 4 7 8 6 9 6 8 7 4 8 5 7 6 9 6 6 6 6 9 9 7 9 7 9 9 7 6 8 7 7]\n",
            "S dataset \n",
            " [[1.02516019 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.94853233 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.88592416 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.11742223 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         1.00403801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.89251948\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.025084   0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.89669956 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94463272 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99519016]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 295, 10)\n",
            "y_train length  295\n",
            "-------> size test:  20000  , size train:  295 nbr_full_seen (train):  0  nbr_at_least_one_miss :  295\n",
            "X  295   10\n",
            "y shape (295,)\n",
            "nm  2950\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:00, 42.51it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 45.86it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 45.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.1874239222215053\n",
            "---------------------------------> best coeff  [ 1.31297015  0.23189623  0.75795372  1.11077129 -0.94712952  0.34322413\n",
            "  0.16495188 -0.29338054 -0.76402627 -1.39522819]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.96387421 0.97688838 0.99070092 1.07263057 0.98792238 0.96947353\n",
            " 0.95135506 1.00202554 0.99825255 1.00904379]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  216.17994155863332\n",
            "[7 7 8 7 7 8 6 8 9 8 8 4 8 7 7 9 8 5 5 8 6 7 8 5 7 8 6 8 9 8 3 9 8 8 6 9 6\n",
            " 6 7 7 8 6 8 7 9 9 8 7 9 6 6 7 5 5 6 8 6 9 8 8 8 6 6 8 7 5 7 4 8 8 7 9 6 6\n",
            " 5 5 8 7 7 5 6 7 8 6 7 5 6 9 9 5 6 8 6 6 7 8 6 7 8 8 6 6 7 6 6 5 9 8 8 6 6\n",
            " 8 4 6 4 6 7 6 5 8 9 9 8 6 7 7 7 6 4 9 6 6 5 6 9 6 7 7 8 8 6 6 5 7 9 7 6 5\n",
            " 8 6 5 8 6 8 6 6 8 5 9 5 7 9 6 8 4 8 8 6 9 5 6 7 8 9 6 7 8 7 6 7 8 7 7 7 4\n",
            " 6 6 6 8 6 6 7 8 8 6 5 8 7 7 8 8 7 5 9 5 6 7 5 7 8 7 8 6 9 5 7 8 7 5 6 8 8\n",
            " 9 5 6 7 3 7 6 6 7 8 8 8 6 6 8 6 8 3 6 5 8 6 6 9 7 7 7 9 9 8 7 6 9 6 4 6 5\n",
            " 6 8 8 3 8 8 4 7 8 6 9 6 8 7 4 8 5 7 6 9 6 6 6 6 9 9 7 9 7 9 9 7 6 8 7 7]\n",
            "S dataset \n",
            " [[1.02516019 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.94853233 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.88592416 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.11742223 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         1.00403801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.89251948\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.025084   0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.89669956 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94463272 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99519016]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 295, 10)\n",
            "y_train length  295\n",
            "-------> size test:  20000  , size train:  295 nbr_full_seen (train):  0  nbr_at_least_one_miss :  295\n",
            "X  295   10\n",
            "y shape (295,)\n",
            "nm  2950\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 27.28it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 39.16it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 39.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.1874239222215053\n",
            "---------------------------------> best coeff  [ 1.31297015  0.23189623  0.75795372  1.11077129 -0.94712952  0.34322413\n",
            "  0.16495188 -0.29338054 -0.76402627 -1.39522819]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "x_axis for print in plot_res---->  [100, 200, 300]\n",
            "key in plot_res ('BR_si', 'std_nan', 'adv', 'b') : values\n",
            " {'best_coeff': [array([ 1.69922757, -0.15171203,  0.6149815 ,  0.81787162, -0.68437955,\n",
            "        0.40187532, -0.58880379, -1.13966524, -0.36976909, -1.1061292 ]), array([ 3.81307090e-01, -1.30281742e-10, -4.57582260e-01,  7.23625024e-01,\n",
            "       -1.05765681e+00,  6.00852286e-01, -2.78678692e-01, -8.12113988e-01,\n",
            "       -1.36745608e+00, -1.93224344e+00]), array([ 1.75616696e+00, -4.13005730e-11,  1.51266248e+00,  3.70816240e-12,\n",
            "       -5.72339835e-03, -1.72865951e-10,  4.27876534e-01, -1.19828179e-11,\n",
            "       -1.05529648e-11, -2.97569455e-12])], 'l2_dist_best_coeff_gt': [np.float64(1.821711121937122), np.float64(2.2012627081845304), np.float64(3.0760484850166794)], 'best_score': [np.float64(3.3112424951787602), np.float64(4.866289962873608), np.float64(9.522774227188862)], 'best_hyper_p': [array([ 5., inf]), array([ 2., inf]), array([1.5, inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(2.0), np.float64(1.5)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key in plot_res ('oracle', 'sd', 'adv', 'orange') : values\n",
            " {'best_coeff': [array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895])], 'l2_dist_best_coeff_gt': [np.float64(1.3534487165049819e-11), np.float64(1.4516060545471754e-11), np.float64(1.786535367447329e-11)], 'best_score': [np.float64(1.8660456390432851e-22), np.float64(2.147333860807118e-22), np.float64(3.2553396873108846e-22)], 'best_hyper_p': [array([2.5, inf]), array([2.5, inf]), array([2.5, inf])], 'best_alpha_dts': [np.float64(2.5), np.float64(2.5), np.float64(2.5)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g') : values\n",
            " {'best_coeff': [array([ 1.67507425, -0.059702  , -0.50745558,  0.66150071, -0.51964504,\n",
            "        0.45891016,  0.42969031, -0.16669165, -0.95543941, -0.9384786 ]), array([ 1.07067395, -0.2355901 , -0.08642996,  0.44376903, -0.6254064 ,\n",
            "        0.54277543, -0.07977387, -0.25479589, -0.97749127, -0.85077901]), array([ 1.06416756, -0.20108676,  0.42245039,  0.87639484, -0.90391486,\n",
            "        0.4377993 ,  0.09808296, -0.54206689, -0.75872357, -1.02934911])], 'l2_dist_best_coeff_gt': [np.float64(2.183315220446145), np.float64(2.013824017493696), np.float64(1.4475561096782967)], 'best_score': [np.float64(4.867713851084003), np.float64(4.115311307724778), np.float64(2.1224722485450545)], 'best_hyper_p': [array([5., 5.]), array([5., 5.]), array([5., 5.])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(5.0), np.float64(5.0), np.float64(5.0)]}\n",
            "key in plot_res ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r') : values\n",
            " {'best_coeff': [array([ 1.21498459, -0.22067683, -0.91467831,  0.05923438, -0.79745388,\n",
            "        1.25553143,  0.09450634, -0.51973298, -0.74744078, -1.5007369 ]), array([ 1.18618417, -0.5309376 , -0.16998548,  0.829616  , -1.24527355,\n",
            "        0.49661977,  0.06155747, -0.69094765, -1.18731771, -1.59667863]), array([ 1.31297015,  0.23189623,  0.75795372,  1.11077129, -0.94712952,\n",
            "        0.34322413,  0.16495188, -0.29338054, -0.76402627, -1.39522819])], 'l2_dist_best_coeff_gt': [np.float64(2.511406033147326), np.float64(1.5386312246852507), np.float64(1.467160782630632)], 'best_score': [np.float64(6.408676836502915), np.float64(2.3800433856241883), np.float64(2.1874239222215053)], 'best_hyper_p': [array([ 5., inf]), array([ 5., inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key in plot_res ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple') : values\n",
            " {'best_coeff': [array([ 1.21498459, -0.22067683, -0.91467831,  0.05923438, -0.79745388,\n",
            "        1.25553143,  0.09450634, -0.51973298, -0.74744078, -1.5007369 ]), array([ 1.18618417, -0.5309376 , -0.16998548,  0.829616  , -1.24527355,\n",
            "        0.49661977,  0.06155747, -0.69094765, -1.18731771, -1.59667863]), array([ 1.31297015,  0.23189623,  0.75795372,  1.11077129, -0.94712952,\n",
            "        0.34322413,  0.16495188, -0.29338054, -0.76402627, -1.39522819])], 'l2_dist_best_coeff_gt': [np.float64(2.511406033147326), np.float64(1.5386312246852507), np.float64(1.467160782630632)], 'best_score': [np.float64(6.408676836502915), np.float64(2.3800433856241883), np.float64(2.1874239222215053)], 'best_hyper_p': [array([ 5., inf]), array([ 5., inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(1.821711121937122), np.float64(2.2012627081845304), np.float64(3.0760484850166794)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(1.3534487165049819e-11), np.float64(1.4516060545471754e-11), np.float64(1.786535367447329e-11)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(2.183315220446145), np.float64(2.013824017493696), np.float64(1.4475561096782967)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(2.511406033147326), np.float64(1.5386312246852507), np.float64(1.467160782630632)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(2.511406033147326), np.float64(1.5386312246852507), np.float64(1.467160782630632)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "lb[i] in plot_res  best_score    [np.float64(3.3112424951787602), np.float64(4.866289962873608), np.float64(9.522774227188862)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  best_score    [np.float64(1.8660456390432851e-22), np.float64(2.147333860807118e-22), np.float64(3.2553396873108846e-22)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  best_score    [np.float64(4.867713851084003), np.float64(4.115311307724778), np.float64(2.1224722485450545)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  best_score    [np.float64(6.408676836502915), np.float64(2.3800433856241883), np.float64(2.1874239222215053)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  best_score    [np.float64(6.408676836502915), np.float64(2.3800433856241883), np.float64(2.1874239222215053)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(2.0), np.float64(1.5)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(2.5), np.float64(2.5), np.float64(2.5)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "--------------------------------------------------------------------------------------nbr_experiment external --------------->  2 - 2   2 - 2   2\n",
            "[[], [], []]\n",
            "[]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20300, 10)\n",
            "p_missing in generate mask  [0.3, 1, 1, 1, 1, 1]\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  0\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20100, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   100\n",
            "X shape in clear data  (100, 10)\n",
            "y shape in clear data  (100,)\n",
            "M shape in clear data  (100,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(97, 10)\n",
            "(97, 10)\n",
            "(97,)\n",
            "full masks in run experiment  [[1 0 1 ... 1 0 1]\n",
            " [1 1 0 ... 1 1 1]\n",
            " [1 1 0 ... 0 1 1]\n",
            " ...\n",
            " [0 1 1 ... 1 0 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [1 1 1 ... 0 1 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 9.58296001e-01,  9.86216526e-01, -8.08466849e-01,\n",
            "         3.02956622e-01, -2.44060222e-01,  2.13610989e+00,\n",
            "         2.22873082e-01, -1.10327699e+00, -5.63715480e-01,\n",
            "         1.16694997e+00],\n",
            "       [-8.08406472e-01,  2.03286306e+00,  2.63037033e-01,\n",
            "        -2.96368556e-01,  1.18269225e+00,  2.83038054e-01,\n",
            "        -1.02418274e+00, -1.69833538e-01,  5.55825798e-03,\n",
            "        -2.01270017e+00],\n",
            "       [-1.51662813e+00,  3.23221379e+00, -6.03731108e-01,\n",
            "        -4.22903497e-01,  1.59605833e-01, -1.26546376e+00,\n",
            "        -8.19018459e-01,  2.60732495e-01, -2.21818509e-01,\n",
            "        -1.94125958e+00],\n",
            "       [ 7.00962363e-01,  1.44638641e-01,  1.46845789e-01,\n",
            "         1.08889098e+00,  6.18254763e-01, -5.06838272e-01,\n",
            "         1.45586570e+00,  1.81503363e-01,  1.46218783e+00,\n",
            "         3.25065974e-01],\n",
            "       [ 4.75860049e-01, -1.90842178e+00,  1.21350354e+00,\n",
            "         1.28308334e+00, -5.04704703e-01,  8.98190829e-01,\n",
            "        -5.24177052e-01,  9.08956587e-01, -3.93700738e-01,\n",
            "         1.09513483e+00],\n",
            "       [ 1.93492742e-01, -5.96775741e-01,  2.07691440e+00,\n",
            "        -1.01611194e+00,  7.11889320e-01, -1.23722685e-02,\n",
            "        -3.35040305e-01, -1.75904489e+00,  1.05266761e+00,\n",
            "         1.57815728e-01],\n",
            "       [ 8.22489692e-01, -9.20567528e-01, -6.77505014e-01,\n",
            "        -2.22563178e+00,  6.57897576e-01, -3.01588792e-02,\n",
            "         9.05889347e-01,  2.14916220e-01, -1.71681366e+00,\n",
            "         7.01876687e-01],\n",
            "       [-1.00159560e+00, -2.11251259e-02, -3.91572639e-01,\n",
            "         1.44501700e+00, -1.74106318e+00,  7.68236940e-02,\n",
            "        -5.89575046e-01, -1.60090403e+00,  4.17678465e-01,\n",
            "        -1.21453541e+00],\n",
            "       [ 6.34730970e-01,  1.43842599e+00, -1.79125355e-01,\n",
            "        -1.22524491e+00, -3.84914403e-01, -5.55613259e-01,\n",
            "        -6.26746459e-01, -2.06111810e+00,  6.44172083e-01,\n",
            "        -2.62734375e+00],\n",
            "       [-5.27204150e-01,  4.86789959e-01, -1.87419395e+00,\n",
            "        -1.74617736e-01, -4.47849441e-01,  1.42722523e+00,\n",
            "         2.48761631e-02, -6.30516012e-01, -3.99806654e-01,\n",
            "        -4.08763784e-01],\n",
            "       [ 4.69970419e-01,  1.33756423e+00,  4.65867555e-01,\n",
            "         1.18098969e-01,  1.57374803e-01, -9.46190026e-02,\n",
            "         1.26535298e-01, -1.46992517e-01,  3.95469777e-01,\n",
            "        -4.70660747e-01],\n",
            "       [-2.10904240e-02, -1.10143471e+00,  1.30757325e+00,\n",
            "         2.30371404e+00, -1.09829372e+00, -1.65412967e+00,\n",
            "         1.28297436e+00, -2.65079170e-01,  1.31393094e+00,\n",
            "         1.06202086e+00],\n",
            "       [ 1.81842141e+00,  3.70041568e-01, -6.93115317e-02,\n",
            "         2.19581805e+00, -4.36136774e-01, -8.16788929e-01,\n",
            "        -3.99306351e-01, -4.01062652e+00, -3.30336405e-02,\n",
            "         1.37632225e+00],\n",
            "       [ 9.20865345e-02,  6.15518500e-01, -1.66678424e+00,\n",
            "         1.94423150e+00,  2.46609725e+00,  1.12929857e+00,\n",
            "         7.06761871e-01, -1.31441665e+00,  1.02114948e+00,\n",
            "         4.50765437e-01],\n",
            "       [-4.72355224e-02, -8.99701762e-02,  1.07353187e+00,\n",
            "         5.72864192e-01, -1.76097823e+00, -1.19957284e+00,\n",
            "        -3.35486443e-01, -8.12587102e-01, -6.95308360e-01,\n",
            "        -1.87698636e-01],\n",
            "       [-1.34475616e+00,  1.67215939e+00, -7.81077326e-01,\n",
            "        -3.21203429e-01,  7.07668568e-01,  4.96139173e-01,\n",
            "        -1.99241958e-01, -1.45778739e+00, -2.92816481e-01,\n",
            "        -8.37977328e-01],\n",
            "       [-4.03579054e-01, -1.22237670e+00, -1.72790890e-01,\n",
            "        -2.54230413e+00, -4.52244710e-02,  2.06958710e+00,\n",
            "         1.17778301e-03,  7.09513587e-01,  9.78934924e-01,\n",
            "        -2.96683498e-01],\n",
            "       [ 2.60228085e+00,  5.60383914e-02,  3.13130174e-01,\n",
            "        -1.27182617e+00,  1.38648777e+00,  4.95471102e-01,\n",
            "         8.08542206e-01, -7.18007079e-02,  8.97295715e-01,\n",
            "         1.19264731e-01],\n",
            "       [-7.36317965e-02,  7.42957066e-01, -1.09722336e+00,\n",
            "        -3.63346094e-01, -2.99905215e-01,  3.78600892e-01,\n",
            "         3.43442304e-01, -1.15895826e+00, -2.06759511e-01,\n",
            "         3.83406416e-02],\n",
            "       [ 1.89539770e-01, -1.13729010e+00,  1.13792587e+00,\n",
            "        -5.30296981e-01, -1.55229614e+00, -1.22443161e-01,\n",
            "         6.05729879e-01, -4.17923076e-01, -8.02117232e-01,\n",
            "        -1.22918195e+00],\n",
            "       [ 7.27707450e-01,  1.73569425e-01,  8.87643239e-01,\n",
            "         1.00295923e+00,  1.71703255e-03,  9.38774122e-01,\n",
            "        -6.94312711e-01, -2.91026501e-01, -1.89544560e+00,\n",
            "         4.06355111e-01],\n",
            "       [ 1.40319274e+00,  9.42223539e-02, -8.14579440e-01,\n",
            "         2.00128261e-01,  4.97202114e-01, -3.58923742e-01,\n",
            "        -8.26397297e-01,  6.34213467e-01, -2.53713716e+00,\n",
            "         1.77159387e+00],\n",
            "       [ 3.54917694e-01, -9.22561859e-01, -5.60503056e-01,\n",
            "        -6.57577475e-01, -3.80414876e-01,  6.51123142e-04,\n",
            "         1.48926543e+00,  2.91926428e-01, -5.11306465e-01,\n",
            "         1.25081138e+00],\n",
            "       [ 7.30317920e-01,  1.34588415e+00,  7.50878184e-02,\n",
            "         4.52567148e-01, -9.57892454e-01,  9.96197857e-01,\n",
            "        -4.13758778e-01, -1.09333075e+00,  1.21049508e-01,\n",
            "         1.23190397e-01],\n",
            "       [-1.58549566e+00,  3.20945771e-01, -2.51475063e-01,\n",
            "        -2.56040218e-01, -3.00567650e-02,  7.87215749e-01,\n",
            "        -2.82429230e-01,  6.67713429e-01, -6.08290672e-01,\n",
            "        -1.15173140e+00],\n",
            "       [-1.01003283e-01,  1.57390247e+00, -1.98359302e+00,\n",
            "         1.67444545e-01,  5.92927166e-01, -9.88181970e-01,\n",
            "         2.27498889e+00, -2.47977199e-01,  8.11006425e-01,\n",
            "         3.70939119e-01],\n",
            "       [-5.20535908e-01, -1.51144973e+00,  7.93844861e-01,\n",
            "         2.00916828e-01,  3.96574252e-01,  3.61089317e-01,\n",
            "         5.25771638e-01, -1.17695676e+00,  4.69681370e-01,\n",
            "         9.73799101e-01],\n",
            "       [ 3.86192847e-02,  5.50278802e-01,  1.48043788e-01,\n",
            "         9.52019287e-01, -6.31215942e-01,  1.99433741e-03,\n",
            "         9.61983014e-01, -7.00872408e-01,  3.52199932e-01,\n",
            "         1.18576710e+00],\n",
            "       [-8.06109747e-01, -4.45062108e-01, -6.89015023e-01,\n",
            "        -4.70121503e-01,  7.49505760e-01,  6.60880999e-01,\n",
            "         1.63154110e+00,  1.47129905e+00,  1.40466350e+00,\n",
            "         3.51919313e-01],\n",
            "       [ 1.96137398e+00, -3.57310297e-01,  5.55085131e-01,\n",
            "         2.99814481e-01,  3.66174641e-01, -5.52935302e-01,\n",
            "        -2.10827113e-02, -6.44881338e-01,  2.55567466e+00,\n",
            "         1.58014407e+00],\n",
            "       [-8.80471706e-01,  1.11987640e-01,  1.07366584e+00,\n",
            "        -2.29089016e-01,  7.11314860e-01, -1.36177587e+00,\n",
            "         4.59698697e-01, -1.12539700e+00,  3.56184408e-01,\n",
            "        -1.31799031e+00],\n",
            "       [-4.57317325e-01, -8.24720530e-01, -5.71045018e-01,\n",
            "         7.75419700e-01, -8.51631750e-01, -1.57903565e+00,\n",
            "        -1.11702051e+00, -5.96136053e-01, -1.24995206e-01,\n",
            "         1.33368312e+00],\n",
            "       [ 2.33116025e-01, -1.56985473e-01, -1.59355852e+00,\n",
            "        -2.87393924e-01,  1.45472064e+00,  6.24636062e-01,\n",
            "         9.09922003e-01, -1.20785675e-01,  5.63158062e-01,\n",
            "        -9.14611480e-02],\n",
            "       [-3.64982200e-01,  5.25653495e-01,  3.18143133e-01,\n",
            "         2.57576911e-01, -4.04311055e-01,  3.97848223e-01,\n",
            "        -6.66781845e-01, -8.25476364e-01,  9.24333519e-01,\n",
            "        -5.54110751e-01],\n",
            "       [ 7.24916539e-01,  5.83871344e-02, -8.24072572e-01,\n",
            "         1.67340095e-02,  1.58391747e+00, -2.05661754e-01,\n",
            "        -7.63575153e-01,  2.64115406e+00, -6.48941021e-01,\n",
            "        -2.44504987e-01],\n",
            "       [ 4.19349590e-02,  5.34474330e-01,  6.60054121e-01,\n",
            "        -1.29654750e-01, -8.77261529e-01,  8.85094228e-01,\n",
            "        -2.08969735e-01,  8.39872356e-01,  7.94452017e-01,\n",
            "         1.12964788e+00],\n",
            "       [ 9.52979003e-01, -7.34171984e-01,  2.42718134e-01,\n",
            "         1.69237518e+00, -1.43576152e-01, -1.19329049e+00,\n",
            "         5.76536911e-01, -2.49719667e-01,  2.81326496e+00,\n",
            "         1.24697226e+00],\n",
            "       [-1.00838444e+00,  3.91863601e-01,  5.25199400e-01,\n",
            "         3.93531203e-01,  8.51441403e-01,  7.00613727e-01,\n",
            "        -4.86123927e-01, -1.76428171e-01,  2.66161060e-01,\n",
            "        -1.31321240e+00],\n",
            "       [-1.35758037e+00,  8.18517031e-01,  6.79713773e-01,\n",
            "        -1.12335987e+00, -1.32718268e+00, -1.07341747e+00,\n",
            "        -1.17615080e-02, -1.43926435e+00, -1.21703541e+00,\n",
            "        -6.44826086e-01],\n",
            "       [-6.31798324e-01,  5.01994670e-01, -1.12922330e+00,\n",
            "        -2.30861953e-01, -4.70831587e-01, -5.95057796e-01,\n",
            "         1.79884038e+00, -2.00561681e-01,  1.57140861e+00,\n",
            "         1.06351128e+00],\n",
            "       [ 4.39035762e-02,  8.98942449e-01, -1.54646078e+00,\n",
            "         8.16865510e-01,  1.52902849e-01,  1.27620431e+00,\n",
            "        -2.42766474e-02,  7.95077891e-01,  2.61691688e-01,\n",
            "        -4.97187490e-01],\n",
            "       [-1.00065651e+00,  5.22525172e-01,  1.03566927e+00,\n",
            "         1.37820797e+00,  7.03778232e-01,  1.52819853e+00,\n",
            "        -3.58274619e-01, -7.58029915e-01,  1.77179457e+00,\n",
            "         7.56437907e-01],\n",
            "       [ 3.37991886e-01,  2.02878728e-01,  4.75117184e-01,\n",
            "         7.67659179e-01, -2.23378254e-01,  3.57143950e-01,\n",
            "        -1.21003865e+00,  4.69668782e-01,  6.36831376e-01,\n",
            "         3.64505581e-01],\n",
            "       [-9.77385165e-01,  5.84410637e-01,  6.77851844e-01,\n",
            "        -1.50251309e+00,  3.65241811e-01,  6.78614453e-01,\n",
            "        -2.22473638e+00, -4.63162591e-01,  1.70212942e+00,\n",
            "         2.54874602e-01],\n",
            "       [-1.08083437e+00,  2.87955952e-01, -1.21439683e+00,\n",
            "        -1.87791865e-01,  8.89866187e-01,  4.86091787e-01,\n",
            "         1.28656452e+00, -1.09939306e-01,  9.53017935e-01,\n",
            "        -1.76737567e-01],\n",
            "       [-1.86514462e+00,  6.10192826e-01,  2.30497339e-01,\n",
            "         7.64926228e-01, -8.50228986e-01, -4.69838604e-02,\n",
            "         1.41937615e+00, -6.85704255e-01, -5.90441540e-01,\n",
            "        -2.99497092e-01],\n",
            "       [-3.70908169e-01,  3.13233756e+00,  5.25641522e-02,\n",
            "         1.60421334e-01,  5.18624654e-01,  1.77831837e-01,\n",
            "        -1.09067404e+00,  8.89761630e-01,  1.74167153e-02,\n",
            "        -6.50425927e-01],\n",
            "       [-6.55962539e-01, -2.99580934e-01,  7.73321585e-02,\n",
            "         2.97526770e-01, -7.24224862e-01,  6.51962502e-01,\n",
            "         1.41806543e-01, -1.00364003e+00, -4.94991700e-01,\n",
            "        -1.33870608e+00],\n",
            "       [-2.68902685e-01, -3.67976921e-01,  6.26348256e-01,\n",
            "        -7.83414094e-01, -2.29838992e-01, -1.14875206e+00,\n",
            "         1.96658233e+00, -3.40025614e-01,  3.69461416e-01,\n",
            "        -3.24277238e-01],\n",
            "       [-4.33068912e-01, -8.73778569e-02, -1.33753579e+00,\n",
            "         8.75169899e-02, -2.05161395e+00, -5.40103045e-01,\n",
            "         1.22561242e-01, -6.71387622e-01,  7.48443750e-01,\n",
            "        -1.39627786e+00],\n",
            "       [-9.17086671e-01, -1.20225333e+00,  4.91141379e-01,\n",
            "        -1.56673209e+00,  1.11432339e+00, -7.56445836e-01,\n",
            "         4.66244924e-01, -5.30835503e-02,  1.72813141e+00,\n",
            "         2.73812639e-01],\n",
            "       [-2.43890357e-01, -2.18596000e-01,  1.09146479e+00,\n",
            "        -1.35948471e+00, -9.36941847e-01, -5.76540252e-02,\n",
            "         4.76734909e-01, -5.24011806e-01, -7.57319921e-01,\n",
            "         6.91522956e-01],\n",
            "       [-7.74795011e-02, -9.64858861e-01,  9.16652919e-02,\n",
            "         7.84690319e-02,  1.25379175e-01, -2.54522970e+00,\n",
            "         8.31366676e-01,  1.29120777e+00,  3.34165034e-01,\n",
            "         1.83273531e+00],\n",
            "       [ 8.68663374e-01, -2.14873379e+00, -2.23422120e+00,\n",
            "        -1.03997381e+00,  4.41912599e-01,  3.74143632e-01,\n",
            "         2.99027909e-01, -3.13650971e-02,  4.59841658e-01,\n",
            "        -2.47483467e+00],\n",
            "       [ 1.47998565e+00,  2.68970426e-01, -8.80072640e-01,\n",
            "        -1.13765106e+00,  1.64718591e+00,  9.19898021e-01,\n",
            "        -1.14100512e+00,  3.44589756e-01,  7.83214002e-01,\n",
            "         4.08577144e-01],\n",
            "       [ 5.06481597e-01,  1.78870630e-01,  3.73270633e-01,\n",
            "        -7.06179470e-01, -9.64895635e-02,  5.87438615e-01,\n",
            "        -7.94642633e-01,  4.88338661e-01,  2.00145978e+00,\n",
            "        -1.92205056e+00],\n",
            "       [ 2.42783733e-02, -1.04435831e+00,  7.10607632e-01,\n",
            "        -5.83789667e-01, -6.95021171e-01, -2.00089630e+00,\n",
            "        -2.86286029e+00,  2.45542632e-01, -1.42914842e+00,\n",
            "         2.02468719e-01],\n",
            "       [-1.33967834e+00,  1.09536644e+00, -2.85898206e-02,\n",
            "        -4.60620883e-02,  5.27198640e-03,  6.82407992e-01,\n",
            "        -9.28917759e-01, -2.63441400e+00, -2.16453028e+00,\n",
            "         1.28607724e-01],\n",
            "       [-1.55185635e+00, -3.29574243e-01,  5.33823429e-01,\n",
            "        -1.85663419e+00,  5.75851738e-01, -4.83362577e-01,\n",
            "        -1.72261827e+00, -1.84690738e+00,  8.32359533e-01,\n",
            "        -1.66541329e+00],\n",
            "       [ 2.24215674e+00, -2.08917723e-01, -1.50314501e+00,\n",
            "         6.78079032e-01,  7.64582867e-01,  9.78373738e-01,\n",
            "         1.04720659e+00,  5.11240477e-02,  1.37196656e-01,\n",
            "        -6.89528946e-01],\n",
            "       [ 7.14839315e-02, -3.23274446e-01, -9.90672644e-01,\n",
            "         6.55566315e-01,  1.81204060e+00, -8.91609850e-02,\n",
            "         7.33628035e-01,  1.07250215e+00, -6.64223982e-02,\n",
            "         1.24148928e+00],\n",
            "       [-2.58845657e-02,  7.59286768e-01, -1.78530145e-01,\n",
            "        -4.87237919e-02, -7.73302511e-01, -4.34587172e-01,\n",
            "         2.31733840e+00,  5.27883514e-01, -5.66393825e-01,\n",
            "         2.37244794e-01],\n",
            "       [ 7.15145399e-02, -1.10267894e+00,  3.78897559e-01,\n",
            "        -1.77575763e+00, -7.81515822e-01,  1.91210465e+00,\n",
            "         5.17547875e-01, -5.20011514e-01, -1.15536817e-03,\n",
            "        -8.07947083e-01],\n",
            "       [-4.15663086e-01,  2.09993431e-01,  1.23117042e-01,\n",
            "        -4.45649917e-01, -2.45534785e-01, -4.56571246e-01,\n",
            "         2.83099573e+00, -6.79326173e-01, -7.29410391e-01,\n",
            "        -7.60281207e-01],\n",
            "       [-5.63464583e-01,  9.60124669e-01, -5.50240412e-01,\n",
            "        -1.12606002e+00,  8.11492051e-01, -6.79427838e-01,\n",
            "        -1.44074430e+00,  1.67487070e-01, -1.38475363e+00,\n",
            "        -1.15391178e+00],\n",
            "       [ 1.17840994e+00,  2.01949805e-01,  1.96863077e-01,\n",
            "        -6.56270945e-01,  7.13097091e-01,  8.66315298e-01,\n",
            "         7.49699336e-02,  7.85065211e-01,  9.50055831e-02,\n",
            "        -1.26240092e+00],\n",
            "       [ 1.36377745e+00,  8.06290769e-01, -1.40517291e+00,\n",
            "        -1.01700727e-01, -7.98644534e-01, -1.78082509e+00,\n",
            "         5.39104999e-01,  7.97486600e-01, -9.12684517e-01,\n",
            "        -5.64378855e-02],\n",
            "       [-4.56756053e-01, -2.75383881e+00,  1.78760801e+00,\n",
            "         1.99183986e-02,  2.93595587e-01,  5.03143969e-01,\n",
            "         4.22097976e-01,  5.17934362e-01, -6.01624491e-02,\n",
            "        -5.12643190e-01],\n",
            "       [ 1.09949542e+00, -2.81801014e-01, -2.05915552e+00,\n",
            "         1.70468269e+00, -1.67180306e+00, -5.35202415e-01,\n",
            "         8.77700621e-02, -1.37585984e+00, -9.88464306e-03,\n",
            "        -5.00313948e-01],\n",
            "       [-1.06376295e-01, -1.90068988e+00,  8.51353912e-01,\n",
            "         4.36102999e-01,  5.75541638e-01,  6.88956252e-01,\n",
            "         6.89526593e-01, -1.84222296e-01, -1.14133989e+00,\n",
            "         1.20257099e+00],\n",
            "       [ 3.53169058e-01,  3.27845087e-01, -1.99113203e+00,\n",
            "        -2.12629795e-01,  1.80413112e-01,  1.07725938e+00,\n",
            "         1.78079825e-01,  4.21645105e-01,  1.45125909e+00,\n",
            "         4.37432415e-01],\n",
            "       [ 2.14256141e-01, -1.01792922e+00,  2.99329357e-01,\n",
            "         1.39345831e+00,  1.51717234e-01, -9.21249108e-01,\n",
            "         7.36353006e-01,  1.30803051e-01, -1.53620515e+00,\n",
            "        -3.24512638e-01],\n",
            "       [ 3.80631698e-01,  1.39311362e-01, -1.83688714e+00,\n",
            "         3.89811871e-01, -6.84637350e-01, -1.05719880e+00,\n",
            "         1.46734295e+00, -4.07822227e-01, -5.55290769e-01,\n",
            "        -2.07495505e-01],\n",
            "       [ 1.53402908e+00,  2.01680703e+00, -4.92672579e-01,\n",
            "         7.65880198e-01, -1.67512893e-01, -7.01099733e-02,\n",
            "         1.12055745e-01,  8.95733450e-01, -1.68493218e+00,\n",
            "         2.22411673e-01],\n",
            "       [-1.37794154e+00,  3.30376621e-01, -1.02648798e+00,\n",
            "         1.37824370e+00, -1.72956693e+00, -4.58683085e-01,\n",
            "        -6.87905121e-01,  2.12208012e-01, -2.34633604e-01,\n",
            "        -2.12277386e+00],\n",
            "       [-2.65555296e+00,  6.87910700e-01, -2.12875245e-01,\n",
            "        -2.20407065e-01,  7.57238063e-01, -2.56270089e-01,\n",
            "         1.31803351e+00,  7.34641722e-01, -2.34281490e-01,\n",
            "        -2.83500603e+00],\n",
            "       [-3.92646705e-01, -1.09309017e-01, -1.54272930e+00,\n",
            "         8.91265691e-01, -4.01987126e-01, -1.30501639e-01,\n",
            "        -7.19504106e-01,  2.14432058e+00,  3.44111906e-02,\n",
            "         2.37979783e-01],\n",
            "       [-1.25219783e+00, -1.14504063e+00,  1.76176818e-01,\n",
            "        -4.40928341e-01, -1.66355066e+00, -2.63340394e+00,\n",
            "        -7.97950312e-01,  3.69839762e-01, -1.38917222e-01,\n",
            "        -1.13491661e+00],\n",
            "       [ 5.42720859e-03,  2.99399361e-01, -1.32090686e+00,\n",
            "         2.60819006e-01, -2.23678790e+00, -8.61941082e-01,\n",
            "         8.49187263e-01,  8.33136532e-02, -1.34303318e+00,\n",
            "         1.36874586e+00],\n",
            "       [-2.24930681e-03, -6.98736266e-01, -1.91296746e+00,\n",
            "         1.08458442e+00,  1.52946671e+00,  2.73681313e-01,\n",
            "         1.26443816e+00, -2.13896243e+00,  3.48691565e-01,\n",
            "         2.26423672e+00],\n",
            "       [-5.73570310e-01,  2.44435997e-01,  6.69443059e-01,\n",
            "         7.99641033e-01,  6.34733366e-01,  1.45211141e+00,\n",
            "         1.49635066e+00,  6.19809798e-01,  6.17964542e-01,\n",
            "         1.03876944e+00],\n",
            "       [-9.40433191e-01,  2.04134601e+00, -1.45127859e-01,\n",
            "         3.72932167e-01, -1.80153255e-02, -1.16048451e+00,\n",
            "         1.33942428e+00,  5.89676593e-01, -6.89682276e-01,\n",
            "        -8.84286496e-01],\n",
            "       [-5.70235934e-01, -1.06258574e+00, -2.83575977e+00,\n",
            "        -7.06509183e-01,  4.43000220e-02,  1.46946606e+00,\n",
            "         8.93518980e-01, -1.90213664e-01, -3.53948804e-02,\n",
            "         1.58801407e+00],\n",
            "       [-1.30024659e+00,  3.24664042e-01,  1.93579275e+00,\n",
            "        -1.91323930e+00,  1.37955095e+00,  1.87013666e+00,\n",
            "        -1.39092429e+00,  4.76622029e-01,  5.01678521e-01,\n",
            "         3.18032183e-01],\n",
            "       [-9.94049529e-01,  3.08792568e-01,  3.18622576e-01,\n",
            "        -1.32695295e+00, -5.91760518e-01,  1.09920383e+00,\n",
            "         5.78989951e-01,  6.00440786e-01,  1.08683282e+00,\n",
            "        -3.23550060e+00],\n",
            "       [-3.93104954e-01, -7.19092617e-02,  4.61090394e-01,\n",
            "         5.13558694e-01, -1.43731109e+00,  6.39787076e-01,\n",
            "         9.22018616e-01,  8.72922326e-01,  1.92155010e+00,\n",
            "         8.30072660e-01],\n",
            "       [ 1.03102524e+00,  1.48126047e+00, -7.03228027e-01,\n",
            "         4.71519748e-01,  5.29489445e-01, -3.53431416e-01,\n",
            "        -5.64813371e-01,  1.44274449e+00,  1.89275994e+00,\n",
            "         1.51055554e+00],\n",
            "       [ 1.47633889e+00, -2.51293166e-01,  1.61002814e-01,\n",
            "         1.97128180e-01, -2.07112512e-01, -5.69557847e-01,\n",
            "         2.62231134e-01, -6.17748222e-01,  7.38864657e-01,\n",
            "        -9.96941095e-01],\n",
            "       [ 7.89024883e-01,  2.67188591e-01,  2.05610011e-01,\n",
            "        -7.94614459e-01, -7.11258650e-02, -1.09212556e+00,\n",
            "        -5.71708714e-01,  7.05104565e-01, -8.45641656e-01,\n",
            "        -1.02919402e-01],\n",
            "       [ 6.83663244e-01,  9.06723505e-01,  9.82578889e-01,\n",
            "        -9.43182094e-01, -4.14366819e-01, -8.16748803e-01,\n",
            "         4.83495652e-01, -1.84157492e+00,  1.10640971e+00,\n",
            "         5.84109765e-01],\n",
            "       [ 1.06605222e+00,  1.71205130e+00, -2.46746129e+00,\n",
            "         1.43355383e-01, -7.72642988e-01,  1.15868060e+00,\n",
            "         1.53694635e-01,  1.01663010e-01, -7.92393248e-01,\n",
            "         1.49467299e+00],\n",
            "       [ 5.56177708e-02, -8.38183334e-01,  8.64153121e-01,\n",
            "        -1.24860514e-01, -2.74225663e-01, -8.76308795e-01,\n",
            "        -1.49950510e+00, -8.71039045e-02, -1.49897155e+00,\n",
            "        -1.55086279e+00],\n",
            "       [ 2.38917201e+00, -8.52081714e-01, -6.45242578e-02,\n",
            "        -2.21888550e-01,  6.47963883e-01, -7.46642747e-01,\n",
            "        -4.12123941e-01, -1.14262096e+00, -1.05939964e+00,\n",
            "        -3.34254897e-01],\n",
            "       [-2.91606171e-01,  3.59681175e-01, -1.18195052e+00,\n",
            "         1.30100717e+00,  9.05103641e-01, -3.70763752e-01,\n",
            "         6.52283550e-02, -3.77722687e-01,  6.17895937e-01,\n",
            "         1.95742968e+00],\n",
            "       [ 4.97818223e-01, -1.04928507e+00,  8.81702911e-01,\n",
            "         1.11402669e-01,  6.56246293e-01,  3.02442369e-01,\n",
            "        -6.91403343e-01, -7.78281663e-02,  7.48085237e-01,\n",
            "         1.80398074e+00],\n",
            "       [-1.00762448e+00,  1.84613750e-01,  3.43318152e-01,\n",
            "        -6.96324046e-01, -1.42772560e+00,  2.83936789e-01,\n",
            "        -9.62142898e-02,  7.52847649e-01, -4.48568311e-02,\n",
            "        -2.22925723e-01],\n",
            "       [ 2.85095532e-01, -1.39331644e+00, -4.37466800e-02,\n",
            "        -1.27081738e+00, -1.29317888e+00, -1.47549494e-02,\n",
            "        -8.29939682e-01, -5.47827560e-02,  4.47317704e-01,\n",
            "         1.44623493e-01]]), array([[1, 0, 1, 1, 0, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 0, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 0, 0, 1, 1, 0],\n",
            "       [0, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [0, 0, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 0, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
            "       [1, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "       [1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 0, 0, 0, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 0, 1, 1, 0],\n",
            "       [0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
            "       [0, 0, 0, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 0, 1, 0],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 0, 1, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 0, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 0, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 1, 0, 0, 1, 0, 1, 0],\n",
            "       [0, 1, 0, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 1, 0, 0, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0, 1, 0, 0, 1],\n",
            "       [0, 0, 1, 1, 0, 1, 0, 0, 0, 1],\n",
            "       [1, 1, 1, 0, 0, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 0, 0, 0, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 0, 0, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [0, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 0, 0, 1, 0, 0],\n",
            "       [1, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 0, 0, 1, 0, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
            "       [1, 1, 0, 0, 0, 1, 0, 0, 1, 1],\n",
            "       [1, 0, 0, 1, 0, 1, 1, 0, 1, 0],\n",
            "       [1, 0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 0, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 0, 1, 1, 0, 1, 0],\n",
            "       [0, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [0, 1, 0, 1, 1, 0, 1, 0, 0, 1],\n",
            "       [1, 0, 1, 0, 1, 0, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 0, 1, 1, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
            "       [1, 0, 0, 1, 0, 1, 1, 0, 1, 0],\n",
            "       [1, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n",
            "       [0, 1, 0, 1, 0, 0, 1, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],\n",
            "       [0, 0, 1, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 0, 0, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [0, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 0, 1, 0, 0, 1, 1, 0, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
            "       [0, 0, 1, 1, 1, 1, 0, 1, 1, 0],\n",
            "       [1, 0, 1, 1, 0, 0, 0, 1, 0, 1]])), 'X_test': array([[ 0.04065001, -0.11911612,  0.87272876, ...,  0.34464194,\n",
            "         1.62100985, -0.48836206],\n",
            "       [-0.95396812,  0.65372847, -0.168279  , ...,  1.04919495,\n",
            "         0.22490218, -0.91851888],\n",
            "       [-0.79335864,  0.09122691, -1.86481623, ...,  0.94127311,\n",
            "        -0.40799434, -0.70072626],\n",
            "       ...,\n",
            "       [-0.66564334, -0.26360987, -0.62031519, ...,  0.03497082,\n",
            "         1.26454076,  0.75160116],\n",
            "       [ 0.64394513, -0.25600669,  1.01881115, ..., -0.14770578,\n",
            "         3.18812599, -1.09570717],\n",
            "       [ 0.17857243,  0.75805462,  1.20716663, ..., -0.46339613,\n",
            "         0.10727545, -0.87543808]]), 'y_train': array([ 3.87392119e+00, -8.77489430e-01, -3.07300619e+00, -9.95799912e-01,\n",
            "        2.85314186e+00,  4.58158244e-01, -8.95914722e-01,  4.86264885e+00,\n",
            "        3.92420991e+00,  9.28200743e-01,  1.04483595e+00,  1.76309913e+00,\n",
            "        7.90135006e+00, -2.19585637e+00,  5.16659828e+00, -8.44543877e-01,\n",
            "       -3.32912527e+00,  3.18144737e-01,  9.51075519e-01,  6.60367633e+00,\n",
            "        5.97758891e+00,  7.32388134e-01, -4.57962592e-01,  4.55004409e+00,\n",
            "       -8.84643381e-01, -3.98731468e+00, -9.70919625e-02,  1.41486287e+00,\n",
            "       -6.25501816e+00, -1.96493561e+00, -9.69318355e-02, -1.70089440e+00,\n",
            "       -3.13921037e+00,  9.44548677e-01, -4.52872618e+00, -1.10506355e+00,\n",
            "       -2.18985872e+00, -9.41858763e-02,  2.56786872e+00, -4.57608227e+00,\n",
            "       -4.89685547e-01, -1.57643038e+00, -1.21876618e-01, -5.72420076e+00,\n",
            "       -4.28754081e+00,  2.06350298e+00, -2.20417582e+00,  4.71533111e+00,\n",
            "       -4.62846003e-03,  2.31072761e+00, -7.22812044e+00,  1.65487878e+00,\n",
            "       -6.10468963e+00,  6.79801353e-01, -4.06223656e+00, -4.22831155e-01,\n",
            "       -3.92908718e-01,  3.95335181e+00, -2.76721712e+00,  3.55922845e+00,\n",
            "       -5.23067763e+00,  1.40492855e+00,  3.42079685e+00,  3.12695077e+00,\n",
            "       -2.00044902e+00,  1.46214207e+00,  8.34556143e-01,  1.68614292e+00,\n",
            "        5.93584784e+00,  1.78067355e+00, -3.96282928e+00,  3.98220021e+00,\n",
            "        1.59611323e+00,  3.66997854e+00,  2.91101385e+00, -2.28873658e+00,\n",
            "       -3.88435487e+00, -1.08376473e+00,  2.08229206e+00, -2.69372290e+00,\n",
            "       -1.29418022e+00, -4.04542748e-01, -4.19501312e+00, -5.01584835e+00,\n",
            "        1.20699639e+00, -1.27811718e+00, -6.45751018e+00,  3.51717647e+00,\n",
            "       -1.34969046e-01,  9.11668503e-01,  5.75336980e-01,  3.95000222e+00,\n",
            "        4.92979365e+00, -4.69928672e+00, -2.40826837e+00, -2.25572014e-01,\n",
            "       -1.77800799e-02]), 'y_test': array([-1.68035763, -1.43072336, -2.71181276, ..., -5.77844636,\n",
            "       -1.63276574,  4.60769535]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97386823 1.0307547  1.02181154 0.96391889 0.92616805 0.97331432\n",
            " 1.00141201 0.99413902 1.03010236 1.15435072]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -90.64957076772453\n",
            "crush test------------------------------------------------->  -90.64957076772453\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5]\n",
            "S dataset \n",
            " [[0.97102972 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.7642783  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.9944259  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.86397167 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.87352538 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01649395\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.09680186 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.17531034 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94934194 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.02703415]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 94.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.01 0.  ] , min score  2.836527575979336\n",
            "---------------------------------> best coeff  [ 1.03876401  0.01311614  0.78364583  0.9639556  -1.84064869 -0.20065582\n",
            "  0.79384503 -1.63551029 -2.08721368 -0.45415686]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97386823 1.0307547  1.02181154 0.96391889 0.92616805 0.97331432\n",
            " 1.00141201 0.99413902 1.03010236 1.15435072]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -11.71669910649834\n",
            "crush test------------------------------------------------->  -11.71669910649834\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "S dataset \n",
            " [[0.97386823 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.0307547  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.02181154 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.96391889 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92616805 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.97331432\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.00141201 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.99413902 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         1.03010236 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.15435072]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  97  nbr_at_least_one_miss :  0\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 79.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.01 0.  ] , min score  4.865703757227807e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97386823 1.0307547  1.02181154 0.96391889 0.92616805 0.97331432\n",
            " 1.00141201 0.99413902 1.03010236 1.15435072]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [-73.61448677 -85.40145438 -74.22668775 -98.47958496 -93.82015859]\n",
            "crush test------------------------------------------------->  -425.54237244649204\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5]\n",
            "S dataset \n",
            " [[0.97102972 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.7642783  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.9944259  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.86397167 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.87352538 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01649395\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.09680186 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.17531034 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94934194 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.02703415]]\n",
            "S missing shape\n",
            "  (97, 10, 10)\n",
            "S missing\n",
            "  [[[0.63103527 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.67864848 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.63325821 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.09912463]]\n",
            "\n",
            " [[0.86437058 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.72758022 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.67242728 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.10554839 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.53107274]]\n",
            "\n",
            " [[0.44320497 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.55806332 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.86906071 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.1626718 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.92848853 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.02435118 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.81338649 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.31463389 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.13482804 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.37356587]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.28415682 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.7687505  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.75151663 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.04847375 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.70107893 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.955199   0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.16378656]]]\n",
            "shape X_imputed in post_imputation  (5, 97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[[0.63103527 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.67864848 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.63325821 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.09912463]]\n",
            "\n",
            " [[0.86437058 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.72758022 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.67242728 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.10554839 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.53107274]]\n",
            "\n",
            " [[0.44320497 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.55806332 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.86906071 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.1626718 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.92848853 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.02435118 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.81338649 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.31463389 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.13482804 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.37356587]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.28415682 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.7687505  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.75151663 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.04847375 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.70107893 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.955199   0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.16378656]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[0.97 0.00 ... 0.00 0.00]\n",
            " [0.00 0.76 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.95 0.00]\n",
            " [0.00 0.00 ... 0.00 1.03]] @ Promote(adv_radius_times_dts, (970, 10)) + [[0.63 0.00 ... 0.00 0.00]\n",
            " [0.00 0.00 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.00 0.00]\n",
            " [0.00 0.00 ... 0.00 1.16]] @ Promote(adv_radius_times_mis, (970, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 13.40it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 15.42it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 17.06it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 17.71it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 18.05it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:00<00:00, 18.65it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 17.87it/s]\n",
            " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 17.88it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 17.11it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 21.00it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 24.06it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 24.12it/s]\n",
            " 67%|██████▋   | 2/3 [00:01<00:00,  1.40it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 29.56it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 30.65it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:00<00:00, 30.40it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 30.30it/s]\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 1.e-05] , min score  2.5671494395246683\n",
            "---------------------------------> best coeff  [ 0.82365199 -0.41890523  0.58791165  0.54796875 -1.42459199 -0.02134403\n",
            " -0.11633189 -1.49876305 -1.52121266 -0.6320238 ]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97386823 1.0307547  1.02181154 0.96391889 0.92616805 0.97331432\n",
            " 1.00141201 0.99413902 1.03010236 1.15435072]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 3.94 s, sys: 212 ms, total: 4.15 s\n",
            "Wall time: 2.32 s\n",
            "X_imputed in experiment_2d_external_dataset  [-66.5014818  -57.69128303 -72.68640738 -59.12106867 -71.6787057 ]\n",
            "crush test------------------------------------------------->  -327.6789465696132\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5]\n",
            "S dataset \n",
            " [[0.97102972 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.7642783  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.9944259  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.86397167 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.87352538 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01649395\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.09680186 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.17531034 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94934194 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.02703415]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 93.44it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  3.3983445359876945\n",
            "---------------------------------> best coeff  [ 1.0745071  -0.32129684  0.64424359  0.07331847 -1.51485913 -0.3531312\n",
            "  0.56580449 -1.75424065 -1.67043177 -0.73507963]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.97386823 1.0307547  1.02181154 0.96391889 0.92616805 0.97331432\n",
            " 1.00141201 0.99413902 1.03010236 1.15435072]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -327.6789465696132\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5]\n",
            "S dataset \n",
            " [[0.97102972 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.7642783  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.9944259  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.86397167 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.87352538 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01649395\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.09680186 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.17531034 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.94934194 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.02703415]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 75.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  3.3983445359876945\n",
            "---------------------------------> best coeff  [ 1.0745071  -0.32129684  0.64424359  0.07331847 -1.51485913 -0.3531312\n",
            "  0.56580449 -1.75424065 -1.67043177 -0.73507963]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  1\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20200, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   200\n",
            "X shape in clear data  (200, 10)\n",
            "y shape in clear data  (200,)\n",
            "M shape in clear data  (200,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(197, 10)\n",
            "(197, 10)\n",
            "(197,)\n",
            "full masks in run experiment  [[1 0 1 ... 1 0 1]\n",
            " [1 1 0 ... 1 1 1]\n",
            " [1 1 0 ... 0 1 1]\n",
            " ...\n",
            " [0 1 1 ... 1 0 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [1 1 1 ... 0 1 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 0.958296  ,  0.98621653, -0.80846685, ..., -1.10327699,\n",
            "        -0.56371548,  1.16694997],\n",
            "       [-0.80840647,  2.03286306,  0.26303703, ..., -0.16983354,\n",
            "         0.00555826, -2.01270017],\n",
            "       [-1.51662813,  3.23221379, -0.60373111, ...,  0.2607325 ,\n",
            "        -0.22181851, -1.94125958],\n",
            "       ...,\n",
            "       [ 1.12295604,  0.3538262 , -1.40175346, ..., -1.27753136,\n",
            "         0.09827774,  1.15145431],\n",
            "       [ 0.6003045 , -0.71643042,  0.74853121, ..., -0.66613883,\n",
            "         0.27231838, -1.49986016],\n",
            "       [ 0.55426167,  0.94081781, -0.15363519, ..., -0.72634202,\n",
            "        -0.84811294, -0.94154098]]), array([[1, 0, 1, ..., 1, 0, 1],\n",
            "       [1, 1, 0, ..., 1, 1, 1],\n",
            "       [1, 1, 0, ..., 0, 1, 1],\n",
            "       ...,\n",
            "       [1, 1, 0, ..., 1, 0, 0],\n",
            "       [1, 1, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 1, ..., 1, 1, 1]])), 'X_test': array([[ 0.04065001, -0.11911612,  0.87272876, ...,  0.34464194,\n",
            "         1.62100985, -0.48836206],\n",
            "       [-0.95396812,  0.65372847, -0.168279  , ...,  1.04919495,\n",
            "         0.22490218, -0.91851888],\n",
            "       [-0.79335864,  0.09122691, -1.86481623, ...,  0.94127311,\n",
            "        -0.40799434, -0.70072626],\n",
            "       ...,\n",
            "       [-0.66564334, -0.26360987, -0.62031519, ...,  0.03497082,\n",
            "         1.26454076,  0.75160116],\n",
            "       [ 0.64394513, -0.25600669,  1.01881115, ..., -0.14770578,\n",
            "         3.18812599, -1.09570717],\n",
            "       [ 0.17857243,  0.75805462,  1.20716663, ..., -0.46339613,\n",
            "         0.10727545, -0.87543808]]), 'y_train': array([ 3.87392119e+00, -8.77489430e-01, -3.07300619e+00, -9.95799912e-01,\n",
            "        2.85314186e+00,  4.58158244e-01, -8.95914722e-01,  4.86264885e+00,\n",
            "        3.92420991e+00,  9.28200743e-01,  1.04483595e+00,  1.76309913e+00,\n",
            "        7.90135006e+00, -2.19585637e+00,  5.16659828e+00, -8.44543877e-01,\n",
            "       -3.32912527e+00,  3.18144737e-01,  9.51075519e-01,  6.60367633e+00,\n",
            "        5.97758891e+00,  7.32388134e-01, -4.57962592e-01,  4.55004409e+00,\n",
            "       -8.84643381e-01, -3.98731468e+00, -9.70919625e-02,  1.41486287e+00,\n",
            "       -6.25501816e+00, -1.96493561e+00, -9.69318355e-02, -1.70089440e+00,\n",
            "       -3.13921037e+00,  9.44548677e-01, -4.52872618e+00, -1.10506355e+00,\n",
            "       -2.18985872e+00, -9.41858763e-02,  2.56786872e+00, -4.57608227e+00,\n",
            "       -4.89685547e-01, -1.57643038e+00, -1.21876618e-01, -5.72420076e+00,\n",
            "       -4.28754081e+00,  2.06350298e+00, -2.20417582e+00,  4.71533111e+00,\n",
            "       -4.62846003e-03,  2.31072761e+00, -7.22812044e+00,  1.65487878e+00,\n",
            "       -6.10468963e+00,  6.79801353e-01, -4.06223656e+00, -4.22831155e-01,\n",
            "       -3.92908718e-01,  3.95335181e+00, -2.76721712e+00,  3.55922845e+00,\n",
            "       -5.23067763e+00,  1.40492855e+00,  3.42079685e+00,  3.12695077e+00,\n",
            "       -2.00044902e+00,  1.46214207e+00,  8.34556143e-01,  1.68614292e+00,\n",
            "        5.93584784e+00,  1.78067355e+00, -3.96282928e+00,  3.98220021e+00,\n",
            "        1.59611323e+00,  3.66997854e+00,  2.91101385e+00, -2.28873658e+00,\n",
            "       -3.88435487e+00, -1.08376473e+00,  2.08229206e+00, -2.69372290e+00,\n",
            "       -1.29418022e+00, -4.04542748e-01, -4.19501312e+00, -5.01584835e+00,\n",
            "        1.20699639e+00, -1.27811718e+00, -6.45751018e+00,  3.51717647e+00,\n",
            "       -1.34969046e-01,  9.11668503e-01,  5.75336980e-01,  3.95000222e+00,\n",
            "        4.92979365e+00, -4.69928672e+00, -2.40826837e+00, -2.25572014e-01,\n",
            "       -1.77800799e-02,  3.73243668e+00,  1.17996711e+00,  3.33599530e+00,\n",
            "       -1.91129880e+00, -1.76801771e+00, -7.53195468e-01,  1.24155258e+00,\n",
            "       -1.10299166e-01, -2.83030675e+00,  1.85106058e+00,  8.06512897e-01,\n",
            "        5.67975691e-01, -2.84086795e+00,  1.45498396e+00,  4.43980413e+00,\n",
            "        1.08805095e+00, -6.63938787e+00, -5.93886956e+00,  9.30528149e-02,\n",
            "        3.31662295e+00, -5.39093945e+00, -3.82683071e+00,  5.67511095e+00,\n",
            "       -5.36788250e-01,  1.02953046e+00, -3.38971159e+00, -8.02177770e-02,\n",
            "        1.21636952e+00,  6.05857220e+00, -3.45627332e+00,  4.69968275e+00,\n",
            "        7.05827279e-01,  5.61969002e-02,  3.02875616e-01,  2.57854695e+00,\n",
            "       -2.50088299e+00, -1.09941237e-02, -5.63733729e+00,  4.11450871e+00,\n",
            "        4.56792069e+00, -2.78040146e+00, -4.22009821e+00,  2.52782830e-01,\n",
            "       -9.75908006e-01, -4.96415167e-01, -1.83002300e+00,  3.47339524e+00,\n",
            "        2.87206503e+00,  2.67599369e-01, -1.40539861e+00,  4.21449596e+00,\n",
            "        8.40043294e+00, -2.06414224e+00,  7.45120633e+00, -2.77693299e+00,\n",
            "       -7.46622283e+00, -3.01659923e+00,  2.08741555e-02,  2.83505218e+00,\n",
            "       -5.55854769e+00,  6.24490956e-01,  4.33479899e+00, -2.61587264e+00,\n",
            "       -2.47835624e+00, -2.56244039e+00, -2.16713903e+00,  3.46926036e+00,\n",
            "       -2.57336032e+00, -3.77239419e+00, -1.42512031e+00, -1.07961409e+00,\n",
            "       -2.30002843e+00, -6.89092348e-01,  3.64257235e+00,  2.34141986e-01,\n",
            "        2.16202895e+00,  1.19555588e+00, -1.89612905e+00, -7.88242243e-01,\n",
            "        1.47469127e+00, -3.52432618e+00,  1.69093728e+00,  1.42501918e+00,\n",
            "        1.92797594e+00, -1.43439248e+00,  5.60533746e-01,  2.36539432e+00,\n",
            "        9.22491726e-01,  1.26326028e+00, -4.88932050e-01,  2.55853872e+00,\n",
            "        1.79071449e+00,  5.88798861e-01,  7.93182765e+00,  5.23175405e-01,\n",
            "       -1.59867904e+00, -1.02929770e+00,  3.09186326e-01,  4.10974391e+00,\n",
            "        4.42271428e+00]), 'y_test': array([-1.68035763, -1.43072336, -2.71181276, ..., -5.77844636,\n",
            "       -1.63276574,  4.60769535]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.02888114 0.99961534 1.08788428 0.99535528 0.90420252 0.96600106\n",
            " 1.01746575 1.06477828 0.97287033 1.11828285]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_imputed in experiment_2d_external_dataset  -72.43631245879796\n",
            "crush test------------------------------------------------->  -72.43631245879796\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9]\n",
            "S dataset \n",
            " [[1.03656051 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87116376 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.23896154 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.04048943 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8578097  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01072927\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10933158 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07702268 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.96726798 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99398528]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 37.44it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 50.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  6.323736169185968\n",
            "---------------------------------> best coeff  [ 7.77897043e-01  6.03947820e-01 -3.13260939e-11  3.28704297e-01\n",
            " -1.69243016e+00 -5.58604750e-01  4.54142917e-10 -1.01967455e+00\n",
            " -9.75772934e-01 -1.37162627e-01]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.02888114 0.99961534 1.08788428 0.99535528 0.90420252 0.96600106\n",
            " 1.01746575 1.06477828 0.97287033 1.11828285]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -59.392784834108525\n",
            "crush test------------------------------------------------->  -59.392784834108525\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.02888114 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.99961534 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.08788428 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.99535528 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.90420252 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.96600106\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.01746575 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.06477828 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.97287033 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.11828285]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  197  nbr_at_least_one_miss :  0\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 27.20it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 45.07it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 43.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  2.997368710764615e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.02888114 0.99961534 1.08788428 0.99535528 0.90420252 0.96600106\n",
            " 1.01746575 1.06477828 0.97287033 1.11828285]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [ -18.31954991 -127.46893103 -158.93107226 -106.21065399 -160.42244228]\n",
            "crush test------------------------------------------------->  -571.352649477239\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9]\n",
            "S dataset \n",
            " [[1.03656051 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87116376 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.23896154 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.04048943 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8578097  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01072927\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10933158 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07702268 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.96726798 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99398528]]\n",
            "S missing shape\n",
            "  (197, 10, 10)\n",
            "S missing\n",
            "  [[[0.71320617 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.68596759 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.30911528 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.42500976]]\n",
            "\n",
            " [[1.06438722 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.42043698 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.34413776 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.99772538 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.4787066 ]]\n",
            "\n",
            " [[0.58782143 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.56710213 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.754729   0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.55899256]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1.58789039 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.54108213 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.69008185 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.31286673 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.83672122 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.22596528 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.15588996 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.34337388 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.04235105 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.69878201]]]\n",
            "shape X_imputed in post_imputation  (5, 197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[[0.71320617 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.68596759 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.30911528 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.42500976]]\n",
            "\n",
            " [[1.06438722 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.42043698 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.34413776 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.99772538 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.4787066 ]]\n",
            "\n",
            " [[0.58782143 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.56710213 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.754729   0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.55899256]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1.58789039 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.54108213 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.69008185 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.31286673 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.83672122 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.22596528 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.15588996 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.34337388 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.04235105 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.69878201]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.04 0.00 ... 0.00 0.00]\n",
            " [0.00 0.87 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.97 0.00]\n",
            " [0.00 0.00 ... 0.00 0.99]] @ Promote(adv_radius_times_dts, (1970, 10)) + [[0.71 0.00 ... 0.00 0.00]\n",
            " [0.00 0.00 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 1.04 0.00]\n",
            " [0.00 0.00 ... 0.00 0.70]] @ Promote(adv_radius_times_mis, (1970, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:01,  8.40it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01, 11.61it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:00, 12.34it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 12.84it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 12.50it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:00<00:00, 12.87it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:01<00:00, 12.88it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00, 12.44it/s]\n",
            " 33%|███▎      | 1/3 [00:01<00:02,  1.21s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01, 12.20it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 12.97it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 13.23it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 13.25it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 12.92it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:00<00:00, 13.22it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00, 12.83it/s]\n",
            " 67%|██████▋   | 2/3 [00:02<00:01,  1.19s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 13.03it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 13.21it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 13.59it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 13.52it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 13.56it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:00<00:00, 13.15it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00, 13.14it/s]\n",
            "100%|██████████| 3/3 [00:03<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 1.e-05] , min score  3.8329445297572398\n",
            "---------------------------------> best coeff  [ 0.44110434  0.13146217  0.21264363  0.72562446 -1.35902766  0.28926753\n",
            "  0.15611765 -1.05517764 -0.64063793 -0.34051453]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.02888114 0.99961534 1.08788428 0.99535528 0.90420252 0.96600106\n",
            " 1.01746575 1.06477828 0.97287033 1.11828285]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 6.72 s, sys: 321 ms, total: 7.04 s\n",
            "Wall time: 4.63 s\n",
            "X_imputed in experiment_2d_external_dataset  [-105.45542988  -72.57825174 -121.43253975  -43.56959674  -82.06371059]\n",
            "crush test------------------------------------------------->  -425.09952869412587\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9]\n",
            "S dataset \n",
            " [[1.03656051 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87116376 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.23896154 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.04048943 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8578097  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01072927\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10933158 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07702268 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.96726798 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99398528]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 31.45it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 34.34it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 32.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.367420493554844\n",
            "---------------------------------> best coeff  [ 0.83258085  0.55365496  0.56158439  0.73171457 -1.4289791   0.04308332\n",
            "  0.59925812 -1.0504256  -1.13983772 -0.6350485 ]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.02888114 0.99961534 1.08788428 0.99535528 0.90420252 0.96600106\n",
            " 1.01746575 1.06477828 0.97287033 1.11828285]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -425.09952869412587\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9]\n",
            "S dataset \n",
            " [[1.03656051 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87116376 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.23896154 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.04048943 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8578097  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.01072927\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10933158 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07702268 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.96726798 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99398528]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 197, 10)\n",
            "y_train length  197\n",
            "-------> size test:  20000  , size train:  197 nbr_full_seen (train):  0  nbr_at_least_one_miss :  197\n",
            "X  197   10\n",
            "y shape (197,)\n",
            "nm  1970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 17.92it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 26.99it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:00<00:00, 29.42it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 29.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.367420493554844\n",
            "---------------------------------> best coeff  [ 0.83258085  0.55365496  0.56158439  0.73171457 -1.4289791   0.04308332\n",
            "  0.59925812 -1.0504256  -1.13983772 -0.6350485 ]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  2\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20300, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   300\n",
            "X shape in clear data  (300, 10)\n",
            "y shape in clear data  (300,)\n",
            "M shape in clear data  (300,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(293, 10)\n",
            "(293, 10)\n",
            "(293,)\n",
            "full masks in run experiment  [[1 0 1 ... 1 0 1]\n",
            " [1 1 0 ... 1 1 1]\n",
            " [1 1 0 ... 0 1 1]\n",
            " ...\n",
            " [0 1 1 ... 1 0 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [1 1 1 ... 0 1 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 9.58296001e-01,  9.86216526e-01, -8.08466849e-01, ...,\n",
            "        -1.10327699e+00, -5.63715480e-01,  1.16694997e+00],\n",
            "       [-8.08406472e-01,  2.03286306e+00,  2.63037033e-01, ...,\n",
            "        -1.69833538e-01,  5.55825798e-03, -2.01270017e+00],\n",
            "       [-1.51662813e+00,  3.23221379e+00, -6.03731108e-01, ...,\n",
            "         2.60732495e-01, -2.21818509e-01, -1.94125958e+00],\n",
            "       ...,\n",
            "       [-2.84785057e-01,  5.78949113e-02, -7.84197376e-01, ...,\n",
            "         4.30700571e-01, -2.73352033e+00,  1.67488100e+00],\n",
            "       [ 5.04499111e-01, -2.30434720e-01, -8.88339226e-02, ...,\n",
            "         7.37270791e-01, -2.38300897e+00,  1.60110528e+00],\n",
            "       [-1.55140354e+00, -7.54411535e-01,  8.27297522e-02, ...,\n",
            "        -4.37902467e-01,  3.10085752e-03, -2.73707477e-01]]), array([[1, 0, 1, ..., 1, 0, 1],\n",
            "       [1, 1, 0, ..., 1, 1, 1],\n",
            "       [1, 1, 0, ..., 0, 1, 1],\n",
            "       ...,\n",
            "       [0, 1, 1, ..., 1, 0, 1],\n",
            "       [1, 1, 1, ..., 0, 0, 1],\n",
            "       [1, 1, 1, ..., 0, 1, 0]])), 'X_test': array([[ 0.04065001, -0.11911612,  0.87272876, ...,  0.34464194,\n",
            "         1.62100985, -0.48836206],\n",
            "       [-0.95396812,  0.65372847, -0.168279  , ...,  1.04919495,\n",
            "         0.22490218, -0.91851888],\n",
            "       [-0.79335864,  0.09122691, -1.86481623, ...,  0.94127311,\n",
            "        -0.40799434, -0.70072626],\n",
            "       ...,\n",
            "       [-0.66564334, -0.26360987, -0.62031519, ...,  0.03497082,\n",
            "         1.26454076,  0.75160116],\n",
            "       [ 0.64394513, -0.25600669,  1.01881115, ..., -0.14770578,\n",
            "         3.18812599, -1.09570717],\n",
            "       [ 0.17857243,  0.75805462,  1.20716663, ..., -0.46339613,\n",
            "         0.10727545, -0.87543808]]), 'y_train': array([ 3.87392119e+00, -8.77489430e-01, -3.07300619e+00, -9.95799912e-01,\n",
            "        2.85314186e+00,  4.58158244e-01, -8.95914722e-01,  4.86264885e+00,\n",
            "        3.92420991e+00,  9.28200743e-01,  1.04483595e+00,  1.76309913e+00,\n",
            "        7.90135006e+00, -2.19585637e+00,  5.16659828e+00, -8.44543877e-01,\n",
            "       -3.32912527e+00,  3.18144737e-01,  9.51075519e-01,  6.60367633e+00,\n",
            "        5.97758891e+00,  7.32388134e-01, -4.57962592e-01,  4.55004409e+00,\n",
            "       -8.84643381e-01, -3.98731468e+00, -9.70919625e-02,  1.41486287e+00,\n",
            "       -6.25501816e+00, -1.96493561e+00, -9.69318355e-02, -1.70089440e+00,\n",
            "       -3.13921037e+00,  9.44548677e-01, -4.52872618e+00, -1.10506355e+00,\n",
            "       -2.18985872e+00, -9.41858763e-02,  2.56786872e+00, -4.57608227e+00,\n",
            "       -4.89685547e-01, -1.57643038e+00, -1.21876618e-01, -5.72420076e+00,\n",
            "       -4.28754081e+00,  2.06350298e+00, -2.20417582e+00,  4.71533111e+00,\n",
            "       -4.62846003e-03,  2.31072761e+00, -7.22812044e+00,  1.65487878e+00,\n",
            "       -6.10468963e+00,  6.79801353e-01, -4.06223656e+00, -4.22831155e-01,\n",
            "       -3.92908718e-01,  3.95335181e+00, -2.76721712e+00,  3.55922845e+00,\n",
            "       -5.23067763e+00,  1.40492855e+00,  3.42079685e+00,  3.12695077e+00,\n",
            "       -2.00044902e+00,  1.46214207e+00,  8.34556143e-01,  1.68614292e+00,\n",
            "        5.93584784e+00,  1.78067355e+00, -3.96282928e+00,  3.98220021e+00,\n",
            "        1.59611323e+00,  3.66997854e+00,  2.91101385e+00, -2.28873658e+00,\n",
            "       -3.88435487e+00, -1.08376473e+00,  2.08229206e+00, -2.69372290e+00,\n",
            "       -1.29418022e+00, -4.04542748e-01, -4.19501312e+00, -5.01584835e+00,\n",
            "        1.20699639e+00, -1.27811718e+00, -6.45751018e+00,  3.51717647e+00,\n",
            "       -1.34969046e-01,  9.11668503e-01,  5.75336980e-01,  3.95000222e+00,\n",
            "        4.92979365e+00, -4.69928672e+00, -2.40826837e+00, -2.25572014e-01,\n",
            "       -1.77800799e-02,  3.73243668e+00,  1.17996711e+00,  3.33599530e+00,\n",
            "       -1.91129880e+00, -1.76801771e+00, -7.53195468e-01,  1.24155258e+00,\n",
            "       -1.10299166e-01, -2.83030675e+00,  1.85106058e+00,  8.06512897e-01,\n",
            "        5.67975691e-01, -2.84086795e+00,  1.45498396e+00,  4.43980413e+00,\n",
            "        1.08805095e+00, -6.63938787e+00, -5.93886956e+00,  9.30528149e-02,\n",
            "        3.31662295e+00, -5.39093945e+00, -3.82683071e+00,  5.67511095e+00,\n",
            "       -5.36788250e-01,  1.02953046e+00, -3.38971159e+00, -8.02177770e-02,\n",
            "        1.21636952e+00,  6.05857220e+00, -3.45627332e+00,  4.69968275e+00,\n",
            "        7.05827279e-01,  5.61969002e-02,  3.02875616e-01,  2.57854695e+00,\n",
            "       -2.50088299e+00, -1.09941237e-02, -5.63733729e+00,  4.11450871e+00,\n",
            "        4.56792069e+00, -2.78040146e+00, -4.22009821e+00,  2.52782830e-01,\n",
            "       -9.75908006e-01, -4.96415167e-01, -1.83002300e+00,  3.47339524e+00,\n",
            "        2.87206503e+00,  2.67599369e-01, -1.40539861e+00,  4.21449596e+00,\n",
            "        8.40043294e+00, -2.06414224e+00,  7.45120633e+00, -2.77693299e+00,\n",
            "       -7.46622283e+00, -3.01659923e+00,  2.08741555e-02,  2.83505218e+00,\n",
            "       -5.55854769e+00,  6.24490956e-01,  4.33479899e+00, -2.61587264e+00,\n",
            "       -2.47835624e+00, -2.56244039e+00, -2.16713903e+00,  3.46926036e+00,\n",
            "       -2.57336032e+00, -3.77239419e+00, -1.42512031e+00, -1.07961409e+00,\n",
            "       -2.30002843e+00, -6.89092348e-01,  3.64257235e+00,  2.34141986e-01,\n",
            "        2.16202895e+00,  1.19555588e+00, -1.89612905e+00, -7.88242243e-01,\n",
            "        1.47469127e+00, -3.52432618e+00,  1.69093728e+00,  1.42501918e+00,\n",
            "        1.92797594e+00, -1.43439248e+00,  5.60533746e-01,  2.36539432e+00,\n",
            "        9.22491726e-01,  1.26326028e+00, -4.88932050e-01,  2.55853872e+00,\n",
            "        1.79071449e+00,  5.88798861e-01,  7.93182765e+00,  5.23175405e-01,\n",
            "       -1.59867904e+00, -1.02929770e+00,  3.09186326e-01,  4.10974391e+00,\n",
            "        4.42271428e+00, -5.36084715e+00,  1.94124373e+00, -1.24975560e+00,\n",
            "       -5.74308722e-01,  6.98082803e+00, -1.03582280e+00,  1.97131345e+00,\n",
            "       -4.02159386e+00, -2.83514346e+00, -4.04904689e-01, -7.07073072e+00,\n",
            "        5.64142479e+00,  6.48509376e-01, -4.46587750e+00,  3.80419958e+00,\n",
            "        3.00648478e+00, -1.18515566e+00,  6.98338379e+00, -1.67484828e+00,\n",
            "        3.26290127e+00,  5.18919097e-01, -2.28064247e+00,  4.64908054e+00,\n",
            "       -1.63024290e+00, -2.19069169e+00,  1.68922010e+00, -2.20030731e+00,\n",
            "       -9.06799246e-01, -4.15845315e+00, -3.27999656e+00, -4.89130122e+00,\n",
            "        3.59410602e+00, -4.11087682e+00,  3.82217150e+00, -6.03420420e+00,\n",
            "        3.98539694e+00,  1.16818161e-01, -2.18468007e+00, -3.00931658e-01,\n",
            "        5.58517434e-01, -1.41080292e+00, -3.18118115e+00,  4.31886239e+00,\n",
            "        7.19179768e-01, -3.63493465e+00, -1.10012738e+00,  2.63631736e+00,\n",
            "        5.45896631e+00, -1.92741745e+00,  4.64762009e+00,  5.44783829e-01,\n",
            "        1.21207624e+00, -2.83266470e+00,  4.38153223e+00,  2.25555765e+00,\n",
            "        2.84472022e+00,  8.03466467e-01, -3.62554430e+00,  6.28817767e+00,\n",
            "       -6.75344802e+00, -4.79302747e+00,  3.24291241e+00, -2.97640200e+00,\n",
            "        7.53306382e-01,  6.16459463e-01,  3.55788210e+00, -4.48993120e+00,\n",
            "       -5.50382469e+00, -1.45077949e+00,  4.90933148e+00, -4.47193579e+00,\n",
            "        5.82650812e+00,  1.56286705e+00,  4.10682525e+00,  4.27276444e+00,\n",
            "        2.76921361e+00,  2.71662464e+00,  3.06921449e-01, -7.93574376e-02,\n",
            "        5.34063847e+00,  3.25599016e+00,  2.72773424e+00, -4.63260178e-01,\n",
            "       -3.95980482e+00, -1.30643236e+00,  2.15542880e+00, -4.38550018e+00,\n",
            "       -2.32969126e-01,  3.07636350e+00,  4.73904508e-01, -1.55838951e+00,\n",
            "        1.92248978e+00,  9.06666967e-01, -4.33846292e+00,  2.13912783e+00,\n",
            "        2.02072637e+00]), 'y_test': array([-1.68035763, -1.43072336, -2.71181276, ..., -5.77844636,\n",
            "       -1.63276574,  4.60769535]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03154997 0.97016642 1.0463155  0.94308586 0.93931518 0.99579179\n",
            " 1.00048217 1.03561293 0.99641654 1.1040137 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -164.56476013552646\n",
            "crush test------------------------------------------------->  -164.56476013552646\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9 7 7 5 6 7 7 9 7 6 7 7 8 4 8 6 8 3 9 6 6 8 7 7 6 8\n",
            " 6 8 3 6 7 5 8 6 8 5 3 5 5 8 5 8 8 7 6 7 6 5 6 7 7 7 5 8 7 9 7 7 9 3 8 6 9\n",
            " 5 7 5 9 4 8 8 8 6 9 8 7 6 7 6 7 8 3 7 6 5 5 7 7 3 9 5 6 6 8 7 7 7 6]\n",
            "S dataset \n",
            " [[1.01492924 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87851612 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.16306074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.93908759 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9604321  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.02836025\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10518162 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07054644 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99724814 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96560791]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (293, 10)\n",
            "y_train length  293\n",
            "-------> size test:  20000  , size train:  293 nbr_full_seen (train):  0  nbr_at_least_one_miss :  293\n",
            "X  293   10\n",
            "y shape (293,)\n",
            "nm  2930\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 23.80it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 30.22it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:00<00:00, 30.85it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 30.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  3.4110750830372556\n",
            "---------------------------------> best coeff  [ 0.79404678  0.47387723  1.05117319  0.45647285 -1.46338171 -0.39296993\n",
            "  0.40151919 -0.79459222 -1.05462002 -0.77398696]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03154997 0.97016642 1.0463155  0.94308586 0.93931518 0.99579179\n",
            " 1.00048217 1.03561293 0.99641654 1.1040137 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -58.43575148924363\n",
            "crush test------------------------------------------------->  -58.43575148924363\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.03154997 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.97016642 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.0463155  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.94308586 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.93931518 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.99579179\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.00048217 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.03561293 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99641654 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.1040137 ]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (293, 10)\n",
            "y_train length  293\n",
            "-------> size test:  20000  , size train:  293 nbr_full_seen (train):  293  nbr_at_least_one_miss :  0\n",
            "X  293   10\n",
            "y shape (293,)\n",
            "nm  2930\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 17.47it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:00, 22.06it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 27.80it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:00<00:00, 26.67it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 26.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  3.871727649191083e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03154997 0.97016642 1.0463155  0.94308586 0.93931518 0.99579179\n",
            " 1.00048217 1.03561293 0.99641654 1.1040137 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [-133.73575989 -163.89925728 -240.79091048 -155.86694658 -184.78383361]\n",
            "crush test------------------------------------------------->  -879.0767078490718\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9 7 7 5 6 7 7 9 7 6 7 7 8 4 8 6 8 3 9 6 6 8 7 7 6 8\n",
            " 6 8 3 6 7 5 8 6 8 5 3 5 5 8 5 8 8 7 6 7 6 5 6 7 7 7 5 8 7 9 7 7 9 3 8 6 9\n",
            " 5 7 5 9 4 8 8 8 6 9 8 7 6 7 6 7 8 3 7 6 5 5 7 7 3 9 5 6 6 8 7 7 7 6]\n",
            "S dataset \n",
            " [[1.01492924 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87851612 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.16306074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.93908759 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9604321  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.02836025\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10518162 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07054644 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99724814 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96560791]]\n",
            "S missing shape\n",
            "  (293, 10, 10)\n",
            "S missing\n",
            "  [[[1.23414561 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.14547058 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.75191715 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.67485654]]\n",
            "\n",
            " [[1.03626937 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.98333058 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.7183581  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.45082041 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.58602217]]\n",
            "\n",
            " [[0.6131783  0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.847926   0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.95557206 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.64216995]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.28199962 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.80195333 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.1079807  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.98981749]]\n",
            "\n",
            " [[1.13293447 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.90322648 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.84936972 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.29513823]]\n",
            "\n",
            " [[0.46410929 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.35544699 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.00042375 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.84022307 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 293, 10)\n",
            "y_train length  293\n",
            "-------> size test:  20000  , size train:  293 nbr_full_seen (train):  0  nbr_at_least_one_miss :  293\n",
            "X  293   10\n",
            "y shape (293,)\n",
            "nm  2930\n",
            "S_mis in Adbvt training  [[[1.23414561 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.14547058 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.75191715 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.67485654]]\n",
            "\n",
            " [[1.03626937 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.98333058 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.7183581  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         1.45082041 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.58602217]]\n",
            "\n",
            " [[0.6131783  0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.847926   0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.95557206 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.64216995]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.28199962 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.80195333 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.1079807  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.98981749]]\n",
            "\n",
            " [[1.13293447 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.90322648 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.84936972 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.29513823]]\n",
            "\n",
            " [[0.46410929 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.35544699 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         1.00042375 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.84022307 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.01 0.00 ... 0.00 0.00]\n",
            " [0.00 0.88 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 1.00 0.00]\n",
            " [0.00 0.00 ... 0.00 0.97]] @ Promote(adv_radius_times_dts, (2930, 10)) + [[1.23 0.00 ... 0.00 0.00]\n",
            " [0.00 0.00 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.84 0.00]\n",
            " [0.00 0.00 ... 0.00 0.00]] @ Promote(adv_radius_times_mis, (2930, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:02,  6.22it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01,  6.83it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01,  7.15it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:01,  7.40it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:01,  7.55it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:01,  7.45it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:01,  7.53it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:01<00:00,  7.41it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:01<00:00,  6.97it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:01<00:00,  7.07it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:01<00:00,  7.32it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:01<00:00,  7.35it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:01<00:00,  7.43it/s]\u001b[A\n",
            " 93%|█████████▎| 14/15 [00:01<00:00,  6.73it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:02<00:00,  6.94it/s]\n",
            " 33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:02,  4.95it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:02,  5.01it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:02,  4.94it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:02,  4.91it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:01<00:02,  4.98it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:01<00:01,  5.04it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:01<00:01,  4.96it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:01<00:01,  4.86it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:01<00:01,  4.50it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:02<00:01,  4.58it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:02<00:00,  4.75it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:02<00:00,  4.78it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:02<00:00,  4.80it/s]\u001b[A\n",
            " 93%|█████████▎| 14/15 [00:02<00:00,  4.72it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:03<00:00,  4.93it/s]\n",
            " 67%|██████▋   | 2/3 [00:05<00:02,  2.69s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:02,  6.95it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:01,  7.54it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:01,  7.72it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:01,  7.70it/s]\u001b[A\n",
            " 33%|███▎      | 5/15 [00:00<00:01,  7.79it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:01,  7.85it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:01,  7.49it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:01<00:00,  7.59it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:01<00:00,  7.65it/s]\u001b[A\n",
            " 67%|██████▋   | 10/15 [00:01<00:00,  7.74it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:01<00:00,  7.79it/s]\u001b[A\n",
            " 80%|████████  | 12/15 [00:01<00:00,  7.69it/s]\u001b[A\n",
            " 87%|████████▋ | 13/15 [00:01<00:00,  7.57it/s]\u001b[A\n",
            " 93%|█████████▎| 14/15 [00:01<00:00,  7.63it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:01<00:00,  7.56it/s]\n",
            "100%|██████████| 3/3 [00:07<00:00,  2.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 1.e-05] , min score  3.5966617270025227\n",
            "---------------------------------> best coeff  [ 0.62680116  0.31894135  0.54931678  0.3649007  -1.51539999  0.41266356\n",
            "  0.23571826 -0.5033428  -0.8668039  -0.34150486]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03154997 0.97016642 1.0463155  0.94308586 0.93931518 0.99579179\n",
            " 1.00048217 1.03561293 0.99641654 1.1040137 ]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 6.28 s, sys: 408 ms, total: 6.69 s\n",
            "Wall time: 3.64 s\n",
            "X_imputed in experiment_2d_external_dataset  [-235.36548994 -100.92666302 -173.79331426 -220.15912917 -154.0024166 ]\n",
            "crush test------------------------------------------------->  -884.2470129929511\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9 7 7 5 6 7 7 9 7 6 7 7 8 4 8 6 8 3 9 6 6 8 7 7 6 8\n",
            " 6 8 3 6 7 5 8 6 8 5 3 5 5 8 5 8 8 7 6 7 6 5 6 7 7 7 5 8 7 9 7 7 9 3 8 6 9\n",
            " 5 7 5 9 4 8 8 8 6 9 8 7 6 7 6 7 8 3 7 6 5 5 7 7 3 9 5 6 6 8 7 7 7 6]\n",
            "S dataset \n",
            " [[1.01492924 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87851612 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.16306074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.93908759 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9604321  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.02836025\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10518162 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07054644 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99724814 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96560791]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 293, 10)\n",
            "y_train length  293\n",
            "-------> size test:  20000  , size train:  293 nbr_full_seen (train):  0  nbr_at_least_one_miss :  293\n",
            "X  293   10\n",
            "y shape (293,)\n",
            "nm  2930\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [00:00<00:08,  1.58it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 10.42it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 15.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.7090579847024046\n",
            "---------------------------------> best coeff  [ 0.7897863   0.07571378  0.77923078  0.6591436  -1.88536119 -0.07913077\n",
            "  0.27771942 -0.61773718 -1.36422533 -0.55502605]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.03154997 0.97016642 1.0463155  0.94308586 0.93931518 0.99579179\n",
            " 1.00048217 1.03561293 0.99641654 1.1040137 ]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -884.2470129929511\n",
            "[7 9 7 9 6 7 9 6 8 4 7 8 5 8 6 6 7 6 6 4 6 8 7 7 7 7 9 8 8 6 6 6 7 7 8 7 8\n",
            " 4 4 6 8 9 5 6 8 8 8 4 5 8 8 6 7 7 5 5 6 5 8 7 7 9 6 5 8 5 5 9 8 6 7 7 5 9\n",
            " 8 5 5 4 5 8 7 8 7 8 6 9 7 7 7 9 8 6 8 9 9 6 5 6 7 8 9 4 8 9 7 8 7 8 9 7 8\n",
            " 4 6 6 8 6 8 6 5 9 8 7 8 8 6 5 8 8 5 6 8 7 6 3 8 7 8 5 6 8 6 7 5 6 9 8 9 6\n",
            " 7 6 6 5 5 8 7 9 7 7 8 7 7 6 7 8 9 8 5 8 6 6 7 7 8 6 7 7 8 7 7 9 6 7 8 9 4\n",
            " 6 6 7 7 7 6 6 8 7 4 5 9 7 7 5 6 7 7 9 7 6 7 7 8 4 8 6 8 3 9 6 6 8 7 7 6 8\n",
            " 6 8 3 6 7 5 8 6 8 5 3 5 5 8 5 8 8 7 6 7 6 5 6 7 7 7 5 8 7 9 7 7 9 3 8 6 9\n",
            " 5 7 5 9 4 8 8 8 6 9 8 7 6 7 6 7 8 3 7 6 5 5 7 7 3 9 5 6 6 8 7 7 7 6]\n",
            "S dataset \n",
            " [[1.01492924 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.87851612 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.16306074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.93908759 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.9604321  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.02836025\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10518162 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.07054644 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99724814 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.96560791]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 293, 10)\n",
            "y_train length  293\n",
            "-------> size test:  20000  , size train:  293 nbr_full_seen (train):  0  nbr_at_least_one_miss :  293\n",
            "X  293   10\n",
            "y shape (293,)\n",
            "nm  2930\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 28.62it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 37.78it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 38.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  2.7090579847024046\n",
            "---------------------------------> best coeff  [ 0.7897863   0.07571378  0.77923078  0.6591436  -1.88536119 -0.07913077\n",
            "  0.27771942 -0.61773718 -1.36422533 -0.55502605]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "res partial \n",
            "\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')  value:  {'best_coeff': [array([ 1.03876401,  0.01311614,  0.78364583,  0.9639556 , -1.84064869,\n",
            "       -0.20065582,  0.79384503, -1.63551029, -2.08721368, -0.45415686]), array([ 7.77897043e-01,  6.03947820e-01, -3.13260939e-11,  3.28704297e-01,\n",
            "       -1.69243016e+00, -5.58604750e-01,  4.54142917e-10, -1.01967455e+00,\n",
            "       -9.75772934e-01, -1.37162627e-01]), array([ 0.79404678,  0.47387723,  1.05117319,  0.45647285, -1.46338171,\n",
            "       -0.39296993,  0.40151919, -0.79459222, -1.05462002, -0.77398696])], 'l2_dist_best_coeff_gt': [np.float64(1.7028916660822733), np.float64(2.504226516960293), np.float64(1.838454950084178)], 'best_score': [np.float64(2.836527575979336), np.float64(6.323736169185968), np.float64(3.4110750830372556)], 'best_hyper_p': [array([ 2., inf]), array([2.5, inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(2.0), np.float64(2.5), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')  value:  {'best_coeff': [array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895])], 'l2_dist_best_coeff_gt': [np.float64(2.1854600729146582e-11), np.float64(1.713415786690701e-11), np.float64(1.947650441514205e-11)], 'best_score': [np.float64(4.865703757227807e-22), np.float64(2.997368710764615e-22), np.float64(3.871727649191083e-22)], 'best_hyper_p': [array([ 2., inf]), array([2.5, inf]), array([2.5, inf])], 'best_alpha_dts': [np.float64(2.0), np.float64(2.5), np.float64(2.5)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')  value:  {'best_coeff': [array([ 0.82365199, -0.41890523,  0.58791165,  0.54796875, -1.42459199,\n",
            "       -0.02134403, -0.11633189, -1.49876305, -1.52121266, -0.6320238 ]), array([ 0.44110434,  0.13146217,  0.21264363,  0.72562446, -1.35902766,\n",
            "        0.28926753,  0.15611765, -1.05517764, -0.64063793, -0.34051453]), array([ 0.62680116,  0.31894135,  0.54931678,  0.3649007 , -1.51539999,\n",
            "        0.41266356,  0.23571826, -0.5033428 , -0.8668039 , -0.34150486])], 'l2_dist_best_coeff_gt': [np.float64(1.6031286277526224), np.float64(1.9394586978725938), np.float64(1.8746319443594834)], 'best_score': [np.float64(2.5671494395246683), np.float64(3.8329445297572398), np.float64(3.5966617270025227)], 'best_hyper_p': [array([5., 5.]), array([5., 5.]), array([5., 5.])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(5.0), np.float64(5.0), np.float64(5.0)]}\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')  value:  {'best_coeff': [array([ 1.0745071 , -0.32129684,  0.64424359,  0.07331847, -1.51485913,\n",
            "       -0.3531312 ,  0.56580449, -1.75424065, -1.67043177, -0.73507963]), array([ 0.83258085,  0.55365496,  0.56158439,  0.73171457, -1.4289791 ,\n",
            "        0.04308332,  0.59925812, -1.0504256 , -1.13983772, -0.6350485 ]), array([ 0.7897863 ,  0.07571378,  0.77923078,  0.6591436 , -1.88536119,\n",
            "       -0.07913077,  0.27771942, -0.61773718, -1.36422533, -0.55502605])], 'l2_dist_best_coeff_gt': [np.float64(1.846205433543642), np.float64(1.5344865441235163), np.float64(1.63736277866057)], 'best_score': [np.float64(3.3983445359876945), np.float64(2.367420493554844), np.float64(2.7090579847024046)], 'best_hyper_p': [array([ 5., inf]), array([ 5., inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')  value:  {'best_coeff': [array([ 1.0745071 , -0.32129684,  0.64424359,  0.07331847, -1.51485913,\n",
            "       -0.3531312 ,  0.56580449, -1.75424065, -1.67043177, -0.73507963]), array([ 0.83258085,  0.55365496,  0.56158439,  0.73171457, -1.4289791 ,\n",
            "        0.04308332,  0.59925812, -1.0504256 , -1.13983772, -0.6350485 ]), array([ 0.7897863 ,  0.07571378,  0.77923078,  0.6591436 , -1.88536119,\n",
            "       -0.07913077,  0.27771942, -0.61773718, -1.36422533, -0.55502605])], 'l2_dist_best_coeff_gt': [np.float64(1.846205433543642), np.float64(1.5344865441235163), np.float64(1.63736277866057)], 'best_score': [np.float64(3.3983445359876945), np.float64(2.367420493554844), np.float64(2.7090579847024046)], 'best_hyper_p': [array([ 5., inf]), array([ 5., inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "x_axis for print in plot_res---->  [100, 200, 300]\n",
            "key in plot_res ('BR_si', 'std_nan', 'adv', 'b') : values\n",
            " {'best_coeff': [array([ 1.03876401,  0.01311614,  0.78364583,  0.9639556 , -1.84064869,\n",
            "       -0.20065582,  0.79384503, -1.63551029, -2.08721368, -0.45415686]), array([ 7.77897043e-01,  6.03947820e-01, -3.13260939e-11,  3.28704297e-01,\n",
            "       -1.69243016e+00, -5.58604750e-01,  4.54142917e-10, -1.01967455e+00,\n",
            "       -9.75772934e-01, -1.37162627e-01]), array([ 0.79404678,  0.47387723,  1.05117319,  0.45647285, -1.46338171,\n",
            "       -0.39296993,  0.40151919, -0.79459222, -1.05462002, -0.77398696])], 'l2_dist_best_coeff_gt': [np.float64(1.7028916660822733), np.float64(2.504226516960293), np.float64(1.838454950084178)], 'best_score': [np.float64(2.836527575979336), np.float64(6.323736169185968), np.float64(3.4110750830372556)], 'best_hyper_p': [array([ 2., inf]), array([2.5, inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(2.0), np.float64(2.5), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key in plot_res ('oracle', 'sd', 'adv', 'orange') : values\n",
            " {'best_coeff': [array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895]), array([ 1.51656702, -0.13590466,  0.94059738,  1.06341436, -1.48150709,\n",
            "        0.86347603,  0.48680358, -1.20718219, -1.41379846, -1.24296895])], 'l2_dist_best_coeff_gt': [np.float64(2.1854600729146582e-11), np.float64(1.713415786690701e-11), np.float64(1.947650441514205e-11)], 'best_score': [np.float64(4.865703757227807e-22), np.float64(2.997368710764615e-22), np.float64(3.871727649191083e-22)], 'best_hyper_p': [array([ 2., inf]), array([2.5, inf]), array([2.5, inf])], 'best_alpha_dts': [np.float64(2.0), np.float64(2.5), np.float64(2.5)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key in plot_res ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g') : values\n",
            " {'best_coeff': [array([ 0.82365199, -0.41890523,  0.58791165,  0.54796875, -1.42459199,\n",
            "       -0.02134403, -0.11633189, -1.49876305, -1.52121266, -0.6320238 ]), array([ 0.44110434,  0.13146217,  0.21264363,  0.72562446, -1.35902766,\n",
            "        0.28926753,  0.15611765, -1.05517764, -0.64063793, -0.34051453]), array([ 0.62680116,  0.31894135,  0.54931678,  0.3649007 , -1.51539999,\n",
            "        0.41266356,  0.23571826, -0.5033428 , -0.8668039 , -0.34150486])], 'l2_dist_best_coeff_gt': [np.float64(1.6031286277526224), np.float64(1.9394586978725938), np.float64(1.8746319443594834)], 'best_score': [np.float64(2.5671494395246683), np.float64(3.8329445297572398), np.float64(3.5966617270025227)], 'best_hyper_p': [array([5., 5.]), array([5., 5.]), array([5., 5.])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(5.0), np.float64(5.0), np.float64(5.0)]}\n",
            "key in plot_res ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r') : values\n",
            " {'best_coeff': [array([ 1.0745071 , -0.32129684,  0.64424359,  0.07331847, -1.51485913,\n",
            "       -0.3531312 ,  0.56580449, -1.75424065, -1.67043177, -0.73507963]), array([ 0.83258085,  0.55365496,  0.56158439,  0.73171457, -1.4289791 ,\n",
            "        0.04308332,  0.59925812, -1.0504256 , -1.13983772, -0.6350485 ]), array([ 0.7897863 ,  0.07571378,  0.77923078,  0.6591436 , -1.88536119,\n",
            "       -0.07913077,  0.27771942, -0.61773718, -1.36422533, -0.55502605])], 'l2_dist_best_coeff_gt': [np.float64(1.846205433543642), np.float64(1.5344865441235163), np.float64(1.63736277866057)], 'best_score': [np.float64(3.3983445359876945), np.float64(2.367420493554844), np.float64(2.7090579847024046)], 'best_hyper_p': [array([ 5., inf]), array([ 5., inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "key in plot_res ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple') : values\n",
            " {'best_coeff': [array([ 1.0745071 , -0.32129684,  0.64424359,  0.07331847, -1.51485913,\n",
            "       -0.3531312 ,  0.56580449, -1.75424065, -1.67043177, -0.73507963]), array([ 0.83258085,  0.55365496,  0.56158439,  0.73171457, -1.4289791 ,\n",
            "        0.04308332,  0.59925812, -1.0504256 , -1.13983772, -0.6350485 ]), array([ 0.7897863 ,  0.07571378,  0.77923078,  0.6591436 , -1.88536119,\n",
            "       -0.07913077,  0.27771942, -0.61773718, -1.36422533, -0.55502605])], 'l2_dist_best_coeff_gt': [np.float64(1.846205433543642), np.float64(1.5344865441235163), np.float64(1.63736277866057)], 'best_score': [np.float64(3.3983445359876945), np.float64(2.367420493554844), np.float64(2.7090579847024046)], 'best_hyper_p': [array([ 5., inf]), array([ 5., inf]), array([ 5., inf])], 'best_alpha_dts': [np.float64(5.0), np.float64(5.0), np.float64(5.0)], 'best_alpha_mis': [np.float64(inf), np.float64(inf), np.float64(inf)]}\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(1.7028916660822733), np.float64(2.504226516960293), np.float64(1.838454950084178)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(2.1854600729146582e-11), np.float64(1.713415786690701e-11), np.float64(1.947650441514205e-11)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(1.6031286277526224), np.float64(1.9394586978725938), np.float64(1.8746319443594834)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(1.846205433543642), np.float64(1.5344865441235163), np.float64(1.63736277866057)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  l2_dist_best_coeff_gt    [np.float64(1.846205433543642), np.float64(1.5344865441235163), np.float64(1.63736277866057)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "lb[i] in plot_res  best_score    [np.float64(2.836527575979336), np.float64(6.323736169185968), np.float64(3.4110750830372556)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  best_score    [np.float64(4.865703757227807e-22), np.float64(2.997368710764615e-22), np.float64(3.871727649191083e-22)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  best_score    [np.float64(2.5671494395246683), np.float64(3.8329445297572398), np.float64(3.5966617270025227)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  best_score    [np.float64(3.3983445359876945), np.float64(2.367420493554844), np.float64(2.7090579847024046)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  best_score    [np.float64(3.3983445359876945), np.float64(2.367420493554844), np.float64(2.7090579847024046)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(2.0), np.float64(2.5), np.float64(5.0)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(2.0), np.float64(2.5), np.float64(2.5)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  best_alpha_dts    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('BR_si', 'std_nan', 'adv', 'b')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('oracle', 'sd', 'adv', 'orange')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(5.0), np.float64(5.0), np.float64(5.0)]\n",
            "key:  ('mi', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'g')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 10, 'adv', 'r')\n",
            "lb[i] in plot_res  best_alpha_mis    [np.float64(inf), np.float64(inf), np.float64(inf)]\n",
            "key:  ('mf_imp', 'mean', 'cond_var', 'std_nan', 5, 0, 'adv', 'purple')\n",
            "res in run multipl experiments\n",
            "\n",
            "--------------------------------------------------------------------------------------nbr_experiment external --------------->  3 - 3   3 - 3   3\n",
            "[[], [], []]\n",
            "[]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20300, 10)\n",
            "p_missing in generate mask  [0.3, 1, 1, 1, 1, 1]\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  0\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20100, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   100\n",
            "X shape in clear data  (100, 10)\n",
            "y shape in clear data  (100,)\n",
            "M shape in clear data  (100,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(97, 10)\n",
            "(97, 10)\n",
            "(97,)\n",
            "full masks in run experiment  [[1 1 1 ... 1 0 0]\n",
            " [1 1 1 ... 0 1 0]\n",
            " [1 1 1 ... 1 0 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 0 1 ... 0 1 0]\n",
            " [1 1 1 ... 1 1 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-2.73236645e-01,  3.16889689e-01, -2.37118687e-01,\n",
            "         4.37920681e-01, -8.97610423e-01,  6.97087226e-01,\n",
            "         5.67937341e-01, -6.66835050e-01, -6.88806857e-02,\n",
            "         6.05381598e-01],\n",
            "       [-1.00223095e-01,  1.46855097e+00, -1.15795132e+00,\n",
            "         9.17665330e-01,  9.19669788e-01, -1.25102715e+00,\n",
            "         4.21799141e-01,  1.33142283e+00,  8.37563593e-01,\n",
            "        -7.72434192e-01],\n",
            "       [ 1.07149305e+00,  1.98600683e+00,  3.87571186e-01,\n",
            "        -1.08056018e-01, -5.95530479e-01, -5.17994393e-01,\n",
            "        -8.89086646e-01,  1.56297886e+00, -1.09673690e+00,\n",
            "        -6.09309542e-01],\n",
            "       [ 5.31368938e-01, -1.38631388e-02,  5.75946295e-01,\n",
            "        -2.63402098e-01,  4.21591032e-01,  1.22826243e+00,\n",
            "         1.97240733e+00, -8.46247783e-01, -1.21644966e+00,\n",
            "         1.06935379e+00],\n",
            "       [-1.20055937e+00,  3.49105733e-01, -2.90765158e-03,\n",
            "         6.74268474e-01,  6.03469827e-01, -5.78832251e-01,\n",
            "        -1.07235140e-01, -2.94713452e-01,  4.26825275e-01,\n",
            "         8.86757949e-01],\n",
            "       [ 2.24142932e-01, -2.57398851e+00,  1.16206434e+00,\n",
            "         7.42529707e-02,  9.86926241e-01,  4.91878397e-01,\n",
            "        -5.21185941e-01, -1.26382846e+00, -4.85166536e-01,\n",
            "        -1.31340156e-01],\n",
            "       [-1.62030153e+00, -3.11036751e-01, -1.02302559e+00,\n",
            "         8.28869531e-02, -1.24120295e+00,  1.58053781e+00,\n",
            "        -8.50389969e-01, -1.19410497e+00, -2.15124026e-01,\n",
            "        -2.38724328e-01],\n",
            "       [ 8.00201016e-02, -3.41207157e-01,  8.36971661e-01,\n",
            "         7.39567654e-03, -1.66398811e-01, -2.08853411e+00,\n",
            "         3.87704322e-01, -2.48222435e-01, -1.22951603e-01,\n",
            "        -1.65619694e+00],\n",
            "       [-8.68439168e-01, -1.24966836e+00,  3.27009234e-01,\n",
            "        -7.90073517e-01, -1.08425180e-01, -1.74094449e-01,\n",
            "        -5.58908133e-01,  6.18850740e-01,  5.97675268e-01,\n",
            "        -5.42994478e-01],\n",
            "       [-9.68291136e-01,  2.26604766e-01,  2.10220677e-01,\n",
            "         1.20042721e-01,  1.00744255e-01, -9.81848333e-01,\n",
            "        -2.09488998e+00,  5.94840498e-01,  1.48934566e+00,\n",
            "        -5.33974468e-01],\n",
            "       [ 1.88264271e+00, -2.54160093e-01,  1.98277875e-01,\n",
            "        -5.50412847e-01,  1.35186065e+00, -2.31524188e-01,\n",
            "         2.24364475e+00, -1.96210510e-01, -5.66746840e-02,\n",
            "        -1.66936894e+00],\n",
            "       [ 1.15621001e+00,  5.11510616e-01, -1.54268423e-01,\n",
            "        -1.08320042e+00,  8.81749329e-01,  2.41877276e+00,\n",
            "        -8.80389756e-01, -1.88505648e+00, -3.16315476e-01,\n",
            "         1.18893069e+00],\n",
            "       [ 4.01732782e-01, -1.43056802e+00, -8.73452972e-02,\n",
            "        -4.31353283e-01, -3.49949190e-01, -1.02171400e-01,\n",
            "         1.81885957e-01, -1.88432862e+00, -4.89992781e-01,\n",
            "        -6.39226903e-01],\n",
            "       [-4.62077966e-01,  1.65572834e+00,  5.18948818e-01,\n",
            "        -3.91712297e-01, -2.03309370e-01,  1.10530458e+00,\n",
            "        -4.30683934e-01, -1.21908454e-01, -1.63952750e-01,\n",
            "         9.33793046e-01],\n",
            "       [ 9.00901488e-01, -1.61488317e-01,  6.02778916e-01,\n",
            "         8.41767113e-01, -6.44067762e-01, -8.01440784e-02,\n",
            "         1.23259483e-01,  5.32898929e-01, -3.25995679e-01,\n",
            "        -8.53725570e-01],\n",
            "       [ 1.17059614e-01, -3.19719030e-01,  8.38639114e-01,\n",
            "        -1.14655399e+00, -4.56788765e-01,  1.04133764e+00,\n",
            "        -2.65397153e-01,  1.88749513e+00, -1.24085742e+00,\n",
            "        -1.15290250e+00],\n",
            "       [-2.75697925e-01, -5.74724603e-01,  5.26431961e-01,\n",
            "        -1.86891943e+00, -6.36419976e-01,  2.09136439e+00,\n",
            "        -3.95889964e-01, -2.70376688e-01, -9.37032465e-01,\n",
            "        -7.64876115e-01],\n",
            "       [ 7.64802732e-01, -1.62538884e+00, -7.01386578e-01,\n",
            "         6.42503758e-01,  4.18606938e-02,  5.13585437e-01,\n",
            "        -6.23213756e-01,  1.18056164e+00,  8.11710212e-01,\n",
            "        -4.59928789e-01],\n",
            "       [-5.72905506e-01,  1.19109140e-01,  3.29465296e-01,\n",
            "         2.53300526e-01,  7.31251133e-01, -1.46393665e+00,\n",
            "         1.36426179e+00, -4.66563062e-01,  2.30414568e-01,\n",
            "        -1.61255662e+00],\n",
            "       [ 1.09590696e+00, -1.84966796e-01,  1.22471101e+00,\n",
            "         2.22669267e-01, -1.25921008e-01,  1.06155885e+00,\n",
            "         1.94775909e+00, -1.02984565e+00, -5.77108429e-02,\n",
            "        -1.41167976e+00],\n",
            "       [-6.08514647e-01, -1.47188926e+00,  9.46086760e-01,\n",
            "        -1.17231568e+00, -1.37504446e+00, -1.02647614e+00,\n",
            "        -2.81215392e-01, -1.08529318e+00,  1.42055998e+00,\n",
            "         1.31312588e+00],\n",
            "       [ 3.53870001e-01,  4.69220094e-01,  3.84166211e-01,\n",
            "         8.17694175e-01, -8.21365558e-01, -7.63074361e-01,\n",
            "         5.06254946e-01, -1.32306705e-01, -6.26690005e-01,\n",
            "        -6.09748961e-02],\n",
            "       [ 1.06260706e+00, -8.64334778e-01,  7.42986135e-02,\n",
            "        -1.71560848e+00, -3.03014565e-01,  4.49548442e-01,\n",
            "         2.44964556e-01, -1.12646195e+00,  4.01258931e-01,\n",
            "        -1.01410476e-01],\n",
            "       [-2.70516125e-01,  4.94944333e-01, -1.24764436e+00,\n",
            "        -1.84066027e-01,  7.32229135e-01,  2.02131344e+00,\n",
            "        -1.15558297e+00, -3.75374680e-01,  7.79285049e-01,\n",
            "        -5.27145133e-01],\n",
            "       [-1.06034669e+00,  7.29444732e-01,  3.34378906e-01,\n",
            "        -7.25065620e-02,  4.80235999e-01,  5.09800403e-01,\n",
            "         1.18791444e+00,  7.87480901e-01,  1.38365113e+00,\n",
            "         2.54754068e+00],\n",
            "       [-3.41460145e-01,  1.34032219e+00, -6.88186656e-02,\n",
            "         1.75707964e+00, -5.06667122e-01,  6.90354740e-01,\n",
            "        -6.33037205e-02,  5.84064875e-01,  6.62867660e-01,\n",
            "         1.22954694e-01],\n",
            "       [-7.67372239e-01, -3.54459582e-01,  1.07247209e+00,\n",
            "        -1.08671169e+00,  9.96415193e-01, -9.27419592e-01,\n",
            "         6.41858613e-01,  8.46161916e-01, -6.99232419e-01,\n",
            "         3.30348346e-01],\n",
            "       [-6.42014823e-01,  1.61079641e+00,  7.09720359e-01,\n",
            "        -1.00381606e+00,  2.81130573e-01,  1.77109757e-01,\n",
            "        -2.38621247e+00, -4.42807805e-01,  2.16302578e-02,\n",
            "         2.83155779e-01],\n",
            "       [ 1.31120771e+00, -9.91982076e-01, -1.47883978e+00,\n",
            "        -2.07839035e+00, -2.26350023e-02,  4.52864495e-01,\n",
            "        -3.06966549e+00, -7.86698856e-01, -9.22369912e-01,\n",
            "         6.11986122e-01],\n",
            "       [ 6.80277300e-01, -7.25636633e-01,  1.49992618e-01,\n",
            "         1.86670534e-02, -1.37124221e-01, -1.62007970e+00,\n",
            "         1.17522688e+00,  1.53335794e+00, -2.18347062e-01,\n",
            "         1.53698276e-01],\n",
            "       [ 1.31539143e-01,  1.62715594e-01, -2.64061637e-02,\n",
            "         1.22288167e+00, -5.21252632e-01, -4.09704602e-02,\n",
            "        -6.36906195e-01,  3.64956972e-01,  1.92464309e+00,\n",
            "         2.71429531e-02],\n",
            "       [-3.65012414e+00,  1.11014211e+00, -3.78314242e-02,\n",
            "         1.38363808e+00, -1.45382742e-01, -6.55478107e-01,\n",
            "         1.30230138e+00,  6.55093787e-02, -1.40430879e-01,\n",
            "        -1.11568691e+00],\n",
            "       [ 5.42583954e-01,  7.61929851e-01,  5.15587876e-01,\n",
            "        -1.66414096e+00,  7.34078841e-01,  1.31164207e+00,\n",
            "        -1.47454315e-01,  5.29200988e-02, -1.55258728e-01,\n",
            "         1.08719343e+00],\n",
            "       [-1.65639874e-01,  9.42798534e-01, -3.37698654e-01,\n",
            "         1.43378449e+00,  1.49855186e+00, -1.58886432e+00,\n",
            "        -3.11560589e-01, -1.54304597e-02, -3.99715493e-01,\n",
            "         9.87545333e-01],\n",
            "       [ 6.20653305e-01, -8.66088592e-01, -1.45346891e+00,\n",
            "         6.74678489e-01, -5.28996277e-01, -3.29351210e-01,\n",
            "         2.67409092e-01,  1.86694841e-01, -5.47482551e-01,\n",
            "         8.24417896e-01],\n",
            "       [-2.14090208e+00, -1.08473971e+00,  1.81683999e-01,\n",
            "         1.10711808e+00,  8.84270361e-01,  8.76763299e-01,\n",
            "        -8.46122068e-04,  1.00150606e+00, -1.39246255e+00,\n",
            "        -4.10635770e-01],\n",
            "       [-1.08685830e+00, -6.13936967e-02,  1.94310969e-01,\n",
            "        -1.17497918e+00, -4.48925969e-01,  4.60982979e-01,\n",
            "        -2.39243161e-01,  8.65216619e-01,  2.70632303e-01,\n",
            "        -9.66325597e-01],\n",
            "       [ 1.07119251e+00,  1.53572181e-01, -1.64924453e-02,\n",
            "        -1.04758037e+00, -2.69777542e-01,  1.48230067e-01,\n",
            "        -7.61520928e-01,  8.09464245e-01, -2.09008665e-01,\n",
            "        -1.19974984e+00],\n",
            "       [ 1.34766238e+00, -8.16037155e-01, -1.93317993e+00,\n",
            "        -1.38594283e-01,  1.15453471e+00,  6.80002583e-01,\n",
            "         6.79873459e-01, -1.31595951e+00, -7.07366241e-01,\n",
            "         3.53422896e-01],\n",
            "       [ 6.30598567e-01, -6.53947099e-01, -1.71894014e-01,\n",
            "         1.20461346e+00, -1.75638328e+00, -6.06169355e-01,\n",
            "        -1.55022218e+00, -1.61881393e-01,  1.16332349e+00,\n",
            "         1.13919579e+00],\n",
            "       [ 1.77822375e+00,  1.54593891e+00, -1.03862733e+00,\n",
            "         1.44162295e+00,  1.42048522e+00, -7.35049010e-01,\n",
            "         1.15119216e+00,  1.39673726e-01,  6.62854186e-01,\n",
            "         8.75384262e-01],\n",
            "       [ 1.07441678e+00, -1.25164898e+00, -3.52211811e-01,\n",
            "         3.07767433e-01, -1.89365748e-01, -5.38772137e-01,\n",
            "         4.29151798e-01,  7.77691326e-01,  2.08050377e+00,\n",
            "        -9.02029335e-01],\n",
            "       [-6.57182901e-02,  1.46793665e+00, -2.70158158e-01,\n",
            "         4.22273175e-01, -1.83281471e+00, -4.96373183e-02,\n",
            "        -5.60252646e-01, -7.18298861e-01, -4.27373005e-01,\n",
            "         1.62799676e+00],\n",
            "       [ 2.88401593e-01, -7.68975092e-02,  4.97061169e-01,\n",
            "         1.32182121e+00,  3.18659901e-02, -5.06952718e-01,\n",
            "         5.73509728e-01,  8.91987229e-01,  1.08613455e+00,\n",
            "         5.83248068e-01],\n",
            "       [-2.21317255e-01,  1.00147077e+00, -4.16449024e-01,\n",
            "        -5.69064691e-01, -1.27544519e+00, -1.91915929e-02,\n",
            "         1.41068446e+00,  7.55025062e-01, -1.78362647e+00,\n",
            "        -7.67290992e-01],\n",
            "       [-4.58254111e-01,  1.32375389e+00,  1.95628518e+00,\n",
            "        -1.68007352e+00,  5.90923964e-01, -1.08452955e-01,\n",
            "        -1.76746255e+00,  1.09352245e+00,  1.41452517e+00,\n",
            "        -1.01050896e+00],\n",
            "       [ 4.42244738e-01, -2.64547503e-04,  5.81006568e-01,\n",
            "         5.75619682e-01, -1.12633984e+00,  1.59586664e+00,\n",
            "        -2.96438894e-02,  5.61497484e-01, -4.04291072e-01,\n",
            "         4.20171163e-01],\n",
            "       [-1.35445901e-02,  3.19950245e-01,  5.28086013e-01,\n",
            "         4.28027171e-02, -2.70461247e-01,  2.94795446e-01,\n",
            "         1.78299577e-01,  1.39400734e+00,  1.09214136e-01,\n",
            "         1.33334865e+00],\n",
            "       [ 6.62830047e-01, -8.08630325e-01,  1.42335970e+00,\n",
            "        -9.07217747e-01, -4.87515779e-01, -1.16661237e+00,\n",
            "         4.99411487e-01, -4.89833161e-02, -7.17447661e-01,\n",
            "         2.98151482e-01],\n",
            "       [ 1.85650456e+00, -6.63921216e-01,  3.30043778e-01,\n",
            "         1.27081071e+00,  1.49348517e-01, -1.53607099e+00,\n",
            "         2.09034205e-01,  4.46420718e-01, -9.31343654e-01,\n",
            "        -2.87710731e-01],\n",
            "       [-7.14631852e-01,  1.17851462e+00,  1.06978083e+00,\n",
            "         7.82201492e-01,  1.21470560e+00, -2.47153649e-01,\n",
            "        -9.22129779e-01,  1.97792644e+00,  9.15571536e-01,\n",
            "        -2.12635185e-01],\n",
            "       [ 1.31140217e+00,  1.55198036e+00, -1.08404008e-01,\n",
            "         1.09546203e+00,  1.74273147e+00,  3.53469547e-01,\n",
            "         1.76222338e+00,  1.52203800e+00,  2.34658080e+00,\n",
            "         9.36577358e-02],\n",
            "       [ 1.23370987e-01, -1.02660145e+00, -1.75224457e-02,\n",
            "        -1.34575667e+00,  8.93141086e-01, -1.01103804e-01,\n",
            "        -2.23895959e+00,  1.30710968e+00,  4.90033391e-01,\n",
            "        -1.01274412e+00],\n",
            "       [-8.85446476e-01, -1.19303907e+00,  5.73795776e-01,\n",
            "        -6.83994605e-01,  2.53818223e-01,  6.07162999e-01,\n",
            "        -4.51250494e-01,  5.85144116e-01,  6.15611782e-01,\n",
            "         3.19129807e-01],\n",
            "       [ 6.30396736e-01,  8.93204740e-02, -4.86383968e-01,\n",
            "         7.15214867e-02,  2.38247942e-01,  8.69115508e-01,\n",
            "         1.48390029e+00,  1.69274044e+00,  2.05531048e+00,\n",
            "        -9.50471498e-01],\n",
            "       [-5.41429850e-01,  1.66517748e+00,  1.06451465e+00,\n",
            "        -2.42106350e-01, -3.90428614e-01, -2.20329155e+00,\n",
            "        -2.61277898e+00,  9.96274915e-02, -7.04904304e-01,\n",
            "        -7.31858470e-01],\n",
            "       [-6.39670866e-01,  7.64511154e-01, -3.62055958e-01,\n",
            "        -1.31196691e+00,  6.07509454e-01, -5.11383668e-01,\n",
            "         1.16097580e-01,  1.09118686e+00, -2.18204650e-01,\n",
            "        -1.80620652e-01],\n",
            "       [ 5.09037372e-01,  8.36232436e-01,  2.38799483e+00,\n",
            "         1.85970764e-01,  1.14123697e+00, -4.12063963e-01,\n",
            "         6.14480541e-01,  1.13103904e+00, -1.87419896e+00,\n",
            "        -7.60160778e-01],\n",
            "       [ 1.25125914e-01, -1.72136883e-01, -1.07755735e+00,\n",
            "         1.07202091e+00,  4.73155416e-01, -1.43020032e-01,\n",
            "        -3.79908874e-02, -1.11744969e+00,  1.64053065e+00,\n",
            "        -1.05102008e-01],\n",
            "       [ 1.49517072e+00,  1.82462402e-02,  1.56690234e-01,\n",
            "         7.12992647e-01,  1.03930084e+00, -1.00876640e+00,\n",
            "        -1.60061387e+00, -1.90220908e-01,  2.45587745e+00,\n",
            "         1.24735831e-01],\n",
            "       [-1.13615123e+00, -3.01796998e-01, -1.33422633e+00,\n",
            "         5.14228630e-01,  2.64243345e-01,  2.16954568e-01,\n",
            "         5.88056317e-01,  9.09903990e-01, -5.38247982e-01,\n",
            "        -2.27941935e-01],\n",
            "       [ 2.59674957e-01,  9.29359424e-01, -2.91291556e-03,\n",
            "         2.01853640e-01,  7.28012847e-01,  7.13293000e-01,\n",
            "         5.25427157e-01, -5.86218846e-01, -3.66645368e-02,\n",
            "         1.52560089e+00],\n",
            "       [-1.66959403e+00, -9.74712396e-01,  1.36459447e-03,\n",
            "        -4.39263993e-01,  1.36799836e-01, -1.05967294e+00,\n",
            "        -1.60099939e+00,  6.36350264e-02, -3.51087754e-01,\n",
            "         8.38055695e-01],\n",
            "       [-4.17087660e-01, -1.19516970e+00,  5.47177658e-01,\n",
            "         1.68790540e-02,  1.66647905e+00,  1.06492111e-01,\n",
            "         1.91313033e+00,  1.01547796e+00,  2.35656635e-01,\n",
            "         9.10427221e-01],\n",
            "       [ 7.60646195e-01,  1.21453525e+00, -2.85147887e-01,\n",
            "         1.12598614e+00, -4.70158162e-01, -6.27114347e-01,\n",
            "         6.14190202e-01,  4.59881405e-01,  1.51120627e+00,\n",
            "         3.44097348e-01],\n",
            "       [ 1.52836178e+00, -7.65769699e-01, -5.86142151e-01,\n",
            "        -9.66316017e-01, -3.42187371e-01,  7.50026217e-01,\n",
            "         6.81880134e-01,  4.36379552e-01,  5.06680214e-01,\n",
            "         3.70040390e-01],\n",
            "       [ 1.38688434e+00,  1.34734506e+00, -2.74675530e-01,\n",
            "         1.22123773e+00,  3.92230348e-01,  3.83688178e-01,\n",
            "         9.95176868e-01, -4.65072411e-01, -1.00273644e+00,\n",
            "        -2.09803516e+00],\n",
            "       [-8.09991332e-01, -9.66276469e-01, -6.07737278e-01,\n",
            "         1.47191639e+00, -7.92618140e-01,  6.28831657e-01,\n",
            "        -1.37753188e+00,  1.37539748e-01,  2.27763394e-01,\n",
            "         4.28249662e-01],\n",
            "       [ 1.44590474e+00,  4.84142668e-01,  7.19065233e-01,\n",
            "         4.30846667e-01,  1.64476626e-02,  6.56820426e-01,\n",
            "         6.36859297e-01,  1.03559416e+00,  3.89893256e-01,\n",
            "         1.54749173e-01],\n",
            "       [ 2.62796456e+00, -3.47390807e-01, -9.28365965e-01,\n",
            "        -9.79510516e-01,  1.57205861e-02,  5.00551260e-01,\n",
            "         9.13494148e-02,  7.48252431e-01,  1.34955432e+00,\n",
            "         1.28074093e-02],\n",
            "       [ 2.33849188e+00,  1.15953911e+00,  3.19971304e-01,\n",
            "         8.14126075e-01,  9.37003620e-01,  2.17681904e+00,\n",
            "         1.35385214e+00,  6.71891454e-01,  5.92061072e-01,\n",
            "         2.72556089e-01],\n",
            "       [ 3.71200881e-01, -1.44937527e+00, -4.20328826e-01,\n",
            "        -3.18184598e-01,  4.99579770e-01, -1.36500894e-01,\n",
            "        -9.34473626e-01,  1.63800699e+00,  2.88757631e-02,\n",
            "         9.11101416e-01],\n",
            "       [ 1.51184500e-01,  3.33084859e-02,  1.37073962e+00,\n",
            "        -7.94939217e-01,  9.40013292e-01, -8.29897521e-01,\n",
            "         5.73616840e-01,  5.24112114e-01, -7.75190843e-01,\n",
            "         2.05926762e+00],\n",
            "       [ 1.93577262e+00, -3.77714710e-01, -6.24064271e-01,\n",
            "         1.53610174e+00, -7.74184081e-01,  9.64683033e-02,\n",
            "        -4.05622682e-01, -1.33415095e+00,  3.55640827e-02,\n",
            "         1.28246435e+00],\n",
            "       [ 2.71119139e+00, -9.06915701e-01,  8.86599673e-01,\n",
            "         4.61902832e-01, -6.90572486e-01, -1.55850630e+00,\n",
            "        -6.67245311e-01,  7.67111693e-01, -2.19736655e+00,\n",
            "         7.20594479e-01],\n",
            "       [-7.99507307e-02, -1.11347655e+00, -2.28008754e+00,\n",
            "         2.95360745e-01,  2.24285866e-01, -5.31368737e-01,\n",
            "        -5.06991017e-01, -1.44536048e+00,  3.58533386e-01,\n",
            "         9.34050449e-01],\n",
            "       [-5.24473734e-01, -1.69296834e+00, -7.60564184e-01,\n",
            "        -2.65984110e-01, -9.17224243e-01,  3.27695033e-01,\n",
            "        -1.43383747e+00, -8.88535031e-01,  1.18488716e-01,\n",
            "        -1.65065145e+00],\n",
            "       [ 1.34140436e+00, -1.05358460e+00, -3.37610344e-01,\n",
            "        -1.12078627e+00,  6.83273258e-01, -2.36352854e+00,\n",
            "         5.31603225e-01, -8.08623016e-01,  8.13508220e-01,\n",
            "        -1.56186313e+00],\n",
            "       [-1.06299807e+00,  4.65959704e-01, -1.86511651e+00,\n",
            "        -5.47568552e-01, -1.06144167e+00, -8.10923154e-02,\n",
            "        -6.39409253e-01,  3.51508691e-01,  7.91357063e-01,\n",
            "        -8.28639166e-01],\n",
            "       [ 1.13866832e+00,  2.21398807e-01,  7.41890673e-02,\n",
            "         6.27108259e-01,  1.11778328e+00,  8.68778066e-01,\n",
            "        -3.13962966e-01,  7.84370273e-01, -2.12696786e-01,\n",
            "        -8.26483771e-01],\n",
            "       [-1.35993130e-01, -1.02491158e-01, -1.28020889e+00,\n",
            "        -1.38367734e+00, -9.94251925e-03, -1.00070713e+00,\n",
            "         7.59173070e-02,  4.45553948e-02, -8.58952523e-01,\n",
            "        -1.83147284e-01],\n",
            "       [-3.71913189e+00, -6.35757142e-01,  2.43983787e+00,\n",
            "        -2.54965788e-01,  7.17649536e-01, -6.71227898e-01,\n",
            "        -5.84559244e-02, -4.02067067e-01, -7.97902755e-01,\n",
            "         1.67954330e-01],\n",
            "       [ 1.97906568e+00, -6.27125625e-01,  8.73239751e-01,\n",
            "        -7.49864623e-01, -4.52749192e-01,  1.95496701e+00,\n",
            "         1.24245634e+00, -1.12502936e+00, -8.72192175e-01,\n",
            "         2.86462190e-01],\n",
            "       [-1.74594273e+00,  1.41599563e+00,  2.36147390e+00,\n",
            "         2.28914672e+00, -6.45280086e-01,  1.08678625e+00,\n",
            "         1.23579651e+00,  5.92476204e-01, -1.06430923e+00,\n",
            "        -1.50841446e+00],\n",
            "       [-3.62406202e-01, -1.66570452e+00,  6.34472026e-02,\n",
            "        -1.63593039e+00, -8.63457756e-01,  1.96395505e+00,\n",
            "        -6.29378102e-02, -3.59096005e-01,  2.71013624e-02,\n",
            "        -8.04093700e-02],\n",
            "       [-5.79299431e-01,  5.63289103e-01,  1.22571331e+00,\n",
            "        -1.69284964e+00,  3.69526171e-01, -2.11725919e-01,\n",
            "         4.15857159e-01, -5.10508992e-01, -3.55609223e-01,\n",
            "        -1.30615774e+00],\n",
            "       [-7.59336357e-02, -3.68897224e-01,  1.97802812e-01,\n",
            "        -1.21381950e+00, -2.17215392e-01, -1.03050145e+00,\n",
            "         1.76494837e-01, -7.54914706e-01,  2.97046294e-01,\n",
            "         7.63810282e-02],\n",
            "       [-8.15289007e-02, -6.66492199e-01, -5.97715451e-01,\n",
            "         1.71019793e+00, -2.21505698e+00, -7.01513020e-01,\n",
            "         1.13600772e+00,  6.37320517e-01,  9.63005220e-01,\n",
            "        -7.71558533e-01],\n",
            "       [-1.49005294e+00,  8.20355505e-01, -6.06783301e-01,\n",
            "         1.28705030e+00,  4.43700958e-01, -4.38859597e-01,\n",
            "        -3.37630073e-01, -1.89555976e-01,  3.47050267e-01,\n",
            "        -5.26559194e-01],\n",
            "       [-4.48782486e-01,  1.05017971e+00,  2.46072959e-01,\n",
            "         3.50270788e-01, -2.30201380e+00,  4.71929574e-01,\n",
            "        -7.86738595e-02,  5.19011718e-01,  2.63032585e-01,\n",
            "        -4.73063251e-01],\n",
            "       [ 2.47485645e-01, -5.94354840e-01,  1.33742143e+00,\n",
            "         3.04185685e-01, -6.54609019e-01,  3.79940848e-01,\n",
            "        -3.05935757e-01, -1.96796888e+00, -9.96207362e-01,\n",
            "        -1.52702008e+00],\n",
            "       [-1.27124068e+00, -7.26855905e-01, -7.50831639e-01,\n",
            "        -1.19590273e-02, -1.09863530e+00,  6.09162658e-01,\n",
            "         5.63785883e-01, -1.75325398e+00,  1.52604956e+00,\n",
            "         4.62708827e-01],\n",
            "       [ 1.54727179e+00,  4.54392677e-02,  8.29124823e-01,\n",
            "        -7.67829385e-01,  1.01884248e+00,  6.15035759e-02,\n",
            "        -7.34053793e-01,  2.66562042e+00,  1.18260418e+00,\n",
            "        -4.50122206e-01],\n",
            "       [ 1.05446884e-01,  2.54323767e+00, -1.94671415e-01,\n",
            "        -1.26049719e+00, -8.56538568e-01,  9.89371054e-01,\n",
            "        -1.70025233e+00,  9.78096699e-01, -6.21036091e-02,\n",
            "         1.46581682e+00],\n",
            "       [-1.74385601e-01,  2.16919860e+00, -9.20880456e-01,\n",
            "        -1.29100929e+00, -1.43488469e+00,  3.11729821e-01,\n",
            "        -1.23661439e+00,  5.72542493e-01, -1.21819827e-01,\n",
            "         1.08709439e+00],\n",
            "       [ 6.41464210e-01,  9.21857779e-01, -5.17722809e-01,\n",
            "        -6.08781580e-01, -9.76180320e-01,  1.37252028e+00,\n",
            "        -3.01970339e-01, -8.35806751e-01, -1.97032940e+00,\n",
            "         2.07826110e-01],\n",
            "       [-1.01312977e-01, -1.78523964e+00, -8.35649678e-01,\n",
            "         5.73499344e-01,  4.63504804e-01, -8.04683337e-01,\n",
            "        -1.11449630e-01,  5.57254990e-01,  3.49411299e-01,\n",
            "        -1.85998996e-02]]), array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n",
            "       [1, 0, 1, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 0, 1, 1, 0, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],\n",
            "       [0, 1, 0, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 0, 0, 0, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 0, 1, 1, 0, 0],\n",
            "       [0, 1, 0, 1, 0, 1, 1, 0, 0, 1],\n",
            "       [1, 0, 1, 1, 0, 1, 0, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 0, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [0, 1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 0, 0, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 0, 1, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 0, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 0, 1, 1, 0, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 0, 0, 1, 1, 1, 0, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 1, 1, 0, 1, 0, 0, 1, 0],\n",
            "       [1, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
            "       [1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 1, 1, 1, 0, 1, 0, 1, 1],\n",
            "       [1, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 0, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
            "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 0],\n",
            "       [1, 0, 0, 1, 0, 1, 1, 0, 1, 0],\n",
            "       [1, 0, 1, 1, 0, 0, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 1, 0, 0, 0, 1],\n",
            "       [1, 0, 1, 0, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [0, 1, 0, 0, 0, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
            "       [1, 0, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "       [1, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 0, 0, 1, 1],\n",
            "       [0, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 0, 1, 0, 0, 1, 1, 1, 1, 1],\n",
            "       [0, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [0, 0, 1, 1, 0, 0, 1, 0, 0, 1],\n",
            "       [0, 1, 0, 1, 1, 0, 0, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 1, 1, 0, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 0, 1, 0, 0, 1, 1, 1, 0],\n",
            "       [1, 0, 0, 1, 1, 1, 0, 1, 1, 1],\n",
            "       [1, 0, 1, 1, 0, 1, 1, 0, 0, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
            "       [0, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "       [0, 1, 0, 1, 0, 0, 1, 1, 1, 1],\n",
            "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 1],\n",
            "       [1, 1, 0, 1, 1, 1, 0, 1, 1, 0]])), 'X_test': array([[-0.06470611,  0.18506786, -0.06014236, ...,  0.74753203,\n",
            "         1.3001457 , -1.06618776],\n",
            "       [-0.23976973,  0.65327858, -0.73026675, ...,  0.68879103,\n",
            "         0.97194714, -1.40223762],\n",
            "       [ 1.12262132, -1.00947562,  0.17428604, ..., -2.10380428,\n",
            "         1.03708756,  1.11550605],\n",
            "       ...,\n",
            "       [-0.06844588,  0.69627458, -0.39684854, ...,  0.38027045,\n",
            "        -0.17874823,  0.86743255],\n",
            "       [-0.94510975, -0.7720317 ,  0.63300286, ...,  0.46014241,\n",
            "        -2.02067698, -0.66608017],\n",
            "       [-0.70491627, -0.53784843, -0.15038692, ..., -1.84488706,\n",
            "         0.85612638, -0.9334491 ]]), 'y_train': array([ 2.14332198, -4.53358573,  2.0280374 ,  3.87774505, -3.94982172,\n",
            "        2.94546363,  1.54286927,  2.12678309, -2.85870682, -5.35074444,\n",
            "        3.77234786,  1.98562449,  4.5436021 , -0.58998809,  4.67407609,\n",
            "        2.14604324,  3.32558746, -0.51870346,  0.25274477,  8.20674039,\n",
            "       -2.39609694,  3.6297226 ,  1.84940213, -1.74216077, -7.23615269,\n",
            "        0.62462619, -3.67051139, -2.86565322, -1.05453193, -1.06579367,\n",
            "       -1.31558414, -2.46115064, -1.78787582, -3.55974007,  0.56273158,\n",
            "       -1.03451553, -1.98598171,  1.44067573,  1.54605836,  0.62329789,\n",
            "       -1.32977339, -0.9392664 ,  1.7432975 , -1.22208114,  3.65508087,\n",
            "       -4.71482974,  4.23308415, -2.27429332,  2.15007956,  4.25715407,\n",
            "       -5.28566995, -3.84930961, -4.63330583, -3.41318638, -2.08550667,\n",
            "       -1.11357513, -4.87905617,  3.58404604, -1.34313653, -3.41685305,\n",
            "       -2.36216192, -0.86420591, -5.38459269, -4.07378806, -0.74767923,\n",
            "        0.62645898,  7.78207133, -0.07714883,  2.12061063, -0.25594869,\n",
            "        3.71919486, -4.43736386, -3.25761617,  5.0325997 ,  6.19753607,\n",
            "       -2.76146402,  2.33709354, -0.35887099, -3.33398619,  1.75588877,\n",
            "       -2.29205137, -3.79670834,  8.30937151,  6.9756235 ,  1.43630346,\n",
            "        0.61231759, -1.25543595,  3.2804364 , -2.3813105 ,  3.14984261,\n",
            "        8.86867375, -0.73616217, -3.84030325, -3.32858532, -2.87551145,\n",
            "        5.73383739, -2.66651885]), 'y_test': array([ 0.34880905, -0.33815493,  4.01285545, ..., -2.22988731,\n",
            "        2.43709014, -1.9382586 ]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.1443282  1.02507657 0.89551028 0.98335448 0.85577053 0.99106313\n",
            " 1.04375062 0.95180285 0.95188617 0.92509627]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -11.05266275951037\n",
            "crush test------------------------------------------------->  -11.05266275951037\n",
            "[8 8 7 9 4 7 8 9 7 9 9 8 6 7 8 7 5 9 9 7 6 5 5 7 6 8 6 5 9 9 7 9 5 9 7 4 6\n",
            " 7 6 9 6 8 7 8 8 7 9 9 5 8 7 8 6 5 6 6 7 6 8 6 9 9 6 6 6 5 6 5 6 7 6 7 5 7\n",
            " 6 5 7 8 7 7 7 7 8 4 6 7 7 6 7 6 7 4 7 9 6 4 7]\n",
            "S dataset \n",
            " [[1.12728094 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.11370934 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.94810918 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.99520248 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92926622 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.10298687\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8184589  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.95258473 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.86561982 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.90953358]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 88.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  7  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.03162278 0.        ] , min score  8.645100292867825\n",
            "---------------------------------> best coeff  [ 4.39025235e-01  4.03163515e-01  1.56596406e-09 -1.65667182e-01\n",
            " -1.40584371e+00  2.88669245e-01  2.19616778e+00 -8.15265812e-01\n",
            " -1.70111227e+00 -2.20951222e-02]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.1443282  1.02507657 0.89551028 0.98335448 0.85577053 0.99106313\n",
            " 1.04375062 0.95180285 0.95188617 0.92509627]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  34.73244998809203\n",
            "crush test------------------------------------------------->  34.73244998809203\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "S dataset \n",
            " [[1.1443282  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.02507657 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.89551028 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.98335448 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.85577053 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.99106313\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.04375062 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.95180285 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.95188617 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.92509627]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  97  nbr_at_least_one_miss :  0\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 74.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  6  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.01 0.  ] , min score  2.6153431179541682e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.1443282  1.02507657 0.89551028 0.98335448 0.85577053 0.99106313\n",
            " 1.04375062 0.95180285 0.95188617 0.92509627]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "nbr features  10\n",
            "X_imputed in experiment_2d_external_dataset  [-16.54239169 -12.71663847  -1.35992296  -7.04717629   0.9508828 ]\n",
            "crush test------------------------------------------------->  -36.71524660577573\n",
            "[8 8 7 9 4 7 8 9 7 9 9 8 6 7 8 7 5 9 9 7 6 5 5 7 6 8 6 5 9 9 7 9 5 9 7 4 6\n",
            " 7 6 9 6 8 7 8 8 7 9 9 5 8 7 8 6 5 6 6 7 6 8 6 9 9 6 6 6 5 6 5 6 7 6 7 5 7\n",
            " 6 5 7 8 7 7 7 7 8 4 6 7 7 6 7 6 7 4 7 9 6 4 7]\n",
            "S dataset \n",
            " [[1.12728094 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.11370934 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.94810918 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.99520248 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92926622 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.10298687\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8184589  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.95258473 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.86561982 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.90953358]]\n",
            "S missing shape\n",
            "  (97, 10, 10)\n",
            "S missing\n",
            "  [[[0.7293708  0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.06011883 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.87714146 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.00486167 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.48877754 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.95561762 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.6341697  ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.98377509 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.28628867 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.7395477  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.45834229 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.7593463  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.7712361 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.95009445 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.78817297 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.60225932 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.77846815]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.7922741  0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.59014825]]\n",
            "\n",
            " [[1.3862752  0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.47235918 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.07571485 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.58478443 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
            "shape X_imputed in post_imputation  (5, 97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[[0.7293708  0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.06011883 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.87714146 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.00486167 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.48877754 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.95561762 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.6341697  ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.98377509 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "\n",
            " [[1.28628867 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.7395477  0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.45834229 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.7593463  0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.7712361 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.95009445 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.78817297 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.60225932 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.77846815]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.7922741  0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.59014825]]\n",
            "\n",
            " [[1.3862752  0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.         1.47235918 0.         ... 0.         0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 1.07571485 0.         0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.58478443 0.        ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
            "S type  <class 'cvxpy.atoms.affine.add_expr.AddExpression'>\n",
            "S is a tensor, concatenated\n",
            "final S after conc \n",
            " [[1.13 0.00 ... 0.00 0.00]\n",
            " [0.00 1.11 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.87 0.00]\n",
            " [0.00 0.00 ... 0.00 0.91]] @ Promote(adv_radius_times_dts, (970, 10)) + [[0.73 0.00 ... 0.00 0.00]\n",
            " [0.00 1.06 ... 0.00 0.00]\n",
            " ...\n",
            " [0.00 0.00 ... 0.58 0.00]\n",
            " [0.00 0.00 ... 0.00 0.00]] @ Promote(adv_radius_times_mis, (970, 10))\n",
            "multiple matrices in input, S conc\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [1.00000000e-05 3.16227766e-03 1.00000000e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 23.35it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 25.20it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 26.66it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 26.47it/s]\n",
            " 33%|███▎      | 1/3 [00:00<00:01,  1.74it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 26.44it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 27.10it/s]\u001b[A\n",
            " 60%|██████    | 9/15 [00:00<00:00, 27.95it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 28.24it/s]\n",
            " 67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 27.86it/s]\u001b[A\n",
            " 47%|████▋     | 7/15 [00:00<00:00, 30.54it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:00<00:00, 30.60it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 29.22it/s]\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  15  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.00000000e-05 3.16227766e-03] , min score  5.1533411047968976\n",
            "---------------------------------> best coeff  [ 0.62199614  0.91457831  0.00623528 -0.01387586 -0.74218449  0.6128956\n",
            "  0.81548371 -0.67745765 -1.41565306 -0.69783586]\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "g\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 10, 'algo_superv_learn': 'adv', 'color': 'r'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.1443282  1.02507657 0.89551028 0.98335448 0.85577053 0.99106313\n",
            " 1.04375062 0.95180285 0.95188617 0.92509627]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "CPU times: user 3.87 s, sys: 202 ms, total: 4.08 s\n",
            "Wall time: 2.28 s\n",
            "X_imputed in experiment_2d_external_dataset  [-19.95580247  11.84412052 -34.25397223 -27.81560995 -51.15668121]\n",
            "crush test------------------------------------------------->  -121.33794533245452\n",
            "[8 8 7 9 4 7 8 9 7 9 9 8 6 7 8 7 5 9 9 7 6 5 5 7 6 8 6 5 9 9 7 9 5 9 7 4 6\n",
            " 7 6 9 6 8 7 8 8 7 9 9 5 8 7 8 6 5 6 6 7 6 8 6 9 9 6 6 6 5 6 5 6 7 6 7 5 7\n",
            " 6 5 7 8 7 7 7 7 8 4 6 7 7 6 7 6 7 4 7 9 6 4 7]\n",
            "S dataset \n",
            " [[1.12728094 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.11370934 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.94810918 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.99520248 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92926622 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.10298687\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8184589  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.95258473 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.86561982 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.90953358]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 92.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  4.091267038817403\n",
            "---------------------------------> best coeff  [ 0.44894079  0.28050714  0.57562939  0.36927302 -1.22230206  0.65857929\n",
            "  1.46622376 -0.85173305 -1.70341004 -0.25629778]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "10\n",
            "adv\n",
            "r\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mf_imp', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_candidates_mm': 0, 'algo_superv_learn': 'adv', 'color': 'purple'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.1443282  1.02507657 0.89551028 0.98335448 0.85577053 0.99106313\n",
            " 1.04375062 0.95180285 0.95188617 0.92509627]\n",
            "A PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  -121.33794533245452\n",
            "[8 8 7 9 4 7 8 9 7 9 9 8 6 7 8 7 5 9 9 7 6 5 5 7 6 8 6 5 9 9 7 9 5 9 7 4 6\n",
            " 7 6 9 6 8 7 8 8 7 9 9 5 8 7 8 6 5 6 6 7 6 8 6 9 9 6 6 6 5 6 5 6 7 6 7 5 7\n",
            " 6 5 7 8 7 7 7 7 8 4 6 7 7 6 7 6 7 4 7 9 6 4 7]\n",
            "S dataset \n",
            " [[1.12728094 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.11370934 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.94810918 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.99520248 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92926622 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.10298687\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.8184589  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.95258473 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.86561982 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.90953358]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (5, 97, 10)\n",
            "y_train length  97\n",
            "-------> size test:  20000  , size train:  97 nbr_full_seen (train):  0  nbr_at_least_one_miss :  97\n",
            "X  97   10\n",
            "y shape (97,)\n",
            "nm  970\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 27%|██▋       | 4/15 [00:00<00:00, 39.42it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 54.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  0  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [1.e-05 0.e+00] , min score  4.091267038817403\n",
            "---------------------------------> best coeff  [ 0.44894079  0.28050714  0.57562939  0.36927302 -1.22230206  0.65857929\n",
            "  1.46622376 -0.85173305 -1.70341004 -0.25629778]\n",
            "mf_imp\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "5\n",
            "0\n",
            "adv\n",
            "purple\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  1\n",
            "{'data': 'Gaussian', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[  7.66400015,   2.90536803,   0.42824454,  -1.74788819,\n",
            "         -1.99036753,   3.04831236,  -3.62462875,  -2.73182598,\n",
            "          1.13685925,   1.02985169],\n",
            "       [  2.90536803,  15.5116041 ,   0.08901085,  -0.24599194,\n",
            "        -11.14343491,   3.69805847,  -1.78944663,   0.67705677,\n",
            "         -2.47472582,  -5.38737873],\n",
            "       [  0.42824454,   0.08901085,   6.81038411,   0.51691665,\n",
            "         -2.07196286,   0.76163037,  -6.2730586 ,   0.76252179,\n",
            "          0.55511679,   0.8142412 ],\n",
            "       [ -1.74788819,  -0.24599194,   0.51691665,   7.24063437,\n",
            "          4.64916049,  -4.27046866,   0.16596041,   0.74739356,\n",
            "          0.34161385,  -0.09432629],\n",
            "       [ -1.99036753, -11.14343491,  -2.07196286,   4.64916049,\n",
            "         20.55490816,  -4.28895065,   5.02813069,  -1.52124154,\n",
            "         -1.66525305,   5.72883106],\n",
            "       [  3.04831236,   3.69805847,   0.76163037,  -4.27046866,\n",
            "         -4.28895065,   7.33703898,  -3.57349333,   2.10654355,\n",
            "          0.68105807,   1.15628803],\n",
            "       [ -3.62462875,  -1.78944663,  -6.2730586 ,   0.16596041,\n",
            "          5.02813069,  -3.57349333,  13.78703461,  -0.39416664,\n",
            "         -1.11419656,  -4.41372606],\n",
            "       [ -2.73182598,   0.67705677,   0.76252179,   0.74739356,\n",
            "         -1.52124154,   2.10654355,  -0.39416664,   7.48265915,\n",
            "          3.09946168,  -1.95245932],\n",
            "       [  1.13685925,  -2.47472582,   0.55511679,   0.34161385,\n",
            "         -1.66525305,   0.68105807,  -1.11419656,   3.09946168,\n",
            "          7.67334949,  -0.88408148],\n",
            "       [  1.02985169,  -5.38737873,   0.8142412 ,  -0.09432629,\n",
            "          5.72883106,   1.15628803,  -4.41372606,  -1.95245932,\n",
            "         -0.88408148,   8.21067765]])}\n",
            "(20200, 10)\n",
            "n_tot_fll  [100, 200, 300] ,   200\n",
            "X shape in clear data  (200, 10)\n",
            "y shape in clear data  (200,)\n",
            "M shape in clear data  (200,)\n",
            "shapes X_train cleaned, mask train cleaned, y train cleaned\n",
            "(195, 10)\n",
            "(195, 10)\n",
            "(195,)\n",
            "full masks in run experiment  [[1 1 1 ... 1 0 0]\n",
            " [1 1 1 ... 0 1 0]\n",
            " [1 1 1 ... 1 0 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 0 1 ... 0 1 0]\n",
            " [1 1 1 ... 1 1 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[-0.27323664,  0.31688969, -0.23711869, ..., -0.66683505,\n",
            "        -0.06888069,  0.6053816 ],\n",
            "       [-0.10022309,  1.46855097, -1.15795132, ...,  1.33142283,\n",
            "         0.83756359, -0.77243419],\n",
            "       [ 1.07149305,  1.98600683,  0.38757119, ...,  1.56297886,\n",
            "        -1.0967369 , -0.60930954],\n",
            "       ...,\n",
            "       [ 2.95144646,  0.02278706, -0.57855066, ...,  0.12804511,\n",
            "         0.05277739,  1.90770052],\n",
            "       [-0.08244642,  0.48279255,  1.128947  , ...,  0.82821335,\n",
            "         0.57680394, -0.92211006],\n",
            "       [-0.64192159, -1.73212458, -1.09019425, ..., -0.3038562 ,\n",
            "        -1.22137207, -1.05859555]]), array([[1, 1, 1, ..., 1, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 1, 0],\n",
            "       [1, 1, 1, ..., 1, 0, 1],\n",
            "       ...,\n",
            "       [1, 1, 0, ..., 1, 0, 1],\n",
            "       [0, 1, 0, ..., 1, 1, 1],\n",
            "       [1, 0, 0, ..., 1, 0, 0]])), 'X_test': array([[-0.06470611,  0.18506786, -0.06014236, ...,  0.74753203,\n",
            "         1.3001457 , -1.06618776],\n",
            "       [-0.23976973,  0.65327858, -0.73026675, ...,  0.68879103,\n",
            "         0.97194714, -1.40223762],\n",
            "       [ 1.12262132, -1.00947562,  0.17428604, ..., -2.10380428,\n",
            "         1.03708756,  1.11550605],\n",
            "       ...,\n",
            "       [-0.06844588,  0.69627458, -0.39684854, ...,  0.38027045,\n",
            "        -0.17874823,  0.86743255],\n",
            "       [-0.94510975, -0.7720317 ,  0.63300286, ...,  0.46014241,\n",
            "        -2.02067698, -0.66608017],\n",
            "       [-0.70491627, -0.53784843, -0.15038692, ..., -1.84488706,\n",
            "         0.85612638, -0.9334491 ]]), 'y_train': array([ 2.14332198, -4.53358573,  2.0280374 ,  3.87774505, -3.94982172,\n",
            "        2.94546363,  1.54286927,  2.12678309, -2.85870682, -5.35074444,\n",
            "        3.77234786,  1.98562449,  4.5436021 , -0.58998809,  4.67407609,\n",
            "        2.14604324,  3.32558746, -0.51870346,  0.25274477,  8.20674039,\n",
            "       -2.39609694,  3.6297226 ,  1.84940213, -1.74216077, -7.23615269,\n",
            "        0.62462619, -3.67051139, -2.86565322, -1.05453193, -1.06579367,\n",
            "       -1.31558414, -2.46115064, -1.78787582, -3.55974007,  0.56273158,\n",
            "       -1.03451553, -1.98598171,  1.44067573,  1.54605836,  0.62329789,\n",
            "       -1.32977339, -0.9392664 ,  1.7432975 , -1.22208114,  3.65508087,\n",
            "       -4.71482974,  4.23308415, -2.27429332,  2.15007956,  4.25715407,\n",
            "       -5.28566995, -3.84930961, -4.63330583, -3.41318638, -2.08550667,\n",
            "       -1.11357513, -4.87905617,  3.58404604, -1.34313653, -3.41685305,\n",
            "       -2.36216192, -0.86420591, -5.38459269, -4.07378806, -0.74767923,\n",
            "        0.62645898,  7.78207133, -0.07714883,  2.12061063, -0.25594869,\n",
            "        3.71919486, -4.43736386, -3.25761617,  5.0325997 ,  6.19753607,\n",
            "       -2.76146402,  2.33709354, -0.35887099, -3.33398619,  1.75588877,\n",
            "       -2.29205137, -3.79670834,  8.30937151,  6.9756235 ,  1.43630346,\n",
            "        0.61231759, -1.25543595,  3.2804364 , -2.3813105 ,  3.14984261,\n",
            "        8.86867375, -0.73616217, -3.84030325, -3.32858532, -2.87551145,\n",
            "        5.73383739, -2.66651885, -1.45666549, -1.02834122, -0.30999553,\n",
            "        4.4332739 , -3.88996379,  0.11405452, -0.77887484, -0.57256375,\n",
            "       -4.38887594, -5.7120952 ,  3.75622027,  2.58594063, -8.53042566,\n",
            "       -1.56876235, -5.60692288,  4.7485927 ,  4.34082516,  1.07655226,\n",
            "        2.75623743, -6.25905723,  2.42150834,  1.47250483,  0.22576056,\n",
            "        2.20206251, -0.97509075,  1.38298933, -6.18960688, -4.04480761,\n",
            "        1.71042163,  5.90860092,  4.70320806, -4.05946076,  3.51071468,\n",
            "        3.54984847,  5.02484939,  2.2829846 , -0.98923591,  0.86492929,\n",
            "       -5.51587623, -2.75565412, -3.26179846,  4.61500638,  4.24550703,\n",
            "       -5.78747655,  5.75442636,  0.8186821 , -1.55588803, -1.24579409,\n",
            "        2.3365591 , -1.57959241,  0.84437615,  1.17781821,  1.73043847,\n",
            "       -1.09634624, -4.98535266,  1.86504245,  0.50684294,  8.17590536,\n",
            "       -4.75814201, -6.74189015, -1.3987757 ,  5.90770339,  5.36737644,\n",
            "        2.80712119, -1.58949994, -0.81139418, -3.16482187,  5.68838354,\n",
            "       -0.62595967, -2.40786464, -6.0517594 ,  0.5774535 , -0.77324026,\n",
            "       -0.68663738, -4.65591992, -4.08779361,  0.85600431,  2.9988818 ,\n",
            "        0.63656807,  4.00371601, -2.39189862, -3.60503914,  0.96825623,\n",
            "        3.93190051, -4.60043401,  2.3197726 ,  4.21624719, -1.70279701,\n",
            "       -3.64253117,  2.10621556,  1.89859662, -4.27139162, -5.90628155,\n",
            "       -2.99220659, -5.6471152 ,  2.69488359, -1.22383269,  1.65121224]), 'y_test': array([ 0.34880905, -0.33815493,  4.01285545, ..., -2.22988731,\n",
            "        2.43709014, -1.9382586 ]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': [], 'mf_imp': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 100, 'adv_rad_times_delta_mis_max': 1, 'alpha_ridge_reg_max': 100, 'eps_adv_rad_times_delta_dts': 1e-07, 'eps_adv_rad_times_delta_mis': 1e-05, 'eps_alpha_ridge_reg': 1e-07, 'n_a_dts': 15, 'n_a_mis': 3, 'n_a_rid': 15}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan', 'algo_superv_learn': 'adv', 'color': 'b'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.11252161 1.0024672  1.00497688 1.00005348 0.93761535 1.02758624\n",
            " 1.00850033 0.9982638  0.99989305 0.99924958]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  16.291614941847666\n",
            "crush test------------------------------------------------->  16.291614941847666\n",
            "[8 8 7 9 4 7 8 9 7 9 9 8 6 7 8 7 5 9 9 7 6 5 5 7 6 8 6 5 9 9 7 9 5 9 7 4 6\n",
            " 7 6 9 6 8 7 8 8 7 9 9 5 8 7 8 6 5 6 6 7 6 8 6 9 9 6 6 6 5 6 5 6 7 6 7 5 7\n",
            " 6 5 7 8 7 7 7 7 8 4 6 7 7 6 7 6 7 4 7 9 6 4 7 8 7 8 8 8 6 5 7 3 8 9 7 6 6\n",
            " 8 7 7 7 7 6 8 6 8 8 3 7 6 7 9 6 4 7 8 9 7 8 5 7 7 9 6 5 5 9 9 6 6 8 8 8 5\n",
            " 7 6 9 4 7 7 8 5 5 7 8 8 8 6 8 7 8 8 7 4 8 6 5 6 6 8 8 5 6 8 9 9 6 8 7 9 9\n",
            " 7 6 7 5 8 5 7 7 6 4]\n",
            "S dataset \n",
            " [[1.12038713 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.03331848 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.05286731 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.86499029 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.95641312 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.09343049\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.9865875  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.91073427 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.98646573 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.93168087]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (195, 10)\n",
            "y_train length  195\n",
            "-------> size test:  20000  , size train:  195 nbr_full_seen (train):  0  nbr_at_least_one_miss :  195\n",
            "X  195   10\n",
            "y shape (195,)\n",
            "nm  1950\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 3/15 [00:00<00:00, 28.51it/s]\u001b[A\n",
            " 53%|█████▎    | 8/15 [00:00<00:00, 36.95it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 35.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
            "/tmp/ipython-input-594497198.py:379: RuntimeWarning: divide by zero encountered in log10\n",
            "  return best_coeff, min_score, -np.log10(best_hyper_p)  # -np.log10((best_alpha_delta_dts + best_alpha_delta_mis)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  4.057791072347018\n",
            "---------------------------------> best coeff  [ 7.64072399e-01  1.38197468e-01  1.22263114e+00  3.49500560e-01\n",
            " -1.34122393e+00  4.62915136e-01  1.13141429e+00 -1.80483622e+00\n",
            " -8.67349734e-01  8.01525113e-08]\n",
            "BR_si\n",
            "std_nan\n",
            "adv\n",
            "b\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd', 'algo_superv_learn': 'adv', 'color': 'orange'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.11252161 1.0024672  1.00497688 1.00005348 0.93761535 1.02758624\n",
            " 1.00850033 0.9982638  0.99989305 0.99924958]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "X_imputed in experiment_2d_external_dataset  -8.081822042613085\n",
            "crush test------------------------------------------------->  -8.081822042613085\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.]\n",
            "S dataset \n",
            " [[1.11252161 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         1.0024672  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         1.00497688 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.00005348 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.93761535 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.02758624\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.00850033 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.9982638  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.99989305 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.99924958]]\n",
            "shape oject in cov strategy missing  10\n",
            "shape oject in cov strategy missing  (20000, 10)\n",
            "S missing shape\n",
            "  (10, 10)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (195, 10)\n",
            "y_train length  195\n",
            "-------> size test:  20000  , size train:  195 nbr_full_seen (train):  195  nbr_at_least_one_miss :  0\n",
            "X  195   10\n",
            "y shape (195,)\n",
            "nm  1950\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-05 3.16227766e-05 1.00000000e-04 3.16227766e-04\n",
            " 1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
            " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
            " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|█▎        | 2/15 [00:00<00:00, 15.13it/s]\u001b[A\n",
            " 40%|████      | 6/15 [00:00<00:00, 27.48it/s]\u001b[A\n",
            " 73%|███████▎  | 11/15 [00:00<00:00, 33.56it/s]\u001b[A\n",
            "100%|██████████| 15/15 [00:00<00:00, 32.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 10) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  5  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00316228 0.        ] , min score  2.11535655266326e-22\n",
            "---------------------------------> best coeff  [ 1.51656702 -0.13590466  0.94059738  1.06341436 -1.48150709  0.86347603\n",
            "  0.48680358 -1.20718219 -1.41379846 -1.24296895]\n",
            "oracle\n",
            "sd\n",
            "adv\n",
            "orange\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [1.11252161 1.0024672  1.00497688 1.00005348 0.93761535 1.02758624\n",
            " 1.00850033 0.9982638  0.99989305 0.99924958]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "info in imputations  {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "info mi {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 5, 'nbr_feature': 10, 'algo_superv_learn': 'adv', 'color': 'g'}\n",
            "nbr features  10\n",
            "nbr features  10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3278374342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0mnbr_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m67\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0mmean_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multiple_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_x_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PLOT OF THE MEANS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0mdicc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_infer_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'seed: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', nbr_exp: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', data: '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', dim: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ', cov: ' + str(cov_var)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2362957099.py\u001b[0m in \u001b[0;36mrun_multiple_experiments\u001b[0;34m(nbr_exp, rdm_seed, dictio, info_x_axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;31m#np.random.seed(rdm_seed * (i+2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0mres_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_methods_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"res partial \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2362957099.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(dictio, methods_strategy)\u001b[0m\n\u001b[1;32m     95\u001b[0m           \u001b[0mcoeff_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_p_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_2d_ext_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_obser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_imp_cov_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnbr_ima\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnbr_ima\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# == 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m           \u001b[0mcoeff_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_p_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_2d_ext_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_obser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_imp_cov_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoeff_round\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdictio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta_gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0ml2_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-594497198.py\u001b[0m in \u001b[0;36mexperiment_2d_ext_dataset\u001b[0;34m(dict_obs, dict_imp, ax)\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0;31m#results = imputations(dict_imp, X_nan_train, dict_obs['y_train'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NO PREVIOUS IMPUTATION HAS BEEN DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m       \u001b[0mX_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_from_X_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_from_X_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m  \u001b[0;31m# imputations(dict_imp, X_nan_train, dict_obs['y_train'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_imputed in experiment_2d_external_dataset \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-594497198.py\u001b[0m in \u001b[0;36mimputations\u001b[0;34m(info, dict_obs_for_imp)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imp_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'mi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mi_pure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"info in imputations \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiple_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_nan\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# size (info['mi_nbr], n, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imp_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mf_imp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmiceforest_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3127010465.py\u001b[0m in \u001b[0;36mmultiple_imputation\u001b[0;34m(info_mi, X_nan)\u001b[0m\n\u001b[1;32m     30\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nbr features \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m        \u001b[0mice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_posterior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nearest_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbr_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m        \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m        \u001b[0;31m#print(\"fin res shape\", res.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m        \u001b[0;31m#if nbr_mi == 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    857\u001b[0m                     \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_corr_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 )\n\u001b[0;32m--> 859\u001b[0;31m                 Xt, estimator = self._impute_one_feature(\n\u001b[0m\u001b[1;32m    860\u001b[0m                     \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                     \u001b[0mmask_missing_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36m_impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode, params)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             )\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# if no missing values, don't predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Update alpha and lambda according to (MacKay, 1992)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mgamma_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigen_vals_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigen_vals_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0mlambda_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0malpha_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrmse_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2250\u001b[0;31m def _sum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,\n\u001b[0m\u001b[1;32m   2251\u001b[0m                     initial=None, where=None):\n\u001b[1;32m   2252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function _draw_all_if_interactive at 0x7a0640ca9260> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_draw_all_if_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m         with (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    381\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3258\u001b[0m                     renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3179\u001b[0m             \u001b[0m_draw_rasterized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3181\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3182\u001b[0m             renderer, self, artists, self.get_figure(root=True).suppressComposite)\n\u001b[1;32m   3183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/legend.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegendPatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'legend'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_supports_rasterization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0m_bbox_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_supports_rasterization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0m_bbox_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_supports_rasterization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bbox_and_child_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36m_get_bbox_and_child_offsets\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    450\u001b[0m                     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         (x0, x1), xoffsets = _get_aligned_offsets(\n\u001b[1;32m    454\u001b[0m             [bbox.intervalx for bbox in bboxes], self.width, self.align)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_bbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Return the bbox of the offsetbox, ignoring parent offsets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bbox_and_child_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36m_get_bbox_and_child_offsets\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpicor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/offsetbox.py\u001b[0m in \u001b[0;36mget_bbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         _, h_, d_ = renderer.get_text_width_height_descent(\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             ismath=\"TeX\" if self._text.get_usetex() else False)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m64.0\u001b[0m  \u001b[0;31m# convert from subpixels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m64.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 6000x750 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function flush_figures at 0x7a0640e727a0> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2182\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2185\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2039\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \"\"\"\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    427\u001b[0m         *pil_kwargs* and *metadata* are forwarded).\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    431\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m         with (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    381\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3258\u001b[0m                     renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3179\u001b[0m             \u001b[0m_draw_rasterized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3181\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3182\u001b[0m             renderer, self, artists, self.get_figure(root=True).suppressComposite)\n\u001b[1;32m   3183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    806\u001b[0m                                           mtext=mtext)\n\u001b[1;32m    807\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                     textrenderer.draw_text(gc, x, y, clean_line,\n\u001b[0m\u001b[1;32m    809\u001b[0m                                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                                            ismath=ismath, mtext=mtext)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_text\u001b[0;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# space) in the following call to draw_text_image).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         font.draw_glyphs_to_bitmap(\n\u001b[0m\u001b[1;32m    194\u001b[0m             antialiased=gc.get_antialiased())\n\u001b[1;32m    195\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m64.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DJHHiKFqIUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FhKy2v5qIb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "840TDfGaqIei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SijOuiZYgmon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TG_Fsg4Mgmrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZRfmkoYlgmuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2vbxlxxNgmyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zJgEeongm1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkEtCuWEgm3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjbzANmcg_cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JsQXdlOg_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4FH2Zo7g_j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxm1VFuIg_q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3cxU4-RZg_uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktlqpLJ9g_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doiemfrVg_zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bzoCpqTg_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwoz_Lp2g_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-Kc_0IPg_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMqppMFSgm5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSeaLOr-qLYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azRmYEueqLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4l2vYHzqLd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7X3AQIZqLgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iv34YkpnqLju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCRKDvv-qLmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJ6b5Zd_vZ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7swocNpvZ_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cxt5tWj1vaCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kCvPWMOtvaE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9kxssOuRMv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWcLfNW2RM1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S5O3hTLTvaIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE8VHJ90vaMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZnN2xpSvaOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze5Q9M4Tycsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzWhOlCoycwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZMXiJW-ycz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uAINCofcyc20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uORnN_wO05n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQ441A0hO09K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iF_8aBrWO1Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHLiMt5wO1Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gB_XEEFvaQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFwxXhyWefs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Kw8bLBTefv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXN7C2Jfefzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeFvCalref4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "An113TsYef7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kF5dEO1zef-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zuC2em6egA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MM7Zk7OWegDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVL97vbaegFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA3cOcmeegJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FpYA6ClegNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3MxLnLIqLol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DgSOhmwgm7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSdrq6HmqIhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4nfPNbTqIjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4xXWwHeeMR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oonp7YBzeMUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnVLZhvbeMXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9Yk_s6leMZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5asNezNqImF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwGCYcYWqIrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6dLlbTgqIt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lu0iNCNHc_0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "031VAAc5c_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quVErgChc_-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVqmuefndAEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7M3O9KqdAL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LN_xYsFMdAQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wo4YT1OODeeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl-gtIlyDeh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnKMsLPgDemY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKCZUoDYDesF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1vpjYZ9dAVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1Fx16kedAX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(2, 5, size=(2, 2, 2))\n",
        "print(X)\n",
        "\n",
        "XX = np.concatenate(X)\n",
        "print(XX)\n",
        "\n",
        "\n",
        "Y = np.random.randint(2, 5, size=(1, 3, 2))\n",
        "print(Y)\n",
        "\n",
        "YY = np.concatenate(Y)\n",
        "print(YY)\n",
        "\n",
        "\n",
        "Z = np.random.randint(2, 5, size=(5, 2))\n",
        "print(Z)\n",
        "\n",
        "ZZ = np.concatenate(Z)\n",
        "print(ZZ)\n",
        "\n",
        "print(\"other\")\n",
        "s = np.random.randint(2, 4, 5)\n",
        "print(s)\n",
        "z = np.tile(s, reps=3)  # np.array([s] * 2)\n",
        "print(z)\n",
        "\n",
        "\n",
        "print(\"other mult\")\n",
        "s = np.random.randint(2, 8, size=(3, 2))\n",
        "print(s)\n",
        "z = np.tile(s, reps=(3, 1))  # np.array([s] * 2)\n",
        "print(z)\n"
      ],
      "metadata": {
        "id": "J-KLwpDqTkGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBkG1_lacBfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBILRQvDuI4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dPT52NAbKyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2ShK9JYb6c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fk7A_5N_c1gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgcEt2LBhEBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FiP-uNujLRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uENE-JShLaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JeqAEblFooY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXByx8OrjqZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TCzI5siopUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4pGls4IpDT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWpiTpQ5lVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ASCmfdEnvjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jq6GembmmAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nb6YB8DbvKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9pv_OW7pJtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgNt4tVYQk7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlebwxRZ1_QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1dmiXA-FcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDRrQMKGU3Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnNTv-mXVIB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBlyABpt0-qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQgiJb-V-hIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCuJj9HPb2cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VM2QQJkmcsdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## random forest imputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_estimator = RandomForestRegressor(n_estimators=4, max_depth=10, bootstrap=True, max_samples=0.5, n_jobs=2, random_state=0)\n",
        "\n",
        "X_rf = single_imputation(X_nan, rf_estimator)\n",
        "print(X_rf.shape)\n",
        "sd_rf = np.std(X_rf, axis=0)\n",
        "S_inv_rf = np.diag(1 / sd_rf)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std rf\\n \", sd_rf)\n",
        "fig, ax = plt.subplots(num='advtrain_linf_rf')\n",
        "linfadvtrain_rf = AdversarialTraining(X_rf, y, S_inv_rf, p=np.inf)\n",
        "estimator_rf = lambda X, y, a:  linfadvtrain_rf(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_rf  = get_path(X_rf, y, estimator_rf, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_rf, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "uSgnV3aVXL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## iterative imputer Bayesian Ridge\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "br_estimator = BayesianRidge()\n",
        "\n",
        "X_br = single_imputation(X_nan, br_estimator)\n",
        "sd_br = np.std(X_br, axis=0)\n",
        "S_inv_br = np.diag(1 / sd_br)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std  br\\n \", sd_br)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_br')\n",
        "linfadvtrain_br = AdversarialTraining(X_br, y, S_inv_br, p=np.inf)\n",
        "estimator_br = lambda X, y, a:  linfadvtrain_br(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_br  = get_path(X_br, y, estimator_br, 1e4)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_br, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "pgNaP74gWAga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## mean imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_mean = imp_mean.fit_transform(X_nan)\n",
        "sd_mean = np.std(X_mean, axis=0)\n",
        "print(sd_mean)\n",
        "S_inv_mean = np.diag(1 / sd_mean)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_mean')\n",
        "linfadvtrain_mean = AdversarialTraining(X_mean, y, S_inv_mean, p=np.inf)\n",
        "estimator_mean = lambda X, y, a:  linfadvtrain_mean(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_mean  = get_path(X_mean, y, estimator_mean, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_mean, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "u0kpCJCkFbcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# imputation elliptic\n",
        "\n",
        "mu = np.nanmean(X_nan, axis=0)\n",
        "print(\"means \", mu)\n",
        "delta = np.mean(masks) # parameter missingness\n",
        "print(\"delta \", delta)\n",
        "X_0 = np.nan_to_num(X_nan)\n",
        "print(\"nbr obs\", X_0.shape[0])\n",
        "S_ellp =  X_0.T @ X_0 / X_0.shape[0]\n",
        "S_ellp = (1/delta - 1/(delta**2)) * np.diag(np.diag(S_ellp)) + 1/(delta**2) * S_ellp\n",
        "print(\"eig cov \", np.linalg.eigvalsh(S_ellp))\n",
        "X_ellp = imputation_elliptic(mu, S_ellp, X_nan, masks)\n",
        "#S_inv_ellp = np.linalg.inv(S_ellp)  # other variance\n",
        "sd_inv_ellp = np.std(X_ellp, axis=0)\n",
        "print(\"sd ellp\", sd_inv_ellp)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_ellp')\n",
        "linfadvtrain_ellp = AdversarialTraining(X_ellp, y, S_ellp, p=np.inf)\n",
        "estimator_ellp = lambda X, y, a:  linfadvtrain_ellp(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_ellp  = get_path(X_ellp, y, estimator_ellp, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_ellp, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "2RYR4_BJhXjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mlM-FR-OfL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgxEbR071wT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7pwDiPU0D_ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdM7Mk_mjf0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYa8pmuMk4jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMwgzXI1_rEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Example data\n",
        "x_test_rect = np.random.rand(10)\n",
        "y_test_rect = np.random.rand(10)\n",
        "\n",
        "# Plot the points\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x_test_rect, y_test_rect)\n",
        "\n",
        "width = 0.1\n",
        "height = 0.1\n",
        "\n",
        "#add_rectangles(x_test_rect, y_test_rect, width, height, ax)\n",
        "\n",
        "# Add the rectangle to the plot\n"
      ],
      "metadata": {
        "id": "-9qaVcwZUB6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WZeO2EOWHwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for some tests\n",
        "\n",
        "def test_clear_dataset(n, d):\n",
        "  print(\"test clear dataset\")\n",
        "  X = np.random.randint(1, 3, size=(n, d))\n",
        "  y = np.random.randint(1, 3, size=n)\n",
        "  masks = np.random.binomial(1, 0.3, size=(n, d))\n",
        "  print(\"X \\n\", X)\n",
        "  print(\"y\\n\", y)\n",
        "  print(\"masks \\n\", masks)\n",
        "  masks[:, 0] = np.ones(n)\n",
        "  masks[0, :] = np.ones(d)\n",
        "  X_res, y_res, masks_res = clear_dataset(X, y, masks)\n",
        "  print(\"X_res \\n\", X_res)\n",
        "  print(\"y\\n\", y_res)\n",
        "  print(\"masks \\n\", masks_res)\n",
        "  print(\"test clear dataset ended successfully\")\n",
        "\n",
        "def test_generate_X():\n",
        "    print(\"test generate_X started\")\n",
        "    fig, ax = plt.subplots(3, 1, figsize=(10, 8), num='advtrain_linf')\n",
        "    gen = generate_X('circles', 2)\n",
        "    data = gen(1000)\n",
        "    print(data.shape)\n",
        "    ax[0].scatter(data[:, 0], data[:, 1])\n",
        "    print(\"test generate passed syccessfully\")\n",
        "\n",
        "def test_preparation_dataset(n, d):\n",
        "      print(\"\\ntest preparation dataset started\")\n",
        "      X_train = np.random.rand(n, d)\n",
        "      print(\"X_train \\n\", X_train)\n",
        "      mask = np.random.binomial(1, 0.5, (n, d))\n",
        "      print(\"mask, 0 seen, 1 missing \\n \", mask)\n",
        "      X_masked = X_train * (1 - mask)\n",
        "      print(\"X_masked \\n\", X_masked)\n",
        "      X_nan_train = X_train.copy()\n",
        "      X_nan_train[mask == 1] = np.nan\n",
        "      print(\"X_nan_train \\n\", X_nan_train)\n",
        "      X_br_train = single_imputation(X_nan_train, BayesianRidge())\n",
        "      print(\"X_br_train\\n \", X_br_train)\n",
        "\n",
        "      print(\"what happens if we run single_imputation of full dataset\")\n",
        "      X_br_full = single_imputation(X_train, BayesianRidge())\n",
        "      print(\"X_br_full\\n \", X_br_full)\n",
        "      np.testing.assert_allclose(X_train, X_br_full)  # shuold be untouched\n",
        "      print(\"test preparation dataset ended successfully\")\n",
        "\n",
        "def test_listwise_delection(n, d):\n",
        "    print(\"\\n test list_wise delection started\")\n",
        "    X = np.random.rand(n, d)\n",
        "    print(\"data\\n\", X)\n",
        "    mask = np.random.binomial(1, 0.2, (n, d))\n",
        "    print(\"mask \\n\", mask)\n",
        "    X_ld = listwise_delection(X, mask)\n",
        "    print(\"after calling function, X_ld \\n\", X_ld)\n",
        "\n",
        "    print(\"edge cases, all missing\")\n",
        "    mask_1 = np.ones_like(X)  # all missing\n",
        "    X1 = listwise_delection(X, mask_1)\n",
        "    print(\"X1 \\n\", X1)  # should be empty\n",
        "    mask_0 = np.zeros_like(X)  # all seen\n",
        "    X0 = listwise_delection(X, mask_0)\n",
        "    print(\"X0 \\n\", X0)\n",
        "    np.testing.assert_allclose(X0, X)  # should be the original dataset\n",
        "\n",
        "    print(\"one dimnsional array\")\n",
        "    y = np.random.rand(n)\n",
        "    print(\"y before \", y)\n",
        "    y_ld = listwise_delection(y, mask)\n",
        "    print(\"y after ld \", y_ld)\n",
        "    print(\"test listwise_delection passed\")\n",
        "\n",
        "\n",
        "test_generate_X()\n",
        "test_preparation_dataset(3, 4)\n",
        "test_listwise_delection(3, 4)\n",
        "test_clear_dataset(6, 3)\n",
        "\n",
        "xxx = np.random.randint(2, 5, size=(3, 3)) * 1.0\n",
        "mmm = np.random.binomial(1, 0.5, size=(3, 3))\n",
        "print(xxx)\n",
        "print(mmm)\n",
        "print(mmm == 1)\n",
        "print(xxx[mmm == 1])\n",
        "xxx[mmm == 1] = np.nan\n",
        "print(xxx)\n",
        "mask_from_xxx = np.isnan(xxx).astype(int)\n",
        "print(\"mask from xxx \\n\", mask_from_xxx)\n"
      ],
      "metadata": {
        "id": "SDHMAeapZVgK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test best predictor\n",
        "\n",
        "def test_best_predictor(n, d, nb_coeff):\n",
        "  X_test = np.random.randint(1, 9, size=(n, d))\n",
        "  beta_gt_test = np.random.randint(1, 7, size=d)\n",
        "  y_test = X_test @ beta_gt_test\n",
        "  #print(\"X_test \\n\", X_test, \"\\n beta_gt\", beta_gt_test, \"\\n y_test = X_test @ beta_gt_test \", y_test)\n",
        "  coeff_test = np.random.randint(1, 5, size=(d, nb_coeff))\n",
        "  rdm_idx = np.random.randint(1, d+1, size=1)\n",
        "  print(rdm_idx)\n",
        "  #print(\"coeff test partial \", coeff_test[:, -1])\n",
        "  rng = np.arange(nb_coeff)\n",
        "  #print(rng != rdm_idx)\n",
        "  coeff_test[:, rng != rdm_idx] = coeff_test[:, rng != rdm_idx] + 1000  # increase artificially the value of the other coefficient, to induce the minimum index to be rdm_idx\n",
        "  #print(\"coeff_test \\n\", coeff_test)\n",
        "  best_coeff, best_score = best_predictor(X_test, coeff_test, y_test)\n",
        "  print(\"best coeff \", best_coeff)\n",
        "  print(\"best score \", best_score)\n",
        "  np.testing.assert_allclose(best_coeff, coeff_test[:,rdm_idx].squeeze())\n",
        "  print(\"test best predictor passed\")\n",
        "\n",
        "test_best_predictor(100, 5, 20)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJk1Yaj1ReIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test train_and_plot\n",
        "\n",
        "X_diab, y_diab = datasets.load_diabetes(return_X_y=True)\n",
        "n, d = X_diab.shape\n",
        "print(\"n:  \", n, \", d: \", d)\n",
        "# Standardize data\n",
        "X_diab -= X_diab.mean(axis=0)\n",
        "X_diab /= X_diab.std(axis=0)\n",
        "\n",
        "## original lasso\n",
        "fig_l, ax_l = plt.subplots(num='lasso')\n",
        "alphas_lasso, coefs_lasso, _ = get_lasso_path(X_diab, y_diab)\n",
        "plot_coefs_l1norm(coefs_lasso, ax_l)\n",
        "\n",
        "## Antonio's algo, 1 matrix\n",
        "S_diab_eye = np.eye(X_diab.shape[1])\n",
        "fig, ax_1 = plt.subplots(1, 1, num='advtrain_linf_diab')\n",
        "fig, ax_2 = plt.subplots(1, 1, num='advtrain_linf_diab_2')\n",
        "train_and_plot(X_diab, y_diab, S_diab_eye, [ax_1, ax_2])\n",
        "\n",
        "## Antonio's algo, multiple diagonal matrix\n",
        "#S_diab = np.eye(X_diab.shape[1])\n",
        "#S_diab = np.random.randint(1, 3, size=(n, d))\n",
        "#print(S_diab)\n",
        "#fig, ax_5 = plt.subplots(1, 1, num='advtrain_linf_diab_5')\n",
        "#fig, ax_6 = plt.subplots(1, 1, num='advtrain_linf_diab_6')\n",
        "#train_and_plot(X_diab, y_diab, S_diab, [ax_5, ax_6])\n",
        "\n",
        "\n",
        "## Antonio's algo, multiple matrices (same matrix stacked multiple time)\n",
        "S_diab_stacked = np.array([S_diab_eye] * X_diab.shape[0])\n",
        "S_diab_stacked = np.concatenate(S_diab_stacked)\n",
        "fig, ax_3 = plt.subplots(1, 1, num='advtrain_linf_diab_3')\n",
        "fig, ax_4 = plt.subplots(1, 1, num='advtrain_linf_diab_4')\n",
        "train_and_plot(X_diab, y_diab, S_diab_stacked, [ax_3, ax_4])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KjpHk0mYdiFh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test imputations\n",
        "\n",
        "np.random.seed(45)\n",
        "\n",
        "\n",
        "def test_imputations(n, d):\n",
        "  X = np.random.randint(2, 5, size=(n, d)) * 1.0\n",
        "  y = X @ np.random.randint(1, 3, size=d)\n",
        "  m = np.random.binomial(1, 0.4, size=(n, d))  # 1 missing, 0 seen\n",
        "  print(\"m original\\n\", m)\n",
        "  X, y, m = clear_dataset(X, y, m)\n",
        "  print(m)\n",
        "  X_nan = X.copy()\n",
        "  X_nan[m == 1] = np.nan\n",
        "\n",
        "  #mask_from_xxx = np.isnan(xxx).astype(int)\n",
        "  print(\"X\\n \", X)\n",
        "  print(\"masks \\n\", m)\n",
        "  print(\"X_nan\\n \", X_nan)\n",
        "  methods = ['BR_si', 'mi', 'l_d']\n",
        "  nbr_mi = [1, 3]\n",
        "  #for method in methods:\n",
        "  #  dict_info = {'imp_method': method, 'mi_nbr':nbr_mi}\n",
        "  #dict_info = {'imp_method':methods, 'mi_nbr':nbr_mi}\n",
        "  for method in methods:\n",
        "    print(\"---------- method: \", method)\n",
        "    if method == 'mi':\n",
        "      for x in nbr_mi:\n",
        "        print(\"-------------------- nbr mi: \", x)\n",
        "        dict_info = {'imp_method':method, 'mi_nbr':x}\n",
        "        #print(\"XNANNANAN \", X_nan)\n",
        "        X_res, y_res, mask_res = imputations(dict_info, X_nan, y)\n",
        "        print(X_res, y_res, \"\\n\", mask_res)\n",
        "    else:\n",
        "      dict_info = {'imp_method': method}\n",
        "      X_res, y_res, mask_res = imputations(dict_info, X_nan, y)\n",
        "      print(X_res, y_res, \"\\n\", mask_res)\n",
        "    print(\"test imputations ended successfully\")\n",
        "\n",
        "test_imputations(6, 3)\n"
      ],
      "metadata": {
        "id": "z5crxb1usyn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = np.array([1, 2])\n",
        "x.append(y)\n",
        "x.append(y)\n",
        "x.append(y)\n",
        "xx = np.stack(x)\n",
        "print(x)\n",
        "print(xx)\n",
        "print(type(xx))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sizes = [100, 1000, 10000, 100000]\n",
        "values = [0.8, 0.85, 0.9, 0.92]\n",
        "positions = range(len(sizes))\n",
        "\n",
        "plt.plot(positions, values, marker='o', label='Model Accuracy')  # Add label here\n",
        "plt.xticks(positions, sizes)\n",
        "\n",
        "plt.xlabel(\"Dataset Size (equispaced)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Performance vs Dataset Size (equispaced x-axis)\")\n",
        "#plt.legend()  # Show legend\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GU2RjW63SNaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dictio = {'a':1, 'b':2, 'c':3}\n",
        "vv = dictio.values()\n",
        "#print(vv)\n",
        "#print(vv[1])\n",
        "\n",
        "x1 = np.array([1, 2, 3])\n",
        "x2 = np.array([3, 2 ,1])\n",
        "v = np.maximum(x1, x2)\n",
        "print(v)\n"
      ],
      "metadata": {
        "id": "UE1NuR4D2h8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "648zfFp8ERD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n, d = 2, 3, 2\n",
        "x_int = np.random.randint(1, 9, (m, n, d))\n",
        "print(x_int)\n",
        "s = np.std(x_int, axis=0)\n",
        "print(s)\n",
        "\n",
        "# manual\n",
        "print(\"manual computation\")\n",
        "x = np.zeros((m, d))\n",
        "for i in range(n):\n",
        "  print(\"i -----> \", i)\n",
        "  x = x_int[:, i, :]\n",
        "  print(\"x\\n\", x)\n",
        "  ss = np.std(x, axis=0)\n",
        "  print(ss)\n",
        "\n",
        "\n",
        "print(\"little exp on squeeze\")\n",
        "sss = np.random.rand(1, 3, 3)\n",
        "print(sss)\n",
        "print(sss.squeeze())\n",
        "print(sss.squeeze())\n",
        "\n"
      ],
      "metadata": {
        "id": "vpBvPibeERnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(34.99)\n",
        "\n",
        "xxxx = np.random.randint(2, 4, (5, 2))\n",
        "print(xxxx)\n",
        "xxxx[0:2, :] = 1\n",
        "print(xxxx)\n",
        "\n",
        "print(\"yyyy\\n\")\n",
        "yy = []\n",
        "yy.append([1, 2, 3])\n",
        "yy.append([4, 5, 6])\n",
        "print(yy)\n",
        "print(np.stack( yy ).T)\n",
        "print(\"\\n\\n\")\n",
        "yyy = np.random.randint(1, 10, size=(3 , 3))\n",
        "print(yyy)\n",
        "yyy_a = np.array([yyy] * 2)\n",
        "print(yyy_a.shape)\n",
        "print(np.concatenate([yyy] * 2))\n",
        "#print(np.tile(yyy_a, (2, 1, 1) ))\n",
        "\n",
        "zzz = np.zeros((2, 2))\n",
        "\n",
        "np.sum(np.zeros((2, 2)) == zzz)"
      ],
      "metadata": {
        "id": "et578OpzERsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def multiple_imputation1(nbr_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 1000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res shape\", res.shape)\n",
        "       #if nbr_mi == 1:\n",
        "        #res = res[0, :, :]\n",
        "        #print(\"fin res shape\", res.shape)\n",
        "    return res\n",
        "\n",
        "\n",
        "Xx = np.random.randint(1, 3, (4, 4)) * 1.0\n",
        "mm = np.random.binomial(1, 0.25, (4, 4))\n",
        "print(Xx)\n",
        "print(mm)\n",
        "Xx[mm == 1] = np.nan\n",
        "print(Xx)\n",
        "\n",
        "ice = IterativeImputer(random_state=18, max_iter=50, sample_posterior=True)\n",
        "ice.fit(Xx)\n",
        "XxX = np.random.randint(1, 3, (2, 4)) * 1.0\n",
        "mmM = np.random.binomial(1, 0.5, (2, 4))\n",
        "print(XxX)\n",
        "print(mmM)\n",
        "XxX[mmM == 1] = np.nan\n",
        "print(XxX)\n",
        "\n",
        "print(ice.transform(XxX))\n",
        "print(ice.transform(XxX))\n",
        "\n",
        "print(\"new\")\n",
        "\n",
        "ls = [[[]],[[]]]\n",
        "print(ls)\n",
        "ls[0][0]\n",
        "\n"
      ],
      "metadata": {
        "id": "_U_r_qaJ9pw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "XX = np.random.randint(1, 7, (2, 3, 3))\n",
        "print(XX)\n",
        "XXX = np.tile(XX, (2, 1, 1))\n",
        "print(XXX)\n",
        "\n",
        "print(np.zeros(2))\n",
        "\n",
        "y_o = np.array([1, 2])\n",
        "y_oo = np.tile(y_o, 3)\n",
        "print(y_oo)\n"
      ],
      "metadata": {
        "id": "PXfceAK8es4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def generate_masks_binomial_general(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "\n",
        "\n",
        "#mm = np.random.binomial(1, [[0.2, 0.2, 0.2], [0.8, 0.8, 0.8]], (2, 3, 3))\n",
        "#print(mm)\n",
        "cc = np.array([np.random.binomial(1, x, (4, 4)) for x in [0.2, 0.2, 0.2]])\n",
        "print(cc)\n",
        "s_cc = np.cumsum(cc, axis=0)\n",
        "print(s_cc)\n",
        "s_cc[s_cc>1] = 1\n",
        "print(s_cc)\n",
        "\n",
        "s_v = np.random.randint(1, 4, (3, 4))\n",
        "print(s_v)\n",
        "s_vv = s_v[:, None, :] * np.eye(4)\n",
        "print(s_vv)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "auugsvFPZ88A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import ridge_regression\n",
        "\n",
        "X = np.random.randn(100, 4) #rng.randn(100, 4)\n",
        "\n",
        "y = 2.0 * X[:, 0] - 1.0 * X[:, 1] + 0.1 * np.random.randn(100)\n",
        "np.random.seed(4)\n",
        "alphas = [0.00001, 0.001, 0.1, 1]\n",
        "estim = lambda XX, yy, rad: ridge_regression(XX, yy, alpha=rad, return_intercept=False, random_state=0)\n",
        "for a in alphas:\n",
        "  #coef, intercept = estim(X, y, a)\n",
        "  coef = estim(X, y, a)\n",
        "  print(\"coef : \", coef)\n",
        "  #print(\"intercpt \", intercept)\n",
        "  coef, intercept = ridge_regression(X, y, alpha=a, return_intercept=True, random_state=0)\n",
        "  #print(\"coef : \", coef)\n",
        "  #print(\"intercpt \", intercept)\n",
        "\n",
        "\n",
        "lg = np.random.logistic(loc=0.0, scale=1.0, size=(4, 3))\n",
        "print(\"log res \", lg)\n",
        "\n"
      ],
      "metadata": {
        "id": "t3KaZyJKwnRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import miceforest as mf\n",
        "#from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "d = 5\n",
        "n = 10\n",
        "print(\"ciao \")\n",
        "x = np.random.randint(low=0, high=100, size=(n, d))\n",
        "x = pd.DataFrame(x)\n",
        "x.columns = x.columns.astype(str)\n",
        "m = np.random.binomial(1, 0.3, size=(n, d))\n",
        "mm = (m==1)\n",
        "x[mm] = np.nan\n",
        "print(mm)\n",
        "print(x)\n",
        "\n",
        "\n",
        "# Create kernel.\n",
        "kernel = mf.ImputationKernel(\n",
        "  x,\n",
        "  num_datasets=4,\n",
        "  random_state=1,\n",
        "  mean_match_candidates=0\n",
        ")\n",
        "\n",
        "# Run the MICE algorithm for 2 iterations on each of the datasets\n",
        "\n",
        "%time kernel.mice(3)\n",
        "\n",
        "\n",
        "cd1 = kernel.complete_data(dataset=1)\n",
        "cd2 = kernel.complete_data(dataset=2)\n",
        "#print(\"cd1\\n\", cd1, \"\\ncd2\\n\", cd2)\n",
        "res = np.zeros((4, n, d))\n",
        "\n",
        "for i in range(4):\n",
        "  res[i, :, :] = kernel.complete_data(dataset=i)\n",
        "\n",
        "print(\"res\\n \", res)\n",
        "\n",
        "# Printing the kernel will show you some high level information.\n",
        "print(kernel)\n",
        "\n"
      ],
      "metadata": {
        "id": "X4Yyr2ZEACBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72e69d0d"
      },
      "source": [
        "# test miceforest\n",
        "\n",
        "def test_miceforest(n, d, p_seen, nbr_c):\n",
        "    x_mf_test = np.random.randint(low=0, high=99, size=(n, d)) + 0.0\n",
        "    m_mf_test = np.random.binomial(1, p_seen, size=(n, d))\n",
        "    x_mf_test[m_mf_test == 1] = np.nan\n",
        "    print(x_mf_test)\n",
        "    info_mf_test = {'mi_nbr': 5, 'nbr_candidates_mm': nbr_c}\n",
        "\n",
        "    print(np.isnan(x_mf_test))\n",
        "    print(np.isnan(x_mf_test).sum() )\n",
        "\n",
        "\n",
        "    res = miceforest_imputation(info_mf_test, x_mf_test)\n",
        "    print(res)\n",
        "\n",
        "test_miceforest(13, 5, 0.2, 5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0972221c"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a8ebaea"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}