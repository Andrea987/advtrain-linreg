{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea987/advtrain-linreg/blob/main/notebooks/fig1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Sgo-CifolM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ggDSA-ktpXgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6023a7a-22e2-418b-bc99-edc4761c2420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CLARABEL', 'CVXOPT', 'GLPK', 'GLPK_MI', 'HIGHS', 'OSQP', 'SCIPY', 'SCS']\n",
            "end block\n"
          ]
        }
      ],
      "source": [
        "from re import VERBOSE\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from sklearn.linear_model import lasso_path\n",
        "from sklearn import datasets\n",
        "from sklearn import linear_model\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import tqdm\n",
        "import cvxpy as cp\n",
        "print(cp.installed_solvers())\n",
        "import numpy as np\n",
        "\n",
        "import traceback\n",
        "\n",
        "\n",
        "def compute_q(p):\n",
        "    if p != np.inf and p > 1:\n",
        "        q = p / (p - 1)\n",
        "    elif p == 1:\n",
        "        q = np.inf\n",
        "    else:\n",
        "        q = 1\n",
        "    return q\n",
        "\n",
        "\n",
        "class AdversarialTraining:\n",
        "    def __init__(self, X, y, S_inv, p):  # S is the matrix such that ||S @ Dx||\\leq delta. As a consequence, S_inv appears in the unconstrained problem\n",
        "        m, n = X.shape\n",
        "        q = compute_q(p)\n",
        "        print(\"who is q \", q)\n",
        "        # Formulate problem\n",
        "        param = cp.Variable(n)\n",
        "        print(\"shape param \", param.shape)\n",
        "        print(\"dim \", n)\n",
        "        print(S_inv.shape)\n",
        "        print(\"S_inv \", S_inv)\n",
        "        partial = S_inv @ param  # should be (m * n,)\n",
        "        if S_inv.shape == (n, n):\n",
        "          print(\"S_inv (n, n)\")\n",
        "          param_norm = cp.pnorm(partial, p=q)\n",
        "        else:  # should be a stack of matrix\n",
        "          print(\"S_inv conc\")\n",
        "          print(\"shape partial 1\", partial.shape)\n",
        "          partial = cp.reshape(partial, (m, n), order='C')\n",
        "          print(\"shape partial \", partial.shape)\n",
        "          param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        print(\"param_norm.shape\", param_norm.shape)\n",
        "        print(\"param_norm\\n\", param_norm)\n",
        "        adv_radius = cp.Parameter(name='adv_radius', nonneg=True)\n",
        "        print(\"ciao2\")\n",
        "        abs_error = cp.abs(X @ param - y)\n",
        "        print(\"abs_error.shape \", abs_error.shape)\n",
        "        print(\"ciao3\")\n",
        "        adv_loss = 1 / m * cp.sum((abs_error + adv_radius * param_norm) ** 2)\n",
        "        print(\"ciao4\")\n",
        "        prob = cp.Problem(cp.Minimize(adv_loss))\n",
        "        self.prob = prob\n",
        "        self.adv_radius = adv_radius\n",
        "        self.param = param\n",
        "        self.warm_start = False\n",
        "\n",
        "\n",
        "    def __call__(self, adv_radius, **kwargs):\n",
        "        try:\n",
        "            self.adv_radius.value = adv_radius\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "\n",
        "\n",
        "def get_lasso_path(X, y, eps_lasso=1e-5):\n",
        "    alphas, coefs, _ = lasso_path(X, y, eps=eps_lasso)\n",
        "    coefs= np.concatenate([np.zeros([X.shape[1], 1]), coefs], axis=1)\n",
        "    alphas = np.concatenate([1e2 * np.ones([1]), alphas], axis=0)\n",
        "    return alphas, coefs, []\n",
        "\n",
        "\n",
        "def get_path(X, y, estimator, amax, eps=1e-5, n_alphas=200):\n",
        "    _, m = X.shape\n",
        "    amin = eps * amax\n",
        "    alphas = np.logspace(np.log10(amin), np.log10(amax), n_alphas)\n",
        "    coefs_ = []\n",
        "    for a in tqdm.tqdm(alphas):\n",
        "        coefs = estimator(X, y, a)\n",
        "        #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "        coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "    return alphas, np.stack((coefs_)).T\n",
        "\n",
        "\n",
        "def plot_coefs(alphas, coefs, ax):\n",
        "    print(\"you are printing coefs in function of 1/alphas\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).sum(axis=0)\n",
        "    ax.set_xlabel(\"1/alphas\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.semilogx(1/alphas, coef_l, c=c)\n",
        "        #ax.semilogx(1/alphas, l1norm, c=c)\n",
        "        #ax.plot(1/alphas, coef_l, c=c)\n",
        "\n",
        "\n",
        "def plot_coefs_l1norm(coefs, ax):\n",
        "    print(\"you are printing coeff in function of l1 norm\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).mean(axis=0)\n",
        "    l1norm = np.abs(coefs).sum(axis=0)\n",
        "    #print(\"coef \", coefs)\n",
        "    #print(\"l1norm \", l1norm)\n",
        "    ax.set_xlabel(\"l1norm\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.plot(l1norm, coef_l, c=c)\n",
        "\n",
        "\n",
        "def train_and_plot(X, y, S_inv, list_ax):\n",
        "    linfadvtrain = AdversarialTraining(X, y, S_inv, p=np.inf)\n",
        "    estimator = lambda X, y, a:  linfadvtrain(adv_radius=a)\n",
        "    alphas_adv, coefs_advtrain_linf  = get_path(X, y, estimator, 1e1)\n",
        "    plot_coefs_l1norm(coefs_advtrain_linf, list_ax[0])\n",
        "    plot_coefs(alphas_adv, coefs_advtrain_linf, list_ax[1])\n",
        "    return coefs_advtrain_linf\n",
        "\n",
        "\n",
        "def add_rectangles(x, y, box_width, box_height, ax):\n",
        "  for xi, yi in zip(x, y):\n",
        "      rect = patches.Rectangle(\n",
        "        (xi-box_width/2, yi-box_height/2),\n",
        "        box_width, box_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "      )\n",
        "      ax.add_patch(rect)\n",
        "print(\"end block\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation's block\n",
        "\n",
        "def clear_dataset(x, masks):\n",
        "  # remove observations full NaN\n",
        "  M = np.sum(1 - masks, axis=1) > 0\n",
        "  return x[M, :], masks[M, :]\n",
        "\n",
        "\n",
        "def single_imputation(X_nan, impute_estimator):\n",
        "    ice = IterativeImputer(estimator=impute_estimator)\n",
        "    return ice.fit_transform(X_nan)\n",
        "\n",
        "\n",
        "def multiple_imputation(nbr_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 1000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res \", res)\n",
        "    return res\n",
        "\n",
        "\n",
        "def imputation_elliptic(mu, sigma, x, masks):\n",
        "  # mu, mean elliptical distribution (,d)\n",
        "  # sigma, cov matrix elliptical distribution (d, d)\n",
        "  # x: dataset (n, d)\n",
        "  # masks: mask data, 0 seen, 1 missing\n",
        "  n, d = x.shape\n",
        "  print(n, d)\n",
        "  x_imp = x.copy()\n",
        "  #print(\"x_imp clean\", x_imp)\n",
        "  for i in range(n):\n",
        "    if not (masks[i, :] == 0).all():  # if we have at least one missing component\n",
        "      #print(\"nbr : \", i)\n",
        "      x_c = x[i, :]\n",
        "      m_bool = (masks[i, :] == 0)  # True seen, False missing\n",
        "      sigma_aa_inv = np.linalg.inv(sigma[m_bool, :][:, m_bool])\n",
        "      sigma_ma = sigma[~m_bool, :][:, m_bool]\n",
        "      mu_cond = mu[~m_bool] + sigma_ma @ sigma_aa_inv @ (x_c[m_bool] - mu[m_bool])\n",
        "      x_imp[i, ~m_bool] = mu_cond\n",
        "  return x_imp\n",
        "\n"
      ],
      "metadata": {
        "id": "qyWskXpdOW9e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define observations\n",
        "np.random.seed(45)\n",
        "n_observationsss = 300\n",
        "dim = 10\n",
        "#cov = np.random.randint(low=1, high=10, size=(d, d))\n",
        "#cov = np.random.randn(d, d)\n",
        "#cov = cov.T @ cov + np.eye(dim) * 1e-5\n",
        "#print(cov)\n",
        "#print(np.linalg.eigvalsh(cov))\n",
        "cov = np.eye(dim)\n",
        "X_orig = np.random.rand(n_observationsss, dim) @ cov\n",
        "#X_orig = np.random.randint(low=1, high=4, size=(n, d)) * 1.0\n",
        "#X -= X.mean(axis=0)\n",
        "#X /= X.std(axis=0)\n",
        "b = np.random.rand(dim)\n",
        "\n",
        "#L = np.linalg.cholesky(S)  # return L such that S = LL.T\n",
        "#L_inv = np.linalg.inv(L)\n",
        "#S_inv = L_inv.T @ L_inv\n",
        "\n",
        "masks = np.random.binomial(1, 0.25, (n_observationsss, dim))  # 1 missing, 0 seen\n",
        "\n",
        "X_orig, masks = clear_dataset(X_orig, masks)\n",
        "n_observationsss = X_orig.shape[0]\n",
        "print(\"shape \", X_orig.shape)\n",
        "print(\"final shape \", X_orig.shape)\n",
        "y = X_orig @ b\n",
        "X_nan = X_orig.copy()\n",
        "X_nan[masks == 1] = np.nan\n",
        "print(\"end block\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElCvHxBiO_2t",
        "outputId": "bdfc3cce-dae7-4e5b-c3de-0d63e471a428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape  (300, 10)\n",
            "final shape  (300, 10)\n",
            "end block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## original lasso\n",
        "fig, ax = plt.subplots(num='lasso')\n",
        "alphas_lasso, coefs_lasso, _ = get_lasso_path(X_orig, y)\n",
        "plot_coefs_l1norm(coefs_lasso, ax)"
      ],
      "metadata": {
        "id": "ZA7J67yAuQM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training with original dataset X_orig\n",
        "fig, ax = plt.subplots(num='advtrain_linf')\n",
        "sd_orig = np.std(X_orig, axis=0)\n",
        "print(\"sd_orig \\n\", sd_orig)\n",
        "S_inv_orig = np.diag(1 / sd_orig)\n",
        "#S_inv_orig = np.eye(dim)\n",
        "S_inv_orig = np.array([S_inv_orig] * n_observationsss)\n",
        "S_inv_orig = np.concatenate(S_inv_orig)\n",
        "print(\"S_inv_orig.shape \", S_inv_orig.shape)\n",
        "test = S_inv_orig @ np.arange(dim)\n",
        "#print(\"test mult\\n\", test)\n",
        "#print(\"test reshape \\n\", test.reshape(n_observationsss, dim, order='C'))\n",
        "#print(S_inv_orig)\n",
        "#S_inv_orig = np.diag(1 / sd_orig)\n",
        "#print(\"S_inv_orig shape\\n \", S_inv_orig.shape)\n",
        "#S_inv_orig = np.eye(X_orig.shape[0])\n",
        "linfadvtrain = AdversarialTraining(X_orig, y, S_inv_orig, p=np.inf)\n",
        "estimator = lambda X, y, a:  linfadvtrain(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf  = get_path(X_orig, y, estimator, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf, ax)\n",
        "#plot_coefs(alphas_adv, coefs_advtrain_linf, ax)"
      ],
      "metadata": {
        "id": "N1uZArXkprXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2d toy example\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10, 8), num='advtrain_linf_2d')\n",
        "\n",
        "\n",
        "def generate_masks_2d(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    # p_missing = [0.3, 0.3, 0.4]\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "\n",
        "np.random.seed(42)\n",
        "nb_2d_train = 20\n",
        "nb_2d_test = 50\n",
        "nb_tot = nb_2d_train + nb_2d_test\n",
        "ts = nb_2d_test / nb_tot\n",
        "print(\"test size \", ts)\n",
        "beta_2d = np.array([0.5, 2])  # beta_true\n",
        "p_miss_2d = [0.2, 0.4, 0.4]\n",
        "mask_2d = generate_masks_2d(nb_2d_train, p_miss_2d)  # 1 missing, 0 observed\n",
        "M = np.sum(mask_2d, axis=1)  # M[i] > 0 iff i has missing component\n",
        "print(\"nbr components without missing entries \", np.sum(1-M))\n",
        "#print(mask_2d)\n",
        "print(\"print M, M[i] == 1 iff one component is missing\", M)\n",
        "X_complete_2d = np.random.randn(nb_2d_train + nb_2d_test, 2)\n",
        "y_complete_2d = X_complete_2d @ beta_2d + np.random.randn(nb_tot) * 1e-1\n",
        "\n",
        "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(X_complete_2d, y_complete_2d, test_size=ts)\n",
        "\n",
        "X_2d_masked = X_train_2d * (1 - mask_2d)\n",
        "print(mask_2d)\n",
        "print(X_2d_masked)\n",
        "\n",
        "X_nan_train_2d = X_train_2d.copy()\n",
        "X_nan_train_2d[mask_2d == 1] = np.nan\n",
        "#print(X_nan_2d)\n",
        "X_br_train_2d = single_imputation(X_nan_train_2d, BayesianRidge())\n",
        "sd = np.std(X_br_train_2d, axis=0)\n",
        "print(\"sd deviation columnwise: \", sd)\n",
        "#S_inv_2d = np.eye(2)\n",
        "S_inv_2d = np.diag(1 / sd) * 1\n",
        "plt.tight_layout()\n",
        "ax[0].scatter(X_br_train_2d[M == 0, 0], X_br_train_2d[M == 0, 1])\n",
        "ax[0].scatter(X_br_train_2d[M == 1, 0], X_br_train_2d[M == 1, 1])\n",
        "add_rectangles(X_br_train_2d[:, 0], X_br_train_2d[:, 1], S_inv_2d[0, 0], S_inv_2d[1, 1], ax[0])\n",
        "\n",
        "\n",
        "#def train_and_plot(X, y, S_inv, list_ax):\n",
        "#  linfadvtrain_2d = AdversarialTraining(X, y, S_inv, p=np.inf)\n",
        "#  estimator = lambda X, y, a:  linfadvtrain_2d(adv_radius=a)\n",
        "#  alphas_adv, coefs_advtrain_linf_2d  = get_path(X_br_train_2d, y_train_2d, estimator, 1e1)\n",
        "#  plot_coefs_l1norm(coefs_advtrain_linf_2d, list_ax[0])\n",
        "#  plot_coefs(alphas_adv, coefs_advtrain_linf_2d, list_ax[1])\n",
        "\n",
        "def best_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  print(\"size haty \", hat_y.shape)\n",
        "  r = hat_y - y  # residual\n",
        "  print(\"size r \", r.shape)\n",
        "  score = np.sum(r * r, axis=0)\n",
        "  i_min = np.argmin(score)\n",
        "  return coeff[:, i_min]\n",
        "\n",
        "\n",
        "coeff_res = train_and_plot(X_br_train_2d, y_train_2d, S_inv_2d, [ax[1], ax[2]])\n",
        "print(\"shape coeff \", coeff_res.shape)\n",
        "#print(\"coeff \", coeff_res.T)\n",
        "best_coeff = best_predictor(X_test_2d, coeff_res, y_test_2d)\n",
        "print(\"best coeff \", best_coeff)\n",
        "\n",
        "\n",
        "\n",
        "# could be interesting to make a confrontation with listwise delection (delete observation with one missing components)\n",
        "\n",
        "\n",
        "#linfadvtrain_2d = AdversarialTraining(X_br_train_2d, y_train_2d, S_inv_2d, p=np.inf)\n",
        "#estimator = lambda X, y, a:  linfadvtrain_2d(adv_radius=a)\n",
        "#alphas_adv, coefs_advtrain_linf_2d  = get_path(X_br_train_2d, y_train_2d, estimator, 1e1)\n",
        "#plot_coefs_l1norm(coefs_advtrain_linf_2d, ax[1])\n",
        "#plot_coefs(alphas_adv, coefs_advtrain_linf_2d, ax[2])\n",
        "\n",
        "#print(\"coef \", coefs_advtrain_linf_2d)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-lnYAbHhiPC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "p_miss_2d = [0.2, 0.4, 0.4]\n",
        "beta_2d = np.array([0.5, 2])  # ground truth\n",
        "def experiment_2d(n_tot, perc_test, p_miss, beta_gt):\n",
        "\n",
        "    fig, ax = plt.subplots(3, 1, figsize=(10, 8), num='advtrain_linf_2d')\n",
        "    X_complete = np.random.randn(n_tot, beta_gt.size)\n",
        "    y_complete = X_complete @ beta_gt + np.random.randn(n_tot) * 1e-1\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_complete, y_complete, test_size=perc_test)\n",
        "\n",
        "    n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
        "    mask = generate_masks_2d(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    M = np.sum(mask, axis=1)  # M[i] > 0 iff i has missing component\n",
        "    print(M.size)\n",
        "    print(\"nbr components without missing entries \", np.sum(1-M))\n",
        "    print(\"print M, M[i] == 1 iff one component is missing\", M)\n",
        "\n",
        "    X_masked = X_train * (1 - mask)\n",
        "    #print(mask)\n",
        "    #print(X_masked)\n",
        "\n",
        "    X_nan_train = X_train.copy()\n",
        "    X_nan_train[mask == 1] = np.nan\n",
        "\n",
        "    X_br_train = single_imputation(X_nan_train, BayesianRidge())\n",
        "    sd = np.std(X_br_train, axis=0)\n",
        "    print(\"shape X_bri Train \", X_br_train.shape)\n",
        "    print(\"sd deviation columnwise: \", sd)\n",
        "\n",
        "    S_inv = np.diag(1 / sd) * 1\n",
        "    plt.tight_layout()\n",
        "    print(X_br_train[M == 0, 0])\n",
        "    ax[0].scatter(X_br_train[M == 0, 0], X_br_train[M == 0, 1])\n",
        "    ax[0].scatter(X_br_train[M == 1, 0], X_br_train[M == 1, 1])\n",
        "    add_rectangles(X_br_train[:, 0], X_br_train[:, 1], S_inv[0, 0], S_inv[1, 1], ax[0])\n",
        "\n",
        "    coeff_res = train_and_plot(X_br_train, y_train, S_inv, [ax[1], ax[2]])\n",
        "    print(\"shape coeff \", coeff_res.shape)\n",
        "    best_coeff = best_predictor(X_test, coeff_res, y_test)\n",
        "    print(\"best coeff \", best_coeff)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "AN61ok0A_Mbv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_miss_2d = [0.2, 0.4, 0.4]\n",
        "beta_2d = np.array([0.5, 2])  # ground truth\n",
        "\n",
        "experiment_2d(100, 0.1, p_miss_2d, beta_2d)"
      ],
      "metadata": {
        "id": "OhNXUBahJgBL",
        "outputId": "18cefb84-ad2d-4916-81ce-06596d6c2725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n",
            "nbr components without missing entries  13.0\n",
            "print M, M[i] == 1 iff one component is missing [1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "shape X_bri Train  (90, 2)\n",
            "sd deviation columnwise:  [0.60990397 0.78669293]\n",
            "[ 0.91540212  0.09707755  1.57921282 -1.72491783 -0.97468167 -0.88385744\n",
            " -0.44651495  0.08704707  0.06023021  0.17318093  1.86577451 -0.54438272\n",
            "  1.15859558]\n",
            "who is q  1\n",
            "shape param  (2,)\n",
            "dim  2\n",
            "(2, 2)\n",
            "S_inv  [[1.63960239 0.        ]\n",
            " [0.         1.271144  ]]\n",
            "S_inv (n, n)\n",
            "param_norm.shape ()\n",
            "param_norm\n",
            " norm1([[1.64 0.00]\n",
            " [0.00 1.27]] @ var537)\n",
            "ciao2\n",
            "abs_error.shape  (90,)\n",
            "ciao3\n",
            "ciao4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:01<00:00, 138.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are printing coeff in function of l1 norm\n",
            "you are printing coefs in function of 1/alphas\n",
            "shape coeff  (2, 200)\n",
            "size haty  (200, 10)\n",
            "size r  (200, 10)\n",
            "best coeff  [0.35529822 2.01630895]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## random forest imputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_estimator = RandomForestRegressor(n_estimators=4, max_depth=10, bootstrap=True, max_samples=0.5, n_jobs=2, random_state=0)\n",
        "\n",
        "X_rf = single_imputation(X_nan, rf_estimator)\n",
        "print(X_rf.shape)\n",
        "sd_rf = np.std(X_rf, axis=0)\n",
        "S_inv_rf = np.diag(1 / sd_rf)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std rf\\n \", sd_rf)\n",
        "fig, ax = plt.subplots(num='advtrain_linf_rf')\n",
        "linfadvtrain_rf = AdversarialTraining(X_rf, y, S_inv_rf, p=np.inf)\n",
        "estimator_rf = lambda X, y, a:  linfadvtrain_rf(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_rf  = get_path(X_rf, y, estimator_rf, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_rf, ax)\n"
      ],
      "metadata": {
        "id": "uSgnV3aVXL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## iterative imputer Bayesian Ridge\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "br_estimator = BayesianRidge()\n",
        "\n",
        "X_br = single_imputation(X_nan, br_estimator)\n",
        "sd_br = np.std(X_br, axis=0)\n",
        "S_inv_br = np.diag(1 / sd_br)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std  br\\n \", sd_br)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_br')\n",
        "linfadvtrain_br = AdversarialTraining(X_br, y, S_inv_br, p=np.inf)\n",
        "estimator_br = lambda X, y, a:  linfadvtrain_br(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_br  = get_path(X_br, y, estimator_br, 1e4)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_br, ax)"
      ],
      "metadata": {
        "id": "pgNaP74gWAga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## mean imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_mean = imp_mean.fit_transform(X_nan)\n",
        "sd_mean = np.std(X_mean, axis=0)\n",
        "print(sd_mean)\n",
        "S_inv_mean = np.diag(1 / sd_mean)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_mean')\n",
        "linfadvtrain_mean = AdversarialTraining(X_mean, y, S_inv_mean, p=np.inf)\n",
        "estimator_mean = lambda X, y, a:  linfadvtrain_mean(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_mean  = get_path(X_mean, y, estimator_mean, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_mean, ax)\n"
      ],
      "metadata": {
        "id": "u0kpCJCkFbcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation elliptic\n",
        "\n",
        "mu = np.nanmean(X_nan, axis=0)\n",
        "print(\"means \", mu)\n",
        "delta = np.mean(masks) # parameter missingness\n",
        "print(\"delta \", delta)\n",
        "X_0 = np.nan_to_num(X_nan)\n",
        "print(\"nbr obs\", X_0.shape[0])\n",
        "S_ellp =  X_0.T @ X_0 / X_0.shape[0]\n",
        "S_ellp = (1/delta - 1/(delta**2)) * np.diag(np.diag(S_ellp)) + 1/(delta**2) * S_ellp\n",
        "print(\"eig cov \", np.linalg.eigvalsh(S_ellp))\n",
        "X_ellp = imputation_elliptic(mu, S_ellp, X_nan, masks)\n",
        "S_inv_ellp = np.linalg.inv(S_ellp)  # other variance\n",
        "sd_inv_ellp = np.std(X_ellp, axis=0)\n",
        "print(\"sd ellp\", sd_inv_ellp)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_ellp')\n",
        "linfadvtrain_ellp = AdversarialTraining(X_ellp, y, S_inv_ellp, p=np.inf)\n",
        "estimator_ellp = lambda X, y, a:  linfadvtrain_ellp(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_ellp  = get_path(X_ellp, y, estimator_ellp, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_ellp, ax)\n"
      ],
      "metadata": {
        "id": "2RYR4_BJhXjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mi bayesian ridge\n",
        "\n",
        "number_multiple_imputed_datasets = 5\n",
        "X_mi = np.vstack(multiple_imputation(number_multiple_imputed_datasets, X_nan))\n",
        "sd_mi = np.std(X_mi, axis=0)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"sd_mi\\n \", sd_mi)\n",
        "S_inv_mi = np.diag(1 / sd_mi)\n",
        "yy = np.concatenate([y] * number_multiple_imputed_datasets)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_mi')\n",
        "linfadvtrain_mi = AdversarialTraining(X_mi, yy, S_inv_mi, p=np.inf)\n",
        "estimator_mi = lambda X, y, a:  linfadvtrain_mi(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_mi  = get_path(X_mi, yy, estimator_mi, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_mi, ax)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6mlM-FR-OfL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Observations:\n",
        "\n",
        "-) If the data are np.random.randn(), all the graphs looks similar\n",
        "-) very caotic results if we multiply by a cov matrix\n"
      ],
      "metadata": {
        "id": "FgxEbR071wT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pwDiPU0D_ks",
        "outputId": "56a47f07-4d4d-4ce6-fb97-e508fe0a86de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "def add_rectangles(x, y, box_width, box_height, ax):\n",
        "  for xi, yi in zip(x, y):\n",
        "      rect = patches.Rectangle(\n",
        "        (xi-box_width/2, yi-box_height/2),\n",
        "        box_width, box_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "      )\n",
        "      ax.add_patch(rect)\n",
        "      plt.show()\n",
        "\n",
        "# Example data\n",
        "x_test_rect = np.random.rand(10)\n",
        "y_test_rect = np.random.rand(10)\n",
        "\n",
        "# Plot the points\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x_test_rect, y_test_rect)\n",
        "\n",
        "width = 0.1\n",
        "height = 0.1\n",
        "\n",
        "add_rectangles(x_test_rect, y_test_rect, width, height, ax)\n",
        "\n",
        "# Add the rectangle to the plot\n"
      ],
      "metadata": {
        "id": "-9qaVcwZUB6w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "f453b465-ab0e-4fb2-e6f0-7d51d2786107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.randint(1, 10, size=10)\n",
        "print(x)\n",
        "xx = np.reshape(x, (2, 5), order='C')\n",
        "print(xx.shape[0])\n",
        "print(np.reshape(x, (2, 5), order='C'))\n",
        "print(x.size)\n",
        "print(np.floor(5 * 0.8))\n",
        "print(np.floor(5 * 0.8))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WZeO2EOWHwz",
        "outputId": "60e43419-98ad-40a8-95f8-12bd98cb95b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 1 8 6 3 9 2 8 3 5]\n",
            "2\n",
            "[[6 1 8 6 3]\n",
            " [9 2 8 3 5]]\n",
            "10\n",
            "4.0\n",
            "4.0\n"
          ]
        }
      ]
    }
  ]
}