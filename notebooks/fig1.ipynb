{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea987/advtrain-linreg/blob/main/notebooks/fig1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Sgo-CifolM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ggDSA-ktpXgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454fa81e-193c-4099-81d1-6c6685d0459c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CLARABEL', 'CVXOPT', 'GLPK', 'GLPK_MI', 'HIGHS', 'OSQP', 'SCIPY', 'SCS']\n",
            "end block\n"
          ]
        }
      ],
      "source": [
        "from re import VERBOSE\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from sklearn.linear_model import lasso_path\n",
        "from sklearn import datasets\n",
        "from sklearn import linear_model\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import tqdm\n",
        "import cvxpy as cp\n",
        "print(cp.installed_solvers())\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "import traceback\n",
        "\n",
        "\n",
        "def compute_q(p):\n",
        "    if p != np.inf and p > 1:\n",
        "        q = p / (p - 1)\n",
        "    elif p == 1:\n",
        "        q = np.inf\n",
        "    else:\n",
        "        q = 1\n",
        "    return q\n",
        "\n",
        "\n",
        "class AdversarialTraining:\n",
        "    def __init__(self, X, y, S_dict, p):  # S is the matrix such that ||S^(-1) @ Dx||\\leq delta. As a consequence, S appears in the unconstrained problem\n",
        "        # S: (d, d) matrix, or S = np.concatenate(tS), with tS = [S1,..,S_m], so S is (d * n, d)\n",
        "        n, d = X.shape\n",
        "        q = compute_q(p)\n",
        "\n",
        "        #print(\"who is X\", X)\n",
        "        #print(\"who is y\", y)\n",
        "        #print(\"who is S\", S)\n",
        "        #print(\"who is q in AdversarialTraining: \", q)\n",
        "        #Formulate problem\n",
        "        param = cp.Variable(d)\n",
        "        #print(\"shape param \", param.shape)\n",
        "        #print(\"dim \", n)\n",
        "        print(\"X \", n,\" \", d)\n",
        "        print(\"y shape\", y.shape)\n",
        "        #print(\"S_dict \", S_dict)\n",
        "        #print(\"S in adv training\", S)\n",
        "        print(\"nm \", d*n)\n",
        "        S_dts = S_dict['S_dts']\n",
        "        S_mis = S_dict['S_mis']\n",
        "        adv_radius_times_scale_dts = cp.Parameter(name='adv_radius_times_dts', nonneg=True)\n",
        "        adv_radius_times_scale_mis = cp.Parameter(name='adv_radius_times_mis', nonneg=True)\n",
        "        #scale_dts = cp.Parameter(name='scale_dts', nonneg=True)\n",
        "        #scale_mis = cp.Parameter(name='scale_mis', nonneg=True)\n",
        "        print(\"S_mis in Adbvt training \", S_mis)\n",
        "        #if np.sum(S_mis * S_mis) == 0:\n",
        "        if np.all(S_dict['S_mis'] == 0):\n",
        "          print(\"no missing part\")\n",
        "          S = S_dts * adv_radius_times_scale_dts\n",
        "        else:  # S_mis.shape == (n, d, d):\n",
        "          S_dts_tiled = np.concatenate([S_dts] * n)\n",
        "          S_mis_conc = np.concatenate(S_mis)\n",
        "          #np.concatenate([yyy] * 2)\n",
        "          S = S_dts_tiled * adv_radius_times_scale_dts + S_mis_conc * adv_radius_times_scale_mis\n",
        "          print(\"S type \", type(S))\n",
        "          #S = np.concatenate(S)\n",
        "          print(\"S is a tensor, concatenated\")\n",
        "          print(\"final S after conc \\n\", S)\n",
        "\n",
        "        if S.shape == (d, d):\n",
        "          print(\"one matrix in input, S.shape = (n, n)\")\n",
        "          partial = S @ param  # should be (m * n,)\n",
        "          param_norm = cp.pnorm(partial, p=q)\n",
        "        elif S.shape == (d * n, d):  # should be a stack of matrices\n",
        "          print(\"multiple matrices in input, S conc\")\n",
        "          partial = S @ param  # should be (m * n,)\n",
        "          partial = cp.reshape(partial, (n, d), order='C')\n",
        "          param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        else:\n",
        "          print(\"--------> ERROR: NO MATRIX S FOUND IN ADVERSARIAL TRAINING\")\n",
        "        #elif S.shape == (m , n):  # stack of diagonal matrices\n",
        "        #  print(\"multiple matrices in input, S_i diag\")\n",
        "          #S_cvx = cp.Constant(S)\n",
        "        #  partial = cp.multiply(cp.Parameter(S), param)\n",
        "        #  param_norm = cp.pnorm(partial, p=q, axis=1)\n",
        "        abs_error = cp.abs(X @ param - y)\n",
        "        adv_loss = 1 / n * cp.sum((abs_error + param_norm) ** 2)\n",
        "        prob = cp.Problem(cp.Minimize(adv_loss))\n",
        "        self.prob = prob\n",
        "        self.adv_radius_times_scale_dts = adv_radius_times_scale_dts\n",
        "        self.adv_radius_times_scale_mis = adv_radius_times_scale_mis\n",
        "        #self.scale_dts = scale_dts\n",
        "        #self.scale_mis = scale_mis\n",
        "        self.param = param\n",
        "        self.warm_start = False\n",
        "\n",
        "\n",
        "    def __call__(self, dict_hyper_p, **kwargs):\n",
        "        try:\n",
        "            #print(\"dic thyper p \", dict_hyper_p)\n",
        "            self.adv_radius_times_scale_dts.value = dict_hyper_p['adv_radius_times_dts']\n",
        "            self.adv_radius_times_scale_mis.value = dict_hyper_p['adv_radius_times_mis']\n",
        "            #self.scale_dts.value = dict_hyper_p['scale_dts\n",
        "            #self.scale_mis.value = dict_hyper_p['scale_mis']\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "\n",
        "'''\n",
        "    def __call__(self, adv_radius, **kwargs):\n",
        "        try:\n",
        "            self.adv_radius.value = adv_radius\n",
        "            self.prob.solve(warm_start=self.warm_start, solver=cp.CLARABEL, max_iter=10000, **kwargs)\n",
        "            v = self.param.value\n",
        "        except Exception as e:\n",
        "          print(\"------------------> Error occurred:\")\n",
        "          traceback.print_exc()\n",
        "          v = np.zeros(self.param.shape)\n",
        "        #except:\n",
        "        #    print(\"----------------------> you are in except\")\n",
        "        #    v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "'''\n",
        "\n",
        "\n",
        "def get_lasso_path(X, y, eps_lasso=1e-5):\n",
        "    alphas, coefs, _ = lasso_path(X, y, eps=eps_lasso)\n",
        "    coefs= np.concatenate([np.zeros([X.shape[1], 1]), coefs], axis=1)\n",
        "    alphas = np.concatenate([1e2 * np.ones([1]), alphas], axis=0)\n",
        "    return alphas, coefs, []\n",
        "\n",
        "# dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4 'eps_adv_rad_times_delta_dts': 1e-4}}\n",
        "def get_path(X, y, estimator, S_dict): #eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "    _, m = X.shape\n",
        "    n_a_dts = S_dict['n_a_dts']\n",
        "    a_d_dts_max = S_dict['adv_rad_times_delta_dts_max']\n",
        "    a_d_dts_min = a_d_dts_max * S_dict['eps_adv_rad_times_delta_dts']\n",
        "    if np.all(S_dict['S_mis'] == 0):\n",
        "      n_a_mis, a_d_mis_max, a_d_mis_min = 1, 0, 0\n",
        "    else:\n",
        "      n_a_mis = S_dict['n_a_mis']\n",
        "      a_d_mis_max = S_dict['adv_rad_times_delta_mis_max']\n",
        "      a_d_mis_min = a_d_mis_max * S_dict['eps_adv_rad_times_delta_mis']\n",
        "\n",
        "\n",
        "    if a_d_dts_max < 0 or a_d_mis_max < 0 or n_a_dts < 1 or n_a_mis <1:\n",
        "      print(\"WARNING: some bad values for the grid of cross validation, the number of grid point should be strictly potive, the radius strictly positive\")\n",
        "    alphas_dts = np.logspace(np.log10(a_d_dts_min), np.log10(a_d_dts_max), n_a_dts) if a_d_dts_max > 0 else np.zeros(1)\n",
        "    alphas_mis = np.logspace(np.log10(a_d_mis_min), np.log10(a_d_mis_max), n_a_mis) if a_d_mis_max > 0 else np.zeros(1)\n",
        "    #alphas_dts = np.logspace(np.log10(a_d_dts_min), np.log10(a_d_dts_max), n_a_dts)\n",
        "    #alphas_mis = np.logspace(np.log10(a_d_mis_min), np.log10(a_d_mis_max), n_a_mis)\n",
        "    print(\"dts deltas \", alphas_dts)\n",
        "    print(\"mis deltas \", alphas_mis)\n",
        "    #hyper_p = {'scale_dts': dts_deltas, 'scale_mis': mis_deltas}\n",
        "    hyper_p_ret_ = []\n",
        "    coefs_ = []\n",
        "    for a_mis_value in tqdm.tqdm(alphas_mis):\n",
        "      for a_dts_value in tqdm.tqdm(alphas_dts):\n",
        "          #tuple_key = (scale_dts_value, scale_mis_value)\n",
        "          #coefs_ = []\n",
        "          #for a in tqdm.tqdm(alphas):\n",
        "            #dict_hyper_p_values = {'adv_radius': a, 'scale_dts': scale_dts_value, 'scale_mis': scale_mis_value}\n",
        "            dict_hyper_p_values = {'adv_radius_times_dts': a_dts_value, 'adv_radius_times_mis': a_mis_value}\n",
        "            #print(\"dict hyper in get path \", dict_hyper_p_values)\n",
        "            coefs = estimator(X, y, dict_hyper_p_values)\n",
        "            #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "            coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "            hyper_p_ret_.append([a_dts_value, a_mis_value])\n",
        "          #res[tuple_key] = np.stack((coefs_)).T\n",
        "    '''\n",
        "    for scale_dts_value in tqdm.tqdm(dts_deltas):\n",
        "        for scale_mis_value in tqdm.tqdm(mis_deltas):\n",
        "          #tuple_key = (scale_dts_value, scale_mis_value)\n",
        "          #coefs_ = []\n",
        "          for a in tqdm.tqdm(alphas):\n",
        "              #dict_hyper_p_values = {'adv_radius': a, 'scale_dts': scale_dts_value, 'scale_mis': scale_mis_value}\n",
        "              dict_hyper_p_values = {'adv_radius_times_scale_dts': a * scale_dts_value, 'adv_radius_times_scale_mis': a * scale_mis_value}\n",
        "              coefs = estimator(X, y, dict_hyper_p_values)\n",
        "              #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "              coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "              hyper_p_ret_.append([a, scale_dts_value, scale_mis_value])\n",
        "          #res[tuple_key] = np.stack((coefs_)).T\n",
        "    '''\n",
        "    return np.stack((hyper_p_ret_)).T, np.stack((coefs_)).T\n",
        "\n",
        "'''\n",
        "def get_path(X, y, estimator, amax, eps=1e-5, n_alphas=200):\n",
        "    _, m = X.shape\n",
        "    amin = eps * amax\n",
        "    alphas = np.logspace(np.log10(amin), np.log10(amax), n_alphas)\n",
        "    coefs_ = []\n",
        "    for a in tqdm.tqdm(alphas):\n",
        "        coefs = estimator(X, y, a)\n",
        "        #print(\"alpha  \", a, \"coef: \", coefs)\n",
        "        coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "    return alphas, np.stack((coefs_)).T\n",
        "'''\n",
        "\n",
        "\n",
        "def plot_coefs(alphas, coefs, ax):\n",
        "    #print(\"you are printing coefs in function of 1/alphas\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).sum(axis=0)\n",
        "    ax.set_xlabel(\"1/alphas\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.semilogx(1/alphas, coef_l, c=c)\n",
        "        #ax.semilogx(1/alphas, l1norm, c=c)\n",
        "        #ax.plot(1/alphas, coef_l, c=c)\n",
        "\n",
        "\n",
        "def plot_coefs_l1norm(coefs, ax):\n",
        "    #print(\"you are printing coeff in function of l1 norm\")\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    #l1norm = np.abs(coefs).mean(axis=0)\n",
        "    l1norm = np.abs(coefs).sum(axis=0)\n",
        "    #print(\"coef \", coefs)\n",
        "    #print(\"l1norm \", l1norm)\n",
        "    ax.set_xlabel(\"l1norm\")\n",
        "    ax.set_ylabel(\"coef\")\n",
        "\n",
        "\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.plot(l1norm, coef_l, c=c)\n",
        "\n",
        "\n",
        "def train_and_plot(X, y, S_dict, list_ax):\n",
        "    linfadvtrain = AdversarialTraining(X, y, S_dict, p=np.inf)\n",
        "    estimator = lambda X, y, dic_h:  linfadvtrain(dict_hyper_p=dic_h)\n",
        "    hyper_p, coefs_advtrain_linf  = get_path(X, y, estimator, S_dict)\n",
        "    #print(\"hyper_p used\\n \", hyper_p)\n",
        "    if len(list_ax) > 0:\n",
        "      plot_coefs_l1norm(coefs_advtrain_linf, list_ax[0])\n",
        "      plot_coefs(alphas_adv, coefs_advtrain_linf, list_ax[1])\n",
        "    return hyper_p, coefs_advtrain_linf\n",
        "\n",
        "'''\n",
        "def add_rectangles_old(x, y, box_width, box_height, ax):\n",
        "  r_c = (np.random.binomial(1, 1, size=x.size) == 1)  # 1 taken, 0 not taken\n",
        "  #print(r_c)\n",
        "\n",
        "  for xi, yi in zip(x[r_c], y[r_c]):\n",
        "      rect = patches.Rectangle(\n",
        "        (xi-box_width/2, yi-box_height/2),\n",
        "        box_width, box_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "      )\n",
        "      ax.add_patch(rect)\n",
        "'''\n",
        "\n",
        "def add_rectangles(x, y, S, ax):\n",
        "  r_c = (np.random.binomial(1, 1, size=x.size) == 1)  # 1 taken, 0 not taken\n",
        "  #print(r_c)\n",
        "  d = S.shape[-1]\n",
        "  #S = S * 100\n",
        "  if S.ndim == 2 or S.shape == (1, d, d):\n",
        "    S = S.squeeze()\n",
        "    print(\"------------------------> who is S in add_rectangles\\n\", S)\n",
        "    box_width = S[0, 0]\n",
        "    box_height = S[1, 1]\n",
        "    for xi, yi in zip(x[r_c], y[r_c]):\n",
        "        rect = patches.Rectangle(\n",
        "          (xi-box_width/2, yi-box_height/2),\n",
        "          box_width, box_height,\n",
        "          linewidth=1, edgecolor='r', facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "  else:  # S is something like (n, d, d)\n",
        "    #print(\"---------------> who is S in add_rectangles (mult imp)\\n\", S)\n",
        "    box_width = S[:, 0, 0]\n",
        "    box_height = S[:, 1, 1]\n",
        "    #print(\"bw\\n \", box_width)\n",
        "    #print(\"bh\\n \", box_height)\n",
        "    #print(\"------------------------------> boxes printed\")\n",
        "    for xi, yi, bw, bh in zip(x[r_c], y[r_c], box_width[r_c], box_height[r_c]):\n",
        "        #print(\"bw, bh \", bw, \",   \", bh)\n",
        "        rect = patches.Rectangle(\n",
        "          (xi-bw/2, yi-bh/2),\n",
        "          bw, bh, linewidth=1, edgecolor='r', facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "\n",
        "\n",
        "print(\"end block\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation's block\n",
        "\n",
        "def clear_dataset(X, y, masks):\n",
        "  # remove observations full NaN\n",
        "  # X is an (n, d) matrix, y is a (n,) vector,\n",
        "  # masks is an (n, d) binary matrix associated to X. 1 missing, 0 seen\n",
        "  M = np.sum(1 - masks, axis=1) > 0\n",
        "  M_col = np.sum(1 - masks, axis=0) > 0  # True if in the column there is at least one seen component\n",
        "  if np.sum(M_col) < masks.shape[1]:\n",
        "    print(\"Careful, there is one column full of nan\")\n",
        "  return X[M, :][:, M_col], y[M], masks[M, :][:, M_col]\n",
        "\n",
        "\n",
        "def single_imputation(X_nan, impute_estimator):\n",
        "    ice = IterativeImputer(estimator=impute_estimator)\n",
        "    return ice.fit_transform(X_nan)\n",
        "\n",
        "\n",
        "def multiple_imputation(nbr_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 100000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res shape\", res.shape)\n",
        "       #if nbr_mi == 1:\n",
        "        #res = res[0, :, :]\n",
        "        #print(\"fin res shape\", res.shape)\n",
        "    return res\n",
        "\n",
        "\n",
        "def imputation_elliptic(mu, sigma, x, masks):\n",
        "  # mu, mean elliptical distribution (,d)\n",
        "  # sigma, cov matrix elliptical distribution (d, d)\n",
        "  # x: dataset (n, d)\n",
        "  # masks: mask data, 0 seen, 1 missing\n",
        "  n, d = x.shape\n",
        "  print(n, d)\n",
        "  x_imp = x.copy()\n",
        "  #print(\"x_imp clean\", x_imp)\n",
        "  for i in range(n):\n",
        "    if not (masks[i, :] == 0).all():  # if we have at least one missing component\n",
        "      #print(\"nbr : \", i)\n",
        "      x_c = x[i, :]\n",
        "      m_bool = (masks[i, :] == 0)  # True seen, False missing\n",
        "      sigma_aa_inv = np.linalg.inv(sigma[m_bool, :][:, m_bool])\n",
        "      sigma_ma = sigma[~m_bool, :][:, m_bool]\n",
        "      mu_cond = mu[~m_bool] + sigma_ma @ sigma_aa_inv @ (x_c[m_bool] - mu[m_bool])\n",
        "      x_imp[i, ~m_bool] = mu_cond\n",
        "  return x_imp\n",
        "\n",
        "\n",
        "def listwise_delection(X, masks):\n",
        "  # masks: 1 missing, 0 seen\n",
        "    M = np.sum(masks, axis=1) == 0  # zeros components are the one with full entries\n",
        "    ret = X[M, :] if X.ndim == 2 else X[M]\n",
        "    return ret\n"
      ],
      "metadata": {
        "id": "qyWskXpdOW9e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ElCvHxBiO_2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZA7J67yAuQM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(42)\n",
        "\n",
        "#p_miss_2d = [0.2, 0.4, 0.4]\n",
        "#beta_2d = np.array([0.5, 2])  # ground truth\n",
        "\n",
        "from sklearn.datasets import make_moons, make_circles\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import train_test_split\n",
        "'''\n",
        "def generate_masks_2d(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "'''\n",
        "\n",
        "def generate_masks(dictio_data):#nbr_of_sample, dim, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    dim = len(dictio_data['beta_gt'][0])\n",
        "    nbr_of_sample = dictio_data['n_train'][0]\n",
        "    p_missing = dictio_data['p_miss'][0]\n",
        "    print(\"p_missing in generate mask \", p_missing)\n",
        "    if dim == 2:\n",
        "      if len(p_missing) < 3:\n",
        "        print(\"WARNING: p_missing should be a list with a length of 3 if the dimension is 2\")\n",
        "      masks = np.zeros((nbr_of_sample, 2))\n",
        "      v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "      masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "      masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "      masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    else:\n",
        "      # in this branch, p_missing = [p1,.., pl],\n",
        "      masks = np.array([np.random.binomial(1, 1-pr, (nbr_of_sample, dim)) for pr in p_missing])\n",
        "      masks = np.cumsum(masks, axis=0)  # each round\n",
        "      masks[masks>1] = 1\n",
        "    return masks\n",
        "\n",
        "def best_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  r = hat_y - y  # residual\n",
        "  score = np.mean(r * r, axis=1)\n",
        "  print(\"scores:  \", score)\n",
        "  i_min = np.argmin(score)\n",
        "  return coeff[:, i_min], score[i_min]\n",
        "\n",
        "def best_idx_predictor(X, coeff, y):\n",
        "  hat_y = (X @ coeff).T  # (n, d) @ (d, m) = (n, m)\n",
        "  r = hat_y - y  # residual\n",
        "  #score = np.mean(r * r, axis=1)\n",
        "  score = np.mean(r * r, axis=1)\n",
        "  #print(\"score in best idx\", score)\n",
        "  i_min = np.argmin(score)\n",
        "  #### find the minimum value with a threshold, so we get bigger uncertainty set that are visible\n",
        "  min = np.min(score)\n",
        "  max = np.max(score)\n",
        "  score[ score < min + -1 ] = max\n",
        "  ####\n",
        "  #print(\"score after \", score)\n",
        "  i_min = np.argmin(score)\n",
        "  return i_min, score[i_min]\n",
        "\n",
        "\n",
        "\n",
        "def generate_X(data, dim):\n",
        "    if data == 'Gaussian':\n",
        "      def generator(n):\n",
        "        return np.random.randn(n, dim)\n",
        "    elif data == 'Uniform':\n",
        "      def generator(n):\n",
        "        return np.random.rand(n, dim)\n",
        "    elif data == 'moons':\n",
        "      def generator(n):\n",
        "        return make_moons(n, noise=0.1)[0]\n",
        "    elif data == 'circles':\n",
        "      def generator(n):\n",
        "        return make_circles(n, noise=0.1, factor=0.4)[0]\n",
        "    return generator\n"
      ],
      "metadata": {
        "id": "AN61ok0A_Mbv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jB0J9uh-dJBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwSkM31ztfUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment 2d with dataset generated externally\n",
        "\n",
        "def imputations(info, dict_obs_for_imp):  # X_nan, y):\n",
        "  # info contains the method and possible extra information\n",
        "  # X_nan is the dataset with nan in place of the missing components\n",
        "  # y is return as it is, unless the method require to change it, like in\n",
        "  # listwise deletion\n",
        "    #print(info)\n",
        "    X_nan = dict_obs_for_imp['X_nan']\n",
        "    y = dict_obs_for_imp['y_train']\n",
        "    mask_from_X_nan = np.isnan(X_nan).astype(int)\n",
        "    if info['imp_method'] == 'BR_si':  # Baeysian_Ridge_single_imputation\n",
        "        X = single_imputation(X_nan, BayesianRidge())\n",
        "    elif info['imp_method'] in  ['mi', 'mi_pure']:\n",
        "        X = multiple_imputation(info['mi_nbr'], X_nan)  # size (info['mi_nbr], n, d)\n",
        "    elif info['imp_method'] == 'l_d':  # listwise_deletion\n",
        "        #mask_from_X_nan = np.isnan(X_nan).astype(int)\n",
        "        X = listwise_delection(X_nan, mask_from_X_nan)\n",
        "        y = listwise_delection(y, mask_from_X_nan)\n",
        "        if len(X) == 0:  # no elements left, add an artificial element\n",
        "            X = np.zeros((1, X_nan.shape[-1]))\n",
        "            y = np.zeros(1)\n",
        "        mask_from_X_nan = np.zeros_like(X)\n",
        "    elif info['imp_method'] == 'oracle':\n",
        "        X = dict_obs_for_imp['X_train_masked'][0]\n",
        "        mask_from_X_nan = np.zeros_like(X)\n",
        "    else:\n",
        "      print(\"-------------------> ERROR: WRONG KEYWORD (in imputations)\")\n",
        "    return X, y, mask_from_X_nan\n",
        "\n",
        "\n",
        "def cov_strategy(info, dict_observations):\n",
        "    X_imputed = dict_observations['X_imputed']\n",
        "    X_nan = dict_observations['X_nan']\n",
        "    masks = dict_observations['masks_after_imputation']\n",
        "    print(np.sum(masks, axis=-1))\n",
        "    if info['cov_strategy'] == 'sd':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      #print(\"sd in cov strategy \", sd)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(sd)\n",
        "    elif info['cov_strategy'] == 'inv_sd':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(1 / sd)\n",
        "    elif info['cov_strategy'] == 'zero':\n",
        "      #sd = np.std(X_imputed, axis=0)\n",
        "      #S = np.diag(sd)  # check if here it is 1 / sd or sd. The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.zeros((X_imputed.shape[-1], X_imputed.shape[-1]))\n",
        "    elif info['cov_strategy'] == 'eye':\n",
        "      S = np.eye(X_imputed.shape[-1])\n",
        "    elif info['cov_strategy'] == 'threshold':\n",
        "      sd = np.std(X_imputed, axis=0)\n",
        "      sd[sd < info['threshold']] = info['threshold']\n",
        "      #S = np.diag(sd) The intuition is that, small covariance means small boxes where the points can move\n",
        "      S = np.diag(sd)\n",
        "    elif info['cov_strategy'] == 'std_nan':\n",
        "      if info['imp_method'] in ['oracle']:\n",
        "        print(\"DON'T USE std_nan with oracle and ld because you do not have any nan. Use sd\")\n",
        "      else:\n",
        "        std_columnwise = np.nanstd(X_nan, axis=0)\n",
        "        S = np.diag(std_columnwise)\n",
        "    elif info['imp_method'] in ['mi_pure', 'mi']:\n",
        "      if info['cov_strategy'] == 'std_mi':   # std of the imputed dataset, then the mean\n",
        "        std_vectors = np.std(X_imputed, axis=-2)  # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        #s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        S = std_vectors[:, None, :] * np.eye(std_vectors.shape[-1])  # should be (m, d, d), with each diagonal the diagonals of std_vectors\n",
        "        #S = s_within\n",
        "        #S = np.diag(s_within)\n",
        "        print(\"final S.shape in cov strategy std_mi \", S.shape)\n",
        "      elif info['cov_strategy'] == 'RR':\n",
        "        #if info['mi_nbr'] == 1:\n",
        "        #  X_imputed = np.array([X_imputed])\n",
        "        # X shape = (m, n, d)\n",
        "        std_vectors = np.std(X_imputed, axis=-2)  # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        print(\"s_within \", s_within)\n",
        "        print(\"cov computed\")\n",
        "        #print(s_mean)\n",
        "        s_between = np.std(std_vectors, axis=0) # between imputation variance  # shape: d. That's already scaled because we are computing the std\n",
        "        print(\"s_between \", s_between)\n",
        "        S = np.diag(s_within + s_between * (1 + 1 / info['mi_nbr']))\n",
        "        print(\"final S in cov strategy RR \", S)\n",
        "        #mu = np.mean(X_imputed, axis=0)\n",
        "        #sigma = np.cov(X_imputed, rowvar=False)\n",
        "      elif info['cov_strategy'] == 'RR_scaled (to check)':\n",
        "        print(\"Rub Rule right scaled\")\n",
        "        #if info['mi_nbr'] == 1:\n",
        "        #  X_imputed = np.array([X_imputed])\n",
        "        # X shape = (m, n, d)\n",
        "        std_vectors = np.std(X_imputed, axis=-2) # shape: (m, d)\n",
        "        #print(\"std vectors \", std_vectors)\n",
        "        s_within = np.mean(std_vectors, axis=0)  # within imputation variance  # shape : d\n",
        "        print(\"s_within \", s_within)\n",
        "        print(\"cov computed\")\n",
        "        #print(s_mean)\n",
        "        s_between = np.std(std_vectors, axis=0) # between imputation variance  # shape: d\n",
        "        #s_between = np.sqrt(s_between)\n",
        "        print(\"s_between \", s_between)\n",
        "        S = np.diag(s_within + s_between * (1 + 1 / info['mi_nbr']))\n",
        "        #S = np.sqrt(S)\n",
        "        print(\"final S in cov strategy RR \", S)\n",
        "      #elif info['cov_strategy'] == 'cond_var':\n",
        "        # we have imputed [X1,..,X_m]\n",
        "        #s = np.std(X_imputed, axis=0)\n",
        "        #print(\"s\\n \", s)\n",
        "        #eye = np.array([np.eye(X_imputed.shape[-1])] * X_imputed.shape[-2])\n",
        "        #S = eye * s[:, None, :]\n",
        "        #S = np.concatenate(S, axis=0)\n",
        "        #print(\"S in cond variance \", S)\n",
        "    elif info['cov_strategy'] == 'lounici':\n",
        "      mu = np.nanmean(X_nan, axis=0)\n",
        "      print(\"means \", mu)\n",
        "      delta = 1 - np.mean(masks) # parameter missingness\n",
        "      print(\"delta \", delta)\n",
        "      X_0 = np.nan_to_num(X_nan - mu)  # check if this is correct\n",
        "      print(\"nbr obs\", X_0.shape[0])\n",
        "      S =  X_0.T @ X_0 / X_0.shape[0]\n",
        "      S = (1/delta - 1/(delta**2)) * np.diag(np.diag(S)) + 1/(delta**2) * S\n",
        "    else:\n",
        "      raise ValueError(\"-------------> ERROR: NO COVARIANCE METHOD HAS BEEN CHOSEN\")\n",
        "      #print(\"-------------> ERROR: NO COVARIANCE METHOD HAS BEEN CHOSEN\")\n",
        "      #S = np.diag(S)\n",
        "      #mu = np.mean(X_imputed, axis=0)\n",
        "      #sigma = np.cov(X_imputed, rowvar=False)\n",
        "    return S\n",
        "\n",
        "\n",
        "def cov_strategy_missing(info, dict_observations):\n",
        "    # undertainty that come from the imputed part. It is zero\n",
        "    X_imputed = dict_observations['X_imputed']\n",
        "    if info['imp_method'] in ['mi', 'mi_pure'] and 'cov_strategy_between' in info.keys():\n",
        "      m, n, d = X_imputed.shape\n",
        "      if info['cov_strategy_between'] == 'cond_var':\n",
        "        # we have imputed [X1,..,X_m], so shape (m, n, d)\n",
        "        s = np.std(X_imputed, axis=0)\n",
        "        s[s<1e-14] = 0  # set to zero values that are basically zero\n",
        "        #print(\"var \", s)\n",
        "        eye = np.array([np.eye(X_imputed.shape[-1])] * X_imputed.shape[-2])\n",
        "        S_mis = eye * s[:, None, :]\n",
        "        if info['post_imp'] == 'conc':\n",
        "          S_mis = np.tile(S_mis, (m, 1, 1))\n",
        "    else:  # not using a mi method, so uncertainty on missing part should be zero\n",
        "      print(\"shape oject in cov strategy missing \", dict_observations['X_test'].shape[-1])\n",
        "      print(\"shape oject in cov strategy missing \", dict_observations['X_test'].shape)\n",
        "      d = dict_observations['X_test'].shape[-1]\n",
        "      S_mis = np.zeros((d, d))\n",
        "    return S_mis\n",
        "\n",
        "\n",
        "def post_imputation(info_imp, dict_dataset):\n",
        "  # X_imptued should be a matrix (n, d) or tensor (m, d, n) (in multiple imputations methods)\n",
        "    X_imputed = dict_dataset['X_imputed']\n",
        "    y_train = dict_dataset['y_from_X_imputed']\n",
        "    #print(\"info imp in post_imp\", info_imp)\n",
        "    print(\"shape X_imputed in post_imputation \", X_imputed.shape)\n",
        "    mask_train = dict_dataset['masks_after_imputation']\n",
        "    if 'post_imp' not in info_imp.keys():\n",
        "      X_train = X_imputed\n",
        "    elif info_imp['post_imp'] == 'mean':\n",
        "      #print(\"entered in pst_iputation, in mi_mean\")\n",
        "      X_train = np.mean(X_imputed, axis=0)\n",
        "    elif info_imp['post_imp'] == 'conc':\n",
        "      print(\"shape X_imputed \", X_imputed.shape)\n",
        "      X_train = np.concatenate(X_imputed)\n",
        "      y_train = np.tile(y_train, X_imputed.shape[0])\n",
        "    else:\n",
        "      X_train = X_imputed\n",
        "    return X_train, y_train, mask_train\n",
        "\n",
        "\n",
        "def generate_dataset(data, n_tot, dim, beta_gt, perc_test, p_miss, err):\n",
        "    print(data)\n",
        "    if data['data'] == 'Gaussian':\n",
        "      X_complete = np.random.randn(n_tot, dim)\n",
        "    elif data['data'] == 'Normal':\n",
        "      #print(\"you are here\")\n",
        "      if len(beta_gt) != len(data['mean']) or len(beta_gt) != data['cov'].shape[0]:\n",
        "        print(\"ERROR: DIMENSION MISSMATCH\")\n",
        "      X_complete = np.random.multivariate_normal(mean=data['mean'], cov=data['cov'], size=n_tot)\n",
        "    elif data['data'] == 'Uniform':\n",
        "      X_complete = np.random.rand(n_tot, dim)\n",
        "    elif data['data'] == 'moons':\n",
        "      X_complete = make_moons(n_tot, noise=0.1)[0]\n",
        "    elif data['data'] == 'circles':\n",
        "      X_complete = make_circles(n_tot, noise=0.1, factor=0.4)[0]\n",
        "\n",
        "    if err['type'] == 'Gaussian_on_y':\n",
        "      #print(\"---> you have entered in GAUSSIAN ERROR \", \"scaling : \", err['scaling'])\n",
        "      error = np.random.randn(n_tot) * err['scaling']\n",
        "    elif err['type'] == 'Uniform_on_y':\n",
        "      error = (np.random.rand(n_tot)-0.5) * err['scaling']\n",
        "    elif err['type'] == 'Gaussian_on_X':\n",
        "      error = (np.random.randn(n_tot, dim) @ beta_gt) * err['scaling']  # error is of the form DX@beta_gt + error\n",
        "    #elif err['type'] == 'Gaussian':\n",
        "    #  error = np.random.randn(n_tot) * err['scaling']\n",
        "\n",
        "    print(X_complete.shape)\n",
        "\n",
        "    y_complete = X_complete @ beta_gt + error  #np.random.randn(n_tot) * err  # (np.random.rand(n_tot) - 0.5) * err\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_complete, y_complete, test_size=perc_test)\n",
        "    n_train = X_train.shape[0]\n",
        "    # masks_train = generate_masks_2d(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    # masks_train = generate_masks_binomial(n_train, p_miss)  # 1 missing, 0 observed\n",
        "    #X_train, y_train, masks_train = clear_dataset(X_train, y_train, masks_train)\n",
        "    # M = np.sum(masks, axis=1)  # M[i] > 0 iff i has missing component\n",
        "    # dict_obs = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test, 'masks_train': masks_train}\n",
        "    dict_obs = {'X_train_masked': (X_train, []), 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}#, 'masks_train': masks_train}\n",
        "    return dict_obs\n",
        "\n",
        "\n",
        "def experiment_2d_ext_dataset(dict_obs, dict_imp, ax):\n",
        "    # dict_obs contains info on the observations, i.e. train, test, masks\n",
        "    # dict_imp contains info on the imputation an covariance methods used,\n",
        "    # dict_imp = {'imp_method': , 'cov_strategy': , .... }\n",
        "    # ax contains info for the plots\n",
        "\n",
        "    X_test = dict_obs['X_test']\n",
        "    y_test = dict_obs['y_test']\n",
        "    mask = dict_obs['X_train_masked'][1]\n",
        "\n",
        "    M = np.sum(mask, axis=1)  # M[i] > 0 iff i has missing component\n",
        "\n",
        "    X_nan_train = dict_obs['X_train_masked'][0].copy()\n",
        "    oracle_sd = np.std(X_nan_train, axis=0)\n",
        "    print(\"-------> ORACLE SD, std of the original dataset (with no missing)\", oracle_sd)\n",
        "    X_nan_train[mask == 1] = np.nan\n",
        "    #print(\"dict imp -----> \", dict_imp)\n",
        "    dict_obs = dict_obs | {'X_nan': X_nan_train} #, 'y_from_X_imputed': y_from_X_imputed, 'masks_after_imputation': mask_from_X_imputed}\n",
        "    if len(dict_obs['imp_ds'][dict_imp['imp_method']]) == 0:  # no previous imputation has been done\n",
        "      #results = imputations(dict_imp, X_nan_train, dict_obs['y_train'])\n",
        "      print(\"NO PREVIOUS IMPUTATION HAS BEEN DONE\")\n",
        "      results = imputations(dict_imp, dict_obs)\n",
        "      X_imputed, y_from_X_imputed, mask_from_X_imputed = results  # imputations(dict_imp, X_nan_train, dict_obs['y_train'])\n",
        "      dict_obs['imp_ds'][dict_imp['imp_method']].append(results)\n",
        "      print(\"crush test-------------------------------------------------> \", np.sum(X_imputed))\n",
        "    else:\n",
        "      print(\"A PREVIOUS IMPUTATION HAS BEEN DONE\")\n",
        "      X_imputed, y_from_X_imputed, mask_from_X_imputed = dict_obs['imp_ds'][dict_imp['imp_method']][0]\n",
        "      print(\"crush test-------------------------------------------------> \", np.sum(X_imputed))\n",
        "    #print(\"X_imputed \", X_imputed)\n",
        "    n_imputed, n_test = X_imputed.shape[-2], X_test.shape[-2]\n",
        "    #print(\"X_train\\n \", X_train)\n",
        "    M = np.sum(mask_from_X_imputed, axis=1)  # M[i] > 0 iff i has missing component\n",
        "\n",
        "    dict_obs = dict_obs | {'X_imputed': X_imputed, 'y_from_X_imputed': y_from_X_imputed, 'masks_after_imputation': mask_from_X_imputed}\n",
        "    #  print(dict_obs)\n",
        "    S_dataset = cov_strategy(dict_imp, dict_obs) #* dict_imp['multip_dataset']\n",
        "    print(\"S dataset \\n\", S_dataset)\n",
        "    #  dict_obs = dict_obs | {'cov_within': S_within}\n",
        "    S_missing = cov_strategy_missing(dict_imp, dict_obs)  #* dict_imp['multip_missing']\n",
        "    print(\"S missing shape\\n \", S_missing.shape)\n",
        "    print(\"S missing\\n \", S_missing)\n",
        "    if 'post_imp' in dict_obs.keys():\n",
        "      if dict_obs['post_imp'] == 'conc':\n",
        "        print(S_missing)\n",
        "    #  dict_obs = dict_obs | {'cov_between': S_between}\n",
        "    S_dict = {'S_dts': S_dataset, 'S_mis': S_missing} | dict_obs['info_algo']  #, 'multipliers_dts': dict_imp['multip_dataset'], 'multipliers_mis': dict_imp['multip_missing']}\n",
        "    # dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4 'eps_adv_rad_times_delta_dts': 1e-4}}\n",
        "\n",
        "    #if True:  # check what to do of this part later\n",
        "      #S = S_dataset * dict_imp['multip_dataset'] + S_missing * dict_imp['multip_missing']\n",
        "      #if S.ndim == 2:\n",
        "      #  print(\"final S \\n\", S)\n",
        "\n",
        "\n",
        "    #print(\"matrices S \\n\", S)\n",
        "    #print(\"---....---....----....--> diag matrix: \", np.diag(S))\n",
        "\n",
        "    #if dict_imp['imp_method'] == 'mi':  # prepare the training set in case of multiple imputation\n",
        "    #  X_train = np.concatenate(X_train)  # X_train, if the method is mi, should be (mi_nbr, n, dim)\n",
        "    #  y_train = np.tile(y_train, reps=dict_imp['mi_nbr'])\n",
        "    #  mask_train = np.tile(mask_train, reps=(dict_imp['mi_nbr'], 1))\n",
        "    #  M = np.sum(mask_train, axis=1)\n",
        "    #print(\"final matrices (exp 2d ext run)\\n \", S)\n",
        "    X_train, y_train, mask_train = post_imputation(dict_imp, dict_obs)\n",
        "    n_train = X_train.shape[-2]\n",
        "    print(\"y_train length \", y_train.shape[0])\n",
        "    print(\"-------> size test: \", n_test, \" , size train: \", n_train, \"nbr_seen (train): \", np.sum(M == 0), \" nbr_miss : \", np.sum(M > 0))\n",
        "\n",
        "#    plt.tight_layout()\n",
        "    #S_between = S.copy()\n",
        "    if dict_imp['imp_method'] == 'mi' and dict_imp['cov_strategy'] == 'std_mi':  # run a standard multiple imputation procedure\n",
        "      best_coeff = np.zeros(X_train.shape[-1])\n",
        "      best_alpha = 0\n",
        "      min_score = 0\n",
        "      temporary_dictionary = copy.deepcopy(S_dict)\n",
        "      for i in range(dict_imp['mi_nbr']):\n",
        "        print(\"i  mi .-------------> \", i)\n",
        "        #dict_obs_i = {'X_imputed': X_train[i, :, :], 'X_nan': X_nan_train, 'masks': mask_train}\n",
        "        #dict_imp_new = {'imp_method': dict_imp['imp_method'], 'cov_strategy': dict_imp['cov_strategy_within']}\n",
        "        #S_within = cov_strategy(dict_imp_new, dict_obs_i)  # within the dataset\n",
        "        #print(\"S_within \", S_within)\n",
        "        #S = S_within[None, :, :] + S_between\n",
        "        #S = np.concatenate(S, axis=0)\n",
        "        #print(S)\n",
        "        #alphas_used, coeff_results = train_and_plot(X_train[i, :, :], y_train, S, [ax[1], ax[2]])\n",
        "        temporary_dictionary['S_dts'] = S_dict['S_dts'][i, :, :]\n",
        "        print(\"temporary dict \", temporary_dictionary)\n",
        "        hyper_p_used, coeff_results = train_and_plot(X_train[i, :, :], y_train, temporary_dictionary, [])\n",
        "        idx_best, min_score_partial = best_idx_predictor(X_test, coeff_results, y_test)\n",
        "        print(\"weee \", idx_best)\n",
        "        print(coeff_results.shape)\n",
        "        print(hyper_p_used.shape)\n",
        "        best_coeff_partial, _ = coeff_results[:, idx_best], hyper_p_used[:, idx_best]\n",
        "        print(\"best coeff partial \", best_coeff_partial)\n",
        "        best_coeff += best_coeff_partial\n",
        "        min_score += min_score_partial\n",
        "        #best_alpha += best_alpha_partial\n",
        "        if len(ax) > 0:\n",
        "          ax[0].scatter(X_train[i, M == 0, 0], X_train[i, M == 0, 1])\n",
        "          ax[0].scatter(X_train[i, M == 1, 0], X_train[i, M == 1, 1])\n",
        "          ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', n_s: ' + str(np.sum(M == 0)) + \" n_m: \" + str(np.sum(M > 0)))  # n_s = nbr seen, n_m = nbr missing\n",
        "          add_rectangles(X_train[i, :, 0], X_train[i, :, 1], S[0, 0] * best_alpha_partial, S[1, 1] * best_alpha_partial, ax[0])\n",
        "      best_coeff /= dict_imp['mi_nbr']\n",
        "      min_score /=  dict_imp['mi_nbr']\n",
        "      best_hyper_p = 0  # not important right now\n",
        "      best_alpha_delta_dts = 1  # not important right now\n",
        "      #best_alpha /= dict_imp['mi_nbr']\n",
        "    else:\n",
        "      #alphas_used, coeff_results = train_and_plot(X_train, y_train, S_dict, [ax[1], ax[2]])\n",
        "      hyper_p_used, coeff_results = train_and_plot(X_train, y_train, S_dict, [])\n",
        "      idx_best, min_score = best_idx_predictor(X_test, coeff_results, y_test)\n",
        "      #best_coeff, best_alpha = coeff_results[:, idx_best], alphas_used[idx_best]\n",
        "      #print(\"-----------------> shape hyper_p used \", hyper_p_used.shape)\n",
        "      best_coeff, best_hyper_p = coeff_results[:, idx_best], hyper_p_used[:, idx_best]\n",
        "      #print(\"hyper_p_used \", hyper_p_used.T)\n",
        "      #input()\n",
        "      #print(X_br_train[M == 0, 0])\n",
        "      best_alpha_delta_dts, best_alpha_delta_mis = best_hyper_p[0], best_hyper_p[1]\n",
        "#      print(\"best alpha ----> \", best_alpha_dts)\n",
        "      if len(ax) > 0:\n",
        "        ax[0].scatter(X_train[M == 0, 0], X_train[M == 0, 1])\n",
        "        ax[0].scatter(X_train[M == 1, 0], X_train[M == 1, 1])\n",
        "        #ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', n_s: ' + str(np.sum(M == 0)) + \" n_m: \" + str(np.sum(M > 0)))  # n_s = nbr seen, n_m = nbr missing\n",
        "        # 'multip_betw': 1, 'multip_with':1\n",
        "        ax[0].set_title(dict_imp['imp_method'] + ', ' + dict_imp['cov_strategy'] + ', dts:'+str(dict_imp['multip_dataset']) + ', mis:' + str(dict_imp['multip_missing']) )  # n_s = nbr seen, n_m = nbr missing\n",
        "        S_plot = S_dict['S_dts'] * best_alpha_delta_dts + S_dict['S_mis'] * best_alpha_delta_mis\n",
        "        #print(\"S_plot \", S_plot)\n",
        "        add_rectangles(X_train[:, 0], X_train[:, 1], S_plot, ax[0])\n",
        "        ax[0].set_aspect('equal')  # equal proportion of the axis\n",
        "    #print(\"X_train \", X_train)\n",
        "    #print(\"y_train \", y_train)\n",
        "    #print(\"mask_train \", mask_train)\n",
        "    #print(\"M \", M)\n",
        "\n",
        "\n",
        "    print(\"X_test shape, \", X_test.shape, \",   y_test shape \", y_test.shape)\n",
        "    #print(\"X_test shape, \", X_test.shape)\n",
        "    print(\"---------------------------------> best idx \", idx_best, \" best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]: \", best_hyper_p, \", min score \", min_score)\n",
        "    print(\"---------------------------------> best coeff \", best_coeff)\n",
        "    #input()\n",
        "    #print(\"best 1/alpha \", 1 / best_alpha)\n",
        "#    print(\"min score \", min_score)\n",
        "\n",
        "    #\n",
        "    #add_rectangles(X_train[:, 0], X_train[:, 1], S[0, 0] * best_alpha, S[1, 1] * best_alpha, ax[0])\n",
        "\n",
        "\n",
        "    # obsere that one day you shoul add the return of alpha_delta_mis also\n",
        "    return best_coeff, min_score, -np.log10(best_alpha_delta_dts)\n",
        "\n"
      ],
      "metadata": {
        "id": "OhNXUBahJgBL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_experiments(dictio, methods_strategy):  # ---------------------> new\n",
        "  # dictio: dictionary of lists that contains the parameters of generate_dataset.\n",
        "  # Each list should have the same length\n",
        "  # methods_strategy = list of dictionary, each one of the form\n",
        "  # {'imp_method': .., 'cov_strategy':.., extra info}\n",
        "\n",
        "    l = len(dictio['data'])  # how many trials shall we do\n",
        "    m = len(methods_strategy)\n",
        "    nbr_iter = len(methods_strategy)\n",
        "    coeff_fin = np.zeros((nbr_iter, 2, l))\n",
        "    scores_fin = np.zeros((nbr_iter, l))\n",
        "\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(3 * l , 9 *l), num='advtrain_linf_')\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(6 * l , 9 *l), num='advtrain_linf_')\n",
        "    #fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(6 * l / 2, 9 *l / 2), num='advtrain_linf_')\n",
        "    print(dictio['plots'])\n",
        "    print(dictio['plots'][0])\n",
        "    nbr_ima = len(dictio['plots'][0])\n",
        "    if nbr_ima == 1:\n",
        "      #nbr_ima = 1\n",
        "      fig, ax = plt.subplots(nbr_ima * nbr_iter, l, figsize=(3 * l, 8/3 * m), squeeze=False)#, num='advtrain_linf_')\n",
        "    elif nbr_ima == 3:  # == 3, one day should be more general\n",
        "      #nbr_ima = 3\n",
        "      fig, ax = plt.subplots(3 * nbr_iter, l, figsize=(3 * l, 8 * m), squeeze=False)#, num='advtrain_linf_')\n",
        "\n",
        "    res = {}\n",
        "    for info_imp_cov_dict in methods_strategy:\n",
        "      key_list = []\n",
        "      for value in info_imp_cov_dict.values():\n",
        "        print(value)\n",
        "        key_list.append(value)\n",
        "      key_tuple = tuple(key_list)\n",
        "      res[key_tuple] = {'best_coeff':[], 'l2_dist_best_coeff_gt':[], 'best_score':[], 'best_alpha':[]}\n",
        "      #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])] = {'best_coeff':[], 'l2_dist_best_coeff_gt':[], 'best_score':[], 'best_alpha':[]}\n",
        "\n",
        "    if dictio['generation'] == 'fixed':  # use this if you want to fix the generated data, and not change at every iteartion\n",
        "      dictio_obser_fixed  = generate_dataset(data=dictio['data'][0],\n",
        "                                    n_tot=dictio['n_tot'][0],\n",
        "                                    dim=dictio['dim'][0],\n",
        "                                    beta_gt=dictio['beta_gt'][0],\n",
        "                                    perc_test=dictio['perc_test'][0],\n",
        "                                    p_miss=dictio['p_miss'][0],\n",
        "                                    err=dictio['err'][0]\n",
        "                                             )  # return {'X_train_masked':(X_train, mask_train) , 'X_test':.., 'y_train':, 'y_test'}\n",
        "      #mask_no_both_seen = generate_masks_2d(dictio['n_train'][0], [0, 0.5, 0.5]) # generate a mask where there are no entries both seen. The idea then will be to consider percentage of this mask seen\n",
        "      full_masks = generate_masks(dictio)\n",
        "    dictio_obser_fixed_copy = copy.deepcopy(dictio_obser_fixed)\n",
        "\n",
        "    for i in range(l):\n",
        "      print(\"---------------------------------------------------------------------------------------------------------------------------> iteration \", i)\n",
        "      #  dict_obs = {'X_train_masked': (X_train, masks_train), 'X_test': ....., 'y_train': ....., 'y_test': ....}\n",
        "      dict_obser_partial = generate_dataset(data=dictio['data'][i],\n",
        "                                    n_tot=dictio['n_tot'][i],\n",
        "                                    dim=dictio['dim'][i],\n",
        "                                    beta_gt=dictio['beta_gt'][i],\n",
        "                                    perc_test=dictio['perc_test'][i],\n",
        "                                    p_miss=dictio['p_miss'][i],\n",
        "                                    err=dictio['err'][i])\n",
        "      if dictio['generation'] == 'fixed':\n",
        "        dict_obser = dictio_obser_fixed\n",
        "        if len(dictio['beta_gt'][0]) == 2:\n",
        "          #mask_partial = dict_obser_partial['X_train_masked'][1]\n",
        "          p_i = dictio['p_miss'][i][0]  # probability of seen both component at round i\n",
        "          n_train = full_masks.shape[0]\n",
        "          mask_partial = full_masks.copy()\n",
        "          mask_partial[0:int(n_train * p_i), :] = 0\n",
        "          tuple_partial = (dictio_obser_fixed['X_train_masked'][0], mask_partial)\n",
        "          dict_obser['X_train_masked'] = tuple_partial\n",
        "        else:\n",
        "          #print(\"size in run experiment\", dictio_obser_fixed_copy['X_train_masked'][0].shape, \"wee \", dictio_obser_fixed['y_train'].shape)\n",
        "          ## we use the next line of code with dictio_obser_fixed_copy because we need to test the mask with the original dataset, otherwise we get size error (the dataset change if an observation get fully hidden)\n",
        "          X_train_cleaned, y_train_cleaned, masks_train_cleaned = clear_dataset(dictio_obser_fixed_copy['X_train_masked'][0], dictio_obser_fixed_copy['y_train'], full_masks[i])\n",
        "          #tuple_partial = (dictio_obser_fixed['X_train_masked'][0], full_masks[i])\n",
        "          print(\"full masks in run experiment \", full_masks[i])\n",
        "          dict_obser['X_train_masked'] = (X_train_cleaned, masks_train_cleaned)\n",
        "          dict_obser['y_train'] = y_train_cleaned\n",
        "      else:\n",
        "        dict_obser = dict_obser_partial\n",
        "\n",
        "      #print(\"dict obser \", dict_obser)\n",
        "      print(\"info algo in run experiments \", dictio['info_algo'])\n",
        "      dict_obser = dict_obser | {'imp_ds':{'BR_si':[], 'l_d':[], 'oracle':[], 'mi':[]}} | {'info_algo': dictio['info_algo']}  # add an entry for imputed dataset, and info for algorithm\n",
        "      print(\"ciaoooooo dict obser in run experiments \\n \", dict_obser)\n",
        "      for idx, info_imp_cov_dict in enumerate(methods_strategy):\n",
        "        print(\"----------------------------------------------> new method tested: \", info_imp_cov_dict)\n",
        "        if nbr_ima > 0:\n",
        "          coeff_round, score_round, alpha_round = experiment_2d_ext_dataset(dict_obser, info_imp_cov_dict, ax[(idx * nbr_ima):((idx+1) * nbr_ima), i])\n",
        "        else:  # == 0\n",
        "          coeff_round, score_round, alpha_round = experiment_2d_ext_dataset(dict_obser, info_imp_cov_dict, [])\n",
        "        r = coeff_round - dictio['beta_gt'][i]\n",
        "        l2_dist = np.linalg.norm(r)\n",
        "        key_list = []\n",
        "        for value in info_imp_cov_dict.values():\n",
        "          print(value)\n",
        "          key_list.append(value)\n",
        "        key_tuple = tuple(key_list)\n",
        "        res[key_tuple]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "        res[key_tuple]['best_coeff'].append(coeff_round)\n",
        "        res[key_tuple]['best_score'].append(score_round)\n",
        "        res[key_tuple]['best_alpha'].append(alpha_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_coeff'].append(coeff_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_score'].append(score_round)\n",
        "        #res[(info_imp_cov_dict['imp_method'], info_imp_cov_dict['cov_strategy'])]['best_alpha'].append(alpha_round)\n",
        "    plt.tight_layout()\n",
        "    return res\n",
        "\n",
        "\n",
        "def plot_res(x_axis_info, res, extra_info):\n",
        "  x_axis = x_axis_info['vector']\n",
        "  print(\"x_axis for print in plot_res----> \", x_axis)\n",
        "  l = len(x_axis)\n",
        "  fig_res, ax_res = plt.subplots(1, 3, figsize=(25, 5))#, num='advtrain_linf_res')\n",
        "  positions = range(l)\n",
        "\n",
        "  for key, values in res.items():\n",
        "    print(\"key \", key, \": \", values)\n",
        "    #print(\"values \", values)\n",
        "  #print(\"res\\n \", res)\n",
        "\n",
        "  ch = ['o', 'x', '+', '*', '<', '>', 'p', 'D', 'd', 'v']\n",
        "  lb = ['l2_dist_best_coeff_gt', 'best_score', 'best_alpha']\n",
        "  for i in range(3):\n",
        "    for idx, (key, dictio) in enumerate(res.items()):\n",
        "      #print(dictio)\n",
        "      ax_res[i].plot(positions, dictio[lb[i]], marker=ch[idx], label=str(key))  # the marker is linked to the key (= method), different key correspond to different marker\n",
        "      #ax_res[1].plot(positions, dictio[lb[idx]], marker=ch[idx], label=str(key))\n",
        "      #ax_res[2].plot(positions, -np.log(dictio['best_alpha']), marker=ch[idx], label=str(key))\n",
        "      #ax_res[0].xticks(positions, n_tot)  # Set custom labels for the x-axis\n",
        "    ax_res[i].set_xticks(positions)         # Set the tick positions\n",
        "    ax_res[i].set_xticklabels(x_axis)        # Set the labels at those positions\n",
        "    ax_res[i].set_xlabel(x_axis_info['name'])\n",
        "    #ax_res[i].legend(loc='upper center', bbox_to_anchor=(1, 1))\n",
        "    ax_res[i].legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
        "  ax_res[0].set_ylabel(\"||hat_Beta - Beta^*||_2\")\n",
        "  ax_res[1].set_ylabel(\"||hat_y - y||_2^2 / n_test\")\n",
        "  dict_err = extra_info['err'][0]\n",
        "  #size_train = extra_info['n_tot'][0]\n",
        "  #ax_res[0].set_title(\"\")\n",
        "  n_test = extra_info['n_test'][0]\n",
        "  #ax_res[1].set_title(\"err: \" + dict_err['type'] + \", scale: \" + str(dict_err['scaling'])  + \", n_test: \" + str(n_test))\n",
        "  #ax_res[0].set_title('n_test: ' + str(n_test) + extra_info['title_infer_error'])\n",
        "  #ax_res[1].set_title('n_test: ' + str(n_test) + extra_info['title_test_error'])\n",
        "  ax_res[0].set_title(extra_info['title_infer_error'])\n",
        "  ax_res[1].set_title(extra_info['title_test_error'])\n",
        "  ax_res[2].set_ylabel(\"-log10(alpha)\")\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n",
        "def make_dictionary_data(nbr_experiments, n_train, n_test, data, beta_gt, p_miss, err_vector, plots):\n",
        "  # make a dictionary where each element is a list of nbr_experiments element made by the other element of the function\n",
        "  if isinstance(n_train, int):  # in case n_train is just a number\n",
        "    n_train = [n_train] * nbr_experiments\n",
        "  else:  # should be a list of integer\n",
        "    print(\"change nbr_experiments to match the size of n_train\")\n",
        "    nbr_experiments = len(n_train)\n",
        "  if isinstance(n_test, int):  # in case n_test is just a number\n",
        "    n_test = [n_test] * nbr_experiments\n",
        "  n_tot = [x + y for x, y in zip(n_train, n_test)]\n",
        "  perc_test = [x / (x+y) for x, y in zip(n_test, n_train)]\n",
        "  dim = beta_gt.size\n",
        "\n",
        "  list_errors = []\n",
        "  for i in range(nbr_experiments):\n",
        "    err_dic_app = {'type': err_vector[0], 'scaling': err_vector[1][i]}\n",
        "    list_errors.append(err_dic_app)\n",
        "\n",
        "  dictio = {'data':[data] * nbr_experiments,\n",
        "        'n_tot': n_tot,\n",
        "        'n_train': n_train,\n",
        "        'n_test': n_test,\n",
        "        'dim': [dim] * nbr_experiments,\n",
        "        'beta_gt': [beta_gt] * nbr_experiments,\n",
        "        'perc_test': perc_test,\n",
        "        #'p_miss': [p_miss] * nbr_experiments,\n",
        "        'err': list_errors,\n",
        "        'plots': [plots] * nbr_experiments\n",
        "        }\n",
        "  dictio['p_miss'] = p_miss\n",
        "\n",
        "  return dictio\n",
        "\n",
        "def make_probabilities(list_prob):\n",
        "  l = []\n",
        "  for x in list_prob:\n",
        "    l.append([x, 0.5 - x/2, 0.5 - x/2])\n",
        "  return l\n",
        "\n",
        "def make_info_axis(vector, name):\n",
        "  if name == 'train':\n",
        "    dictio = {'name': 'size train set', 'vector': vector}\n",
        "  elif name == 'p_seen':\n",
        "    dictio = {'name': 'probability seen full entries', 'vector': vector}\n",
        "  elif name == 'error':\n",
        "    dictio = {'name': 'error', 'vector': vector}\n",
        "  else:\n",
        "    print(\"wrong info_axis\")\n",
        "  return dictio\n",
        "\n",
        "def make_dictionary_method(list_meth):\n",
        "  # make a dictionary where each element is a list of nbr_experiments element made by the other element of the function\n",
        "  list_dictio=[]\n",
        "  list_key = ['imp_method', 'cov_strategy', 'mi_nbr']\n",
        "  for meth in list_meth:\n",
        "    dictio_imp = {}\n",
        "    for i in range(len(meth)):\n",
        "      dictio_imp[list_key[i]] = meth[i] #= {list_key[i]: meth[i]}\n",
        "      #print(dictio_imp)\n",
        "    list_dictio.append(dictio_imp)\n",
        "  return list_dictio\n",
        "\n",
        "\n",
        "def run_multiple_experiments(nbr_exp, rdm_seed, dictio, info_x_axis):\n",
        "  #rdm_seed = 4654321\n",
        "  np.random.seed(rdm_seed)\n",
        "  res = run_experiments(dicc, list_methods_strategy)\n",
        "  plot_res(info_x_axis, res, dicc)\n",
        "  '''\n",
        "  if nbr_exp > 1:\n",
        "    for k in res:\n",
        "      for h in res[k]:\n",
        "        res[k][h] = [res[k][h]]\n",
        "    for i in range(nbr_exp-1):\n",
        "      print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "      #np.random.seed(rdm_seed * (i+2))\n",
        "      res_partial = run_experiments(dictio, list_methods_strategy)\n",
        "      plot_res(info_x_axis, res_partial, dictio)\n",
        "      print(res)\n",
        "      for k in res:\n",
        "        res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "        res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "        res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "        #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "        #res.append(res['l2_dist_best_coeff_gt'])\n",
        "  '''\n",
        "  for k in res:\n",
        "    for h in res[k]:\n",
        "      res[k][h] = [res[k][h]]\n",
        "  for i in range(nbr_exp-1):\n",
        "      print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "      #np.random.seed(rdm_seed * (i+2))\n",
        "      res_partial = run_experiments(dictio, list_methods_strategy)\n",
        "      plot_res(info_x_axis, res_partial, dictio)\n",
        "      print(res)\n",
        "      for k in res:\n",
        "        res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "        res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "        res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "        #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "        #res.append(res['l2_dist_best_coeff_gt'])\n",
        "\n",
        "  print(\"final step, let's take the mean of the results\")\n",
        "  #print(\"res, after all the experimetns \", res)\n",
        "  for k in res:\n",
        "    print(\"key in res \", k)\n",
        "    print(np.array(res[k]['l2_dist_best_coeff_gt']))\n",
        "    print(\"mean l2_dist              \", np.mean(np.array(res[k]['l2_dist_best_coeff_gt']), axis=0))\n",
        "    print(\"mean_l2_dist diff method: \", np.mean(res[k]['l2_dist_best_coeff_gt'], axis=0))\n",
        "  #mean_res = {k: np.mean(v, axis=0) for k, v in res.items()}\n",
        "  mean_res = {k: {v: np.mean(w, axis=0) for v, w in res[k].items()} for k in res}\n",
        "  print(\"final dictionary, dictionary of the means:\")\n",
        "  for k, v in mean_res.items():\n",
        "    print(\"k:   \", k)\n",
        "    for s, t in v.items():\n",
        "      print(s, \": \", t)\n",
        "  return mean_res\n",
        "  #print(np.mean(res, axis=0))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_2LB5UnMpgCC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#info_axis = 'train'\n",
        "#n_train = [400, 800, 1200, 1600, 2000]\n",
        "#p_seen = make_probabilities([0.8, 0.8, 0.8, 0.8, 0.8])\n",
        "#main_vec = n_train if info_axis == 'train' else p_seen\n",
        "#info_x_axis = make_info_axis(main_vec, info_axis)\n",
        "\n",
        "# def get_path(X, y, estimator, amax, dts_max, mis_max, S_dict, eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "gen = 'fixed'\n",
        "info_axis = 'p_seen'  # train or p_seen\n",
        "#p_seen_both = [1, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.40, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.02]\n",
        "#p_seen_both = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
        "#p_seen_both = [1, 0.9, 0.8/0.9, 0.7/0.8, 0.6/0.7, 0.5/0.6]\n",
        "p_seen_both = [1, 0.9, 0.8/0.9, 0.7/0.8, 0.6/0.7, 0.5/0.6]\n",
        "#p_seen_both = [0.1]\n",
        "#p_seen_both = [1, 0.9, 0.8]\n",
        "length_vec = len(p_seen_both)\n",
        "#n_train = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
        "n_train = [20] * length_vec\n",
        "error_vec =  [0] * length_vec\n",
        "#p_seen = make_probabilities(p_seen_both)\n",
        "p_seen = [p_seen_both] * length_vec\n",
        "if info_axis == 'train':\n",
        "  main_vec = n_train\n",
        "elif info_axis == 'p_seen':\n",
        "  main_vec = p_seen_both\n",
        "elif info_axis == 'error':\n",
        "  main_vec = error_vec\n",
        "#main_vec = n_train if info_axis == 'train' else p_seen_both\n",
        "info_x_axis = make_info_axis(main_vec, info_axis)\n",
        "number_test = 20000\n",
        "cov_var = 0.6\n",
        "beta_gt = np.array([-0.5, 2, 1, 3, -2, -3, 4, 0.5, 7, -9, -1, -2, -3, 4, 5, 6, 7, 8])\n",
        "dim = len(beta_gt)\n",
        "mean = np.array([0] * dim)\n",
        "matr = np.random.randn(dim, dim) * 0.1\n",
        "cov = matr.T @ matr + np.eye(dim) * 0.25\n",
        "# np.array([[1, cov_var], [cov_var, 1]])\n",
        "\n",
        "dicc = make_dictionary_data(\n",
        "    nbr_experiments= len(main_vec), n_train = n_train, n_test=number_test,\n",
        "    data = {'data': 'Normal', 'mean': mean, 'cov': cov},\n",
        "    beta_gt = beta_gt,\n",
        "    p_miss = p_seen,\n",
        "    err_vector = ['Gaussian_on_X', error_vec],\n",
        "    plots = []#['points', 'l1_vs_coef', '1/alpha_vs_coef']\n",
        ")\n",
        "#dicc = dicc | {'generation':gen}\n",
        "dicc = dicc | {'generation': gen, 'title_infer_error':'  inference_error', 'title_test_error':'  test_error'}\n",
        "dicc = dicc | {'info_algo': {'adv_rad_times_delta_dts_max': 1, 'adv_rad_times_delta_mis_max': 1, 'eps_adv_rad_times_delta_dts': 1e-4, 'eps_adv_rad_times_delta_mis': 1e-4, 'n_a_dts': 25, 'n_a_mis':4}}\n",
        "\n",
        "for key, value in dicc.items():\n",
        "  print(key, \": \" , value)\n",
        "\n",
        "# (imp method, cov strategy, mi_nbr)\n",
        "#list_imp_cov_methods = [('BR_si', 'sd'), ('l_d', 'sd'), ('mi', 'sd', 1)]\n",
        "\n",
        "#list_methods_strategy = make_dictionary_method(list_imp_cov_methods)\n",
        "mi_nbr = 10\n",
        "# def get_path(X, y, estimator, amax, dts_max, mis_max, S_dict, eps_amax=1e-4, eps_dts_max=1e-3, eps_mis_max=1e-3, n_alphas=100, n_deltas_dts=2, n_deltas_mis=3):\n",
        "\n",
        "list_methods_strategy = [{'imp_method': 'BR_si', 'cov_strategy': 'std_nan'},#, 'multip_dataset': 3, 'multip_missing':0},\n",
        "                        #{'imp_method': 'l_d', 'cov_strategy': 'std_nan', 'multip_dataset': 3, 'multip_missing':3},\n",
        "                        {'imp_method': 'oracle', 'cov_strategy': 'sd'},#, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'oracle', 'cov_strategy': 'sd', 'multip_dataset': 0, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 1},\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 3},\n",
        "                        {'imp_method': 'mi', 'cov_strategy': 'std_mi', 'mi_nbr': mi_nbr},\n",
        "                        #{'imp_method': 'mi_pure', 'cov_strategy': 'cond_var', 'cov_strategy_within': 'sd', 'mi_nbr': 5},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 1},\n",
        "                        #{'imp_method': 'mi_mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'eye', 'mi_nbr': 5},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'zero', 'mi_nbr': mi_nbr, 'multip_betw': 0, 'multip_with': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.2},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.4},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'RR', 'mi_nbr': mi_nbr, 'multip_betw': 1, 'multip_with': 0.6},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 0, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 0, 'multip_missing': 1},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr, 'multip_dataset': 3, 'multip_missing': 0},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_mi', 'mi_nbr': mi_nbr, 'multip_dataset': 3, 'multip_missing': 1},\n",
        "                        {'imp_method': 'mi', 'post_imp':'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr}, #, 'multip_dataset': 3, 'multip_missing': 3},\n",
        "                        #{'imp_method': 'mi', 'post_imp':'conc', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': mi_nbr}#, 'multip_dataset': 3, 'multip_missing': 3}\n",
        "                        #{'imp_method': 'mi', 'cov_strategy': 'RR', 'mi_nbr': 5},\n",
        "                        ]\n",
        "print(list_methods_strategy)\n",
        "for el in list_methods_strategy:\n",
        "  for key, value in el.items():\n",
        "    print(key,\": \" , value)\n",
        "\n",
        "print(\"----> Starting experiments\")\n",
        "\n",
        "'''\n",
        "nbr_exp = 2\n",
        "#res[key_tuple]['l2_dist_best_coeff_gt'].append(l2_dist)\n",
        "#res[key_tuple]['best_coeff'].append(coeff_round)\n",
        "#res[key_tuple]['best_score'].append(score_round)\n",
        "#res[key_tuple]['best_alpha'].append(alpha_round)\n",
        "res_l2 = []\n",
        "\n",
        "rdm_seed = 4654321\n",
        "np.random.seed(rdm_seed)\n",
        "res = run_experiments(dicc, list_methods_strategy)\n",
        "plot_res(info_x_axis, res, dicc)\n",
        "if nbr_exp > 1:\n",
        "  for k in res:\n",
        "    for h in res[k]:\n",
        "      res[k][h] = [res[k][h]]\n",
        "  for i in range(nbr_exp-1):\n",
        "    print(\"--------------------------------------------------------------------------------------nbr_experiment external ---------------> \", i+2, \"-\", i+2, \" \", i+2, \"-\", i+2, \" \", i+2)\n",
        "    #np.random.seed(rdm_seed * (i+2))\n",
        "    res_partial = run_experiments(dicc, list_methods_strategy)\n",
        "    plot_res(info_x_axis, res_partial, dicc)\n",
        "    print(res)\n",
        "    for k in res:\n",
        "      res[k]['l2_dist_best_coeff_gt'].append(res_partial[k]['l2_dist_best_coeff_gt'])\n",
        "      res[k]['best_score'].append(res_partial[k]['best_score'])\n",
        "      res[k]['best_alpha'].append(res_partial[k]['best_alpha'])\n",
        "      #res[k]['best_coeff'].append(res_partial[k]['best_coeff\n",
        "    #res.append(res['l2_dist_best_coeff_gt'])\n",
        "\n",
        "print(\"final \")\n",
        "print(res)\n",
        "for k in res:\n",
        "  print(k)\n",
        "  print(np.array(res[k]['l2_dist_best_coeff_gt']))\n",
        "  print(np.mean(np.array(res[k]['l2_dist_best_coeff_gt']), axis=0))\n",
        "  print(np.mean(res[k]['l2_dist_best_coeff_gt'], axis=0))\n",
        "#mean_res = {k: np.mean(v, axis=0) for k, v in res.items()}\n",
        "mean_res = {k: {v: np.mean(w, axis=0) for v, w in res[k].items()} for k in res}\n",
        "for k, v in mean_res.items():\n",
        "  print(\"k:   \", k)\n",
        "  for s, t in v.items():\n",
        "    print(s, \": \", t)\n",
        "#print(np.mean(res, axis=0))\n",
        "'''\n",
        "nbr_exp = 10\n",
        "seed = 20\n",
        "mean_res = run_multiple_experiments(nbr_exp, seed, dicc, info_x_axis)\n",
        "print(\"PLOT OF THE MEANS\")\n",
        "dicc['title_infer_error'] = 'seed: ' + str(seed) + ', nbr_exp: ' + str(nbr_exp) + ', cov: ' + str(cov_var)\n",
        "dicc['title_test_error'] = 'sigma_err: ' + str(error_vec[0]) + ', n_train: ' + str(n_train[0]) + ', n_test: ' + str(number_test)\n",
        "#dicc = dicc | {'generation':gen, 'title_infer_error':'mean_infer_error, rep: ' + str(nbr_exp), 'title_mean_error':'mean_test_error'}\n",
        "plot_res(info_x_axis, mean_res, dicc)\n",
        "\n",
        "## you can see if you manage to take the index i that maximize alpha\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXcjBX8GqIAF",
        "outputId": "05b7bef6-3009-42ed-dd11-d6acc6176515"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change nbr_experiments to match the size of n_train\n",
            "data :  [{'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}, {'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}, {'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}, {'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}, {'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}, {'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}]\n",
            "n_tot :  [20020, 20020, 20020, 20020, 20020, 20020]\n",
            "n_train :  [20, 20, 20, 20, 20, 20]\n",
            "n_test :  [20000, 20000, 20000, 20000, 20000, 20000]\n",
            "dim :  [18, 18, 18, 18, 18, 18]\n",
            "beta_gt :  [array([-0.5,  2. ,  1. ,  3. , -2. , -3. ,  4. ,  0.5,  7. , -9. , -1. ,\n",
            "       -2. , -3. ,  4. ,  5. ,  6. ,  7. ,  8. ]), array([-0.5,  2. ,  1. ,  3. , -2. , -3. ,  4. ,  0.5,  7. , -9. , -1. ,\n",
            "       -2. , -3. ,  4. ,  5. ,  6. ,  7. ,  8. ]), array([-0.5,  2. ,  1. ,  3. , -2. , -3. ,  4. ,  0.5,  7. , -9. , -1. ,\n",
            "       -2. , -3. ,  4. ,  5. ,  6. ,  7. ,  8. ]), array([-0.5,  2. ,  1. ,  3. , -2. , -3. ,  4. ,  0.5,  7. , -9. , -1. ,\n",
            "       -2. , -3. ,  4. ,  5. ,  6. ,  7. ,  8. ]), array([-0.5,  2. ,  1. ,  3. , -2. , -3. ,  4. ,  0.5,  7. , -9. , -1. ,\n",
            "       -2. , -3. ,  4. ,  5. ,  6. ,  7. ,  8. ]), array([-0.5,  2. ,  1. ,  3. , -2. , -3. ,  4. ,  0.5,  7. , -9. , -1. ,\n",
            "       -2. , -3. ,  4. ,  5. ,  6. ,  7. ,  8. ])]\n",
            "perc_test :  [0.999000999000999, 0.999000999000999, 0.999000999000999, 0.999000999000999, 0.999000999000999, 0.999000999000999]\n",
            "err :  [{'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}, {'type': 'Gaussian_on_X', 'scaling': 0}]\n",
            "plots :  [[], [], [], [], [], []]\n",
            "p_miss :  [[1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334], [1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334], [1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334], [1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334], [1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334], [1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334]]\n",
            "generation :  fixed\n",
            "title_infer_error :    inference_error\n",
            "title_test_error :    test_error\n",
            "info_algo :  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 0, 'eps_adv_rad_times_delta_dts': 0.0001, 'eps_adv_rad_times_delta_mis': 0.0001, 'n_a_dts': 20, 'n_a_mis': 1}\n",
            "[{'imp_method': 'BR_si', 'cov_strategy': 'std_nan'}, {'imp_method': 'oracle', 'cov_strategy': 'sd'}, {'imp_method': 'mi', 'cov_strategy': 'std_mi', 'mi_nbr': 10}, {'imp_method': 'mi', 'post_imp': 'mean', 'cov_strategy_between': 'cond_var', 'cov_strategy': 'std_nan', 'mi_nbr': 10}]\n",
            "imp_method :  BR_si\n",
            "cov_strategy :  std_nan\n",
            "imp_method :  oracle\n",
            "cov_strategy :  sd\n",
            "imp_method :  mi\n",
            "cov_strategy :  std_mi\n",
            "mi_nbr :  10\n",
            "imp_method :  mi\n",
            "post_imp :  mean\n",
            "cov_strategy_between :  cond_var\n",
            "cov_strategy :  std_nan\n",
            "mi_nbr :  10\n",
            "----> Starting experiments\n",
            "[[], [], [], [], [], []]\n",
            "[]\n",
            "BR_si\n",
            "std_nan\n",
            "oracle\n",
            "sd\n",
            "mi\n",
            "std_mi\n",
            "10\n",
            "mi\n",
            "mean\n",
            "cond_var\n",
            "std_nan\n",
            "10\n",
            "{'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}\n",
            "(20020, 18)\n",
            "p_missing in generate mask  [1, 0.9, 0.888888888888889, 0.8749999999999999, 0.8571428571428572, 0.8333333333333334]\n",
            "---------------------------------------------------------------------------------------------------------------------------> iteration  0\n",
            "{'data': 'Normal', 'mean': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cov': array([[ 0.3973404 , -0.0605413 , -0.00429537,  0.02802737,  0.0030939 ,\n",
            "        -0.01791386,  0.02447284,  0.01462934,  0.01503693, -0.03794401,\n",
            "         0.06805199, -0.03813373, -0.02257075,  0.02369544, -0.01686131,\n",
            "         0.01922114,  0.03030011, -0.00854688],\n",
            "       [-0.0605413 ,  0.49634887, -0.07104183, -0.08883847,  0.0541231 ,\n",
            "         0.04650191, -0.01595997,  0.00619709,  0.02047368, -0.02994219,\n",
            "        -0.01727112,  0.01142046, -0.0121061 ,  0.04678753, -0.02408792,\n",
            "         0.02042048, -0.033716  , -0.0036085 ],\n",
            "       [-0.00429537, -0.07104183,  0.4094291 , -0.00185095, -0.0277164 ,\n",
            "        -0.00840508, -0.02875337, -0.02514156,  0.06689651,  0.01069185,\n",
            "        -0.0166394 , -0.01859979,  0.05790109,  0.01787377,  0.02653388,\n",
            "        -0.02087307,  0.00230722,  0.0260469 ],\n",
            "       [ 0.02802737, -0.08883847, -0.00185095,  0.54610991, -0.04865798,\n",
            "        -0.00567648,  0.02919807, -0.01021281, -0.04992742,  0.04022434,\n",
            "         0.07348507,  0.05039666,  0.00604186, -0.04904387,  0.00437915,\n",
            "         0.0174939 ,  0.09210314, -0.02927121],\n",
            "       [ 0.0030939 ,  0.0541231 , -0.0277164 , -0.04865798,  0.34866233,\n",
            "        -0.01617129, -0.01646809, -0.03229961, -0.01324154, -0.05090045,\n",
            "         0.0630129 ,  0.00615031,  0.00744092,  0.05908199, -0.06963146,\n",
            "        -0.03992891, -0.05223042,  0.00436656],\n",
            "       [-0.01791386,  0.04650191, -0.00840508, -0.00567648, -0.01617129,\n",
            "         0.38072739,  0.0652268 , -0.06057084, -0.02775223,  0.01683072,\n",
            "         0.01176755,  0.0677455 , -0.00621621,  0.00972321, -0.00963104,\n",
            "         0.0514444 ,  0.00101305, -0.0104418 ],\n",
            "       [ 0.02447284, -0.01595997, -0.02875337,  0.02919807, -0.01646809,\n",
            "         0.0652268 ,  0.58403656,  0.04112483, -0.08114535, -0.00857381,\n",
            "         0.04846706,  0.01077792, -0.02989345, -0.1446705 , -0.0146736 ,\n",
            "        -0.01857148,  0.0296882 ,  0.03320424],\n",
            "       [ 0.01462934,  0.00619709, -0.02514156, -0.01021281, -0.03229961,\n",
            "        -0.06057084,  0.04112483,  0.41476255,  0.05335558,  0.04074158,\n",
            "        -0.0881539 , -0.04834011, -0.03289236, -0.03036273,  0.02770548,\n",
            "        -0.04807503,  0.04977693,  0.03156961],\n",
            "       [ 0.01503693,  0.02047368,  0.06689651, -0.04992742, -0.01324154,\n",
            "        -0.02775223, -0.08114535,  0.05335558,  0.42498353,  0.00734437,\n",
            "        -0.08338185, -0.03135988,  0.02889985,  0.03225302, -0.00252588,\n",
            "        -0.01321092,  0.03816833,  0.01435652],\n",
            "       [-0.03794401, -0.02994219,  0.01069185,  0.04022434, -0.05090045,\n",
            "         0.01683072, -0.00857381,  0.04074158,  0.00734437,  0.35557105,\n",
            "        -0.06186924,  0.00134109,  0.00283356, -0.03443045,  0.00949882,\n",
            "        -0.02102413,  0.02467552, -0.02176364],\n",
            "       [ 0.06805199, -0.01727112, -0.0166394 ,  0.07348507,  0.0630129 ,\n",
            "         0.01176755,  0.04846706, -0.0881539 , -0.08338185, -0.06186924,\n",
            "         0.4837812 ,  0.01152095,  0.03220658,  0.02748863, -0.06964361,\n",
            "        -0.0270957 , -0.02029599,  0.04187862],\n",
            "       [-0.03813373,  0.01142046, -0.01859979,  0.05039666,  0.00615031,\n",
            "         0.0677455 ,  0.01077792, -0.04834011, -0.03135988,  0.00134109,\n",
            "         0.01152095,  0.38082325, -0.01039061,  0.06173999,  0.01447722,\n",
            "         0.02165315, -0.00479593, -0.01626025],\n",
            "       [-0.02257075, -0.0121061 ,  0.05790109,  0.00604186,  0.00744092,\n",
            "        -0.00621621, -0.02989345, -0.03289236,  0.02889985,  0.00283356,\n",
            "         0.03220658, -0.01039061,  0.33167885, -0.01693428, -0.01456708,\n",
            "        -0.01009415,  0.00819577,  0.01171569],\n",
            "       [ 0.02369544,  0.04678753,  0.01787377, -0.04904387,  0.05908199,\n",
            "         0.00972321, -0.1446705 , -0.03036273,  0.03225302, -0.03443045,\n",
            "         0.02748863,  0.06173999, -0.01693428,  0.50593235,  0.00117447,\n",
            "        -0.02470857, -0.02850751, -0.00254365],\n",
            "       [-0.01686131, -0.02408792,  0.02653388,  0.00437915, -0.06963146,\n",
            "        -0.00963104, -0.0146736 ,  0.02770548, -0.00252588,  0.00949882,\n",
            "        -0.06964361,  0.01447722, -0.01456708,  0.00117447,  0.38595804,\n",
            "         0.02377929,  0.03989745, -0.04884474],\n",
            "       [ 0.01922114,  0.02042048, -0.02087307,  0.0174939 , -0.03992891,\n",
            "         0.0514444 , -0.01857148, -0.04807503, -0.01321092, -0.02102413,\n",
            "        -0.0270957 ,  0.02165315, -0.01009415, -0.02470857,  0.02377929,\n",
            "         0.39937389, -0.00897827, -0.05461947],\n",
            "       [ 0.03030011, -0.033716  ,  0.00230722,  0.09210314, -0.05223042,\n",
            "         0.00101305,  0.0296882 ,  0.04977693,  0.03816833,  0.02467552,\n",
            "        -0.02029599, -0.00479593,  0.00819577, -0.02850751,  0.03989745,\n",
            "        -0.00897827,  0.37413442, -0.02364857],\n",
            "       [-0.00854688, -0.0036085 ,  0.0260469 , -0.02927121,  0.00436656,\n",
            "        -0.0104418 ,  0.03320424,  0.03156961,  0.01435652, -0.02176364,\n",
            "         0.04187862, -0.01626025,  0.01171569, -0.00254365, -0.04884474,\n",
            "        -0.05461947, -0.02364857,  0.44723404]])}\n",
            "(20020, 18)\n",
            "full masks in run experiment  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "info algo in run experiments  {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 0, 'eps_adv_rad_times_delta_dts': 0.0001, 'eps_adv_rad_times_delta_mis': 0.0001, 'n_a_dts': 20, 'n_a_mis': 1}\n",
            "ciaoooooo dict obser in run experiments \n",
            "  {'X_train_masked': (array([[ 1.23417729e-01, -1.63977665e-01, -6.27597175e-01,\n",
            "        -4.63041673e-01,  7.24786618e-01, -2.10096456e-01,\n",
            "        -1.07000717e-01,  1.75404669e-02, -6.58809474e-01,\n",
            "         5.32865300e-01,  1.10872704e+00,  2.80582347e-02,\n",
            "        -7.82931129e-01, -4.89357940e-02, -1.06830629e+00,\n",
            "        -2.10251747e+00, -1.08675373e+00,  1.34996913e+00],\n",
            "       [-4.85775242e-03, -7.31100675e-01,  3.26618317e-01,\n",
            "        -1.08546317e+00, -8.82271827e-01,  2.85925811e-01,\n",
            "         4.23099629e-01,  1.50269253e+00,  1.07453791e+00,\n",
            "        -2.96575650e-03, -1.57453248e+00, -7.74024171e-02,\n",
            "        -2.54014783e-01, -4.85251908e-01,  1.33464181e+00,\n",
            "         1.45782955e-01,  7.12378562e-01,  3.44186140e-01],\n",
            "       [ 1.23580933e+00, -5.43828467e-01,  5.53421068e-01,\n",
            "         6.11832822e-02,  9.92277525e-01,  1.44190802e-01,\n",
            "         2.63164355e-01, -6.62651717e-02, -4.50582067e-03,\n",
            "         5.55218548e-02,  4.01203012e-01,  4.01535472e-01,\n",
            "        -9.34548721e-01,  1.17847189e+00,  5.09031048e-02,\n",
            "        -2.22414055e-01,  1.14864176e-01, -1.22167580e+00],\n",
            "       [ 6.62259209e-01, -1.60423365e-01,  1.62405462e-01,\n",
            "        -4.69536241e-01,  6.15738783e-01, -4.51390387e-01,\n",
            "        -1.42882466e-01, -1.33196762e+00, -8.50028701e-01,\n",
            "        -1.08939991e+00, -1.04891833e-01, -6.31267927e-01,\n",
            "         4.80403131e-01, -3.97976959e-01,  4.24867737e-01,\n",
            "         1.33394166e+00, -7.56166190e-01, -7.25605506e-01],\n",
            "       [ 1.28366079e+00,  2.65910828e-01, -2.81342523e-01,\n",
            "        -7.12630330e-01,  7.43708039e-01,  7.96699312e-01,\n",
            "         7.11813774e-01,  4.05005049e-01,  7.49934176e-02,\n",
            "         5.05352947e-01, -6.64155211e-01, -1.07817683e+00,\n",
            "        -1.78708796e-01, -1.87374795e-01, -8.89505600e-02,\n",
            "        -3.33604196e-01, -6.67883785e-01,  2.44200853e-01],\n",
            "       [ 5.19213933e-01,  3.95040429e-01, -6.12225146e-01,\n",
            "        -4.41809967e-01, -2.02250625e-01,  1.99899338e-01,\n",
            "         8.53479916e-01,  1.14881941e-02,  5.31850814e-01,\n",
            "         5.73998438e-01, -9.90691667e-01,  1.26071342e+00,\n",
            "        -1.86449261e-01,  4.72318564e-01,  3.77782998e-01,\n",
            "         7.08596560e-02, -3.54092726e-01, -7.67802387e-01],\n",
            "       [-7.95732724e-01,  5.01169612e-01,  9.11491659e-01,\n",
            "        -1.07092131e-01,  5.35469170e-01,  7.77716979e-01,\n",
            "         2.31139789e-01, -2.92853764e-01,  4.49361378e-01,\n",
            "         7.04319754e-02,  3.17296304e-01, -6.78382848e-02,\n",
            "        -2.26291059e-01, -3.16481444e-01, -2.06169051e+00,\n",
            "        -5.91278160e-01, -9.28649500e-01, -6.53943229e-01],\n",
            "       [ 1.77491772e-01,  3.65513586e-02,  7.22956203e-02,\n",
            "         1.49664872e-02, -8.50540427e-01,  1.13855548e+00,\n",
            "        -1.07119307e+00, -1.12512698e+00, -1.21098968e-01,\n",
            "         2.26775574e-01,  1.06873392e+00,  9.11861771e-01,\n",
            "         4.39991299e-01,  5.67747246e-01,  2.75559936e-01,\n",
            "         9.30112098e-03, -3.35439074e-01,  5.25764742e-01],\n",
            "       [ 6.30268257e-01,  2.82878376e-01, -4.62883171e-01,\n",
            "         1.40977832e+00, -1.41350534e+00,  6.79699388e-01,\n",
            "         9.59422908e-01,  1.38109251e+00,  3.35634223e-01,\n",
            "         4.07632276e-01,  1.95882872e-01,  3.67338960e-01,\n",
            "         9.18951268e-02,  6.41374978e-01, -1.72391613e-02,\n",
            "         5.70756190e-01,  1.21909775e+00,  9.56222141e-02],\n",
            "       [ 5.47204066e-01,  1.43766501e-01, -3.03221209e-01,\n",
            "        -5.43996771e-01,  2.25970678e-01, -6.83803969e-01,\n",
            "         7.53163136e-01,  4.49753808e-01, -1.31234740e+00,\n",
            "        -1.94039144e-01, -1.25800330e-01, -5.28328429e-02,\n",
            "        -5.39192480e-01,  1.04684911e+00, -8.79420062e-02,\n",
            "         7.40588769e-01,  7.47836011e-01, -2.07505124e-01],\n",
            "       [-2.98972064e-01,  1.48435226e+00, -3.67712465e-02,\n",
            "        -4.88802380e-01,  5.45576163e-01, -3.87501224e-01,\n",
            "        -1.43809067e+00,  7.78642558e-01,  7.05440390e-01,\n",
            "         1.09438872e-01,  8.02851809e-02,  3.76382269e-01,\n",
            "        -2.40760384e-01,  9.16826914e-01,  1.98597935e-01,\n",
            "        -5.07255150e-01,  3.19414418e-01,  2.21312841e-01],\n",
            "       [ 8.39351748e-01, -3.17094423e-01,  3.93744745e-01,\n",
            "         6.49484955e-01,  9.91469986e-01,  3.49314357e-01,\n",
            "        -8.42547352e-02, -5.69166820e-01, -9.33371012e-01,\n",
            "        -5.28023681e-01,  4.88897620e-01,  1.71836214e-02,\n",
            "         1.47012551e-01,  8.88421534e-01,  3.38444755e-01,\n",
            "         1.06338237e+00,  6.11668272e-01, -4.18019622e-01],\n",
            "       [ 9.73230917e-03, -1.33907996e-01,  3.64679217e-01,\n",
            "        -1.73116843e-01,  2.41807676e-02, -1.90542821e-01,\n",
            "         2.48096645e-01, -1.42480134e-01, -2.02123199e-02,\n",
            "        -7.79691688e-01,  3.30036000e-02, -1.23396522e+00,\n",
            "         1.07266614e+00, -8.02117809e-01, -1.24591228e-02,\n",
            "        -7.41736547e-01,  9.27286567e-01,  5.67709551e-01],\n",
            "       [ 6.83002553e-01, -1.12126086e+00, -9.25311229e-01,\n",
            "         8.59902306e-01,  4.19690739e-01, -6.22046823e-01,\n",
            "         4.54845934e-01, -5.55055360e-03, -2.58568778e-01,\n",
            "         3.93863539e-01,  7.67383718e-01,  4.59097314e-01,\n",
            "        -2.21675701e-01,  6.03385406e-01,  7.18685922e-01,\n",
            "        -1.22063039e-01,  9.20752053e-01,  1.14085189e-01],\n",
            "       [-8.60768091e-02, -6.82191584e-01,  5.60352677e-01,\n",
            "        -1.84315162e-01,  1.67962471e-01, -9.28968408e-02,\n",
            "        -6.55715089e-01, -1.91778845e-01, -6.81992817e-01,\n",
            "        -1.29747023e-01,  1.50538686e+00,  1.14584164e+00,\n",
            "        -4.08556576e-01,  1.45506468e-01,  2.96091490e-02,\n",
            "        -8.43110817e-01, -2.01204232e-01, -8.70442868e-02],\n",
            "       [-1.54247280e+00,  1.42668667e-01, -8.41362635e-01,\n",
            "         7.40230112e-01,  1.55734609e-01,  9.88318436e-03,\n",
            "        -8.56983367e-02,  2.16261657e-01, -8.66616119e-02,\n",
            "        -5.66650636e-02,  1.56766661e-01, -4.06491040e-02,\n",
            "        -3.35064998e-01,  4.80962962e-02, -4.15254729e-01,\n",
            "         1.66475447e-01, -8.76884907e-01,  5.66978061e-01],\n",
            "       [-1.15573204e-01, -6.52056148e-02,  1.51526637e+00,\n",
            "        -1.48142539e-01, -4.85321851e-01,  1.51708739e+00,\n",
            "         1.62947127e+00, -9.40984387e-01, -6.98508458e-01,\n",
            "        -7.95983999e-02,  8.12127532e-01,  1.45133411e+00,\n",
            "         4.02760456e-01, -2.40085034e-02, -4.76707745e-01,\n",
            "        -4.50480540e-01,  3.98877257e-01, -2.33885638e-01],\n",
            "       [ 3.48644711e-01, -2.22544952e-01,  1.71759453e-01,\n",
            "        -4.93597132e-01, -1.92191966e-01,  1.98637546e-01,\n",
            "         1.23380793e+00,  7.70702943e-01,  4.84287809e-01,\n",
            "         8.78360670e-02, -7.26024459e-01, -2.89379709e-01,\n",
            "         3.14879842e-01, -1.20894923e+00, -6.71207369e-01,\n",
            "        -5.61038246e-01,  2.76879967e-01,  3.77921172e-01],\n",
            "       [ 1.05729319e+00, -1.18382435e+00,  1.36158273e+00,\n",
            "         3.20437358e-01, -5.43873758e-01, -6.48905939e-01,\n",
            "         5.56263067e-01, -5.46706409e-01,  1.60880402e-02,\n",
            "         5.80591864e-01,  6.84390362e-01,  4.51348363e-01,\n",
            "         6.83466073e-01, -3.18972768e-01, -3.53652877e-01,\n",
            "         2.52837656e-01, -6.83909450e-02, -8.02722769e-01],\n",
            "       [-5.69370985e-01, -2.97527014e-01,  9.22990659e-01,\n",
            "        -1.16885921e-01, -5.86297555e-01, -1.22363280e+00,\n",
            "        -5.55947859e-04, -4.24095214e-01, -6.39733014e-01,\n",
            "         8.18544400e-01,  9.58879004e-01,  3.92273615e-01,\n",
            "        -5.95127151e-02, -2.63411743e-01, -4.44540829e-01,\n",
            "        -1.52955051e+00, -1.50533856e+00,  5.79894498e-01]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])), 'X_test': array([[-1.07584346e-01,  3.89249961e-01,  3.86844920e-01, ...,\n",
            "         8.94301022e-01,  7.39469497e-01, -5.28600502e-01],\n",
            "       [-1.22348472e-01,  6.36356428e-01,  2.60383308e-01, ...,\n",
            "         2.74325250e-01, -4.19858409e-01, -2.18571153e-01],\n",
            "       [ 3.18063380e-01, -6.13131485e-01,  1.23861427e+00, ...,\n",
            "         2.67932278e-01, -4.14145088e-01, -4.66570307e-01],\n",
            "       ...,\n",
            "       [ 8.14652057e-01, -6.50152829e-01,  5.63185781e-03, ...,\n",
            "         6.10161378e-01, -9.80291026e-01, -1.80800080e-01],\n",
            "       [-1.49752390e+00,  5.07420451e-01, -3.47342808e-04, ...,\n",
            "         2.44862216e-01, -5.67314006e-01, -8.80773385e-02],\n",
            "       [ 2.08520933e-01, -2.31309548e-02,  4.56917351e-01, ...,\n",
            "        -3.34662272e-01, -1.72121879e-01,  8.97024287e-01]]), 'y_train': array([-26.82830955,  22.34784442,  -6.63349698,  -1.79430973,\n",
            "        -9.94104283,  -5.01485278, -24.48078045,  -7.99883392,\n",
            "        22.01023094,   9.09071352,   5.7888565 ,   7.45388809,\n",
            "        10.42122357,   8.1709745 , -16.70092588,   0.20579534,\n",
            "        -9.89266244,  -0.4562894 , -12.76508018, -26.87060044]), 'y_test': array([ 22.8705619 , -11.27999097,   7.37563027, ...,  -9.90816225,\n",
            "        -7.6493685 ,  12.97213072]), 'imp_ds': {'BR_si': [], 'l_d': [], 'oracle': [], 'mi': []}, 'info_algo': {'adv_rad_times_delta_dts_max': 10, 'adv_rad_times_delta_mis_max': 0, 'eps_adv_rad_times_delta_dts': 0.0001, 'eps_adv_rad_times_delta_mis': 0.0001, 'n_a_dts': 20, 'n_a_mis': 1}}\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'BR_si', 'cov_strategy': 'std_nan'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.6847393  0.58268157 0.67483062 0.5879967  0.65931461 0.6592983\n",
            " 0.71944187 0.72987008 0.60644668 0.46373542 0.75285682 0.68231767\n",
            " 0.48248903 0.63109408 0.67990194 0.79237838 0.75335528 0.60953626]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  13.940874529898156\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "S dataset \n",
            " [[0.6847393  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.58268157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.67483062 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.5879967  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.65931461 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.6592983\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.71944187 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.72987008 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60644668 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.46373542 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.75285682 0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.68231767\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.48248903 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.63109408 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.67990194 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.79237838 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.75335528 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.60953626]]\n",
            "shape oject in cov strategy missing  18\n",
            "shape oject in cov strategy missing  (20000, 18)\n",
            "S missing shape\n",
            "  (18, 18)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (20, 18)\n",
            "y_train length  20\n",
            "-------> size test:  20000  , size train:  20 nbr_seen (train):  20  nbr_miss :  0\n",
            "X  20   18\n",
            "y shape (20,)\n",
            "nm  360\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-03 1.62377674e-03 2.63665090e-03 4.28133240e-03\n",
            " 6.95192796e-03 1.12883789e-02 1.83298071e-02 2.97635144e-02\n",
            " 4.83293024e-02 7.84759970e-02 1.27427499e-01 2.06913808e-01\n",
            " 3.35981829e-01 5.45559478e-01 8.85866790e-01 1.43844989e+00\n",
            " 2.33572147e+00 3.79269019e+00 6.15848211e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 184.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 18) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  1  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00162378 0.        ] , min score  1.6296376798744856e-20\n",
            "---------------------------------> best coeff  [-0.5  2.   1.   3.  -2.  -3.   4.   0.5  7.  -9.  -1.  -2.  -3.   4.\n",
            "  5.   6.   7.   8. ]\n",
            "BR_si\n",
            "std_nan\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'oracle', 'cov_strategy': 'sd'}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.6847393  0.58268157 0.67483062 0.5879967  0.65931461 0.6592983\n",
            " 0.71944187 0.72987008 0.60644668 0.46373542 0.75285682 0.68231767\n",
            " 0.48248903 0.63109408 0.67990194 0.79237838 0.75335528 0.60953626]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n",
            "crush test------------------------------------------------->  13.940874529898156\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "S dataset \n",
            " [[0.6847393  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.58268157 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.67483062 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.5879967  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.65931461 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.6592983\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.71944187 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.72987008 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60644668 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.46373542 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.75285682 0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.68231767\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.48248903 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.63109408 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.67990194 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.79237838 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.75335528 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.60953626]]\n",
            "shape oject in cov strategy missing  18\n",
            "shape oject in cov strategy missing  (20000, 18)\n",
            "S missing shape\n",
            "  (18, 18)\n",
            "S missing\n",
            "  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "shape X_imputed in post_imputation  (20, 18)\n",
            "y_train length  20\n",
            "-------> size test:  20000  , size train:  20 nbr_seen (train):  20  nbr_miss :  0\n",
            "X  20   18\n",
            "y shape (20,)\n",
            "nm  360\n",
            "S_mis in Adbvt training  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "no missing part\n",
            "one matrix in input, S.shape = (n, n)\n",
            "dts deltas  [1.00000000e-03 1.62377674e-03 2.63665090e-03 4.28133240e-03\n",
            " 6.95192796e-03 1.12883789e-02 1.83298071e-02 2.97635144e-02\n",
            " 4.83293024e-02 7.84759970e-02 1.27427499e-01 2.06913808e-01\n",
            " 3.35981829e-01 5.45559478e-01 8.85866790e-01 1.43844989e+00\n",
            " 2.33572147e+00 3.79269019e+00 6.15848211e+00 1.00000000e+01]\n",
            "mis deltas  [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 20/20 [00:00<00:00, 151.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape,  (20000, 18) ,   y_test shape  (20000,)\n",
            "---------------------------------> best idx  1  best hyperp [best_alpha_delta_dst, best_alpha_delta_mis]:  [0.00162378 0.        ] , min score  1.6293638871291485e-20\n",
            "---------------------------------> best coeff  [-0.5  2.   1.   3.  -2.  -3.   4.   0.5  7.  -9.  -1.  -2.  -3.   4.\n",
            "  5.   6.   7.   8. ]\n",
            "oracle\n",
            "sd\n",
            "----------------------------------------------> new method tested:  {'imp_method': 'mi', 'cov_strategy': 'std_mi', 'mi_nbr': 10}\n",
            "-------> ORACLE SD, std of the original dataset (with no missing) [0.6847393  0.58268157 0.67483062 0.5879967  0.65931461 0.6592983\n",
            " 0.71944187 0.72987008 0.60644668 0.46373542 0.75285682 0.68231767\n",
            " 0.48248903 0.63109408 0.67990194 0.79237838 0.75335528 0.60953626]\n",
            "NO PREVIOUS IMPUTATION HAS BEEN DONE\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-45-244349707.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mnbr_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mmean_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multiple_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_x_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PLOT OF THE MEANS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mdicc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_infer_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'seed: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', nbr_exp: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', cov: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-18-4074395655.py\u001b[0m in \u001b[0;36mrun_multiple_experiments\u001b[0;34m(nbr_exp, rdm_seed, dictio, info_x_axis)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;31m#rdm_seed = 4654321\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdm_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_methods_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m   \u001b[0mplot_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_x_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m   '''\n",
            "\u001b[0;32m/tmp/ipython-input-18-4074395655.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(dictio, methods_strategy)\u001b[0m\n\u001b[1;32m     87\u001b[0m           \u001b[0mcoeff_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_2d_ext_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_obser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_imp_cov_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnbr_ima\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnbr_ima\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# == 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m           \u001b[0mcoeff_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_2d_ext_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_obser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_imp_cov_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoeff_round\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdictio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta_gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0ml2_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-42-22428238.py\u001b[0m in \u001b[0;36mexperiment_2d_ext_dataset\u001b[0;34m(dict_obs, dict_imp, ax)\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0;31m#results = imputations(dict_imp, X_nan_train, dict_obs['y_train'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NO PREVIOUS IMPUTATION HAS BEEN DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m       \u001b[0mX_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_from_X_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_from_X_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m  \u001b[0;31m# imputations(dict_imp, X_nan_train, dict_obs['y_train'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mdict_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imp_ds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict_imp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imp_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-42-22428238.py\u001b[0m in \u001b[0;36mimputations\u001b[0;34m(info, dict_obs_for_imp)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imp_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'mi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mi_pure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiple_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mi_nbr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_nan\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# size (info['mi_nbr], n, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imp_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l_d'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# listwise_deletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#mask_from_X_nan = np.isnan(X_nan).astype(int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-3296519378.py\u001b[0m in \u001b[0;36mmultiple_imputation\u001b[0;34m(nbr_mi, X_nan)\u001b[0m\n\u001b[1;32m     23\u001b[0m        \u001b[0mn_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m        \u001b[0mice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_posterior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m        \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m        \u001b[0;31m#print(\"fin res shape\", res.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m        \u001b[0;31m#if nbr_mi == 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    857\u001b[0m                     \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_corr_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 )\n\u001b[0;32m--> 859\u001b[0;31m                 Xt, estimator = self._impute_one_feature(\n\u001b[0m\u001b[1;32m    860\u001b[0m                     \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                     \u001b[0mmask_missing_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36m_impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode, params)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mmissing_row_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_missing_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             X_train = _safe_indexing(\n\u001b[0m\u001b[1;32m    418\u001b[0m                 \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_filled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_feat_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;34m~\u001b[0m\u001b[0mmissing_row_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_indexing.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \"\"\"Return rows, items or columns of X using indices.\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DJHHiKFqIUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FhKy2v5qIb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "840TDfGaqIei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SijOuiZYgmon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TG_Fsg4Mgmrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZRfmkoYlgmuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2vbxlxxNgmyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zJgEeongm1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkEtCuWEgm3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjbzANmcg_cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JsQXdlOg_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4FH2Zo7g_j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxm1VFuIg_q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3cxU4-RZg_uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktlqpLJ9g_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doiemfrVg_zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bzoCpqTg_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwoz_Lp2g_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-Kc_0IPg_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMqppMFSgm5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSeaLOr-qLYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azRmYEueqLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4l2vYHzqLd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7X3AQIZqLgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iv34YkpnqLju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCRKDvv-qLmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJ6b5Zd_vZ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7swocNpvZ_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cxt5tWj1vaCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kCvPWMOtvaE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9kxssOuRMv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWcLfNW2RM1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S5O3hTLTvaIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE8VHJ90vaMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZnN2xpSvaOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze5Q9M4Tycsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzWhOlCoycwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZMXiJW-ycz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uAINCofcyc20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uORnN_wO05n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQ441A0hO09K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iF_8aBrWO1Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHLiMt5wO1Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gB_XEEFvaQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFwxXhyWefs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Kw8bLBTefv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXN7C2Jfefzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeFvCalref4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "An113TsYef7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kF5dEO1zef-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zuC2em6egA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MM7Zk7OWegDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVL97vbaegFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA3cOcmeegJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FpYA6ClegNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3MxLnLIqLol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DgSOhmwgm7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSdrq6HmqIhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4nfPNbTqIjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4xXWwHeeMR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oonp7YBzeMUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnVLZhvbeMXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9Yk_s6leMZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5asNezNqImF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwGCYcYWqIrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6dLlbTgqIt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lu0iNCNHc_0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "031VAAc5c_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quVErgChc_-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVqmuefndAEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7M3O9KqdAL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LN_xYsFMdAQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wo4YT1OODeeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl-gtIlyDeh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnKMsLPgDemY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKCZUoDYDesF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1vpjYZ9dAVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1Fx16kedAX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(2, 5, size=(2, 2, 2))\n",
        "print(X)\n",
        "\n",
        "XX = np.concatenate(X)\n",
        "print(XX)\n",
        "\n",
        "\n",
        "Y = np.random.randint(2, 5, size=(1, 3, 2))\n",
        "print(Y)\n",
        "\n",
        "YY = np.concatenate(Y)\n",
        "print(YY)\n",
        "\n",
        "\n",
        "Z = np.random.randint(2, 5, size=(5, 2))\n",
        "print(Z)\n",
        "\n",
        "ZZ = np.concatenate(Z)\n",
        "print(ZZ)\n",
        "\n",
        "print(\"other\")\n",
        "s = np.random.randint(2, 4, 5)\n",
        "print(s)\n",
        "z = np.tile(s, reps=3)  # np.array([s] * 2)\n",
        "print(z)\n",
        "\n",
        "\n",
        "print(\"other mult\")\n",
        "s = np.random.randint(2, 8, size=(3, 2))\n",
        "print(s)\n",
        "z = np.tile(s, reps=(3, 1))  # np.array([s] * 2)\n",
        "print(z)\n"
      ],
      "metadata": {
        "id": "J-KLwpDqTkGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBkG1_lacBfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBILRQvDuI4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dPT52NAbKyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2ShK9JYb6c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fk7A_5N_c1gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgcEt2LBhEBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FiP-uNujLRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uENE-JShLaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JeqAEblFooY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXByx8OrjqZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TCzI5siopUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4pGls4IpDT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWpiTpQ5lVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ASCmfdEnvjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jq6GembmmAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nb6YB8DbvKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9pv_OW7pJtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgNt4tVYQk7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlebwxRZ1_QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1dmiXA-FcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDRrQMKGU3Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnNTv-mXVIB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBlyABpt0-qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQgiJb-V-hIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCuJj9HPb2cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VM2QQJkmcsdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## random forest imputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_estimator = RandomForestRegressor(n_estimators=4, max_depth=10, bootstrap=True, max_samples=0.5, n_jobs=2, random_state=0)\n",
        "\n",
        "X_rf = single_imputation(X_nan, rf_estimator)\n",
        "print(X_rf.shape)\n",
        "sd_rf = np.std(X_rf, axis=0)\n",
        "S_inv_rf = np.diag(1 / sd_rf)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std rf\\n \", sd_rf)\n",
        "fig, ax = plt.subplots(num='advtrain_linf_rf')\n",
        "linfadvtrain_rf = AdversarialTraining(X_rf, y, S_inv_rf, p=np.inf)\n",
        "estimator_rf = lambda X, y, a:  linfadvtrain_rf(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_rf  = get_path(X_rf, y, estimator_rf, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_rf, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "uSgnV3aVXL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## iterative imputer Bayesian Ridge\n",
        "\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "br_estimator = BayesianRidge()\n",
        "\n",
        "X_br = single_imputation(X_nan, br_estimator)\n",
        "sd_br = np.std(X_br, axis=0)\n",
        "S_inv_br = np.diag(1 / sd_br)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std  br\\n \", sd_br)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_br')\n",
        "linfadvtrain_br = AdversarialTraining(X_br, y, S_inv_br, p=np.inf)\n",
        "estimator_br = lambda X, y, a:  linfadvtrain_br(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_br  = get_path(X_br, y, estimator_br, 1e4)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_br, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "pgNaP74gWAga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## mean imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_mean = imp_mean.fit_transform(X_nan)\n",
        "sd_mean = np.std(X_mean, axis=0)\n",
        "print(sd_mean)\n",
        "S_inv_mean = np.diag(1 / sd_mean)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_mean')\n",
        "linfadvtrain_mean = AdversarialTraining(X_mean, y, S_inv_mean, p=np.inf)\n",
        "estimator_mean = lambda X, y, a:  linfadvtrain_mean(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_mean  = get_path(X_mean, y, estimator_mean, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_mean, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "u0kpCJCkFbcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# imputation elliptic\n",
        "\n",
        "mu = np.nanmean(X_nan, axis=0)\n",
        "print(\"means \", mu)\n",
        "delta = np.mean(masks) # parameter missingness\n",
        "print(\"delta \", delta)\n",
        "X_0 = np.nan_to_num(X_nan)\n",
        "print(\"nbr obs\", X_0.shape[0])\n",
        "S_ellp =  X_0.T @ X_0 / X_0.shape[0]\n",
        "S_ellp = (1/delta - 1/(delta**2)) * np.diag(np.diag(S_ellp)) + 1/(delta**2) * S_ellp\n",
        "print(\"eig cov \", np.linalg.eigvalsh(S_ellp))\n",
        "X_ellp = imputation_elliptic(mu, S_ellp, X_nan, masks)\n",
        "#S_inv_ellp = np.linalg.inv(S_ellp)  # other variance\n",
        "sd_inv_ellp = np.std(X_ellp, axis=0)\n",
        "print(\"sd ellp\", sd_inv_ellp)\n",
        "\n",
        "fig, ax = plt.subplots(num='advtrain_linf_ellp')\n",
        "linfadvtrain_ellp = AdversarialTraining(X_ellp, y, S_ellp, p=np.inf)\n",
        "estimator_ellp = lambda X, y, a:  linfadvtrain_ellp(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_ellp  = get_path(X_ellp, y, estimator_ellp, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_ellp, ax)\n",
        "'''"
      ],
      "metadata": {
        "id": "2RYR4_BJhXjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mlM-FR-OfL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgxEbR071wT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7pwDiPU0D_ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdM7Mk_mjf0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYa8pmuMk4jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMwgzXI1_rEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Example data\n",
        "x_test_rect = np.random.rand(10)\n",
        "y_test_rect = np.random.rand(10)\n",
        "\n",
        "# Plot the points\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x_test_rect, y_test_rect)\n",
        "\n",
        "width = 0.1\n",
        "height = 0.1\n",
        "\n",
        "add_rectangles(x_test_rect, y_test_rect, width, height, ax)\n",
        "\n",
        "# Add the rectangle to the plot\n"
      ],
      "metadata": {
        "id": "-9qaVcwZUB6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WZeO2EOWHwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for some tests\n",
        "\n",
        "def test_clear_dataset(n, d):\n",
        "  print(\"test clear dataset\")\n",
        "  X = np.random.randint(1, 3, size=(n, d))\n",
        "  y = np.random.randint(1, 3, size=n)\n",
        "  masks = np.random.binomial(1, 0.3, size=(n, d))\n",
        "  print(\"X \\n\", X)\n",
        "  print(\"y\\n\", y)\n",
        "  print(\"masks \\n\", masks)\n",
        "  masks[:, 0] = np.ones(n)\n",
        "  masks[0, :] = np.ones(d)\n",
        "  X_res, y_res, masks_res = clear_dataset(X, y, masks)\n",
        "  print(\"X_res \\n\", X_res)\n",
        "  print(\"y\\n\", y_res)\n",
        "  print(\"masks \\n\", masks_res)\n",
        "  print(\"test clear dataset ended successfully\")\n",
        "\n",
        "def test_generate_X():\n",
        "    print(\"test generate_X started\")\n",
        "    fig, ax = plt.subplots(3, 1, figsize=(10, 8), num='advtrain_linf')\n",
        "    gen = generate_X('circles', 2)\n",
        "    data = gen(1000)\n",
        "    print(data.shape)\n",
        "    ax[0].scatter(data[:, 0], data[:, 1])\n",
        "    print(\"test generate passed syccessfully\")\n",
        "\n",
        "def test_preparation_dataset(n, d):\n",
        "      print(\"\\ntest preparation dataset started\")\n",
        "      X_train = np.random.rand(n, d)\n",
        "      print(\"X_train \\n\", X_train)\n",
        "      mask = np.random.binomial(1, 0.5, (n, d))\n",
        "      print(\"mask, 0 seen, 1 missing \\n \", mask)\n",
        "      X_masked = X_train * (1 - mask)\n",
        "      print(\"X_masked \\n\", X_masked)\n",
        "      X_nan_train = X_train.copy()\n",
        "      X_nan_train[mask == 1] = np.nan\n",
        "      print(\"X_nan_train \\n\", X_nan_train)\n",
        "      X_br_train = single_imputation(X_nan_train, BayesianRidge())\n",
        "      print(\"X_br_train\\n \", X_br_train)\n",
        "\n",
        "      print(\"what happens if we run single_imputation of full dataset\")\n",
        "      X_br_full = single_imputation(X_train, BayesianRidge())\n",
        "      print(\"X_br_full\\n \", X_br_full)\n",
        "      np.testing.assert_allclose(X_train, X_br_full)  # shuold be untouched\n",
        "      print(\"test preparation dataset ended successfully\")\n",
        "\n",
        "def test_listwise_delection(n, d):\n",
        "    print(\"\\n test list_wise delection started\")\n",
        "    X = np.random.rand(n, d)\n",
        "    print(\"data\\n\", X)\n",
        "    mask = np.random.binomial(1, 0.2, (n, d))\n",
        "    print(\"mask \\n\", mask)\n",
        "    X_ld = listwise_delection(X, mask)\n",
        "    print(\"after calling function, X_ld \\n\", X_ld)\n",
        "\n",
        "    print(\"edge cases, all missing\")\n",
        "    mask_1 = np.ones_like(X)  # all missing\n",
        "    X1 = listwise_delection(X, mask_1)\n",
        "    print(\"X1 \\n\", X1)  # should be empty\n",
        "    mask_0 = np.zeros_like(X)  # all seen\n",
        "    X0 = listwise_delection(X, mask_0)\n",
        "    print(\"X0 \\n\", X0)\n",
        "    np.testing.assert_allclose(X0, X)  # should be the original dataset\n",
        "\n",
        "    print(\"one dimnsional array\")\n",
        "    y = np.random.rand(n)\n",
        "    print(\"y before \", y)\n",
        "    y_ld = listwise_delection(y, mask)\n",
        "    print(\"y after ld \", y_ld)\n",
        "    print(\"test listwise_delection passed\")\n",
        "\n",
        "\n",
        "test_generate_X()\n",
        "test_preparation_dataset(3, 4)\n",
        "test_listwise_delection(3, 4)\n",
        "test_clear_dataset(6, 3)\n",
        "\n",
        "xxx = np.random.randint(2, 5, size=(3, 3)) * 1.0\n",
        "mmm = np.random.binomial(1, 0.5, size=(3, 3))\n",
        "print(xxx)\n",
        "print(mmm)\n",
        "print(mmm == 1)\n",
        "print(xxx[mmm == 1])\n",
        "xxx[mmm == 1] = np.nan\n",
        "print(xxx)\n",
        "mask_from_xxx = np.isnan(xxx).astype(int)\n",
        "print(\"mask from xxx \\n\", mask_from_xxx)\n"
      ],
      "metadata": {
        "id": "SDHMAeapZVgK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test best predictor\n",
        "\n",
        "def test_best_predictor(n, d, nb_coeff):\n",
        "  X_test = np.random.randint(1, 9, size=(n, d))\n",
        "  beta_gt_test = np.random.randint(1, 7, size=d)\n",
        "  y_test = X_test @ beta_gt_test\n",
        "  #print(\"X_test \\n\", X_test, \"\\n beta_gt\", beta_gt_test, \"\\n y_test = X_test @ beta_gt_test \", y_test)\n",
        "  coeff_test = np.random.randint(1, 5, size=(d, nb_coeff))\n",
        "  rdm_idx = np.random.randint(1, d+1, size=1)\n",
        "  print(rdm_idx)\n",
        "  #print(\"coeff test partial \", coeff_test[:, -1])\n",
        "  rng = np.arange(nb_coeff)\n",
        "  #print(rng != rdm_idx)\n",
        "  coeff_test[:, rng != rdm_idx] = coeff_test[:, rng != rdm_idx] + 1000  # increase artificially the value of the other coefficient, to induce the minimum index to be rdm_idx\n",
        "  #print(\"coeff_test \\n\", coeff_test)\n",
        "  best_coeff, best_score = best_predictor(X_test, coeff_test, y_test)\n",
        "  print(\"best coeff \", best_coeff)\n",
        "  print(\"best score \", best_score)\n",
        "  np.testing.assert_allclose(best_coeff, coeff_test[:,rdm_idx].squeeze())\n",
        "  print(\"test best predictor passed\")\n",
        "\n",
        "test_best_predictor(100, 5, 20)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJk1Yaj1ReIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test train_and_plot\n",
        "\n",
        "X_diab, y_diab = datasets.load_diabetes(return_X_y=True)\n",
        "n, d = X_diab.shape\n",
        "print(\"n:  \", n, \", d: \", d)\n",
        "# Standardize data\n",
        "X_diab -= X_diab.mean(axis=0)\n",
        "X_diab /= X_diab.std(axis=0)\n",
        "\n",
        "## original lasso\n",
        "fig_l, ax_l = plt.subplots(num='lasso')\n",
        "alphas_lasso, coefs_lasso, _ = get_lasso_path(X_diab, y_diab)\n",
        "plot_coefs_l1norm(coefs_lasso, ax_l)\n",
        "\n",
        "## Antonio's algo, 1 matrix\n",
        "S_diab_eye = np.eye(X_diab.shape[1])\n",
        "fig, ax_1 = plt.subplots(1, 1, num='advtrain_linf_diab')\n",
        "fig, ax_2 = plt.subplots(1, 1, num='advtrain_linf_diab_2')\n",
        "train_and_plot(X_diab, y_diab, S_diab_eye, [ax_1, ax_2])\n",
        "\n",
        "## Antonio's algo, multiple diagonal matrix\n",
        "#S_diab = np.eye(X_diab.shape[1])\n",
        "#S_diab = np.random.randint(1, 3, size=(n, d))\n",
        "#print(S_diab)\n",
        "#fig, ax_5 = plt.subplots(1, 1, num='advtrain_linf_diab_5')\n",
        "#fig, ax_6 = plt.subplots(1, 1, num='advtrain_linf_diab_6')\n",
        "#train_and_plot(X_diab, y_diab, S_diab, [ax_5, ax_6])\n",
        "\n",
        "\n",
        "## Antonio's algo, multiple matrices (same matrix stacked multiple time)\n",
        "S_diab_stacked = np.array([S_diab_eye] * X_diab.shape[0])\n",
        "S_diab_stacked = np.concatenate(S_diab_stacked)\n",
        "fig, ax_3 = plt.subplots(1, 1, num='advtrain_linf_diab_3')\n",
        "fig, ax_4 = plt.subplots(1, 1, num='advtrain_linf_diab_4')\n",
        "train_and_plot(X_diab, y_diab, S_diab_stacked, [ax_3, ax_4])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KjpHk0mYdiFh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test imputations\n",
        "\n",
        "np.random.seed(45)\n",
        "\n",
        "\n",
        "def test_imputations(n, d):\n",
        "  X = np.random.randint(2, 5, size=(n, d)) * 1.0\n",
        "  y = X @ np.random.randint(1, 3, size=d)\n",
        "  m = np.random.binomial(1, 0.4, size=(n, d))  # 1 missing, 0 seen\n",
        "  print(\"m original\\n\", m)\n",
        "  X, y, m = clear_dataset(X, y, m)\n",
        "  print(m)\n",
        "  X_nan = X.copy()\n",
        "  X_nan[m == 1] = np.nan\n",
        "\n",
        "  #mask_from_xxx = np.isnan(xxx).astype(int)\n",
        "  print(\"X\\n \", X)\n",
        "  print(\"masks \\n\", m)\n",
        "  print(\"X_nan\\n \", X_nan)\n",
        "  methods = ['BR_si', 'mi', 'l_d']\n",
        "  nbr_mi = [1, 3]\n",
        "  #for method in methods:\n",
        "  #  dict_info = {'imp_method': method, 'mi_nbr':nbr_mi}\n",
        "  #dict_info = {'imp_method':methods, 'mi_nbr':nbr_mi}\n",
        "  for method in methods:\n",
        "    print(\"---------- method: \", method)\n",
        "    if method == 'mi':\n",
        "      for x in nbr_mi:\n",
        "        print(\"-------------------- nbr mi: \", x)\n",
        "        dict_info = {'imp_method':method, 'mi_nbr':x}\n",
        "        #print(\"XNANNANAN \", X_nan)\n",
        "        X_res, y_res, mask_res = imputations(dict_info, X_nan, y)\n",
        "        print(X_res, y_res, \"\\n\", mask_res)\n",
        "    else:\n",
        "      dict_info = {'imp_method': method}\n",
        "      X_res, y_res, mask_res = imputations(dict_info, X_nan, y)\n",
        "      print(X_res, y_res, \"\\n\", mask_res)\n",
        "    print(\"test imputations ended successfully\")\n",
        "\n",
        "test_imputations(6, 3)\n"
      ],
      "metadata": {
        "id": "z5crxb1usyn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = np.array([1, 2])\n",
        "x.append(y)\n",
        "x.append(y)\n",
        "x.append(y)\n",
        "xx = np.stack(x)\n",
        "print(x)\n",
        "print(xx)\n",
        "print(type(xx))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sizes = [100, 1000, 10000, 100000]\n",
        "values = [0.8, 0.85, 0.9, 0.92]\n",
        "positions = range(len(sizes))\n",
        "\n",
        "plt.plot(positions, values, marker='o', label='Model Accuracy')  # Add label here\n",
        "plt.xticks(positions, sizes)\n",
        "\n",
        "plt.xlabel(\"Dataset Size (equispaced)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Performance vs Dataset Size (equispaced x-axis)\")\n",
        "#plt.legend()  # Show legend\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GU2RjW63SNaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dictio = {'a':1, 'b':2, 'c':3}\n",
        "vv = dictio.values()\n",
        "#print(vv)\n",
        "#print(vv[1])\n",
        "\n",
        "x1 = np.array([1, 2, 3])\n",
        "x2 = np.array([3, 2 ,1])\n",
        "v = np.maximum(x1, x2)\n",
        "print(v)\n"
      ],
      "metadata": {
        "id": "UE1NuR4D2h8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "648zfFp8ERD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n, d = 2, 3, 2\n",
        "x_int = np.random.randint(1, 9, (m, n, d))\n",
        "print(x_int)\n",
        "s = np.std(x_int, axis=0)\n",
        "print(s)\n",
        "\n",
        "# manual\n",
        "print(\"manual computation\")\n",
        "x = np.zeros((m, d))\n",
        "for i in range(n):\n",
        "  print(\"i -----> \", i)\n",
        "  x = x_int[:, i, :]\n",
        "  print(\"x\\n\", x)\n",
        "  ss = np.std(x, axis=0)\n",
        "  print(ss)\n",
        "\n",
        "\n",
        "print(\"little exp on squeeze\")\n",
        "sss = np.random.rand(1, 3, 3)\n",
        "print(sss)\n",
        "print(sss.squeeze())\n",
        "print(sss.squeeze())\n",
        "\n"
      ],
      "metadata": {
        "id": "vpBvPibeERnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(34.99)\n",
        "\n",
        "xxxx = np.random.randint(2, 4, (5, 2))\n",
        "print(xxxx)\n",
        "xxxx[0:2, :] = 1\n",
        "print(xxxx)\n",
        "\n",
        "print(\"yyyy\\n\")\n",
        "yy = []\n",
        "yy.append([1, 2, 3])\n",
        "yy.append([4, 5, 6])\n",
        "print(yy)\n",
        "print(np.stack( yy ).T)\n",
        "print(\"\\n\\n\")\n",
        "yyy = np.random.randint(1, 10, size=(3 , 3))\n",
        "print(yyy)\n",
        "yyy_a = np.array([yyy] * 2)\n",
        "print(yyy_a.shape)\n",
        "print(np.concatenate([yyy] * 2))\n",
        "#print(np.tile(yyy_a, (2, 1, 1) ))\n",
        "\n",
        "zzz = np.zeros((2, 2))\n",
        "\n",
        "np.sum(np.zeros((2, 2)) == zzz)"
      ],
      "metadata": {
        "id": "et578OpzERsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def multiple_imputation1(nbr_mi, X_nan):\n",
        "    n, d = X_nan.shape\n",
        "    res = np.zeros((nbr_mi, n, d))\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 1000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res[i, :, :] = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res shape\", res.shape)\n",
        "       #if nbr_mi == 1:\n",
        "        #res = res[0, :, :]\n",
        "        #print(\"fin res shape\", res.shape)\n",
        "    return res\n",
        "\n",
        "\n",
        "Xx = np.random.randint(1, 3, (4, 4)) * 1.0\n",
        "mm = np.random.binomial(1, 0.25, (4, 4))\n",
        "print(Xx)\n",
        "print(mm)\n",
        "Xx[mm == 1] = np.nan\n",
        "print(Xx)\n",
        "\n",
        "ice = IterativeImputer(random_state=18, max_iter=50, sample_posterior=True)\n",
        "ice.fit(Xx)\n",
        "XxX = np.random.randint(1, 3, (2, 4)) * 1.0\n",
        "mmM = np.random.binomial(1, 0.5, (2, 4))\n",
        "print(XxX)\n",
        "print(mmM)\n",
        "XxX[mmM == 1] = np.nan\n",
        "print(XxX)\n",
        "\n",
        "print(ice.transform(XxX))\n",
        "print(ice.transform(XxX))\n",
        "\n",
        "print(\"new\")\n",
        "\n",
        "ls = [[[]],[[]]]\n",
        "print(ls)\n",
        "ls[0][0]\n",
        "\n"
      ],
      "metadata": {
        "id": "_U_r_qaJ9pw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "XX = np.random.randint(1, 7, (2, 3, 3))\n",
        "print(XX)\n",
        "XXX = np.tile(XX, (2, 1, 1))\n",
        "print(XXX)\n",
        "\n",
        "print(np.zeros(2))\n",
        "\n",
        "y_o = np.array([1, 2])\n",
        "y_oo = np.tile(y_o, 3)\n",
        "print(y_oo)\n"
      ],
      "metadata": {
        "id": "PXfceAK8es4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def generate_masks_binomial_general(nbr_of_sample, p_missing):\n",
        "    # nbr_of_sample is the number of masks\n",
        "    # p_missing=[p00, p01, p10], where p00 is the probability of seeing both components,\n",
        "    # p10 is the probability of seeing the right component, p01 is the probability of seeing the left component\n",
        "    masks = np.zeros((nbr_of_sample, 2))\n",
        "    v = np.random.choice(a=3, size=nbr_of_sample, p=p_missing)\n",
        "    masks[v == 0, :] = np.array([0, 0])  # both seen\n",
        "    masks[v == 1, :] = np.array([0, 1])  # left seen\n",
        "    masks[v == 2, :] = np.array([1, 0])  # right seen\n",
        "    return masks\n",
        "\n",
        "\n",
        "#mm = np.random.binomial(1, [[0.2, 0.2, 0.2], [0.8, 0.8, 0.8]], (2, 3, 3))\n",
        "#print(mm)\n",
        "cc = np.array([np.random.binomial(1, x, (4, 4)) for x in [0.2, 0.2, 0.2]])\n",
        "print(cc)\n",
        "s_cc = np.cumsum(cc, axis=0)\n",
        "print(s_cc)\n",
        "s_cc[s_cc>1] = 1\n",
        "print(s_cc)\n",
        "\n",
        "s_v = np.random.randint(1, 4, (3, 4))\n",
        "print(s_v)\n",
        "s_vv = s_v[:, None, :] * np.eye(4)\n",
        "print(s_vv)"
      ],
      "metadata": {
        "id": "auugsvFPZ88A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbb15a6-0dc3-48b8-bc94-609e7c69d61d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 1 1 0]\n",
            "  [0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [0 0 1 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [0 0 0 0]\n",
            "  [0 0 1 0]]]\n",
            "[[[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 1 1 0]\n",
            "  [0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 1 1 1]\n",
            "  [0 0 1 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [0 1 1 1]\n",
            "  [0 0 2 0]]]\n",
            "[[[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 1 1 0]\n",
            "  [0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 1 1 1]\n",
            "  [0 0 1 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [0 1 1 1]\n",
            "  [0 0 1 0]]]\n",
            "[[2 3 1 2]\n",
            " [2 1 3 1]\n",
            " [1 3 2 1]]\n",
            "[[[2. 0. 0. 0.]\n",
            "  [0. 3. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 2.]]\n",
            "\n",
            " [[2. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 3. 0.]\n",
            "  [0. 0. 0. 1.]]\n",
            "\n",
            " [[1. 0. 0. 0.]\n",
            "  [0. 3. 0. 0.]\n",
            "  [0. 0. 2. 0.]\n",
            "  [0. 0. 0. 1.]]]\n"
          ]
        }
      ]
    }
  ]
}