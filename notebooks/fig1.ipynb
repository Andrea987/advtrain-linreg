{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea987/advtrain-linreg/blob/main/notebooks/fig1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ggDSA-ktpXgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2b5dd8-3bc5-490f-8bad-f55dcd1fdb03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end block\n"
          ]
        }
      ],
      "source": [
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import lasso_path\n",
        "from sklearn import datasets\n",
        "from sklearn import linear_model\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import tqdm\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_q(p):\n",
        "    if p != np.inf and p > 1:\n",
        "        q = p / (p - 1)\n",
        "    elif p == 1:\n",
        "        q = np.inf\n",
        "    else:\n",
        "        q = 1\n",
        "    return q\n",
        "\n",
        "\n",
        "class AdversarialTraining:\n",
        "    def __init__(self, X, y, S_inv, p):  # S is the matrix such that ||S @ Dx||\\leq delta. As a consequence, S_inv appears in the unconstrained problem\n",
        "        m, n = X.shape\n",
        "        q = compute_q(p)\n",
        "        # Formulate problem\n",
        "        param = cp.Variable(n)\n",
        "        param_norm = cp.pnorm(S_inv @ param, p=q)\n",
        "        adv_radius = cp.Parameter(name='adv_radius', nonneg=True)\n",
        "        abs_error = cp.abs(X @ param - y)\n",
        "        adv_loss = 1 / m * cp.sum((abs_error + adv_radius * param_norm) ** 2)\n",
        "        prob = cp.Problem(cp.Minimize(adv_loss))\n",
        "        self.prob = prob\n",
        "        self.adv_radius = adv_radius\n",
        "        self.param = param\n",
        "        self.warm_start = False\n",
        "\n",
        "    def __call__(self, adv_radius, **kwargs):\n",
        "        try:\n",
        "            self.adv_radius.value = adv_radius\n",
        "            self.prob.solve(warm_start=self.warm_start, **kwargs)\n",
        "            v = self.param.value\n",
        "        except:\n",
        "            v = np.zeros(self.param.shape)\n",
        "        return v\n",
        "\n",
        "\n",
        "def get_lasso_path(X, y, eps_lasso=1e-5):\n",
        "    alphas, coefs, _ = lasso_path(X, y, eps=eps_lasso)\n",
        "    coefs= np.concatenate([np.zeros([X.shape[1], 1]), coefs], axis=1)\n",
        "    alphas = np.concatenate([1e2 * np.ones([1]), alphas], axis=0)\n",
        "    return alphas, coefs, []\n",
        "\n",
        "\n",
        "def get_path(X, y, estimator, amax, eps=1e-5, n_alphas=200):\n",
        "    amin = eps * amax\n",
        "    alphas = np.logspace(np.log10(amin), np.log10(amax), n_alphas)\n",
        "    coefs_ = []\n",
        "    for a in tqdm.tqdm(alphas):\n",
        "        coefs = estimator(X, y, a)\n",
        "        coefs_.append(coefs if coefs is not None else np.zeros(m))\n",
        "    return alphas, np.stack((coefs_)).T\n",
        "\n",
        "\n",
        "def plot_coefs(alphas, coefs, ax):\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.semilogx(1/alphas, coef_l, c=c)\n",
        "\n",
        "\n",
        "def plot_coefs_l1norm(coefs, ax):\n",
        "    colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
        "    l1norm = np.abs(coefs).mean(axis=0)\n",
        "    for coef_l, c in zip(coefs, colors):\n",
        "        ax.plot(l1norm, coef_l, c=c)\n",
        "\n",
        "#X, y = datasets.load_diabetes(return_X_y=True)\n",
        "#print(X.shape, y.shape)\n",
        "# Standardize data\n",
        "\n",
        "\n",
        "#M = np.sum(masks, axis=1)\n",
        "#X_nan = X.copy()\n",
        "#X_nan[masks == 1] = np.nan\n",
        "\n",
        "#X = multiple_imputation(1, X_nan)\n",
        "print(\"end block\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation given mean and covariance matrix\n",
        "\n",
        "def clear_dataset(x, masks):\n",
        "  # remove observations full NaN\n",
        "  M = np.sum(1 - masks, axis=1) > 0\n",
        "  return x[M, :], masks[M, :]\n",
        "\n",
        "\n",
        "def single_imputation(X_nan, impute_estimator):\n",
        "    ice = IterativeImputer(estimator=impute_estimator)\n",
        "    return ice.fit_transform(X_nan)\n",
        "\n",
        "\n",
        "def multiple_imputation(nbr_mi, X_nan):\n",
        "    for i in range(nbr_mi):\n",
        "       n_i = np.random.randint(0, 1000)\n",
        "       ice = IterativeImputer(random_state=n_i, max_iter=50, sample_posterior=True)\n",
        "       res = ice.fit_transform(X_nan)\n",
        "       #print(\"fin res \", res)\n",
        "       return res\n",
        "\n",
        "\n",
        "def imputation_elliptic(mu, sigma, x, masks):\n",
        "  # mu, mean elliptical distribution (,d)\n",
        "  # sigma, cov matrix elliptical distribution (d, d)\n",
        "  # x: dataset (n, d)\n",
        "  # masks: mask data, 0 seen, 1 missing\n",
        "  n, d = x.shape\n",
        "  print(n, d)\n",
        "  x_imp = x.copy()\n",
        "  #print(\"x_imp clean\", x_imp)\n",
        "  for i in range(n):\n",
        "    if not (masks[i, :] == 0).all():  # if we have at least one missing component\n",
        "      print(\"nbr : \", i)\n",
        "      x_c = x[i, :]\n",
        "      m_bool = (masks[i, :] == 0)  # True seen, False missing\n",
        "      #print(m_bool)\n",
        "      sigma_aa_inv = np.linalg.inv(sigma[m_bool, :][:, m_bool])\n",
        "      sigma_ma = sigma[~m_bool, :][:, m_bool]\n",
        "      #print(\"matrices computed\")\n",
        "      #print(sigma_aa_inv)\n",
        "      #print(sigma_ma)\n",
        "      #print(\"wee\", x_c[m_bool])\n",
        "      mu_cond = mu[~m_bool] + sigma_ma @ sigma_aa_inv @ (x_c[m_bool] - mu[m_bool])\n",
        "      #print(\"mu cond \", mu_cond)\n",
        "      x_imp[i, ~m_bool] = mu_cond\n",
        "    print(\"x_orig \\n\", x)\n",
        "    print(\"x_imp \\n\", x_imp)\n",
        "    print(\"diff\\n\", x - x_imp)\n",
        "  return x_imp\n",
        "\n",
        "n = 3\n",
        "d = 4\n",
        "S = np.random.randint(low=1, high=10, size=(d, d))\n",
        "S = S.T @ S * 0 + np.eye(d)\n",
        "#print(S)\n",
        "muu = np.array([10, 20, 30, 40])\n",
        "xx = np.random.randint(low=1, high=6, size=(n, d))\n",
        "mm = np.array([[0, 0, 0, 0], [1, 1, 1, 1], [0, 0, 1, 1]])\n",
        "#print(xx)\n",
        "#print(mm)\n",
        "x, m = clear_dataset(xx, mm)\n",
        "#print(\"cleaned ds \\n\", x)\n",
        "#print(\"cleaned masks \\n\", mm)\n",
        "res = imputation_elliptic(muu, S, x, m)\n"
      ],
      "metadata": {
        "id": "qyWskXpdOW9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define observations\n",
        "\n",
        "n = 80\n",
        "d = 4\n",
        "X_orig = np.random.randn(n, d)\n",
        "#X -= X.mean(axis=0)\n",
        "#X /= X.std(axis=0)\n",
        "b = np.random.rand(d)\n",
        "y = X_orig @ b\n",
        "\n",
        "#L = np.linalg.cholesky(S)  # return L such that S = LL.T\n",
        "#L_inv = np.linalg.inv(L)\n",
        "#S_inv = L_inv.T @ L_inv\n",
        "\n",
        "masks = np.random.binomial(1, 0.2, (n, d))  # 1 missing, 0 seen\n",
        "\n",
        "X_orig, masks = clear_dataset(X_orig, masks)\n",
        "X_nan = X_orig.copy()\n",
        "X_nan[masks == 1] = np.nan\n",
        "#print(masks)\n",
        "#print(X_orig)\n",
        "#print(X_nan)\n",
        "print(\"end block\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElCvHxBiO_2t",
        "outputId": "b27634c0-0c41-463f-984d-95ddf91825f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training with original dataset X_orig\n",
        "fig, ax = plt.subplots(num='advtrain_linf')\n",
        "linfadvtrain = AdversarialTraining(X_orig, y, np.eye(X_orig.shape[1]), p=np.inf)\n",
        "estimator = lambda X, y, a:  linfadvtrain(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf  = get_path(X_orig, y, estimator, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf, ax)"
      ],
      "metadata": {
        "id": "N1uZArXkprXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training with original dataset X_orig\n",
        "fig, ax = plt.subplots(num='advtrain_linf')\n",
        "linfadvtrain = AdversarialTraining(X_orig, y, np.eye(X_orig.shape[1]) * 0.0001, p=np.inf)\n",
        "estimator = lambda X, y, a:  linfadvtrain(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf  = get_path(X_orig, y, estimator, 1e1)\n",
        "#print(\"res \", coefs_advtrain_linf.T)\n",
        "#print(\"alphas \", alphas_adv)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf, ax)"
      ],
      "metadata": {
        "id": "h52ZSD3wq6D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## random forest imputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_estimator = RandomForestRegressor(n_estimators=4, max_depth=10, bootstrap=True, max_samples=0.5, n_jobs=2, random_state=0)\n",
        "\n",
        "X_rf = single_imputation(X_nan, rf_estimator)\n",
        "sd_rf = np.std(X_rf, axis=0)\n",
        "S_inv_rf = np.diag(1 / sd_rf)\n",
        "#print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "#print(\"std rf\\n \", sd_rf)\n",
        "#print(\"S_inv std_rf \\n\", np.diag(1 / sd_rf))\n",
        "#print(\"diag matr std \\n\", np.diag(sd_rf))\n",
        "#print(X_orig)\n",
        "#print(masks)\n",
        "#print(X_rf)\n",
        "fig, ax = plt.subplots(num='advtrain_linf_rf')\n",
        "linfadvtrain_rf = AdversarialTraining(X_rf, y, S_inv_rf, p=np.inf)\n",
        "estimator_rf = lambda X, y, a:  linfadvtrain_rf(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_rf  = get_path(X_rf, y, estimator_rf, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_rf, ax)\n"
      ],
      "metadata": {
        "id": "uSgnV3aVXL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## iterative imputer Bayesian Ridge\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "br_estimator = BayesianRidge()\n",
        "\n",
        "X_rf = single_imputation(X_nan, br_estimator)\n",
        "sd_rf = np.std(X_rf, axis=0)\n",
        "S_inv_rf = np.diag(1 / sd_rf)\n",
        "print(\"std_orig: \\n\", np.std(X_orig, axis=0))\n",
        "print(\"std rf\\n \", sd_rf)\n",
        "#print(\"S_inv std_rf \\n\", np.diag(1 / sd_rf))\n",
        "#print(\"diag matr std \\n\", np.diag(sd_rf))\n",
        "#print(X_orig)\n",
        "#print(masks)\n",
        "#print(X_rf)\n",
        "fig, ax = plt.subplots(num='advtrain_linf_rf')\n",
        "linfadvtrain_br = AdversarialTraining(X_rf, y, S_inv_rf, p=np.inf)\n",
        "estimator_br = lambda X, y, a:  linfadvtrain_rf(adv_radius=a)\n",
        "alphas_adv, coefs_advtrain_linf_rf  = get_path(X_br, y, estimator_rf, 1e1)\n",
        "plot_coefs_l1norm(coefs_advtrain_linf_br, ax)\n",
        "\n"
      ],
      "metadata": {
        "id": "YVAHXnCBFJoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(num='lasso')\n",
        "alphas_lasso, coefs_lasso, _ = get_lasso_path(X, y)\n",
        "plot_coefs_l1norm(coefs_lasso, ax)"
      ],
      "metadata": {
        "id": "qOOJdRgbp-3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgNaP74gWAga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some simple tests\n",
        "r = 4\n",
        "S = np.random.randint(low=1, high=4, size=(r, r))\n",
        "S = S.T @ S + np.eye(r)\n",
        "print(S)\n",
        "m = np.array([0, 0, 0, 1])  # 1 missing, 0 seen\n",
        "m_bool = (m == 0)\n",
        "print(\"m bool \", m_bool)\n",
        "print(not m_bool.all())\n",
        "S_sub = S[m_bool, :][:, m_bool]\n",
        "print(S_sub)\n",
        "\n",
        "S_ma = S[m_bool, :][:, ~m_bool]\n",
        "print(S_ma)\n",
        "\n",
        "s = np.array([1, 2, 3, 4])\n",
        "ss = s\n",
        "print(s[m_bool])\n",
        "\n"
      ],
      "metadata": {
        "id": "6mlM-FR-OfL4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}